URL, title, date created, date updated, download link, author id, author name, taverna-version, credits id, credits name, description, number of processors, number of external services, services names, 
"http://www.myexperiment.org/workflows/4/versions/1.html","EBI InterProScan","2007-10-0318:35:46","","http://www.myexperiment.org/workflows/4/download/EBI_InterProScan-v1.xml?version=1","/users/6","Duncan Hull","taverna 1","","",,7, 2, runInterProScan, contentXML, params, Byte___to_String, WSArrayofDataXML, poll, checkStatusWorkflow, ,
"http://www.myexperiment.org/workflows/4/versions/2.html","EBI InterProScan","2007-10-0318:35:46","","http://www.myexperiment.org/workflows/4/download/EBI_InterProScan-v2.xml?version=2","/users/6","Duncan Hull","taverna 1","","","EBI InterProScan. Stop fannying around with BLAST and use InterProScan instead.",7, 2, runInterProScan, contentXML, params, Byte___to_String, WSArrayofDataXML, poll, checkStatusWorkflow, ,
"http://www.myexperiment.org/workflows/5/versions/1.html","DOI2PMID","2007-10-0318:35:47","","http://www.myexperiment.org/workflows/5/download/DOI2PMID-v1.xml?version=1","/users/6","Duncan Hull","taverna 1","","",,6, 1, run_eSearch, eSearch_input_merger, Database, rettype, DOI, eSearch_output_splitter, ,
"http://www.myexperiment.org/workflows/5/versions/2.html","DOI2PMID","2007-10-0318:35:47","","http://www.myexperiment.org/workflows/5/download/DOI2PMID-v2.xml?version=2","/users/6","Duncan Hull","taverna 1","","","Converts Digital Object Identifiers into their corresponding PubMed identifiers, if they exist.",6, 1, run_eSearch, eSearch_input_merger, Database, rettype, DOI, eSearch_output_splitter, ,
"http://www.myexperiment.org/workflows/6/versions/1.html","Genome annotation pipeline demonstrator workflow for Nucleic Acids Research","2007-10-0318:35:47","","http://www.myexperiment.org/workflows/6/download/Genome_annotation_pipeline_demonstrator_workflow_for_Nucleic_Acids_Research-v1.xml?version=1","/users/6","Duncan Hull","taverna 1","","",,8, 4, GI_number, BLASTp, SWISS, Get_Nucleotide_FASTA, BLAST, genscan, repeatmasker, genscansplitter, ,
"http://www.myexperiment.org/workflows/6/versions/2.html","Genome annotation pipeline demonstrator workflow for Nucleic Acids Research","2007-10-0318:35:47","","http://www.myexperiment.org/workflows/6/download/Genome_annotation_pipeline_demonstrator_workflow_for_Nucleic_Acids_Research-v2.xml?version=2","/users/6","Duncan Hull","taverna 1","","","Part of a workflow by Hannah Tipney, adapted by Duncan Hull using GenScan, RepeatMasker and BLAST. <a href=http://dx.doi.org/10.1093/nar/gkl320 rel=nofollow>http://dx.doi.org/10.1093/nar/gkl320</a>",8, 4, GI_number, BLASTp, SWISS, Get_Nucleotide_FASTA, BLAST, genscan, repeatmasker, genscansplitter, ,
"http://www.myexperiment.org/workflows/7/versions/1.html","Fetch Dragon images from BioMoby v2","2007-10-0318:35:48","","http://www.myexperiment.org/workflows/7/download/Fetch_Dragon_images_from_BioMoby_v2-v1.xml?version=1","/users/16","David De Roure","taverna 1","","","Use the local java plugins and some filtering operations to fetch the comic strip image from  <a href=http://www.dilbert.com>http://www.dilbert.com</a>",7, 2, id, namespace, Decode_base64_to_byte, Parse_moby_data___updated__2006, getJpegFromAnnotatedImage, getDragonSimpleAnnotatedImages, Object, ,
"http://www.myexperiment.org/workflows/7/versions/2.html","Fetch Dragon images from BioMoby v2","2007-10-0318:35:48","","http://www.myexperiment.org/workflows/7/download/Fetch_Dragon_images_from_BioMoby_v2-v2.xml?version=2","/users/16","David De Roure","taverna 1","","","demonstration to ISSGC07",7, 2, id, namespace, Decode_base64_to_byte, Parse_moby_data___updated__2006, getJpegFromAnnotatedImage, getDragonSimpleAnnotatedImages, Object, ,
"http://www.myexperiment.org/workflows/10/versions/1.html","HUMAN Microarray CEL file to candidate pathways","2007-10-0318:35:55","2009-11-2617:34:24","http://www.myexperiment.org/workflows/10/download/HUMAN_Microarray_CEL_file_to_candidate_pathways-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","","","This workflow takes in a CEL file and a normalisation method then returns a series of images/graphs which represent the same output obtained using the MADAT software package (MicroArray Data Analysis Tool) [ <a href=http://www.bioinf.manchester.ac.uk/MADAT/index.html>http://www.bioinf.manchester.ac.uk/MADAT/index.html</a> ]. Also retruned by this workflow are a list of the top differentialy expressed genes (size dependant on the number specified as input - geneNumber), which are then used to find the candidate pathways which may be influencing the observed changes in the microarray data. By identifying the candidate pathways, more detailed insights into the gene expression data can be obtained. NOTE - You will also need to install R and Rserv on your machine and install the libaries required by the R script into you R library directory (see for basic info:  <a href=http://www.cs.man.ac.uk/~fisherp/rlib.html>http://www.cs.man.ac.uk/~fisherp/rlib.html</a> ) The example inputs for this workflow are as follows: Samples1 = one or more CEL files for cross-correlating with Samples2 CEL files (new line separated including the .CEL):Liver_Day1_Mouse.CELLiver_Day2_Mouse.CEL Samples2 = one or more CEL files for cross-correlating with Samples1 CEL files (new line separated including the .CEL): Kideny_Day1_Mouse.CELKidney_Day2_Mouse.CEL geneNumber = the number of differentialy expressed gene to be returned above a given p-value, e.g. 20arrayTypeAffy = the name of the Mouse AffyMetrix array used, e.g. mouse4302, hgu133a...path = the direct path to the CEL file location, e.g. C:/Microarray_Data/CEL_FILES/ - note the forward slashesNormalizationMethod = the type of normalisation to perfrom, e.g. rma, gcrma or mmgmostestMethod = e.g. limma, mmtest or pplrp-value = the p-value cut-off value for the array data, e.g. 0.05foldChange = the fold change value for the microarray data, e.g. 1 (means greater than 1 or less than -1)",5, 0, Split_sample1, Split_sample2, String_Constant, AffyDataAnalysis, Nested_Workflow, ,
"http://www.myexperiment.org/workflows/10/versions/2.html","HUMAN Microarray CEL file to candidate pathways","2007-10-0318:35:55","2009-11-2617:34:24","http://www.myexperiment.org/workflows/10/download/HUMAN_Microarray_CEL_file_to_candidate_pathways-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","","","This workflow takes in a CEL file and a normalisation method then returns a series of images/graphs which represent the same output obtained using the MADAT software package (MicroArray Data Analysis Tool) [ <a href=http://www.bioinf.manchester.ac.uk/MADAT/index.html>http://www.bioinf.manchester.ac.uk/MADAT/index.html</a> ]. Also retruned by this workflow are a list of the top differentialy expressed genes (size dependant on the number specified as input - geneNumber), which are then used to find the candidate pathways which may be influencing the observed changes in the microarray data. By identifying the candidate pathways, more detailed insights into the gene expression data can be obtained.  NOTE - You will also need to install R and Rserv on your machine and install the libaries required by the R script into you R library directory (see for basic info:  <a href=http://www.cs.man.ac.uk/~fisherp/rlib.html>http://www.cs.man.ac.uk/~fisherp/rlib.html</a> )  The example inputs for this workflow are as follows: Samples1 = one or more CEL files for cross-correlating with Samples2 CEL files (new line separated including the .CEL):  Liver_Day1_Mouse.CEL Liver_Day2_Mouse.CEL  Samples2 = one or more CEL files for cross-correlating with Samples1 CEL files (new line separated including the .CEL): Kideny_Day1_Mouse.CEL Kidney_Day2_Mouse.CEL  geneNumber = the number of differentialy expressed gene to be returned above a given p-value, e.g. 20 arrayTypeAffy = the name of the Mouse AffyMetrix array used, e.g. mouse4302, hgu133a... path = the direct path to the CEL file location, e.g. C:/Microarray_Data/CEL_FILES/ - note the forward slashes NormalizationMethod = the type of normalisation to perfrom, e.g. rma, gcrma or mmgmos testMethod = e.g. limma, mmtest or pplr p-value = the p-value cut-off value for the array data, e.g. 0.05 foldChange = the fold change value for the microarray data, e.g. 1 (means greater than 1 or less than -1)",5, 0, Split_sample1, Split_sample2, String_Constant, AffyDataAnalysis, Nested_Workflow, ,
"http://www.myexperiment.org/workflows/10/versions/3.html","HUMAN Microarray CEL file to candidate pathways","2007-10-0318:35:55","2009-11-2617:34:24","http://www.myexperiment.org/workflows/10/download/HUMAN_Microarray_CEL_file_to_candidate_pathways-v3.xml?version=3","/users/43","Paul Fisher","taverna 1","","","This workflow takes in a CEL file and a normalisation method then returns a series of images/graphs which represent the same output obtained using the MADAT software package (MicroArray Data Analysis Tool) [ <a href=http://www.bioinf.manchester.ac.uk/MADAT/index.html>http://www.bioinf.manchester.ac.uk/MADAT/index.html</a> ]. Also retruned by this workflow are a list of the top differentialy expressed genes (size dependant on the number specified as input - geneNumber), which are then used to find the candidate pathways which may be influencing the observed changes in the microarray data. By identifying the candidate pathways, more detailed insights into the gene expression data can be obtained.  NOTE - You will also need to install R and Rserv on your machine and install the libaries required by the R script into you R library directory (see for basic info: http:// www. cs. man. ac. uk/ ~fisherp/ rlib.html) &nbsp; The example inputs for this workflow are as follows: Samples1 = one or more CEL files for cross-correlating with Samples2 CEL files (new line separated including the .CEL):  Liver_Day1_Mouse.CEL Liver_Day2_Mouse.CEL  Samples2 = one or more CEL files for cross-correlating with Samples1 CEL files (new line separated including the .CEL): Kideny_Day1_Mouse.CEL Kidney_Day2_Mouse.CEL  geneNumber = the number of differentialy expressed gene to be returned above a given p-value, e.g. 20 arrayTypeAffy = the name of the Mouse AffyMetrix array used, e.g. mouse4302, hgu133a... path = the direct path to the CEL file location, e.g. C:/Microarray_Data/CEL_FILES/ - note the forward slashes NormalizationMethod = the type of normalisation to perfrom, e.g. rma, gcrma or mmgmos testMethod = e.g. limma, mmtest or pplr p-value = the p-value cut-off value for the array data, e.g. 0.05 foldChange = the fold change value for the microarray data, e.g. 1 (means greater than 1 or less than -1)",5, 0, Split_sample1, Split_sample2, AffyDataAnalysis, String_Constant, Nested_Workflow, ,
"http://www.myexperiment.org/workflows/10/versions/4.html","HUMAN Microarray CEL file to candidate pathways","2007-10-0318:35:55","2009-11-2617:34:24","http://www.myexperiment.org/workflows/10/download/HUMAN_Microarray_CEL_file_to_candidate_pathways-v4.xml?version=4","/users/43","Paul Fisher","taverna 1","","","This workflow takes in a CEL file and a normalisation method then returns a series of images/graphs which represent the same output obtained using the MADAT software package (MicroArray Data Analysis Tool) [ <a href=http://www.bioinf.manchester.ac.uk/MADAT/index.html rel=nofollow>http://www.bioinf.manchester.ac.uk/MADAT/index.html</a> ]. Also returned by this workflow are a list of the top differentialy expressed genes (size dependant on the number specified as input - geneNumber), which are then used to find the candidate pathways which may be influencing the observed changes in the microarray data. By identifying the candidate pathways, more detailed insights into the gene expression data can be obtained.  NOTE - You will also need to install R and Rserv on your machine and install the libaries required by the R script into you R library directory (see for basic info:  <a href=http://www.cs.man.ac.uk/~fisherp/rlib.html rel=nofollow>http://www.cs.man.ac.uk/~fisherp/rlib.html</a> )  The example inputs for this workflow are as follows: Samples1 = one or more CEL files for cross-correlating with Samples2 CEL files (new line separated including the .CEL):  Liver_Day1_Mouse.CEL Liver_Day2_Mouse.CEL  Samples2 = one or more CEL files for cross-correlating with Samples1 CEL files (new line separated including the .CEL): Kideny_Day1_Mouse.CEL Kidney_Day2_Mouse.CEL  geneNumber = the number of differentialy expressed gene to be returned above a given p-value, e.g. 20 arrayTypeAffy = the name of the Mouse AffyMetrix array used, e.g. mouse4302, hgu133a... path = the direct path to the CEL file location, e.g. C:/Microarray_Data/CEL_FILES/ - note the forward slashes NormalizationMethod = the type of normalisation to perfrom, e.g. rma, gcrma or mmgmos testMethod = e.g. limma, mmtest or pplr p-value = the p-value cut-off value for the array data, e.g. 0.05 foldChange = the fold change value for the microarray data, e.g. 1 (means greater than 1 or less than -1)",5, 0, String_Constant, Split_sample2, AffyDataAnalysis, Split_sample1, Probeset_to_Pathway, ,
"http://www.myexperiment.org/workflows/12/versions/1.html","Transcribe a DNA sequence into an RNA sequence","2007-10-0318:35:58","2007-11-1316:16:54","http://www.myexperiment.org/workflows/12/download/Transcribe_a_DNA_sequence_into_an_RNA_sequence-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","","","This workflow transcribes a DNA sequence into an RNA sequence",1, 0, Transcribe_DNA, ,
"http://www.myexperiment.org/workflows/12/versions/2.html","Transcribe a DNA sequence into an RNA sequence","2007-10-0318:35:58","2007-11-1316:16:54","http://www.myexperiment.org/workflows/12/download/Transcribe_a_DNA_sequence_into_an_RNA_sequence-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","","","This workflow transcribes a DNA sequence into an RNA sequence",1, 0, Transcribe_DNA, ,
"http://www.myexperiment.org/workflows/13/versions/1.html","KEGG pathways common to both QTL and microarray based investigations","2009-11-2417:14:43","2009-12-0315:28:49","http://www.myexperiment.org/workflows/13/download/KEGG_pathways_common_to_both_QTL_and_microarray_based_investigations-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","","","This workflow takes in two lists of KEGG pathway ids. These are designed to come from pathways found from genes in a QTL (Quantitative Trait Loci) region, and from pathways found from genes differentially expressed in a microarray study. By identifying the intersecting pathways from both studies, a more informative picture is obtained of the candidate processes involved in the expression of a phenotype",2, 2, kegg_pathways, common_pathways, ,
"http://www.myexperiment.org/workflows/13/versions/2.html","KEGG pathways common to both QTL and microarray based investigations","2009-11-2417:14:43","2009-12-0315:28:49","http://www.myexperiment.org/workflows/13/download/KEGG_pathways_common_to_both_QTL_and_microarray_based_investigations-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","","","This workflow takes in two lists of KEGG pathway ids. These are designed to come from pathways found from genes in a QTL (Quantitative Trait Loci) region, and from pathways found from genes differentially expressed in a microarray study. By identifying the intersecting pathways from both studies, a more informative picture is obtained of the candidate processes involved in the expression of a phenotype",2, 2, kegg_pathways, common_pathways, ,
"http://www.myexperiment.org/workflows/13/versions/3.html","KEGG pathways common to both QTL and microarray based investigations","2009-11-2417:14:43","2009-12-0315:28:49","http://www.myexperiment.org/workflows/13/download/KEGG_pathways_common_to_both_QTL_and_microarray_based_investigations-v3.xml?version=3","/users/43","Paul Fisher","taverna 1","","","This workflow takes in two lists of KEGG pathway ids. These are designed to come from pathways found from genes in a QTL (Quantitative Trait Loci) region, and from pathways found from genes differentially expressed in a microarray study. By identifying the intersecting pathways from both studies, a more informative picture is obtained of the candidate processes involved in the expression of a phenotype. &nbsp; Example input for this workflow is given below (as newline separated values). qtl_pathways: path:mmu04060 <br /> path:mmu04370 <br /> path:mmu04510 <br /> path:mmu04060 <br /> path:mmu04670 <br /> path:mmu00040 <br /> path:mmu00150 <br /> path:mmu00500 <br /> path:mmu00860 &nbsp; microarray_pathways: path:mmu04060 <br /> path:mmu04370 <br /> path:mmu00040 <br /> path:mmu00150 <br /> path:mmu00500 <br /> path:mmu00860",6, 2, kegg_pathways, common_pathways, regex, split_pathway_ids, merge_pathway_desc, remove_null_values, ,
"http://www.myexperiment.org/workflows/14/versions/1.html","Cow-Human Ortholog Pathways and Gene annotations for QTL Phenotype","2007-10-0318:36:00","2009-12-0316:16:31","http://www.myexperiment.org/workflows/14/download/Cow-Human_Ortholog_Pathways_and_Gene_annotations_for_QTL_Phenotype-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","","",,38, 5, regex_2, kegg_pathway_release, species, add_ncbi_to_string, remove_pathway_nulls, split_gene_ids, REMOVE_NULLS_2, remove_pathway_nulls_2, remove_desc_gaps, add_uniprot_to_string, remove_Nulls, split_for_duplicates, merge_pathway_desc, merge_gene_desc, merge_uniprot_ids, merge_pathway_list_1, remove_duplicate_kegg_genes, concat_kegg_genes, merge_entrez_genes, merge_genes_pathways_3, remove_uniprot_duplicates, merge_reports, merge_genes_pathways_2, merge_kegg_references, remove_entrez_duplicates, merge_pathway_list_2, merge_genes_pathways, binfo, gene_descriptions, Kegg_gene_ids_2, Kegg_gene_ids, btaurus_gene_ensembl, compara_btau_hsap_orthologs, hsapiens_gene_ensembl, create_report, GetPathways, getcurrentdatabase, remove_nulls_3, ,
"http://www.myexperiment.org/workflows/14/versions/2.html","Cow-Human Ortholog Pathways and Gene annotations for QTL Phenotype","2007-10-0318:36:00","2009-12-0316:16:31","http://www.myexperiment.org/workflows/14/download/Cow-Human_Ortholog_Pathways_and_Gene_annotations_for_QTL_Phenotype-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","","","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in the cow, Bos taurus. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. As the Cow genome is currently unfinished, the workflow subsequently maps the cow ensembl gene ids to human orthologues. Entrez and UniProt identifiers are then identified and sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database. Example input: chromosome_name: 17 start_position: 58127155 end_position: 68127155",38, 5, regex_2, kegg_pathway_release, species, add_ncbi_to_string, remove_pathway_nulls, split_gene_ids, REMOVE_NULLS_2, remove_pathway_nulls_2, remove_desc_gaps, add_uniprot_to_string, remove_Nulls, split_for_duplicates, merge_pathway_desc, merge_gene_desc, merge_uniprot_ids, merge_pathway_list_1, remove_duplicate_kegg_genes, concat_kegg_genes, merge_entrez_genes, merge_genes_pathways_3, remove_uniprot_duplicates, merge_reports, merge_genes_pathways_2, merge_kegg_references, remove_entrez_duplicates, merge_pathway_list_2, merge_genes_pathways, binfo, gene_descriptions, Kegg_gene_ids_2, Kegg_gene_ids, btaurus_gene_ensembl, compara_btau_hsap_orthologs, hsapiens_gene_ensembl, create_report, GetPathways, getcurrentdatabase, remove_nulls_3, ,
"http://www.myexperiment.org/workflows/15/versions/1.html","Entrez Gene to KEGG Pathway","2009-12-0416:04:38","2010-11-3012:18:53","http://www.myexperiment.org/workflows/15/download/Entrez_Gene_to_KEGG_Pathway-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow takes in Entrez gene ids then adds the string ncbi-geneid: to the start of each gene id. These gene ids are then cross-referenced to KEGG gene ids. Each KEGG gene id is then sent to the KEGG pathway database and its relevant pathways returned.",7, 3, merge_pathways, mergePathways_2, split_gene_ids, lister, get_pathways_by_genes, Kegg_gene_ids_all_species, Add_ncbi_to_string, ,
"http://www.myexperiment.org/workflows/15/versions/2.html","Entrez Gene to KEGG Pathway","2009-12-0416:04:38","2010-11-3012:18:53","http://www.myexperiment.org/workflows/15/download/Entrez_Gene_to_KEGG_Pathway-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow takes in Entrez gene ids then adds the string ncbi-geneid: to the start of each gene id. These gene ids are then cross-referenced to KEGG gene ids. Each KEGG gene id is then sent to the KEGG pathway database and its relevant pathways returned.",7, 3, merge_pathways, mergePathways_2, split_gene_ids, lister, get_pathways_by_genes, Kegg_gene_ids_all_species, Add_ncbi_to_string, ,
"http://www.myexperiment.org/workflows/15/versions/3.html","Entrez Gene to KEGG Pathway","2009-12-0416:04:38","2010-11-3012:18:53","http://www.myexperiment.org/workflows/15/download/Entrez_Gene_to_KEGG_Pathway-v3.xml?version=3","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow takes in Entrez gene ids then adds the string ncbi-geneid: to the start of each gene id. These gene ids are then cross-referenced to KEGG gene ids. Each KEGG gene id is then sent to the KEGG pathway database and its relevant pathways returned.",7, 3, mergePathways_2, merge_pathways, split_gene_ids, Add_ncbi_to_string, lister, Kegg_gene_ids_all_species, get_pathways_by_genes, ,
"http://www.myexperiment.org/workflows/15/versions/4.html","Entrez Gene to KEGG Pathway","2009-12-0416:04:38","2010-11-3012:18:53","http://www.myexperiment.org/workflows/15/download/Entrez_Gene_to_KEGG_Pathway-v4.xml?version=4","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow takes in Entrez gene ids then adds the string ncbi-geneid: to the start of each gene id. These gene ids are then cross-referenced to KEGG gene ids. Each KEGG gene id is then sent to the KEGG pathway database and its relevant pathways returned.",7, 3, split_gene_ids, mergePathways_2, Add_ncbi_to_string, merge_pathways, get_pathways_by_genes, lister, Kegg_gene_ids_all_species, ,
"http://www.myexperiment.org/workflows/15/versions/5.html","Entrez Gene to KEGG Pathway","2009-12-0416:04:38","2010-11-3012:18:53","http://www.myexperiment.org/workflows/15/download/Entrez_Gene_to_KEGG_Pathway-v5.xml?version=5","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow takes in Entrez gene ids then adds the string ncbi-geneid: to the start of each gene id. These gene ids are then cross-referenced to KEGG gene ids. Each KEGG gene id is then sent to the KEGG pathway database and its relevant pathways returned.",7, 3, mergePathways_2, merge_pathways, split_gene_ids, Add_ncbi_to_string, get_pathways_by_genes, lister, Kegg_gene_ids_all_species, ,
"http://www.myexperiment.org/workflows/16/versions/1.html","Pathways and Gene annotations for QTL region","2009-11-1918:18:52","2012-09-0718:23:36","http://www.myexperiment.org/workflows/16/download/Pathways_and_Gene_annotations_for_QTL_region-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in the mouse, Mus musculus. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",36, 5, kegg_pathway_release, regex_2, species, merge_entrez_genes, merge_reports, split_for_duplicates, remove_duplicate_kegg_genes, remove_entrez_duplicates, merge_genes_and_pathways, merge_genes_and_pathways_2, merge_pathway_list_1, merge_kegg_references, concat_kegg_genes, remove_Nulls, merge_gene_desc, add_ncbi_to_string, merge_pathway_list_2, remove_uniprot_duplicates, merge_pathway_desc, merge_uniprot_ids, REMOVE_NULLS_2, merge_genes_and_pathways_3, remove_nulls_3, add_uniprot_to_string, create_report, remove_pathway_nulls, remove_pathway_nulls_2, split_gene_ids, mmusculus_gene_ensembl, Kegg_gene_ids_2, Kegg_gene_ids, binfo, gene_descriptions, genes_in_qtl, Get_pathways, getcurrentdatabase, ,
"http://www.myexperiment.org/workflows/16/versions/2.html","Pathways and Gene annotations for QTL region","2009-11-1918:18:52","2012-09-0718:23:36","http://www.myexperiment.org/workflows/16/download/Pathways_and_Gene_annotations_for_QTL_region-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in the mouse, Mus musculus. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",36, 5, kegg_pathway_release, regex_2, species, merge_entrez_genes, merge_reports, split_for_duplicates, remove_duplicate_kegg_genes, remove_entrez_duplicates, merge_genes_and_pathways, merge_genes_and_pathways_2, merge_pathway_list_1, merge_kegg_references, concat_kegg_genes, remove_Nulls, merge_gene_desc, add_ncbi_to_string, merge_pathway_list_2, remove_uniprot_duplicates, merge_pathway_desc, merge_uniprot_ids, REMOVE_NULLS_2, merge_genes_and_pathways_3, remove_nulls_3, add_uniprot_to_string, create_report, remove_pathway_nulls, remove_pathway_nulls_2, split_gene_ids, mmusculus_gene_ensembl, Kegg_gene_ids_2, Kegg_gene_ids, binfo, gene_descriptions, genes_in_qtl, Get_pathways, getcurrentdatabase, ,
"http://www.myexperiment.org/workflows/16/versions/3.html","Pathways and Gene annotations for QTL region","2009-11-1918:18:52","2012-09-0718:23:36","http://www.myexperiment.org/workflows/16/download/Pathways_and_Gene_annotations_for_QTL_region-v3.xml?version=3","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in the mouse, Mus musculus. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to search for pathways in the KEGG pathway database. This workflow can analyse any mouse chromosome region, or QTL.",37, 5, kegg_pathway_release, merge_kegg_references, merge_pathway_list_1, merge_pathway_desc, merge_entrez_genes, merge_genes_and_pathways, merge_uniprot_ids, merge_genes_and_pathways_2, remove_duplicate_kegg_genes, merge_reports, merge_genes_and_pathways_3, regex_2, species, concat_kegg_genes, remove_uniprot_duplicates, split_for_duplicates, remove_entrez_duplicates, merge_pathway_list_2, merge_gene_desc, genes_in_qtl, mmusculus_gene_ensembl, remove_pathway_nulls, REMOVE_NULLS_2, add_uniprot_to_string, remove_pathway_nulls_2, remove_nulls_3, add_ncbi_to_string, remove_Nulls, split_gene_ids, create_report, getcurrentdatabase, gene_descriptions, Kegg_gene_ids, binfo, Kegg_gene_ids_2, Get_pathways, remove_pathway_duplicates, ,
"http://www.myexperiment.org/workflows/16/versions/4.html","Pathways and Gene annotations for QTL region","2009-11-1918:18:52","2012-09-0718:23:36","http://www.myexperiment.org/workflows/16/download/Pathways_and_Gene_annotations_for_QTL_region-v4.xml?version=4","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in the mouse, Mus musculus. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",39, 7, regex_2, species, merge_gene_desc, remove_pathway_duplicates, remove_uniprot_duplicates, merge_entrez_genes, concat_kegg_genes, merge_genes_and_pathways_2, kegg_pathway_release, merge_genes_and_pathways, merge_pathway_list_1, remove_duplicate_kegg_genes, merge_kegg_references, merge_pathway_list_2, remove_entrez_duplicates, merge_uniprot_ids, merge_pathway_desc, split_for_duplicates, merge_genes_and_pathways_3, merge_reports, remove_Nulls, remove_nulls_3, REMOVE_NULLS_2, split_gene_ids, add_ncbi_to_string, add_uniprot_to_string, remove_pathway_nulls_2, remove_pathway_nulls, genes_in_qtl, mmusculus_gene_ensembl, create_report, gene_descriptions, Kegg_gene_ids_2, binfo, Kegg_gene_ids, get_pathway_descriptions, Get_pathways, getcurrentdatabase, flatten_pathway_files, ,
"http://www.myexperiment.org/workflows/16/versions/5.html","Pathways and Gene annotations for QTL region","2009-11-1918:18:52","2012-09-0718:23:36","http://www.myexperiment.org/workflows/16/download/Pathways_and_Gene_annotations_for_QTL_region-v5.xml?version=5","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in the mouse, Mus musculus. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database. Example input: chromosome_name: 17 start_position: 28500000 end_position: 32500000",42, 7, remove_uniprot_duplicates, species, kegg_pathway_release, regex_2, split_for_duplicates, merge_genes_and_pathways_3, merge_genes_and_pathways, merge_kegg_references, remove_pathway_duplicates, merge_pathway_list_1, remove_duplicate_ids, split_for_duplicate_pathways, merge_reports, merge_gene_desc, remove_duplicate_kegg_genes, merge_uniprot_ids, remove_entrez_duplicates, merge_pathway_list_2, merge_pathway_desc, merge_entrez_genes, merge_genes_and_pathways_2, concat_kegg_genes, merge_patwhay_ids, REMOVE_NULLS_2, remove_nulls_3, remove_pathway_nulls, add_ncbi_to_string, remove_Nulls, remove_pathway_nulls_2, add_uniprot_to_string, genes_in_qtl, split_gene_ids, mmusculus_gene_ensembl, create_report, getcurrentdatabase, flatten_pathway_files, Kegg_gene_ids_2, binfo, gene_descriptions, pathway_descriptions, Kegg_gene_ids, Get_pathways, ,
"http://www.myexperiment.org/workflows/16/versions/6.html","Pathways and Gene annotations for QTL region","2009-11-1918:18:52","2012-09-0718:23:36","http://www.myexperiment.org/workflows/16/download/Pathways_and_Gene_annotations_for_QTL_region-v6.t2flow?version=6","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in the mouse, Mus musculus. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.  Example input:  chromosome_name: 17  start_position: 28500000  end_position: 32500000",0, 0, ,
"http://www.myexperiment.org/workflows/16/versions/7.html","Pathways and Gene annotations for QTL region","2009-11-1918:18:52","2012-09-0718:23:36","http://www.myexperiment.org/workflows/16/download/Pathways_and_Gene_annotations_for_QTL_region-v7.t2flow?version=7","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in the mouse, Mus musculus. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",0, 0, ,
"http://www.myexperiment.org/workflows/17/versions/1.html","Remove duplicate strings","2007-10-0318:36:03","2007-11-1316:25:42","http://www.myexperiment.org/workflows/17/download/Remove_duplicate_strings-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","","","This workflow takes in two list of strings and then concatenates them together. Any duplicates that are present are then removed, and the resulting file is returned back to the user.",2, 0, Remove_duplicate_strings, Concatenate_two_strings, ,
"http://www.myexperiment.org/workflows/17/versions/2.html","Remove duplicate strings","2007-10-0318:36:03","2007-11-1316:25:42","http://www.myexperiment.org/workflows/17/download/Remove_duplicate_strings-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","","","This workflow takes in two list of strings and then concatenates them together. Any duplicates that are present are then removed, and the resulting file is returned back to the user.",2, 0, Remove_duplicate_strings, Concatenate_two_strings, ,
"http://www.myexperiment.org/workflows/18/versions/1.html","Back translate a protein sequence into a dna sequence","2007-10-0318:36:03","2009-12-0316:18:43","http://www.myexperiment.org/workflows/18/download/Back_translate_a_protein_sequence_into_a_dna_sequence-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","","","This workflow back translates a protein sequence into a DNA sequence.",1, 1, backtranseq, ,
"http://www.myexperiment.org/workflows/18/versions/2.html","Back translate a protein sequence into a dna sequence","2007-10-0318:36:03","2009-12-0316:18:43","http://www.myexperiment.org/workflows/18/download/Back_translate_a_protein_sequence_into_a_dna_sequence-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","","","This workflow back translates a protein sequence into a DNA sequence. Example input for this workflow is:",1, 1, backtranseq, ,
"http://www.myexperiment.org/workflows/19/versions/1.html","Mouse Microarray Analysis","2007-10-0318:36:05","2009-12-0316:20:33","http://www.myexperiment.org/workflows/19/download/Mouse_Microarray_Analysis-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","","","This workflow takes in probesets from and AffyMetrix micorarray experiment and returns: the genes in the QTL; gene start and end positions; chromosome where genes reside; ensembl trasncripts; SwissProt ids; affy probeset identifiers for chips Mouse430_2 and Mouse430a_2.",35, 5, concat_kegg_genes, split_probesets, split_for_duplicates, merge_pathway_ids_2, merge_gene_desc, merge_genes_and_pathways, regex_2, merge_entrez_genes, merge_genes_pathways_3, remove_duplicate_kegg_genes, species, remove_pathway_duplicates, kegg_pathway_release, remove_uniprot_duplicates, remove_entrez_duplicates, merge_pathway_desc, merge_genes_pathways_2, merge_pathway_ids_1, merge_reports, merge_uniprot_ids, add_ncbi_to_string, REMOVE_NULLS_2, add_uniprot_to_string, remove_description_nulls, Kegg_gene_ids_2, remove_pathway_nulls, split_gene_ids, gene_descriptions, remove_Nulls, create_report, mmusculus_gene_ensembl, Kegg_gene_ids, binfo, Get_Pathways, getcurrentdatabase, ,
"http://www.myexperiment.org/workflows/19/versions/2.html","Mouse Microarray Analysis","2007-10-0318:36:05","2009-12-0316:20:33","http://www.myexperiment.org/workflows/19/download/Mouse_Microarray_Analysis-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","","","This workflow takes in probesets from and AffyMetrix micorarray experiment and returns: the genes in the QTL; gene start and end positions; chromosome where genes reside; ensembl trasncripts; SwissProt ids; affy probeset identifiers for chips Mouse430_2 and Mouse430a_2.",35, 5, concat_kegg_genes, split_probesets, split_for_duplicates, merge_pathway_ids_2, merge_gene_desc, merge_genes_and_pathways, regex_2, merge_entrez_genes, merge_genes_pathways_3, remove_duplicate_kegg_genes, species, remove_pathway_duplicates, kegg_pathway_release, remove_uniprot_duplicates, remove_entrez_duplicates, merge_pathway_desc, merge_genes_pathways_2, merge_pathway_ids_1, merge_reports, merge_uniprot_ids, add_ncbi_to_string, REMOVE_NULLS_2, add_uniprot_to_string, remove_description_nulls, Kegg_gene_ids_2, remove_pathway_nulls, split_gene_ids, gene_descriptions, remove_Nulls, create_report, mmusculus_gene_ensembl, Kegg_gene_ids, binfo, Get_Pathways, getcurrentdatabase, ,
"http://www.myexperiment.org/workflows/19/versions/3.html","Mouse Microarray Analysis","2007-10-0318:36:05","2009-12-0316:20:33","http://www.myexperiment.org/workflows/19/download/Mouse_Microarray_Analysis-v3.xml?version=3","/users/43","Paul Fisher","taverna 1","","","This workflow takes in probesets from and AffyMetrix micorarray experiment and returns: the genes ; gene start and end positions; chromosome where genes reside; ensembl trasncripts; SwissProt ids; affy probeset identifiers for chips Mouse430_2 and Mouse430a_2. Example ids from the  Mouse430_2 affymetrix array are as follows (newline separated): 1447227_at <br /> 1440624_at <br /> 1436240_at <br /> 1454904_at <br /> 1435665_at <br /> 1418148_at <br /> 1429831_at",36, 5, species, remove_duplicate_kegg_genes, merge_pathway_desc, merge_gene_desc, concat_kegg_genes, split_probesets, remove_duplicate_desc, merge_genes_and_pathways, merge_pathway_ids_1, merge_genes_pathways_2, remove_uniprot_duplicates, kegg_pathway_release, split_for_duplicates, regex_2, merge_uniprot_ids, merge_entrez_genes, merge_reports, remove_pathway_duplicates, merge_pathway_ids_2, remove_entrez_duplicates, merge_genes_pathways_3, add_uniprot_to_string, remove_description_nulls, REMOVE_NULLS_2, remove_Nulls, split_gene_ids, remove_pathway_nulls, add_ncbi_to_string, create_report, getcurrentdatabase, Kegg_gene_ids_2, Kegg_gene_ids, gene_descriptions, binfo, Get_Pathways, mmusculus_gene_ensembl, ,
"http://www.myexperiment.org/workflows/20/versions/1.html","Remove null values","2007-10-0318:36:05","2007-11-1316:20:42","http://www.myexperiment.org/workflows/20/download/Remove_null_values-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","","","This workflow removes any null values from a list of strings",1, 0, remove_Nulls, ,
"http://www.myexperiment.org/workflows/20/versions/2.html","Remove null values","2007-10-0318:36:05","2007-11-1316:20:42","http://www.myexperiment.org/workflows/20/download/Remove_null_values-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","","","This workflow removes any null values from a list of strings",1, 0, remove_Nulls, ,
"http://www.myexperiment.org/workflows/21/versions/1.html","BLASTP with simplified results returned","2007-10-0318:36:06","2009-12-0316:28:50","http://www.myexperiment.org/workflows/21/download/BLASTP_with_simplified_results_returned-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","","","Perform a blastp search on protein sequence and extract information based on the user input, e.g. a list of GI numbers. N.B. this workflow does not function correctly as it is designed for use with NCBI blast scripts. Some errors may occur. Please use two blast text file inputs for a secure result output.",4, 2, species_filter, chromosome_filter, blast_ddbj, blastfilecomparer, ,
"http://www.myexperiment.org/workflows/21/versions/2.html","BLASTP with simplified results returned","2007-10-0318:36:06","2009-12-0316:28:50","http://www.myexperiment.org/workflows/21/download/BLASTP_with_simplified_results_returned-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","","","Perform a blastp search on protein sequence and extract information based on the user input, e.g. a list of GI numbers.  N.B. this workflow does not function correctly as it is designed for use with NCBI blast scripts. Some errors may occur. Please use two blast text file inputs for a secure result output. &nbsp; Example input for this service are given below. query: &gt;MySequence  <br /> &nbsp; program: blastp &nbsp; database: DDBJ",4, 2, species_filter, chromosome_filter, blast_ddbj, blastfilecomparer, ,
"http://www.myexperiment.org/workflows/22/versions/1.html","Simplify a BLAST text file","2007-10-0318:36:06","2009-07-2813:01:45","http://www.myexperiment.org/workflows/22/download/Simplify_a_BLAST_text_file-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","","","This workflow simplifies a BLAST text file into identifiers, descriptions and values (P, E-values). In order to extract the relevant ids etc. you need to pass the relevant string into the corresponding port, e.g. the default port being used is gi. This has been passed gi. For any other ports simply pass in the string the SAME as the port name, e.g. seq_id, p, per etc.",2, 1, gi_option, blastsimplifier, ,
"http://www.myexperiment.org/workflows/22/versions/2.html","Simplify a BLAST text file","2007-10-0318:36:06","2009-07-2813:01:45","http://www.myexperiment.org/workflows/22/download/Simplify_a_BLAST_text_file-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","","","This workflow simplifies a BLAST text file into identifiers, descriptions and values (P, E-values). In order to extract the relevant ids etc. you need to pass the relevant string into the corresponding port, e.g. the default port being used is gi. This has been passed gi. For any other ports simply pass in the string the SAME as the port name, e.g. seq_id, p, per etc.",2, 1, gi_option, blastsimplifier, ,
"http://www.myexperiment.org/workflows/23/versions/1.html","BLAST using DDBJ service","2007-10-0318:36:06","2009-12-0316:31:20","http://www.myexperiment.org/workflows/23/download/BLAST_using_DDBJ_service-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","","","Perform a sequence similarity search using the BLAsT algorithm through the DDBJ web service",1, 1, blast_ddbj, ,
"http://www.myexperiment.org/workflows/23/versions/2.html","BLAST using DDBJ service","2007-10-0318:36:06","2009-12-0316:31:20","http://www.myexperiment.org/workflows/23/download/BLAST_using_DDBJ_service-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","","","Perform a sequence similarity search using the BLAST algorithm through the DDBJ web service. &nbsp; Example input for this service are given below. query: &gt;MySequence  <br /> &nbsp; program: blastp",1, 1, blast_ddbj, ,
"http://www.myexperiment.org/workflows/25/versions/1.html","Perform a search through NCBI eUtils eSearch","2009-11-2714:44:11","2009-12-0316:32:26","http://www.myexperiment.org/workflows/25/download/Perform_a_search_through_NCBI_eUtils_eSearch-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","","","This workflow takes in a search term and a database (e.g. snp, gene, protein) in which to perfom the search over. The result is an xml file containing summary information about the search term",2, 1, parametersXML, NCBI_eSearch, ,
"http://www.myexperiment.org/workflows/25/versions/2.html","Perform a search through NCBI eUtils eSearch","2009-11-2714:44:11","2009-12-0316:32:26","http://www.myexperiment.org/workflows/25/download/Perform_a_search_through_NCBI_eUtils_eSearch-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","","","This workflow takes in a search term and a database (e.g. snp, gene, protein) in which to perfom the search over. The result is an xml file containing summary information about the search term",2, 1, parametersXML, NCBI_eSearch, ,
"http://www.myexperiment.org/workflows/25/versions/3.html","Perform a search through NCBI eUtils eSearch","2009-11-2714:44:11","2009-12-0316:32:26","http://www.myexperiment.org/workflows/25/download/Perform_a_search_through_NCBI_eUtils_eSearch-v3.xml?version=3","/users/43","Paul Fisher","taverna 1","","","This workflow takes in a search term and a database (e.g. snp, gene, protein) in which to perfom the search over. The result is an xml file containing summary information about the search term. Example input for this workflow are given below: database: pubmed terms: cancer AND diabetes",3, 1, parametersXML, NCBI_eSearch, parametersXML1, ,
"http://www.myexperiment.org/workflows/26/versions/1.html","Parse UniProt text file","2007-10-0318:36:08","2009-12-0316:36:54","http://www.myexperiment.org/workflows/26/download/Parse_UniProt_text_file-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","","","This workflow performs a search through the SRS linking system to find the text files for a particular UniProt identifier. This UniProt text file is then parsed to extract a small list to summarise the file, primarily consisting of external identifiers.",3, 2, fieldName, parse_uniprot, Uniprot_search, ,
"http://www.myexperiment.org/workflows/26/versions/2.html","Parse UniProt text file","2007-10-0318:36:08","2009-12-0316:36:54","http://www.myexperiment.org/workflows/26/download/Parse_UniProt_text_file-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","","","This workflow performs a search through the SRS linking system to find the text files for a particular UniProt identifier. This UniProt text file is then parsed to extract a small list to summarise the file, primarily consisting of external identifiers. Example input for this workflow is: O35613",3, 2, fieldName, parse_uniprot, Uniprot_search, ,
"http://www.myexperiment.org/workflows/28/versions/1.html","Gene annotation pipeline for the Graves disease scenario","2007-10-0318:36:09","2007-11-2216:03:15","http://www.myexperiment.org/workflows/28/download/Gene_annotation_pipeline_for_the_Graves_disease_scenario-v1.xml?version=1","/users/13","Katy Wolstencroft","taverna 1","/users/13, /users/221,","Katy Wolstencroft, Peter Li,","This is a revised workflow for the Graves disease scenario gene annotation pipeline used in the myGrid project. The  workflow had to be re-written due to the loss of the services invoked in the original workflow.",26, 18, ProbeSetId, removePrefix, cleanGoIds, cleanInterproIds, splitString, createVizSession, destroyVizSession, getInterProIds, getEmblId, getSwissProtId, getMolFuncGoIds, getDotFromViz, addTermToViz, getEC, cleanEcNumbers, getPathwaysByECNumbers, getMedlineIds, getPathwayDiagrams, mark_pathway_by_objects, DDBJ_Blastn, getTargetSequence, ebi_uniprot, ebi_medline2007, ebi_embl, calcMeltTemp, UniprotAndPdb, ,
"http://www.myexperiment.org/workflows/28/versions/2.html","Gene annotation pipeline for the Graves disease scenario","2007-10-0318:36:09","2007-11-2216:03:15","http://www.myexperiment.org/workflows/28/download/Gene_annotation_pipeline_for_the_Graves_disease_scenario-v2.xml?version=2","/users/13","Katy Wolstencroft","taverna 1","/users/13, /users/221,","Katy Wolstencroft, Peter Li,","This is a revised workflow for the Graves disease scenario gene annotation pipeline used in the myGrid project. The  workflow had to be re-written due to the loss of the services invoked in the original workflow.",26, 18, ProbeSetId, removePrefix, cleanGoIds, cleanInterproIds, splitString, createVizSession, destroyVizSession, getInterProIds, getEmblId, getSwissProtId, getMolFuncGoIds, getDotFromViz, addTermToViz, getEC, cleanEcNumbers, getPathwaysByECNumbers, getMedlineIds, getPathwayDiagrams, mark_pathway_by_objects, DDBJ_Blastn, getTargetSequence, ebi_uniprot, ebi_medline2007, ebi_embl, calcMeltTemp, UniprotAndPdb, ,
"http://www.myexperiment.org/workflows/30/versions/1.html","ProteinSynonymsToQuery","2007-10-0318:36:10","2007-11-1323:47:41","http://www.myexperiment.org/workflows/30/download/ProteinSynonymsToQuery-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18, /users/68,","Marco Roos, Martijn Schuemie,","This workflow creates a query string from the query term using Martijn Schuemie's synonym service. The service is limited to proteins, enzymes and genes. An input query that is a boolean string will be split and processed, but the boolean logic of the input query will be lost.",5, 1, Flatten_list, Flatten_list2, Concat_synonyms, SplitQuery, getSynsets, ,
"http://www.myexperiment.org/workflows/30/versions/2.html","ProteinSynonymsToQuery","2007-10-0318:36:10","2007-11-1323:47:41","http://www.myexperiment.org/workflows/30/download/ProteinSynonymsToQuery-v2.xml?version=2","/users/18","Marco Roos","taverna 1","/users/18, /users/68,","Marco Roos, Martijn Schuemie,","This workflow uses Martijn Schuemie's protein synonym service to produce synonyms and a new query string from the input query term. The service is limited to proteins, enzymes and genes. An input query that is a boolean string will be split and processed, but the boolean logic of the input query will be lost. Workflow URL: <a href=http://rdf.adaptivedisclosure.org/~marco/BioAID/Public/Workflows/BioAID/ProteinSynonymsToQuery.xml rel=nofollow>http://rdf.adaptivedisclosure.org/~marco/BioAID/Public/Workflows/BioAID/ProteinSynonymsToQuery.xml</a>",5, 1, Flatten_list, Flatten_list2, Concat_synonyms, SplitQuery, getSynsets, ,
"http://www.myexperiment.org/workflows/31/versions/1.html","DiscoverProteinLink","2007-10-0318:36:12","2007-11-1509:02:44","http://www.myexperiment.org/workflows/31/download/DiscoverProteinLink-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","This workflow implements Swanson's prinicple with services from the AIDA toolbox. It tries to find proteins that link two topics, while they never mentioned together with both topics in any one of the top ranking papers related to either topic 1 or topic 2. It uses the following logic: Discovered Protein Link = (Protein[Topic1 AND NOT Topic2]  AND Protein[Topic2 AND NOT Topic1]) AND NOT Protein[Topic1 AND Topic2]where 'Protein[Topic1 OPERATOR Topic2]' represents a protein discovered in abstracts returned from Medline using 'Topic1 OPERATOR Topic2' as query. Comments: - It may be useful to optimize the queries for the topics by experimenting with a DiscoverProteins subworkflow first. For example 'cancer' surprisingly does not return any proteins, possibly because clinical papers dominate the retrieval results. The query '+cancer -(therapy clinic) +(protein^10.0 proteins^10.0 gene^9 genes^9)' performs much better. It contains the Lucene priority operator '^[priority], where priority=1 is the default.- The nature of the Swansson algorithm makes it much more likely that this workflow returns no results or false positives, than that it returns true positives.- True positives returned by this workflow are true with respect to the results of the information retrieval step and information extraction step. Limits: 1. Information retrieval: limited number of documents returned, uses indexes for searching, searches and returns abstracts only; 2. entity recognition: not guaranteed to recognize all instances of proteins.",7, 0, DiscoverProteinsTopic1not2, DiscoverProteinsTopic2not1, DiscoverProteinsTopic1and2, CombineTopics, IntersectProteinsTopic1not2and2not1, SubtractProteins, AddProteinTag, ,
"http://www.myexperiment.org/workflows/31/versions/2.html","DiscoverProteinLink","2007-10-0318:36:12","2007-11-1509:02:44","http://www.myexperiment.org/workflows/31/download/DiscoverProteinLink-v2.xml?version=2","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","COMPETITION:For friends only:If you find any two topics that return true positives with this workflow I will buy you a bottle of wine (or equivalent).Terms: if we confirm that the protein was indeed never mentioned together with both input topics in one article, we will publish this together.---- This workflow implements Swanson's prinicple with services from the AIDA toolbox. It tries to find proteins that link two topics, while they never mentioned together with both topics in any one of the top ranking papers related to either topic 1 or topic 2. It uses the following logic:Discovered Protein Link = (Protein[Topic1 AND NOT Topic2]  AND Protein[Topic2 AND NOT Topic1]) AND NOT Protein[Topic1 AND Topic2]where 'Protein[Topic1 OPERATOR Topic2]' represents a protein discovered in abstracts returned from Medline using 'Topic1 OPERATOR Topic2' as query. Comments:- It may be useful to optimize the queries for the topics by experimenting with a DiscoverProteins subworkflow first. For example 'cancer' surprisingly does not return any proteins, possibly because clinical papers dominate the retrieval results. The query '+cancer -(therapy clinic) +(protein^10.0 proteins^10.0 gene^9 genes^9)' performs much better. It contains the Lucene priority operator '^[priority], where priority=1 is the default.- The nature of the Swansson algorithm makes it much more likely that this workflow returns no results or false positives, than that it returns true positives.- True positives returned by this workflow are true with respect to the results of the information retrieval step and information extraction step. Limits: 1. Information retrieval: limited number of documents returned, uses indexes for searching, searches and returns abstracts only; 2. entity recognition: not guaranteed to recognize all instances of proteins. Workflow URL: <a href=http://rdf.adaptivedisclosure.org/~marco/BioAID/Public/Workflows/BioAID/SwansonProteins.xml rel=nofollow>http://rdf.adaptivedisclosure.org/~marco/BioAID/Public/Workflows/BioAID/SwansonProteins.xml</a>",7, 0, DiscoverProteinsTopic1not2, DiscoverProteinsTopic2not1, DiscoverProteinsTopic1and2, CombineTopics, IntersectProteinsTopic1not2and2not1, SubtractProteins, AddProteinTag, ,
"http://www.myexperiment.org/workflows/32/versions/1.html","BLASTP with simplified results returned","2007-10-0318:36:12","2008-03-0617:01:32","http://www.myexperiment.org/workflows/32/download/BLASTP_with_simplified_results_returned-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","","","Perform a blastp search on protein sequence and extract information based on the user input, e.g. a list of GI numbers.",8, 2, gi_number, program, query_seq, blast_ddbj, database, blastsimplifier, Get_Protein_FASTA, split_by_newline, ,
"http://www.myexperiment.org/workflows/32/versions/2.html","BLASTP with simplified results returned","2007-10-0318:36:12","2008-03-0617:01:32","http://www.myexperiment.org/workflows/32/download/BLASTP_with_simplified_results_returned-v2.xml?version=2","/users/62","Franck Tanoh","taverna 1","","","This workflow Performs a blastp search on protein sequence, extracts sequence id  within the blast report and retrives the corresponding seuqences.",8, 2, gi_number, program, query_seq, blast_ddbj, database, blastsimplifier, Get_Protein_FASTA, split_by_newline, ,
"http://www.myexperiment.org/workflows/34/versions/1.html","Picture of me","2007-10-0318:36:19","","http://www.myexperiment.org/workflows/34/download/Picture_of_me-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","","",,2, 0, String_Constant, Get_image_from_URL, ,
"http://www.myexperiment.org/workflows/34/versions/2.html","Picture of me","2007-10-0318:36:19","","http://www.myexperiment.org/workflows/34/download/Picture_of_me-v2.xml?version=2","/users/61","Antoon Goderis","taverna 1","","","If you enter  <a href=http://www.cs.man.ac.uk/~goderisa rel=nofollow>http://www.cs.man.ac.uk/~goderisa</a>  as input I smile back at you as output.",2, 0, String_Constant, Get_image_from_URL, ,
"http://www.myexperiment.org/workflows/35/versions/1.html","querySWS_minimalQuery","2007-10-0318:36:19","","http://www.myexperiment.org/workflows/35/download/querySWS_minimalQuery-v1.xml?version=1","/users/69","Paolo Romano","taverna 1","","",,1, 1, querySWS, ,
"http://www.myexperiment.org/workflows/35/versions/2.html","querySWS_minimalQuery","2007-10-0318:36:19","","http://www.myexperiment.org/workflows/35/download/querySWS_minimalQuery-v2.xml?version=2","/users/69","Paolo Romano","taverna 1","","","SRS by WS (SWS) is a set of Web Services allowing to retrieve database entries from libraries included in public SRS sites.The querySWS service implement a search on the basis of the database name (lib) and the term to be searched (query). It automatically identifies the best site to query. Additional parameters include in_fields (in which part of the record the terms are searched), out_fields (which information is returned) and site (the SRS site). This workflow is just a demonstration of the functionality of the system.",1, 1, querySWS, ,
"http://www.myexperiment.org/workflows/36/versions/1.html","Retrieve TP53 mutations for CABRI cell-lines","2010-01-1213:58:46","","http://www.myexperiment.org/workflows/36/download/Retrieve_TP53_mutations_for_CABRI_cell-lines-v1.xml?version=1","/users/69","Paolo Romano","taverna 1","","",,25, 6, token_position, label_identifier_regex, split_list_regex, tp53_somatic_database, wild_card, tp53_iarc_label_separator, Remove_any_blank_space, Remove_any_minus_character, String_Constant, Filter_list_of_strings_extracting_match_to_a_regex_for_tp53, Split_string_into_string_list_by_regular_expression, String_list_intersection, Filter_list_of_strings_extracting_match_to_a_regex, Filter_list_of_strings_extracting_match_to_a_regex1, Split_string_into_string_list_by_regular_expression_for_tp53, Filter_list_of_strings_extracting_match_to_a_regex2, Get_pubmed_xml_by_pmid, Concatenate_two_strings, getP53MutationIdsBySampleName, getP53SampleNames, getCellLineByName, getP53PubMedIdByIds, Retrieve_all_cell_line_names, getP53MutationsBySampleName, Concatenate_two_strings1, ,
"http://www.myexperiment.org/workflows/36/versions/2.html","Retrieve TP53 mutations for CABRI cell-lines","2010-01-1213:58:46","","http://www.myexperiment.org/workflows/36/download/Retrieve_TP53_mutations_for_CABRI_cell-lines-v2.xml?version=2","/users/69","Paolo Romano","taverna 1","","","This workflow retrieve information on known TP53 mutations (from IARC TP53 Mutation Database as implemented in SRS at IST, Genoa) for all cell lines included in a given CABRI collection of human and animal cel lines.The result consists in the list of all cell lines' descriptions each of which is followed by the related information on mutations.",25, 6, token_position, label_identifier_regex, split_list_regex, tp53_somatic_database, wild_card, tp53_iarc_label_separator, Remove_any_blank_space, Remove_any_minus_character, String_Constant, Filter_list_of_strings_extracting_match_to_a_regex_for_tp53, Split_string_into_string_list_by_regular_expression, String_list_intersection, Filter_list_of_strings_extracting_match_to_a_regex, Filter_list_of_strings_extracting_match_to_a_regex1, Split_string_into_string_list_by_regular_expression_for_tp53, Filter_list_of_strings_extracting_match_to_a_regex2, Get_pubmed_xml_by_pmid, Concatenate_two_strings, getP53MutationIdsBySampleName, getP53SampleNames, getCellLineByName, getP53PubMedIdByIds, Retrieve_all_cell_line_names, getP53MutationsBySampleName, Concatenate_two_strings1, ,
"http://www.myexperiment.org/workflows/36/versions/3.html","Retrieve TP53 mutations for CABRI cell-lines","2010-01-1213:58:46","","http://www.myexperiment.org/workflows/36/download/Retrieve_TP53_mutations_for_CABRI_cell-lines-v3.xml?version=3","/users/69","Paolo Romano","taverna 1","","",,26, 6, String_Constant, label_identifier_regex, wild_card, split_list_regex, tp53_iarc_label_separator, token_position, tp53_somatic_database, Filter_list_of_strings_extracting_match_to_a_regex_for_tp53, Split_string_into_string_list_by_regular_expression_for_tp53, Filter_list_of_strings, Filter_list_of_strings_extracting_match_to_a_regex, Split_string_into_string_list_by_regular_expression, Get_pubmed_xml_by_pmid, Filter_list_of_strings_, String_list_intersection, Remove_any_minus_character, Remove_any_blank_space, Concatenate_two_strings, Concatenate_two_strings1, getP53SampleNames, Retrieve_all_cell_line_names, getP53MutationsBySampleName, getCellLineByName, getP53MutationIdsBySampleName, Beanshell_scripting_host, getP53PubMedIdByRefId, ,
"http://www.myexperiment.org/workflows/38/versions/1.html","keggID to Kegg pathways with BioMoby services","2007-10-0318:36:22","2008-03-0513:59:55","http://www.myexperiment.org/workflows/38/download/keggID_to_Kegg_pathways_with_BioMoby_services-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","","","This workflow retrieves KEGG  pathway id and image given a KEGG gene id.e.g hsa:6402 or eco:b0002",7, 2, getKeggPathwaysByKeggID, Object, Parse_Moby_Data_Object, getKeggPathwayAsGif, Parse_Moby_Data_b64_encoded_gif, Decode_base64_to_byte, String_Constant, ,
"http://www.myexperiment.org/workflows/38/versions/2.html","keggID to Kegg pathways with BioMoby services","2007-10-0318:36:22","2008-03-0513:59:55","http://www.myexperiment.org/workflows/38/download/keggID_to_Kegg_pathways_with_BioMoby_services-v2.xml?version=2","/users/62","Franck Tanoh","taverna 1","","","This workflow retrieves KEGG  pathway id and image given a KEGG gene id.e.g hsa:6402 or eco:b0002",7, 2, getKeggPathwaysByKeggID, Object, Parse_Moby_Data_Object, getKeggPathwayAsGif, Parse_Moby_Data_b64_encoded_gif, Decode_base64_to_byte, String_Constant, ,
"http://www.myexperiment.org/workflows/38/versions/3.html","keggID to Kegg pathways with BioMoby services","2007-10-0318:36:22","2008-03-0513:59:55","http://www.myexperiment.org/workflows/38/download/keggID_to_Kegg_pathways_with_BioMoby_services-v3.xml?version=3","/users/62","Franck Tanoh","taverna 1","","","This workflow retrieves KEGG  pathway id and image given a KEGG gene id.e.g hsa:6402 or eco:b0002",6, 2, getKeggPathwaysByKeggID, Object, getKeggPathwayAsGif, Parse_Moby_Data_Object, Parse_Moby_Data_b64_encoded_gif, Decode_base64_to_byte, ,
"http://www.myexperiment.org/workflows/39/versions/1.html","EBI NCBI Blast","2007-10-0318:36:22","","http://www.myexperiment.org/workflows/39/download/EBI_NCBI_Blast-v1.xml?version=1","/users/41","Hong Chang Bum","taverna 1","","",,7, 2, contentXML, paramsXML, WSArrayofDataXML, runNCBIBlast, poll, Nested_Workflow1, Byte___to_String, ,
"http://www.myexperiment.org/workflows/39/versions/2.html","EBI NCBI Blast","2007-10-0318:36:22","","http://www.myexperiment.org/workflows/39/download/EBI_NCBI_Blast-v2.xml?version=2","/users/41","Hong Chang Bum","taverna 1","","","EBI NCBI Blast",7, 2, contentXML, paramsXML, WSArrayofDataXML, runNCBIBlast, poll, Nested_Workflow1, Byte___to_String, ,
"http://www.myexperiment.org/workflows/40/versions/1.html","Microarray CEL file to candidate pathways","2007-10-0318:36:25","","http://www.myexperiment.org/workflows/40/download/Microarray_CEL_file_to_candidate_pathways-v1.xml?version=1","/users/87","J. Seitz","taverna 1","","","This workflow takes in a CEL file and a normalisation method then returns a series of images/graphs which represent the same output obtained using the MADAT software package (MicroArray Data Analysis Tool) [ <a href=http://www.bioinf.manchester.ac.uk/MADAT/index.html>http://www.bioinf.manchester.ac.uk/MADAT/index.html</a> ]. Also retruned by this workflow are a list of the top differentialy expressed genes (size dependant on the number specified as input - geneNumber), which are then used to find the candidate pathways which may be influencing the observed changes in the microarray data. By identifying the candidate pathways, more detailed insights into the gene expression data can be obtained. NOTE - You will also need to install R and Rserv on your machine and install the libaries required by the R script into you R library directory (see for basic info:  <a href=http://www.cs.man.ac.uk/~fisherp/rlib.html>http://www.cs.man.ac.uk/~fisherp/rlib.html</a> ) The example inputs for this workflow are as follows: Samples1 = one or more CEL files for cross-correlating with Samples2 CEL files (new line separated):Liver_Day1_Mouse.CELLiver_Day2_Mouse.CEL Samples2 = one or more CEL files for cross-correlating with Samples1 CEL files (new line separated): Kideny_Day1_Mouse.CELKidney_Day2_Mouse.CEL geneNumber = the number of differentialy expressed gene to be returned above a given p-value, e.g. 20arrayTypeAffy = the name of the Mouse AffyMetrix array used, e.g. mouse4302path = the direct path to the CEL file location, e.g. C:/Microarray_Data/CEL_FILES/ - note the forward slashesNormalizationMethod = the type of normalisation to perfrom, e.g. rma, gcrma or mmgmostestMethod = e.g. limma, mmtest or pplrp-value = the p-value cut-off value for the array data, e.g. 0.05foldChange = the fold change value for the microarray data, e.g. 1 (means greater than 1 or less than -1)",5, 0, String_Constant, Split_sample1, AffyDataAnalysis, Split_sample2, Candidate_Pathways, ,
"http://www.myexperiment.org/workflows/40/versions/2.html","Microarray CEL file to candidate pathways","2007-10-0318:36:25","","http://www.myexperiment.org/workflows/40/download/Microarray_CEL_file_to_candidate_pathways-v2.xml?version=2","/users/87","J. Seitz","taverna 1","","","This workflow takes in a CEL file and a normalisation method then returns a series of images/graphs which represent the same output obtained using the MADAT software package (MicroArray Data Analysis Tool) [ <a href=http://www.bioinf.manchester.ac.uk/MADAT/index.html rel=nofollow>http://www.bioinf.manchester.ac.uk/MADAT/index.html</a> ]. Also retruned by this workflow are a list of the top differentialy expressed genes (size dependant on the number specified as input - geneNumber), which are then used to find the candidate pathways which may be influencing the observed changes in the microarray data. By identifying the candidate pathways, more detailed insights into the gene expression data can be obtained. NOTE - You will also need to install R and Rserv on your machine and install the libaries required by the R script into you R library directory (see for basic info:  <a href=http://www.cs.man.ac.uk/~fisherp/rlib.html rel=nofollow>http://www.cs.man.ac.uk/~fisherp/rlib.html</a> ) The example inputs for this workflow are as follows:Samples1 = one or more CEL files for cross-correlating with Samples2 CEL files (new line separated):Liver_Day1_Mouse.CELLiver_Day2_Mouse.CEL Samples2 = one or more CEL files for cross-correlating with Samples1 CEL files (new line separated):Kideny_Day1_Mouse.CELKidney_Day2_Mouse.CEL geneNumber = the number of differentialy expressed gene to be returned above a given p-value, e.g. 20arrayTypeAffy = the name of the Mouse AffyMetrix array used, e.g. mouse4302path = the direct path to the CEL file location, e.g. C:/Microarray_Data/CEL_FILES/ - note the forward slashesNormalizationMethod = the type of normalisation to perfrom, e.g. rma, gcrma or mmgmostestMethod = e.g. limma, mmtest or pplrp-value = the p-value cut-off value for the array data, e.g. 0.05foldChange = the fold change value for the microarray data, e.g. 1 (means greater than 1 or less than -1)",5, 0, String_Constant, Split_sample1, AffyDataAnalysis, Split_sample2, Candidate_Pathways, ,
"http://www.myexperiment.org/workflows/41/versions/1.html","getFragWithClosure","2007-10-0318:36:25","","http://www.myexperiment.org/workflows/41/download/getFragWithClosure-v1.xml?version=1","/users/6","Duncan Hull","taverna 1","","",,4, 1, getFragmentWithClosure, smiles, group, closure, ,
"http://www.myexperiment.org/workflows/41/versions/2.html","getFragWithClosure","2007-10-0318:36:25","","http://www.myexperiment.org/workflows/41/download/getFragWithClosure-v2.xml?version=2","/users/6","Duncan Hull","taverna 1","","","getFragment with closure workflow, actually just one service, but need example inputs for smiles string, group and closure parameters.",4, 1, getFragmentWithClosure, smiles, group, closure, ,
"http://www.myexperiment.org/workflows/42/versions/1.html","getFragWithClosure2","2007-10-0318:36:25","","http://www.myexperiment.org/workflows/42/download/getFragWithClosure2-v1.xml?version=1","/users/6","Duncan Hull","taverna 1","","",,5, 1, group, smilesURL, closure, getFragmentWithClosure, Get_web_page_from_URL, ,
"http://www.myexperiment.org/workflows/42/versions/2.html","getFragWithClosure2","2007-10-0318:36:25","","http://www.myexperiment.org/workflows/42/download/getFragWithClosure2-v2.xml?version=2","/users/6","Duncan Hull","taverna 1","","","with parameters",5, 1, group, smilesURL, closure, getFragmentWithClosure, Get_web_page_from_URL, ,
"http://www.myexperiment.org/workflows/43/versions/1.html","getFragWithClosure","2007-10-0318:36:26","","http://www.myexperiment.org/workflows/43/download/getFragWithClosure-v1.xml?version=1","/users/6","Duncan Hull","taverna 1","","",,6, 1, closure, smilesURL, group, Get_web_page_from_URL, getFragmentWithClosure, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/43/versions/2.html","getFragWithClosure","2007-10-0318:36:26","","http://www.myexperiment.org/workflows/43/download/getFragWithClosure-v2.xml?version=2","/users/6","Duncan Hull","taverna 1","","","Bit of a hack, but it works now, adds trailing %90 to the output.",6, 1, closure, smilesURL, group, Get_web_page_from_URL, getFragmentWithClosure, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/45/versions/1.html","Translate Nucleotide sequence into Peptide sequence","2007-10-0318:36:27","","http://www.myexperiment.org/workflows/45/download/Translate_Nucleotide_sequence_into_Peptide_sequence-v1.xml?version=1","/users/41","Hong Chang Bum","taverna 1","","",,11, 2, query, style, format, parametersXML, transeqXML, runAndWaitFor_param, sequenceXML, transeqResultXML, fetchData, runAndWaitFor, Merge_string_list_to_string, ,
"http://www.myexperiment.org/workflows/45/versions/2.html","Translate Nucleotide sequence into Peptide sequence","2007-10-0318:36:27","","http://www.myexperiment.org/workflows/45/download/Translate_Nucleotide_sequence_into_Peptide_sequence-v2.xml?version=2","/users/41","Hong Chang Bum","taverna 1","","","Translate Nucleotide sequence into Peptide sequence using EBI Service. <ol><li value=1>Find nucleotide sequence from EBI wsdbfetch(using ref.seq Id NM_005700) </li></ol> <ol><li value=2>Translation nucleotide sequence(from 1) into peptide sequence using EBI EMBOSS4 transeq.</li></ol>",11, 2, query, style, format, parametersXML, transeqXML, runAndWaitFor_param, sequenceXML, transeqResultXML, fetchData, runAndWaitFor, Merge_string_list_to_string, ,
"http://www.myexperiment.org/workflows/46/versions/1.html","pELM_getInstance_Return_Seq","2007-10-0318:36:27","2008-05-0213:09:07","http://www.myexperiment.org/workflows/46/download/pELM_getInstance_Return_Seq-v1.xml?version=1","/users/75","Niall Haslam","taverna 1","/users/75,","Niall Haslam,",,3, 1, getInstanceByIdentifier, parameterXML1, InstanceXML, ,
"http://www.myexperiment.org/workflows/46/versions/2.html","pELM_getInstance_Return_Seq","2007-10-0318:36:27","2008-05-0213:09:07","http://www.myexperiment.org/workflows/46/download/pELM_getInstance_Return_Seq-v2.xml?version=2","/users/75","Niall Haslam","taverna 1","/users/75,","Niall Haslam,","Simple workflow to retrieve the sequence of a phospho.ELM entry given the Instance identifier. Input requires xml as the namespace is not correctly handled by the xml splitter. Example input: &lt;phos:getinstancebyidentifier&gt;&lt;instanceidentifier&gt;I000299&lt;/instanceidentifier&gt;&lt;/phos:getinstancebyidentifier&gt; Further outputs can easily be added, most are text with some xml. See list in InstanceXML.",3, 1, getInstanceByIdentifier, parameterXML1, InstanceXML, ,
"http://www.myexperiment.org/workflows/47/versions/1.html","Add Mesh String to Biological Process","2007-10-0318:36:28","2009-12-0316:42:48","http://www.myexperiment.org/workflows/47/download/Add_Mesh_String_to_Biological_Process-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","","",,1, 0, add_MeSH_to_string, ,
"http://www.myexperiment.org/workflows/47/versions/2.html","Add Mesh String to Biological Process","2007-10-0318:36:28","2009-12-0316:42:48","http://www.myexperiment.org/workflows/47/download/Add_Mesh_String_to_Biological_Process-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","","","This workflow is designed to add the following MeSH term to the end of a KEGG pathway name: AND &quot;Metabolic Networks and Pathways&quot; [MeSH Terms] &nbsp; Example input for this service is as follows: &nbsp; VEGF signaling pathway <br /> Hematopoietic cell lineage <br /> GnRH signaling pathway <br /> Type II diabetes mellitus &nbsp;",1, 0, add_MeSH_to_string, ,
"http://www.myexperiment.org/workflows/48/versions/1.html","BLASTP with simplified results returned","2007-10-0318:36:28","","http://www.myexperiment.org/workflows/48/download/BLASTP_with_simplified_results_returned-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","","","Perform a blastp search on protein sequence and extract information based on the user input, e.g. a list of GI numbers. N.B. this workflow does not function correctly as it is designed for use with NCBI blast scripts. Some errors may occur. Please use two blast text file inputs for a secure result output.",4, 2, chromosome_filter, species_filter, blast_ddbj, blastfilecomparer, ,
"http://www.myexperiment.org/workflows/48/versions/2.html","BLASTP with simplified results returned","2007-10-0318:36:28","","http://www.myexperiment.org/workflows/48/download/BLASTP_with_simplified_results_returned-v2.xml?version=2","/users/61","Antoon Goderis","taverna 1","","","Perform a blastp search on protein sequence and extract information based on the user input, e.g. a list of GI numbers. N.B. this workflow does not function correctly as it is designed for use with NCBI blast scripts. Some errors may occur. Please use two blast text file inputs for a secure result output.",4, 2, chromosome_filter, species_filter, blast_ddbj, blastfilecomparer, ,
"http://www.myexperiment.org/workflows/50/versions/1.html","Daily Dilbert","2007-10-0318:36:29","2008-03-0616:59:35","http://www.myexperiment.org/workflows/50/download/Daily_Dilbert-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","","",,3, 1, DailyDilbertImagePath, parametersXML, GetImage, ,
"http://www.myexperiment.org/workflows/50/versions/2.html","Daily Dilbert","2007-10-0318:36:29","2008-03-0616:59:35","http://www.myexperiment.org/workflows/50/download/Daily_Dilbert-v2.xml?version=2","/users/62","Franck Tanoh","taverna 1","","","Retrieves the Daily Dilbert image ....to start the day with",3, 1, DailyDilbertImagePath, parametersXML, GetImage, ,
"http://www.myexperiment.org/workflows/51/versions/1.html","conditional branch","2007-10-0318:36:29","","http://www.myexperiment.org/workflows/51/download/conditional_branch-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","","","If the input is true then the string 'foo' is emited, if false then 'bar'. Just a simple example to show how the monster works, so to speak.",6, 2, Fail_if_false, Fail_if_true, tempF, tempC, CtoF, FtoC, ,
"http://www.myexperiment.org/workflows/51/versions/2.html","conditional branch","2007-10-0318:36:29","","http://www.myexperiment.org/workflows/51/download/conditional_branch-v2.xml?version=2","/users/62","Franck Tanoh","taverna 1","","","Example of a conditional execution workflow. use 'false' or 'true' as input",6, 2, Fail_if_false, Fail_if_true, tempF, tempC, CtoF, FtoC, ,
"http://www.myexperiment.org/workflows/52/versions/1.html","Example of a conditional execution workflow","2007-10-0318:36:30","2008-01-2721:09:41","http://www.myexperiment.org/workflows/52/download/Example_of_a_conditional_execution_workflow-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","","","If the input is true then the string 'foo' is emited, if false then 'bar'. Just a simple example to show how the monster works, so to speak.",6, 2, Fail_if_false, Fail_if_true, tempF, tempC, CtoF, FtoC, ,
"http://www.myexperiment.org/workflows/52/versions/2.html","Example of a conditional execution workflow","2007-10-0318:36:30","2008-01-2721:09:41","http://www.myexperiment.org/workflows/52/download/Example_of_a_conditional_execution_workflow-v2.xml?version=2","/users/62","Franck Tanoh","taverna 1","","","If the input is true the workflow returns the temperature in Celsius, if false the temperature in Fahrenheit is returned.",6, 2, Fail_if_false, Fail_if_true, tempF, tempC, CtoF, FtoC, ,
"http://www.myexperiment.org/workflows/59/versions/1.html","QR code (matrix code) generator","2007-10-0717:17:03","2012-08-1510:40:51","http://www.myexperiment.org/workflows/59/download/QR_code__matrix_code__generator-v1.xml?version=1","/users/10","Mark Borkum","taverna 1","","",,3, 1, makeBookmark, Byte___to_String, Encode_byte___to_base64, ,
"http://www.myexperiment.org/workflows/59/versions/2.html","QR code (matrix code) generator","2007-10-0717:17:03","2012-08-1510:40:51","http://www.myexperiment.org/workflows/59/download/QR_code__matrix_code__generator-v2.xml?version=2","/users/10","Mark Borkum","taverna 1","","","This workflow creates  <a href=http://en.wikipedia.org/wiki/QR_Code>QR Code</a>  bookmarks using the supplied URL and description.",3, 1, makeBookmark, Byte___to_String, Encode_byte___to_base64, ,
"http://www.myexperiment.org/workflows/59/versions/3.html","QR code (matrix code) generator","2007-10-0717:17:03","2012-08-1510:40:51","http://www.myexperiment.org/workflows/59/download/QR_code__matrix_code__generator-v3.xml?version=3","/users/10","Mark Borkum","taverna 1","","","This workflow creates  <a href=http://en.wikipedia.org/wiki/QR_Code>QR Code</a>  bookmarks using the supplied URL and description.",3, 1, makeBookmark, Byte___to_String, Encode_byte___to_base64, ,
"http://www.myexperiment.org/workflows/59/versions/4.html","QR code (matrix code) generator","2007-10-0717:17:03","2012-08-1510:40:51","http://www.myexperiment.org/workflows/59/download/QR_code__matrix_code__generator-v4.xml?version=4","/users/10","Mark Borkum","taverna 1","","","The latest (and greatest) version of the QR code generator workflow.  This workflow uses the QR code service provided by the  <a href=http://chemtools.chem.soton.ac.uk/ rel=nofollow>ChemTools</a>  project.",1, 1, qrcode, ,
"http://www.myexperiment.org/workflows/60/versions/1.html","CountListElements","2007-10-1714:44:27","2007-10-1716:13:54","http://www.myexperiment.org/workflows/60/download/CountListElements-v1.xml?version=1","/users/18","Marco Roos","taverna 1","","","Very simple workflow to count the number of items in a list (top level only in case of nested lists). Does no more thancount = list.size();",1, 0, CountListElements, ,
"http://www.myexperiment.org/workflows/60/versions/2.html","CountListElements","2007-10-1714:44:27","2007-10-1716:13:54","http://www.myexperiment.org/workflows/60/download/CountListElements-v2.xml?version=2","/users/18","Marco Roos","taverna 1","","","Very simple workflow to count the number of items in a list (top level only in case of nested lists). Does no more thancount = list.size();",1, 0, CountListElements, ,
"http://www.myexperiment.org/workflows/60/versions/3.html","CountListElements","2007-10-1714:44:27","2007-10-1716:13:54","http://www.myexperiment.org/workflows/60/download/CountListElements-v3.xml?version=3","/users/18","Marco Roos","taverna 1","","","Very simple workflow to count the number of items in a list (top level only in case of nested lists). Does no more thancount = list.size();",1, 0, CountListElements, ,
"http://www.myexperiment.org/workflows/60/versions/4.html","CountListElements","2007-10-1714:44:27","2007-10-1716:13:54","http://www.myexperiment.org/workflows/60/download/CountListElements-v4.xml?version=4","/users/18","Marco Roos","taverna 1","","","Very simple workflow to count the number of items in a list (top level only in case of nested lists). Does no more thancount = list.size();",1, 0, CountListElements, ,
"http://www.myexperiment.org/workflows/60/versions/5.html","CountListElements","2007-10-1714:44:27","2007-10-1716:13:54","http://www.myexperiment.org/workflows/60/download/CountListElements-v5.xml?version=5","/users/18","Marco Roos","taverna 1","","","Very simple workflow to count the number of items in a list (top level only in case of nested lists). Does no more thancount = list.size();",1, 0, CountListElements, ,
"http://www.myexperiment.org/workflows/62/versions/1.html","Pathways and Gene annotations for QTL Phenotype annotated","2007-10-3013:04:02","2007-12-0411:18:33","http://www.myexperiment.org/workflows/62/download/Pathways_and_Gene_annotations_for_QTL_Phenotype_annotated-v1.xml?version=1","/users/5","Stian Soiland-Reyes","taverna 1","","",,52, 6, add_uniprot_to_string, regex_2, split_gene_ids, remove_Nulls, Split_for_ncbi_pathways, kegg_pathway_release, species, remove_duplicate_pathways, split_pathways, concat_pathway_lists, remove_pathway_nulls, merge_probesets, comma, comma_sep_probesets, split_probesets, add_string_to_probesets, remove_nulls_4, create_report, merge_reports, remove_entrez_duplicates, remove_uniprot_duplicates, remove_duplicate_kegg_genes, Split_for_swissprot_pathways, add_ncbi_to_string, merge_ncbi_pathways, merge_gene_desc, mmusculus_gene_ensembl, ColumnType, Profile, genes_in_qtl, split_ncbi_gene_ids, merge_uniprot_ids, split_for_duplicates, merge_genes_and_pathways, merge_entrez_genes, Merge_string_list_to_string3, REMOVE_NULLS_2, Merge_string_list_to_string, concat_kegg_genes, merge_uniprot_pathways, gene_descriptions, Kegg_gene_ids, maxdBrowse_query, Kegg_gene_ids_2, binfo, chromosome, start_position, end_position, MeasurementIDs, Uniprot_pathways, NCBI_pathways, getcurrentdatabase, ,
"http://www.myexperiment.org/workflows/66/versions/1.html","Find address entry","2007-11-0521:54:22","2008-09-0814:59:00","http://www.myexperiment.org/workflows/66/download/Find_address_entry-v1.xml?version=1","/users/2","David Withers","taverna 1","/users/2,","David Withers,",,5, 1, returnXML, part1XML1, part1XML, findEntry, Beanshell_scripting_host, ,
"http://www.myexperiment.org/workflows/67/versions/1.html","1","2007-11-0616:59:05","2007-11-2016:18:31","http://www.myexperiment.org/workflows/67/download/1-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/61, /users/25, /users/173,","Antoon Goderis, Carole Goble, A. Random Scientist,",,3, 0, p1, p2, p3, ,
"http://www.myexperiment.org/workflows/67/versions/2.html","1","2007-11-0616:59:05","2007-11-2016:18:31","http://www.myexperiment.org/workflows/67/download/1-v2.xml?version=2","/users/61","Antoon Goderis","taverna 1","/users/61, /users/25, /users/173,","Antoon Goderis, Carole Goble, A. Random Scientist,","Trivial workflow which will initially fail, retry twice then fall over to the alternative specified for the FailingThing process.",3, 0, FooString, BarString, FailingProcessor, ,
"http://www.myexperiment.org/workflows/69/versions/1.html","3","2007-11-0617:10:16","","","/users/61","Antoon Goderis","taverna 1","/users/61,","Antoon Goderis,",,
"http://www.myexperiment.org/workflows/70/versions/1.html","Retrieve SNPs from regions around known genes","2007-11-0715:50:40","","http://www.myexperiment.org/workflows/70/download/Retrieve_SNPs_from_regions_around_known_genes-v1.xml?version=1","/users/206","Jfinch","taverna 1","","","Given a list of Gene IDs this workflow will query against the Ensembl human genome data to fetch the genomic region for each gene, extend that region by 1000bp in each direction and use this set of ranges, one per gene, to build a query against dbSNP to return the SNP identifier and location information (chromosome name, strand and position)",6, 0, Add1000, ForceListType, NCBI36, Subtract1000, CreateReport, dbSNP, ,
"http://www.myexperiment.org/workflows/71/versions/1.html","Retrieve Protein Sequence and BLAST","2007-11-0910:41:12","2008-06-0515:18:07","","/users/13","Katy Wolstencroft","taverna 1","/users/13,","Katy Wolstencroft,","Retrieves a protein sequence in Fasta format from Genbank and then performs a BLAST on that sequence",
"http://www.myexperiment.org/workflows/72/versions/1.html","BioAID_DiseaseDiscovery_RatHumanMouseUniprotFilter","2008-12-1520:46:09","2011-08-1109:22:23","http://www.myexperiment.org/workflows/72/download/BioAID_DiseaseDiscovery_RatHumanMouseUniprotFilter-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","This workflow finds disease relevant to the query string via the following steps: 1. A user query: a list of terms or boolean query - look at the Apache Lucene project for all details. E.g.: (EZH2 OR &quot;Enhancer of Zeste&quot; +(mutation chromatin) -clinical) 2. Retrieve documents: finds relevant documents (abstract+title) based on query (edit maxHits to change the default maximum number of documents returned; the AIDA service inside is based on Apache Lucene) 3. Discover proteins: extract proteins discovered in the set of relevant abstracts  (with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe) 4. Link proteins to disease contained in the OMIM disease database (with a service from Japan that interrogates OMIM)  Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org>http://adaptivedisclosure.org</a> )  Text mining services by Sophia Katrenko and Edgar Meij (AID) OMIM service from the Center for Information Biology and DNA Data Bank of Japan, National Institute of Genetics, director Hideaki Sugawara (see  <a href=http://xml.nig.ac.jp>http://xml.nig.ac.jp</a> )  Workflow URL:  <a href=http://adaptivedisclosure.org/workflows/BioAID/BioAID_DiseaseDiscovery.xml>http://adaptivedisclosure.org/workflows/BioAID/BioAID_DiseaseDiscovery.xml</a>",8, 0, Document_index, search_field, maxHits, Remove_xml_tag, Flatten_and_make_unique, Link_proteins_to_diseases, Discover_proteins, Retrieve_documents, ,
"http://www.myexperiment.org/workflows/72/versions/2.html","BioAID_DiseaseDiscovery_RatHumanMouseUniprotFilter","2008-12-1520:46:09","2011-08-1109:22:23","http://www.myexperiment.org/workflows/72/download/BioAID_DiseaseDiscovery_RatHumanMouseUniprotFilter-v2.xml?version=2","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","This workflow finds disease relevant to the query string via the following steps: 1. A user query: a list of terms or boolean query - look at the Apache Lucene project for all details. E.g.: (EZH2 OR &quot;Enhancer of Zeste&quot; +(mutation chromatin) -clinical); consider adding 'ProteinSynonymsToQuery' in front of the input if your query is a protein. 2. Retrieve documents: finds 'maximumNumberOfHits' relevant documents (abstract+title) based on query (the AIDA service inside is based on Apache's Lucene) 3. Discover proteins: extract proteins discovered in the set of relevant abstracts with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe. This subworkflow also 'filters' false positives from the discovered protein by requiring a discovery has a valid UniProt ID. Martijn Schuemie's service to do that contains only human UniProt IDs, which is why this workflow only works for human proteins. 4. Link proteins to disease contained in the OMIM disease database (with a service from Japan that interrogates OMIM)  Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org>http://adaptivedisclosure.org</a> )  Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam). OMIM service from the Center for Information Biology and DNA Data Bank of Japan, National Institute of Genetics, director Hideaki Sugawara (see  <a href=http://xml.nig.ac.jp>http://xml.nig.ac.jp</a> )  Changes to our original BioAID_DiseaseDiscovery workflow:    * Use of Martijn Schuemie's synsets service to        * provide uniprot ids to discovered proteins        * filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)        * solve a major issue with the original workflow where some false positives could contribute disproportionately to the number of discovered diseases    * Counting of results in various ways.",9, 0, search_field, Document_index, CountProteins, CountDiseases, CountDiseasesPerProtein, Flatten_and_make_unique, Link_proteins_to_diseases, Retrieve_documents, Discover_RatHumanMouseUniProt_proteins, ,
"http://www.myexperiment.org/workflows/72/versions/3.html","BioAID_DiseaseDiscovery_RatHumanMouseUniprotFilter","2008-12-1520:46:09","2011-08-1109:22:23","http://www.myexperiment.org/workflows/72/download/BioAID_DiseaseDiscovery_RatHumanMouseUniprotFilter-v3.xml?version=3","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","This workflow finds disease relevant to the query string via the following steps: 1. A user query: a list of terms or boolean query - look at the Apache Lucene project for all details. E.g.: (EZH2 OR &quot;Enhancer of Zeste&quot; +(mutation chromatin) -clinical); consider adding 'ProteinSynonymsToQuery' in front of the input if your query is a protein. 2. Retrieve documents: finds 'maximumNumberOfHits' relevant documents (abstract+title) based on query (the AIDA service inside is based on Apache's Lucene) 3. Discover proteins: extract proteins discovered in the set of relevant abstracts with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe. This subworkflow also 'filters' false positives from the discovered protein by requiring a discovery has a valid UniProt ID. Martijn Schuemie's service to do that contains only human UniProt IDs, which is why this workflow only works for human proteins. 4. Link proteins to disease contained in the OMIM disease database (with a service from Japan that interrogates OMIM)  Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org>http://adaptivedisclosure.org</a> )  Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam). OMIM service from the Center for Information Biology and DNA Data Bank of Japan, National Institute of Genetics, director Hideaki Sugawara (see  <a href=http://xml.nig.ac.jp>http://xml.nig.ac.jp</a> )  Changes to our original BioAID_DiseaseDiscovery workflow:    * Use of Martijn Schuemie's synsets service to        * provide uniprot ids to discovered proteins        * filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)        * solve a major issue with the original workflow where some false positives could contribute disproportionately to the number of discovered diseases    * Counting of results in various ways.",9, 0, search_field, Document_index, CountProteins, CountDiseases, CountDiseasesPerProtein, Flatten_and_make_unique, Link_proteins_to_diseases, Retrieve_documents, Discover_RatHumanMouseUniProt_proteins, ,
"http://www.myexperiment.org/workflows/72/versions/4.html","BioAID_DiseaseDiscovery_RatHumanMouseUniprotFilter","2008-12-1520:46:09","2011-08-1109:22:23","http://www.myexperiment.org/workflows/72/download/BioAID_DiseaseDiscovery_RatHumanMouseUniprotFilter-v4.xml?version=4","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","This workflow finds disease relevant to the query string via the following steps: 1. A user query: a list of terms or boolean query - look at the Apache Lucene project for all details. E.g.: (EZH2 OR &quot;Enhancer of Zeste&quot; +(mutation chromatin) -clinical); consider adding 'ProteinSynonymsToQuery' in front of the input if your query is a protein. 2. Retrieve documents: finds 'maximumNumberOfHits' relevant documents (abstract+title) based on query (the AIDA service inside is based on Apache's Lucene) 3. Discover proteins: extract proteins discovered in the set of relevant abstracts with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe. This subworkflow also 'filters' false positives from the discovered protein by requiring a discovery has a valid UniProt ID. Martijn Schuemie's service to do that contains only human UniProt IDs, which is why this workflow only works for human proteins. 4. Link proteins to disease contained in the OMIM disease database (with a service from Japan that interrogates OMIM)  Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org rel=nofollow>http://adaptivedisclosure.org</a> )  Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam). OMIM service from the Center for Information Biology and DNA Data Bank of Japan, National Institute of Genetics, director Hideaki Sugawara (see  <a href=http://xml.nig.ac.jp rel=nofollow>http://xml.nig.ac.jp</a> )  Changes to our original BioAID_DiseaseDiscovery workflow:    * Use of Martijn Schuemie's synsets service to        * provide uniprot ids to discovered proteins        * filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)        * solve a major issue with the original workflow where some false positives could contribute disproportionately to the number of discovered diseases    * Counting of results in various ways.",9, 0, search_field, Document_index, CountProteins, CountDiseases, CountDiseasesPerProtein, Flatten_and_make_unique, Link_proteins_to_diseases, Retrieve_documents, Discover_RatHumanMouseUniProt_proteins, ,
"http://www.myexperiment.org/workflows/74/versions/1.html","BioAID_ProteinDiscovery","2010-05-1016:21:09","2013-08-1611:37:33","http://www.myexperiment.org/workflows/74/download/BioAID_ProteinDiscovery-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","This workflow finds proteins relevant to the query string via the following steps: <ol><li>A user query: a list of terms or boolean query - look at the Apache Lucene project for all details. E.g.: EZH2 OR Enhancer of Zeste +(mutation chromatin) -clinical</li><li>Retrieve documents: finds relevant documents (abstract+title) based on query (edit maxHits to change the default maximum number of documents returned)</li><li>Discover proteins: extract proteins discovered in the set of relevant abstracts.</li></ol> Services by Edgar Meij and Sophia Katrenko (AID)",7, 0, maxHits, Document_index, search_field, Flatten_list, Remove_xml_tag, Discover_proteins, Retrieve_documents, ,
"http://www.myexperiment.org/workflows/74/versions/2.html","BioAID_ProteinDiscovery","2010-05-1016:21:09","2013-08-1611:37:33","http://www.myexperiment.org/workflows/74/download/BioAID_ProteinDiscovery-v2.t2flow?version=2","/users/18","Marco Roos","taverna 2","/users/18,","Marco Roos,","This workflow finds proteins relevant to the query string via the following steps: A user query: a list of terms or boolean query - look at the Apache Lucene project for all details. E.g.: EZH2 OR Enhancer of Zeste +(mutation chromatin) -clinicalRetrieve documents: finds relevant documents (abstract+title) based on query (edit maxHits to change the default maximum number of documents returned)Discover proteins: extract proteins discovered in the set of relevant abstracts.Filter extracted protein names by checking if a UniProtID exists that is labelled with the protein name. Services by Edgar Meij, Sophia Katrenko (AID), and Martijn Schuemie (BioSemantics)",0, 0, ,
"http://www.myexperiment.org/workflows/74/versions/3.html","BioAID_ProteinDiscovery","2010-05-1016:21:09","2013-08-1611:37:33","http://www.myexperiment.org/workflows/74/download/BioAID_ProteinDiscovery-v3.t2flow?version=3","/users/18","Marco Roos","taverna 2","/users/18,","Marco Roos,","The workflow extracts protein names from documents retrieved from MedLine based on a user Query (cf Apache Lucene syntax). The protein names are filtered by checking if there exists a valid UniProt ID for the given protein name.",0, 0, ,
"http://www.myexperiment.org/workflows/74/versions/4.html","BioAID_ProteinDiscovery","2010-05-1016:21:09","2013-08-1611:37:33","http://www.myexperiment.org/workflows/74/download/BioAID_ProteinDiscovery-v4.t2flow?version=4","/users/18","Marco Roos","taverna 2","/users/18,","Marco Roos,","The workflow extracts protein names from documents retrieved from MedLine based on a user Query (cf Apache Lucene syntax). The protein names are filtered by checking if there exists a valid UniProt ID for the given protein name.",0, 0, ,
"http://www.myexperiment.org/workflows/74/versions/5.html","BioAID_ProteinDiscovery","2010-05-1016:21:09","2013-08-1611:37:33","http://www.myexperiment.org/workflows/74/download/BioAID_ProteinDiscovery-v5.t2flow?version=5","/users/18","Marco Roos","taverna 2","/users/18,","Marco Roos,","The workflow extracts protein names from documents retrieved from MedLine based on a user Query (cf Apache Lucene syntax). The protein names are filtered by checking if there exists a valid UniProt ID for the given protein name.",0, 0, ,
"http://www.myexperiment.org/workflows/74/versions/6.html","BioAID_ProteinDiscovery","2010-05-1016:21:09","2013-08-1611:37:33","http://www.myexperiment.org/workflows/74/download/BioAID_ProteinDiscovery-v6.t2flow?version=6","/users/18","Marco Roos","taverna 2","/users/18,","Marco Roos,","The workflow extracts protein names from documents retrieved from MedLine based on a user Query (cf Apache Lucene syntax). The protein names are filtered by checking if there exists a valid UniProt ID for the given protein name.",0, 0, ,
"http://www.myexperiment.org/workflows/74/versions/7.html","BioAID_ProteinDiscovery","2010-05-1016:21:09","2013-08-1611:37:33","http://www.myexperiment.org/workflows/74/download/BioAID_ProteinDiscovery-v7.t2flow?version=7","/users/18","Marco Roos","taverna 2","/users/18,","Marco Roos,","This protein discovery workflow extracts protein names from documents retrieved from MedLine based on a user Query (cf Apache Lucene syntax). The protein names are filtered by checking if there exists a valid UniProt ID for the given protein name.",0, 0, ,
"http://www.myexperiment.org/workflows/74/versions/8.html","BioAID_ProteinDiscovery","2010-05-1016:21:09","2013-08-1611:37:33","http://www.myexperiment.org/workflows/74/download/BioAID_ProteinDiscovery-v8.t2flow?version=8","/users/18","Marco Roos","taverna 2","/users/18,","Marco Roos,","The workflow extracts protein names from documents retrieved from MedLine based on a user Query (cf Apache Lucene syntax). The protein names are filtered by checking if there exists a valid UniProt ID for the given protein name.",0, 0, ,
"http://www.myexperiment.org/workflows/75/versions/1.html","BioAID_ProteinToDiseases","2007-11-1412:47:57","2007-11-1509:00:44","http://www.myexperiment.org/workflows/75/download/BioAID_ProteinToDiseases-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18, /users/68,","Marco Roos, Martijn Schuemie,","This workflow was based on BioAID_DiseaseDiscovery, changes: expects only one protein name, adds protein synonyms). This workflow finds diseases relevant to the query string via the following steps: <ol><li value=1>A user query: a single protein name</li><li value=2>Add synonyms (service courtesy of Martijn Scheumie, Erasmus University Rotterdam)</li><li value=3>Retrieve documents: finds relevant documents (abstract+title) based on query</li><li value=4>Discover proteins: extract proteins discovered in the set of relevant abstracts</li></ol> <ol><li value=5>Link proteins to disease contained in the OMIM disease database.</li></ol>",10, 0, search_field, Document_index, maxHits, Flatten_and_make_unique, Remove_xml_tag, Retrieve_documents, Discover_proteins, Link_proteins_to_diseases, Add_protein_synonyms, Flatten_list, ,
"http://www.myexperiment.org/workflows/76/versions/1.html","ChEBI-get_synonyms","2007-11-1412:48:30","","http://www.myexperiment.org/workflows/76/download/ChEBI-get_synonyms-v1.xml?version=1","/users/6","Duncan Hull","taverna 1","/users/6,","Duncan Hull,",,5, 1, getCompleteEntity, parametersXML, resultXML, returnXML, SynonymsXML, ,
"http://www.myexperiment.org/workflows/77/versions/1.html","Query Maxd microarray database","2007-11-1416:01:50","2007-11-2212:06:32","http://www.myexperiment.org/workflows/77/download/Query_Maxd_microarray_database-v1.xml?version=1","/users/221","Peter Li","taverna 1","/users/221,","Peter Li,","Retrieves data from the maxd database given name of data set",3, 1, cleanOutput, queryMaxd, datasetName, ,
"http://www.myexperiment.org/workflows/79/versions/1.html","Mapping microarray data onto metabolic pathways","2007-11-1416:51:26","2007-11-2210:39:32","http://www.myexperiment.org/workflows/79/download/Mapping_microarray_data_onto_metabolic_pathways-v1.xml?version=1","/users/221","Peter Li","taverna 1","/users/221,","Peter Li,","This workflow maps microarray data onto metabolic pathway diagrams represented as SBML models drawn using Cell Designer. To run this workflow requires libsbml to be installed into taverna - see  <a href=http://www.mcisb.org/software/taverna/libsbml/index.html rel=nofollow>http://www.mcisb.org/software/taverna/libsbml/index.html</a>",13, 3, FileLocation, createDictionary, swapAffyIds, extractExpressData, addColorToValues, merge, calcExpressionRange, getSBMLFile, queryMaxd, extractGeneNames, writeSBML, createImage, getAffyIds, ,
"http://www.myexperiment.org/workflows/80/versions/1.html","Discover_proteins_from_text","2007-11-1508:58:00","2007-11-1509:12:34","http://www.myexperiment.org/workflows/80/download/Discover_proteins_from_text-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","This workflow discovers proteins from plain text. It is built around the AIDA 'Named Entity Recognize' web service by Sophia Katrenko (service based on LingPipe), from which output it filters out proteins. The Named Recognizer services uses the pre-learned genomics model, named 'MedLine', to find genomics concepts in plain text.",3, 0, prelearned_genomics_model, Extract_proteins, Discover_entities, ,
"http://www.myexperiment.org/workflows/80/versions/2.html","Discover_proteins_from_text","2007-11-1508:58:00","2007-11-1509:12:34","http://www.myexperiment.org/workflows/80/download/Discover_proteins_from_text-v2.xml?version=2","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","This workflow discovers proteins from plain text. It is built around the AIDA 'Named Entity Recognize' web service by Sophia Katrenko (service based on LingPipe), from which output it filters out proteins. The Named Recognizer services uses the pre-learned genomics model, named 'MedLine', to find genomics concepts in plain text.",3, 0, prelearned_genomics_model, Extract_proteins, Discover_entities, ,
"http://www.myexperiment.org/workflows/81/versions/1.html","BioAID_Discover_proteins_from_text_plus_synonyms","2007-11-1509:40:24","","","/users/18","Marco Roos","taverna 1","/users/18, /users/68,","Marco Roos, Martijn Schuemie,","This workflow discovers proteins from plain text and adds synonyms using Martijn Schuemie's proteins synonym service. Proteins are discovered with the AIDA 'Named Entity Recognize' web service by Sophia Katrenko (service based on LingPipe), from which output it filters out proteins. The Named Recognizer services uses the pre-learned genomics model, named 'MedLine', to find genomics concepts in plain text.",
"http://www.myexperiment.org/workflows/83/versions/1.html","couple","2007-11-1609:06:18","2007-11-1609:19:25","","/users/41","Hong Chang Bum","taverna 1","/users/41,","Hong Chang Bum,","My Girl Friend and me ^o^/",
"http://www.myexperiment.org/workflows/85/versions/1.html","ChEBI-get_synonyms","2007-11-1913:45:42","2007-11-1913:54:44","http://www.myexperiment.org/workflows/85/download/ChEBI-get_synonyms-v1.xml?version=1","/users/255","Sirisha Gollapudi","taverna 1","/users/255,","Sirisha Gollapudi,","This workflow takes a list of entity names separated by a newline and queries the ChEBI database for synonyms. Thanks to Paul Fisher for resolving the problems with the XML Splitter by using an XPath statement to retrieve synonyms.",14, 2, String_Constant, XPath_From_Text, xpath, merge, parametersXML1, returnXML1, resultXML1, returnXML, parametersXML, getLiteEntity, split_search_list, String_Constant1, resultXML, getCompleteEntity, ,
"http://www.myexperiment.org/workflows/85/versions/2.html","ChEBI-get_synonyms","2007-11-1913:45:42","2007-11-1913:54:44","http://www.myexperiment.org/workflows/85/download/ChEBI-get_synonyms-v2.xml?version=2","/users/255","Sirisha Gollapudi","taverna 1","/users/255,","Sirisha Gollapudi,","This workflow takes a list of entity names separated by a newline and queries the ChEBI database for synonyms. Thanks to Paul Fisher for resolving the problems with the XML Splitter by using an XPath statement to retrieve synonyms.",14, 2, String_Constant, XPath_From_Text, xpath, merge, parametersXML1, returnXML1, resultXML1, returnXML, parametersXML, getLiteEntity, split_search_list, String_Constant1, resultXML, getCompleteEntity, ,
"http://www.myexperiment.org/workflows/90/versions/1.html","Multiple Blastp","2007-11-2016:58:38","2008-01-1012:09:38","http://www.myexperiment.org/workflows/90/download/Multiple_Blastp-v1.xml?version=1","/users/227","Kieren Lythgow","taverna 1","/users/227,","Kieren Lythgow,","This is a workflow to automate multiple BLASTp jobs on a large list of protein sequences in FASTA format.",7, 2, Database, searchSimple, Program, Split_string_into_list, Concatenate_two_strings, Regex, removeFirstCharacter, ,
"http://www.myexperiment.org/workflows/90/versions/2.html","Multiple Blastp","2007-11-2016:58:38","2008-01-1012:09:38","http://www.myexperiment.org/workflows/90/download/Multiple_Blastp-v2.xml?version=2","/users/227","Kieren Lythgow","taverna 1","/users/227,","Kieren Lythgow,","This is a workflow to automate multiple BLASTp jobs on a large list of protein sequences in FASTA format.",7, 1, Split_string_into_list, Concatenate_two_strings, Program, Regex, Database, searchSimple, Remove_first_character, ,
"http://www.myexperiment.org/workflows/92/versions/1.html","dreseden-term-extraction1","2007-11-2216:34:51","","","/users/20","Simon Jupp","taverna 1","/users/20,","Simon Jupp,",,
"http://www.myexperiment.org/workflows/95/versions/1.html","SifterWorkflow_Prod_Neu","2007-11-2316:42:24","2008-04-2910:37:12","http://www.myexperiment.org/workflows/95/download/SifterWorkflow_Prod_Neu-v1.xml?version=1","/users/88","Anika Joecker","taverna 1","/users/88,","Anika Joecker,",,10, 5, GetInAndOrthologsFromRefSeq, GetConservedDomainsFromFastaAlignment, buildMultipleAlignmentWithMAFFT, BuildPhylogeneticTreeFromFastaAlignment, Integer, String, gene_name, RunSifter, organism, AminoAcidSequence, ,
"http://www.myexperiment.org/workflows/95/versions/2.html","SifterWorkflow_Prod_Neu","2007-11-2316:42:24","2008-04-2910:37:12","http://www.myexperiment.org/workflows/95/download/SifterWorkflow_Prod_Neu-v2.xml?version=2","/users/88","Anika Joecker","taverna 1","/users/88,","Anika Joecker,","Phylogenomic workflow with SIFTER. The workflow first runs an iterative Blast search against the RefSeq database (Pruitt et al. 2007) (only fully sequenced organisms) and filters the results to get putative orthologous and in-paralogous proteins. These sequences are used to build a multiple alignment with MAFFT (Katoh et al. 2005). After filtering out alignment columns with more than 60% gaps, a phylogenetic tree is build. If there are less than 20 proteins in the alignment Phyml (Guindon and Gascuel 2003), a maximum likelihood approach, is used. For more than 20 proteins BioNJ (Gascuel et al. 1997), a neighbour joining method, is applied to speed up the pipeline. FORESTER (Zmasek and Eddy 2001) is called to reconcile the tree with the species tree, thereby annotating duplication and speciation nodes. Finally SIFTER is run to transfer Gene Ontology (The Gene Ontology Consortium 2000) terms inside the phylogenetic tree. Please use as inputs for organism the latin name with upper case letter in front: e.g. Medicago truncatula &nbsp;",10, 5, BuildPhylogeneticTreeFromFastaAlignment, buildMultipleAlignmentWithMAFFT, GetConservedDomainsFromFastaAlignment, GetInAndOrthologsFromRefSeq, organism, RunSifter, Integer, gene_name, String, AminoAcidSequence, ,
"http://www.myexperiment.org/workflows/97/versions/1.html","Download from ChemSpider using Accurate Mass","2007-11-2617:16:29","2008-02-0512:56:12","http://www.myexperiment.org/workflows/97/download/Download_from_ChemSpider_using_Accurate_Mass-v1.xml?version=1","/users/286","Egon Willighagen","taverna 1","/users/286,","Egon Willighagen,",,8, 2, SearchByMass, parametersXML, Mass_Range, Accurate_Mass, parametersXML1, GetCompoundDetails, parametersXML2, parametersXML3, ,
"http://www.myexperiment.org/workflows/97/versions/2.html","Download from ChemSpider using Accurate Mass","2007-11-2617:16:29","2008-02-0512:56:12","http://www.myexperiment.org/workflows/97/download/Download_from_ChemSpider_using_Accurate_Mass-v2.xml?version=2","/users/286","Egon Willighagen","taverna 1","/users/286,","Egon Willighagen,",,6, 2, parametersXML3, parametersXML1, parametersXML2, parametersXML, GetCompoundDetails, SearchByMass, ,
"http://www.myexperiment.org/workflows/98/versions/1.html","kegg_gene_to_swissprot_identifier","2007-11-2711:53:11","2007-11-2812:58:38","http://www.myexperiment.org/workflows/98/download/kegg_gene_to_swissprot_identifier-v1.xml?version=1","/users/255","Sirisha Gollapudi","taverna 1","/users/255,","Sirisha Gollapudi,","Takes a KEGG gene identifier, e.g. sce:YAL038W (yeast pyruvate kinase) and converts to the corresponding Swissprot identifier.",11, 1, get_linkdb_by_entry, returnXML, database, returnXML1, split, colon, extract, from, to, merge, merge1, ,
"http://www.myexperiment.org/workflows/100/versions/1.html","TestIterator","2007-11-2815:28:43","","http://www.myexperiment.org/workflows/100/download/TestIterator-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","Workflow to experiment with list iteration strategies. Look at metadata of nested workflow 'Concatenate' to see the current iteration strategy.",5, 0, create_numberListOfLists, String_Constant, create_letterListOfLists, Concatenate, create_capitalList, ,
"http://www.myexperiment.org/workflows/101/versions/1.html","Extract_GetCompoundDetails_with_xpath","2007-11-2815:46:02","2008-02-1915:35:47","http://www.myexperiment.org/workflows/101/download/Extract_GetCompoundDetails_with_xpath-v1.xml?version=1","/users/208","Stuart Owen","taverna 1","/users/208, /users/286,","Stuart Owen, Egon Willighagen,",,3, 1, GetCompoundDetails, XPath_From_Text, parametersXML2, ,
"http://www.myexperiment.org/workflows/102/versions/1.html","Fetch Dragon images from BioMoby v2","2007-11-2911:02:22","2007-11-2911:09:59","","/users/301","Mariebrown","taverna 1","/users/301,","Mariebrown,","Use the local java plugins and some filtering operations to fetch the comic strip image from  <a href=http://www.dilbert.com>http://www.dilbert.com</a>",
"http://www.myexperiment.org/workflows/103/versions/1.html","Fetch Dragon images from BioMoby v2","2007-11-2911:02:33","2007-11-2911:30:46","http://www.myexperiment.org/workflows/103/download/Fetch_Dragon_images_from_BioMoby_v2-v1.xml?version=1","/users/162","Yuwei Lin","taverna 1","/users/162, /users/16, /users/70,","Yuwei Lin, David De Roure, Jiten Bhagat,","Trivial workflow which will initially fail, retry twice then fall over to the alternative specified for the FailingThing process.",3, 0, FooString, BarString, FailingProcessor, ,
"http://www.myexperiment.org/workflows/103/versions/2.html","Fetch Dragon images from BioMoby v2","2007-11-2911:02:33","2007-11-2911:30:46","http://www.myexperiment.org/workflows/103/download/Fetch_Dragon_images_from_BioMoby_v2-v2.xml?version=2","/users/162","Yuwei Lin","taverna 1","/users/162, /users/16, /users/70,","Yuwei Lin, David De Roure, Jiten Bhagat,","Trivial workflow which will initially fail, retry twice then fall over to the alternative specified for the FailingThing process.",3, 0, FooString, BarString, FailingProcessor, ,
"http://www.myexperiment.org/workflows/103/versions/3.html","Fetch Dragon images from BioMoby v2","2007-11-2911:02:33","2007-11-2911:30:46","http://www.myexperiment.org/workflows/103/download/Fetch_Dragon_images_from_BioMoby_v2-v3.xml?version=3","/users/162","Yuwei Lin","taverna 1","/users/162, /users/16, /users/70,","Yuwei Lin, David De Roure, Jiten Bhagat,","Use the local java plugins and some filtering operations to fetch the comic strip image from  <a href=http://www.dilbert.com>http://www.dilbert.com</a>",7, 2, id, namespace, Decode_base64_to_byte, Parse_moby_data___updated__2006, getJpegFromAnnotatedImage, getDragonSimpleAnnotatedImages, Object, ,
"http://www.myexperiment.org/workflows/105/versions/1.html","TestIteratorStrategy_withNesting","2007-11-2915:31:32","","http://www.myexperiment.org/workflows/105/download/TestIteratorStrategy_withNesting-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18, /users/297,","Marco Roos, Tomoinn,","Implementation of the iteration workaround by Tom Oin conform the Q&A; below. The nested workflow 'NestedProcessor' is called that to conform to Tom's explanation. For an alternative solution using a java beanshell to clone list items see 'TestIteratorStrategy_withCloning. This workflow implements the following Q&A;: Marco Roos wrote: &gt; Dear Taverna user,&gt;&gt; Issue 1: Complex iteration&gt;&gt;     I would like to perform an iteration including a dot product between&gt;     a list and a list of lists; example: &gt;     Input: &gt;&gt;         [1]&gt;         [A,B,C]&gt;         [[a,b],[c,d],[e,f]]&gt;&gt;     Desired output: &gt;&gt;         [1Aa, 1Ab, 1Bc, 1Bd, 1Ce, 1Cf]&gt;&gt;     Is this possible? If so, how can I achieve this? Yes, but not directly. This is actually the reason for the new T2 feature called 'staged iteration'. The issue is that assuming you iterate down to single items (which appears to be the case) you want to go half way with a dot product and then use a cross product. As the iteration strategies always (in the current code) drill down to the final thing you're asking for you can't do this, at least you can't do it without a trick... So... the trick : First off the [1] is a red herring, that's the easy bit! it doesn't matter where you put that in as it'll always be added onto every single job. So you now have a list and a list of lists, you want to combine item 'n' in the first list with all the items of list 'n' in the second. Firstly you'll need a nested workflow into which you put your processor, the trick being that you also put in an 'echo list' operation. Connect the echo list output to the input of your processor being fed needing the list of lists and the echo list input to a workflow input. Connect the other input (the list) of your processor to a workflow input. The workflow inputs will have type of 'single item' and 'list' as the workflow inputs copy the types of the inputs they're connected to. It should be obvious that if you give this nested workflow the inputs 'A' and [a,b] it'll iterate and give you [f(A*a),f(A*b]. Also note that now the nested workflow mismatches by the same level on both inputs - it has one input with a single item type which you'll feed it a list and another of a list where you feed it a list of lists. This means you can set a dot iteration strategy over the nested workflow with the cross product (default) iteration strategy over the processor within it. This nested workflow will now produce the result you want; it will be called three times with : [A*[a,b], B*[c,d], C*[e,f]] Each one of these then creates a cross product iteration within the nested workflow, so the output is : [f(A*a),f(A*b)],[f(B*c),f(B*d)],[f(C*e),f(C*f)]] Passing the output through a list flatten operation then gives you (leaving out the 'F(x)' and replacing with 'x') : [Aa,Ab,Bc,Bd,Ce,Cf] which is what I believe you wanted? :) Adding the [1] bit in is easy from there! We actually did this exact thing some time ago for Paul, he had a structure he was viewing as two lists of directories where the lists were the same length but the directories could have any number of items in, he wanted a comparison between every item in directory 'n' from list 1 and every item in directory 'n' from list 2. Hope that helps, if you were wondering why we have a superficially pointless 'echo list' local worker now you know :) Tom",6, 0, String_Constant, create_letterListOfLists, create_capitalList, Count1, Count2, Concatenate, ,
"http://www.myexperiment.org/workflows/106/versions/1.html","CloneItemsInList","2007-11-2915:34:52","","http://www.myexperiment.org/workflows/106/download/CloneItemsInList-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","Utility workflow that clones an item copy_number times. You can use this to work around standard iteration strategies, e.g. in combination with the CountListItems workflow. Workflow examples: TestIterationStrategy_withClones. For an alternative approach see TestIterationStrategy_withNesting. Example I/O: input: Acopy_number: 3result: [A,A,A] input: [A,B,C]copy_number: 3result: [[A,A,A][B,B,B][C,C,C]] input: [A,B,C]copy_number: [3,2]result: [[[A,A,A],[A,A]][[B,B,B],[B,B]],[[C,C,C],[C,C]]] input: [A,B,C]copy_number: [3,2,1]iteration strategy: dot productresult: [[A,A,A],[B,B],[C]]",1, 0, Clone, ,
"http://www.myexperiment.org/workflows/107/versions/1.html","TestIteratorStrategy_withCloning","2007-11-2915:35:48","2007-11-2915:40:30","http://www.myexperiment.org/workflows/107/download/TestIteratorStrategy_withCloning-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","This workflow implements a strategy for this problem: &gt; I would like to perform an iteration including a dot product between&gt;     a list and a list of lists; example: &gt;     Input: &gt;&gt;         [1]			(1)&gt;         [A,B,C]		(2)&gt;         [[a,b],[c,d],[e,f]]		(3)&gt;&gt;     Desired output: &gt;&gt;         [1Aa, 1Ab, 1Bc, 1Bd, 1Ce, 1Cf] In this implementation a java beanshell is used to clone the items in list 2 as many times per item as there are items in the sublists of list 3. The iteration strategy for Clone is set top dot product.Thus a count on list 2 produces: [2,2,2]Clone with input: [2,2,2] . [A,B,C] produces [[A,A],[B,B],[C,C]] (note the dot product) (4)Then concatenation of (1)*((4).(3)) produces: [[1Aa,1Ab],[1Bc,1Bd],[1Ce,1Cf]]",7, 0, create_capitalList, String_Constant, create_ListOfLists, Count2, Count1, Concatenate, Clone, ,
"http://www.myexperiment.org/workflows/107/versions/2.html","TestIteratorStrategy_withCloning","2007-11-2915:35:48","2007-11-2915:40:30","http://www.myexperiment.org/workflows/107/download/TestIteratorStrategy_withCloning-v2.xml?version=2","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","This workflow implements a strategy for this problem: &gt; I would like to perform an iteration including a dot product between&gt;     a list and a list of lists; example: &gt;     Input: &gt;&gt;         [1]			(1)&gt;         [A,B,C]		(2)&gt;         [[a,b],[c,d],[e,f]]		(3)&gt;&gt;     Desired output: &gt;&gt;         [1Aa, 1Ab, 1Bc, 1Bd, 1Ce, 1Cf] In this implementation a java beanshell is used to clone the items in list 2 as many times per item as there are items in the sublists of list 3. The iteration strategy for Clone is set to a dot product.Thus a count on list 2 produces: [2,2,2]Clone with input: [2,2,2] . [A,B,C] produces [[A,A],[B,B],[C,C]] (note the dot product) (4)Then concatenation of (1)*((4).(3)) produces: [[1Aa,1Ab],[1Bc,1Bd],[1Ce,1Cf]]",7, 0, create_capitalList, String_Constant, create_ListOfLists, Count2, Count1, Concatenate, Clone, ,
"http://www.myexperiment.org/workflows/109/versions/1.html","DataBiNS - Data Mining Workflow for Biological Pathways and Non-Synonymous SNPs","2007-12-0423:43:01","2007-12-0423:45:25","http://www.myexperiment.org/workflows/109/download/DataBiNS_-_Data_Mining_Workflow_for_Biological_Pathways_and_Non-Synonymous_SNPs-v1.xml?version=1","/users/275","Fong Chun Chan","taverna 1","/users/275,","Fong Chun Chan,","DataBiNS (Data Mining Workflow for Biological Pathways and Non-Synonymous SNPs)  is a workflow that takes an identifier (list of gene ids, or list of KEGG pathway ids) and proceeds to mine for Single Nucleotide Polymorphism (SNP) data that is associated with the identifiers. This particular variation of DataBiNS can take in several gene identifiers.  The version of DataBiNS that takes in a KEGG pathway id can be found as a separate workflow on myExperiment.  The identifers can be from the following sources: 1) KEGG (Kyoto Encyclopedia of Genes and Genomes)2) OMIM (Online Mendelian Inheritance in Man)3) PMID (Pubmed Identifier)4) UniGene5) UniProt6) GenBank7) NCBI_gi When entering the inputs for the workflow, enter the id in the id input, and the source of the identifer into the namespace.  The source name must be EXACTLY the same name as the mentioned above.  So for example, searching by kegg id hsa:10, the namespace input must be KEGG.  Searching by OMIM id 603028, the namespace must be OMIM, etc. etc.  See also the related workflow on KEGG pathway id.",31, 12, Entrez_NS, Remove_duplicate_strings, Remove_duplicate_strings2, entrez_gene_id_list_flatter, entrez_gene_list_flatter2, Parse_Moby_Data_Swiss_Prot, Parse_Moby_Data_Frequencies, Parse_Moby_Data_nsSNP, Parse_Moby_Data_GO_Term, convertSnp2EntrezGeneID, Parse_Moby_Data_pdb_id, convertKeggGeneId2ProtId, Gene2PubMed, convertKeggGeneId2PDBId, getGeneInformationByEntrezGeneID, Gene2Ontology, getSnpsBySwissProtId, PDB_id2RasMolScript, Parse_Moby_Data_Kegg, snp2Frequencies, convertIdentifier2KeggID, getEntryFromPDB, Parse_Moby_Data_Publication, getBase64SnpFrequencyImage, Parse_Moby_Data_rasmol, CreateMobyObject, Parse_Moby_Data_gene_ref, CreateEntrezGeneDataType, Parse_Moby_Data_b64_Encoded_PNG, Parse_Moby_Data_PDB_Text, Parse_Moby_Data_entrez_gene, ,
"http://www.myexperiment.org/workflows/109/versions/2.html","DataBiNS - Data Mining Workflow for Biological Pathways and Non-Synonymous SNPs","2007-12-0423:43:01","2007-12-0423:45:25","http://www.myexperiment.org/workflows/109/download/DataBiNS_-_Data_Mining_Workflow_for_Biological_Pathways_and_Non-Synonymous_SNPs-v2.xml?version=2","/users/275","Fong Chun Chan","taverna 1","/users/275,","Fong Chun Chan,",,32, 12, KEGG_NS, Entrez_NS, entrez_gene_id_list_flatter, Remove_duplicate_strings, entrez_gene_list_flatter2, Remove_duplicate_strings2, Parse_Moby_Data_nsSNP, Parse_Moby_Data_GO_Term, getGeneInformationByEntrezGeneID, Gene2Ontology, Parse_Moby_Data_Frequencies, Parse_Moby_Data_entrez_gene, getSnpsBySwissProtId, convertKeggGeneId2PDBId, getBase64SnpFrequencyImage, Parse_Moby_Data_Publication, Parse_Moby_Data_Swiss_Prot, getEntryFromPDB, convertSnp2EntrezGeneID, Parse_Moby_Data_pdb_id, snp2Frequencies, getKeggIdsByKeggPathway, Gene2PubMed, convertKeggGeneId2ProtId, Parse_Moby_Data_kegg_gene, Parse_Moby_Data_rasmol, CreateEntrezGeneDataType, Parse_Moby_Data_gene_ref, Parse_Moby_Data_b64_Encoded_PNG, CreateKeggPathwayDataType, Parse_Moby_Data_PDB_Text, PDB_id2RasMolScript, ,
"http://www.myexperiment.org/workflows/111/versions/1.html","Discover_entities","2007-12-1021:48:33","2007-12-1022:54:42","http://www.myexperiment.org/workflows/111/download/Discover_entities-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18, /users/343,","Marco Roos, Sophia katrenko,","This workflow contains the 'Named Entity Recognize' web service from the AIDA toolbox, created by Sophia Katrenko. It can be used to discover entities of a certain type (determined by 'learned_model') in documents provided in a lucene output format. Known issues: The output of NErecognize contains concepts with / characters, breaking the xml. For post-processing its results it is better to use string manipulation than xml manipulations.The output is per document, which means entities will  be redundant if they occur in more than one document.",3, 1, Default_input_type, NErecognize, Default_output_type, ,
"http://www.myexperiment.org/workflows/111/versions/2.html","Discover_entities","2007-12-1021:48:33","2007-12-1022:54:42","http://www.myexperiment.org/workflows/111/download/Discover_entities-v2.xml?version=2","/users/18","Marco Roos","taverna 1","/users/18, /users/343,","Marco Roos, Sophia katrenko,","This workflow contains the 'Named Entity Recognize' web service from the AIDA toolbox, created by Sophia Katrenko. It can be used to discover entities of a certain type (determined by 'learned_model') in documents provided in a lucene output format. Known issues: The output of NErecognize contains concepts with / characters, breaking the xml. For post-processing its results it is better to use string manipulation than xml manipulations.The output is per document, which means entities will  be redundant if they occur in more than one document.",3, 1, Default_output_type, Default_input_type, NErecognize, ,
"http://www.myexperiment.org/workflows/113/versions/1.html","Extract_proteins","2007-12-1022:10:51","2007-12-1022:30:53","http://www.myexperiment.org/workflows/113/download/Extract_proteins-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","This workflow filters protein_molecule-labeled terms from an input string(list). The result is a tagged list of proteins (disregarding false positives in the input). Internal information: This workflow is a copy of 'filter_protein_molecule_MR3' used for the NBIC poster (now in Archive).",11, 1, splitOn_protein_molecule_regexp, Remove_duplicate_strings, SplitOn_protein_molecule, filter_protein_molecule_regexp, Filter2, UniProtOrNot, getUniprotID, Filter_protein_molecules, FilterTrueProteinByUniProtID, Filter1, Strip_xml, ,
"http://www.myexperiment.org/workflows/113/versions/2.html","Extract_proteins","2007-12-1022:10:51","2007-12-1022:30:53","http://www.myexperiment.org/workflows/113/download/Extract_proteins-v2.xml?version=2","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","This workflow filters protein_molecule-labeled terms from an input string(list). The result is a tagged list of proteins (disregarding false positives in the input). Internal information: This workflow is a copy of 'filter_protein_molecule_MR3' used for the NBIC poster (now in Archive).",11, 1, splitOn_protein_molecule_regexp, Remove_duplicate_strings, Filter2, SplitOn_protein_molecule, filter_protein_molecule_regexp, UniProtOrNot, Filter_protein_molecules, FilterTrueProteinByUniProtID, getUniprotID, Filter1, Strip_xml, ,
"http://www.myexperiment.org/workflows/114/versions/1.html","Flatten_and_make_unique","2007-12-1022:12:00","","http://www.myexperiment.org/workflows/114/download/Flatten_and_make_unique-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,",,2, 0, Remove_duplicate_strings, Flatten_list, ,
"http://www.myexperiment.org/workflows/115/versions/1.html","Link_protein_to_OMIM_disease","2007-12-1022:13:35","","http://www.myexperiment.org/workflows/115/download/Link_protein_to_OMIM_disease-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,",,8, 1, Flatten_list, Split_OMIM_results, Remove_duplicate_strings, Extract_diseases_from_OMIM, search, filter_disease_regexp, split_OMIM_regexp, label_OMIM_disease, ,
"http://www.myexperiment.org/workflows/116/versions/1.html","Lucene_bioquery_optimizer_MR1","2007-12-1022:14:26","","http://www.myexperiment.org/workflows/116/download/Lucene_bioquery_optimizer_MR1-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","This workflow does four things: <ol><li>it retrieves documents relevant for the query string</li><li>it discovers entities in those documents, these are considered relevant entities</li><li>it filters proteins from those entities (on the tag protein_molecule)</li><li>it removes all terms from the list produced by 3 (query terms temporarily considered proteins)</li></ol> ToDo <ul><li>Replace step 4 by the following procedure:</li></ul> 1. remove the query terms from the output of NER (probably by a regexp matching on what is inside the tag, possibly case-insensitive)2. remove tag_as_protein_molecule (obsolete) <ul><li>Add synonym service/workflow</li></ul> Note that Remove_inputquery has an alternative iteration strategy (dot product instead of cross product). Idem for 'Join' in 'SplitQuery'.",2, 0, Lucene_year_priorities, Prioritise_lucene_query, ,
"http://www.myexperiment.org/workflows/117/versions/1.html","Retrieve_bio_documents","2007-12-1022:15:54","2007-12-1022:45:49","http://www.myexperiment.org/workflows/117/download/Retrieve_bio_documents-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18, /users/231,","Marco Roos, Edgar,","This workflow retrieves relevant documents, based on a query optimized by adding a string to the original query that will rank the search output according to the most recent years. The added string adds years with priorities (most recent is highest); it starts at 2007.",2, 0, Biooptimize_query, Retrieve, ,
"http://www.myexperiment.org/workflows/117/versions/2.html","Retrieve_bio_documents","2007-12-1022:15:54","2007-12-1022:45:49","http://www.myexperiment.org/workflows/117/download/Retrieve_bio_documents-v2.xml?version=2","/users/18","Marco Roos","taverna 1","/users/18, /users/231,","Marco Roos, Edgar,","This workflow retrieves relevant documents, based on a query optimized by adding a string to the original query that will rank the search output according to the most recent years. The added string adds years with priorities (most recent is highest); it starts at 2007.",2, 0, Retrieve, Biooptimize_query, ,
"http://www.myexperiment.org/workflows/118/versions/1.html","Retrieve_documents_MR1","2007-12-1022:17:00","","http://www.myexperiment.org/workflows/118/download/Retrieve_documents_MR1-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18, /users/231,","Marco Roos, Edgar,","This workflow applies the search web service from the AIDA toolbox. Comments: This search service is based on lucene defaults; it may be necessary to optimize the querystring to adopt the behaviour to what is most relevant in a particular domain (e.g. for medline prioritizing based on publication date is useful). Lucene favours shorter sentences, which may be bad for subsequent information extraction.",1, 1, search, ,
"http://www.myexperiment.org/workflows/119/versions/1.html","Demo_DiseaseDiscovery_byHumanUniprot_scaffold","2007-12-1023:10:00","","http://www.myexperiment.org/workflows/119/download/Demo_DiseaseDiscovery_byHumanUniprot_scaffold-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18,","Marco Roos,","This workflow finds disease relevant to the query string via the following steps: <ol><li>A user query: a list of terms or boolean query - look at the Apache Lucene project for all details. E.g.: (EZH2 OR Enhancer of Zeste +(mutation chromatin) -clinical); consider adding 'ProteinSynonymsToQuery' in front of the input if your query is a protein.</li><li>Retrieve documents: finds 'maximumNumberOfHits' relevant documents (abstract+title) based on query (the AIDA service inside is based on Apache's Lucene)</li><li>Discover proteins: extract proteins discovered in the set of relevant abstracts with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe. This subworkflow also 'filters' false positives from the discovered protein by requiring a discovery has a valid UniProt ID. Martijn Schuemie's service to do that contains only human UniProt IDs, which is why this workflow only works for human proteins.</li><li>Link proteins to disease contained in the OMIM disease database (with a service from Japan that interrogates OMIM)</li></ol> Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org>http://adaptivedisclosure.org</a> ) Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam).OMIM service from the Center for Information Biology and DNA Data Bank of Japan, National Institute of Genetics, director Hideaki Sugawara (see  <a href=http://xml.nig.ac.jp>http://xml.nig.ac.jp</a> ) Changes to our original BioAID_DiseaseDiscovery workflow: * Use of Martijn Schuemie's synsets service to* provide uniprot ids to discovered proteins* filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)* solve a major issue with the original workflow where some false positives could contribute disproportionately to the number of discovered diseases* Counting of results in various ways.",5, 0, Document_index, search_field, CountDiseasesPerProtein, CountDiseases, CountProteins, ,
"http://www.myexperiment.org/workflows/120/versions/1.html","EBI Blast","2007-12-1201:07:45","2008-01-1514:41:32","http://www.myexperiment.org/workflows/120/download/EBI_Blast-v1.xml?version=1","/users/345","George","taverna 1","","",,9, 3, WSArrayofDataXML, contentXML, poll, pollXML, params, runWUBlast, Byte___to_String, Byte___to_String1, checkStatusWorkflow, ,
"http://www.myexperiment.org/workflows/122/versions/1.html","iteration-test","2007-12-1811:39:49","","","/users/208","Stuart Owen","taverna 1","/users/208,","Stuart Owen,",,
"http://www.myexperiment.org/workflows/124/versions/1.html","Workflow for Protein Sequence Analysis","2008-01-0912:03:03","2008-01-0912:31:27","http://www.myexperiment.org/workflows/124/download/Workflow_for_Protein_Sequence_Analysis-v1.xml?version=1","/users/411","M.B.Mon...","taverna 1","/users/411,","M.B.Monteiro,","This workflow performs a generic protein sequence analysis. In order to do that a novel protein sequence enters into the software along with a list of known protein identifiers chosen by the biologist to perform a homology search, followed by a multiple sequence alignment and finally a phylogenetic analysis.",28, 8, Fail_if_false_DNA, Fail_if_false_Protein, Not_Protein_Sequence, Get_Protein_FASTA, Is_DNA_RNA, Fail_if_true_Protein, FlattenImage, Fail_if_true_DNA, Split_by_newline, MergeString, MergeUserList, Condition_Protein, toLowerCase, extract_number_sequences, Extract_Duplicates, insert_query_seq, Extract_GI_Evalue, Setting_fasta, Extract_Seq_Description, Condition_DNA_RNA, blastsimplifier, fdrawgram, fprotdist, fneighbor, fdrawtree, prettyplot, ClustalW, searchSimple, ,
"http://www.myexperiment.org/workflows/126/versions/1.html","casimir_paper","2008-01-2216:22:26","2008-05-3014:40:41","http://www.myexperiment.org/workflows/126/download/casimir_paper-v1.xml?version=1","/users/469","Damian","taverna 1","/users/469,","Damian,","This workflow first of all recovers Ensembl Gene IDs, Embl IDs and genomic coordinates from a BioMart mouse genome query. The Embl IDs are converted into KEGG Gene IDs and subsequent KEGG Pathway IDs using KEGG webservices. URLs to the pathways diagrams at KEGG are also recovered as well as a merged output of the ensembl gene ID, embl ID and KEGG pathway ID.  The other branch of the workflow recovers SNPs for the genes and SNP variations per mouse mouse strain using a MOLGENIS variant wrapper around the Mouse Phenome Database (MPD). See  <a href=http://www.myexperiment.org/files/31>http://www.myexperiment.org/files/31</a>  for the MOLGENIS DSL definition of MPD used to generate the services used in this workflow &nbsp;",6, 0, mmusculus_gene_ensembl, mouse_embl_ids, MergeShell, Nested_Workflow, Flatten_list, Merge_string_list_to_string, ,
"http://www.myexperiment.org/workflows/126/versions/2.html","casimir_paper","2008-01-2216:22:26","2008-05-3014:40:41","http://www.myexperiment.org/workflows/126/download/casimir_paper-v2.xml?version=2","/users/469","Damian","taverna 1","/users/469,","Damian,",,18, 0, flattenList1, flattenList2, mergeStringListToString3, removeDupResults, flatten_list3, flattenList4, splitStringByRegularExpression, mergeStringListToString1, mergeStringListToString2, beanshellMergeSnps, convBpToMb, convBbToMb2, beanshellMergePathways, beanshellCleanResults, mouseEmblBioMart, mouseEnsemblBioMart, pathways, snpAlleles, ,
"http://www.myexperiment.org/workflows/127/versions/1.html","VLAM","2008-01-2314:57:16","2008-01-2315:02:57","","/users/472","Wibisono","taverna 1","/users/472,","Wibisono,","This is an experimental workflow for testing interoperability with WS VLAM workflow engine. Bean Shell Script processor is used to invoke existing WS-VLAM Topology(Workflow) which obtains parameters from previous processors in taverna.",
"http://www.myexperiment.org/workflows/128/versions/1.html","casimir_htgt","2008-01-2411:08:05","2008-01-2411:10:27","","/users/469","Damian","taverna 1","/users/469,","Damian,","An update to the original casimir workflow. This now utilises the high throughput gene trapping biomart server that has just gone live at the Sanger which allows filtering on which genes have been selected for the various gene KO projects and which stage in the mouse KO strain production each gene has reached",
"http://www.myexperiment.org/workflows/133/versions/1.html","Fetch PDB flatfile from RCSB server","2008-01-2511:52:38","2008-03-0516:11:13","http://www.myexperiment.org/workflows/133/download/Fetch_PDB_flatfile_from_RCSB_server-v1.xml?version=1","/users/13","Katy Wolstencroft","taverna 1","/users/13,","Katy Wolstencroft,","Given aPDB identifier such as '1crn', this workflow fetches the PDB format flatfile from the RCSB",5, 0, RCSBSuffix, RCSBPrefix, FetchPage, AddSuffix, AddPrefixToID, ,
"http://www.myexperiment.org/workflows/134/versions/1.html","untitled","2008-01-2806:05:36","","","/users/478","Agbiotec","taverna 1","/users/478,","Agbiotec,",,
"http://www.myexperiment.org/workflows/138/versions/1.html","ExampleWorkflow1","2008-02-0414:19:24","2008-02-0415:52:46","http://www.myexperiment.org/workflows/138/download/ExampleWorkflow1-v1.xml?version=1","/users/83","Andy Turner","taverna 1","/users/13,","Katy Wolstencroft,","This version probably doesn't work. The last part of the tutorial I was following I think I did wrong so....",6, 3, Get_Protein_FASTA, searchSimple, database, program, pscan, patmatmotifs, ,
"http://www.myexperiment.org/workflows/138/versions/2.html","ExampleWorkflow1","2008-02-0414:19:24","2008-02-0415:52:46","http://www.myexperiment.org/workflows/138/download/ExampleWorkflow1-v2.xml?version=2","/users/83","Andy Turner","taverna 1","/users/13,","Katy Wolstencroft,","This workflow was created based on the Leeds Taverna Workshop 2008-02-04 material developed by Katy.",6, 3, Get_Protein_FASTA, searchSimple, database, program, pscan, patmatmotifs, ,
"http://www.myexperiment.org/workflows/140/versions/1.html","Success-Abandonment-Classification","2008-02-0614:35:41","2008-07-0217:15:25","http://www.myexperiment.org/workflows/140/download/Success-Abandonment-Classification-v1.xml?version=1","/users/384","Andrea Wiggins","taverna 1","/users/384, /users/550,","Andrea Wiggins, James Howison,","This is a draft of an analysis workflow to replicate the Free/Libre Open Source Software project classification analysis from English &amp; Schweik. The workflow is not yet functional. The original research uses a selection of FLOSS project metrics to classify projects as successes or abandonments in their initial or growth phases.&nbsp; Translation of the original classification as described in the paper to a workflow analysis requires some modification of the way criteria are applied to achieve exhaustiveness. In addition, this version of the analysis parameterizes all of the classification criteria to enable exploration of different threshold values. The main aspects of the workflow that are currently incomplete are data selection and code for the classifier component. Unincorporated progress on workflow development includes&nbsp; some SQL queries for data selection and a reformulated classification criteria set.&nbsp; Assumptions include using a month unit for all time-based criteria, and restriction of classification to the six classes from the original paper.&nbsp; Desired output will be a CSV that will include all derived metrics used for classification as well as an indicator of the specific combination of metrics that results in the final classification, as there are multiple combinations of metrics that can result in any given classification. Extended development of the workflow will incorporate additional RServe components to provide in-depth analysis of the classified data. &nbsp; English, R. and Schweik, C.M. 2007. &quot;Identifying Success and Tragedy of Free/Libre and Open Source (FLOSS) Commons: A Preliminary Classification of Sourceforge.net projects.&quot; Paper accepted for the First International Workshop on Emerging Trends in FLOSS Research and Development that is part of the 29th Int. Conference on Software Engineering. May 21st, 2007. <a href=http://people.umass.edu/cschweik/pdfs/English_Schweik_FLOSS_Classification.pdf>http://people.umass.edu/cschweik/pdfs/English_Schweik_FLOSS_Classification.pdf</a>",9, 0, initiation_age_threshold, mortality_threshold, download_threshold, release_recency_threshold, release_lag_threshold, Fetch_Data, Assemble_Data, Classification, Compute_Project_Stats, ,
"http://www.myexperiment.org/workflows/140/versions/2.html","Success-Abandonment-Classification","2008-02-0614:35:41","2008-07-0217:15:25","http://www.myexperiment.org/workflows/140/download/Success-Abandonment-Classification-v2.xml?version=2","/users/384","Andrea Wiggins","taverna 1","/users/384, /users/550,","Andrea Wiggins, James Howison,","Retrieves data from FLOSSmole and from the Notre Dame SourceForge repository to compute project statistics based on releases, downloads and project lifespan. Project statistics are then used to classify projects according to the criteria set up in English &amp; Schweik, but comparison criteria are parameterized so that a different set of criterion thresholds can be used to evaluate the project characteristics.",13, 0, Class_Analysis, delist_classtypes, release_lag_threshold, release_recency_threshold, release_count_threshold, Stages_Analysis, delist_stages, initiation_age_threshold, release_rate_type, mortality_threshold, download_threshold, Classification, GetData, ,
"http://www.myexperiment.org/workflows/140/versions/3.html","Success-Abandonment-Classification","2008-02-0614:35:41","2008-07-0217:15:25","http://www.myexperiment.org/workflows/140/download/Success-Abandonment-Classification-v3.xml?version=3","/users/384","Andrea Wiggins","taverna 1","/users/384, /users/550,","Andrea Wiggins, James Howison,","Retrieves data from FLOSSmole and from the Notre Dame SourceForge repository to compute project statistics based on releases, downloads and project lifespan. Project statistics are then used to classify projects according to the criteria set up in English &amp; Schweik, but comparison criteria are parameterized so that a different set of criterion thresholds can be used to evaluate the project characteristics.",18, 0, mortality_threshold, release_lag_threshold, download_threshold, initiation_age_threshold, release_rate_type, release_count_threshold, delist_classtypes, delist_stages, Stages_Analysis, classifier, classification_csv, Class_Analysis, release_count_test, growth_stage_test, release_lag_test, downloads_test, mortality_test, GetData, ,
"http://www.myexperiment.org/workflows/142/versions/1.html","Microarray CEL file to candidate pathways","2008-02-0814:17:23","2009-02-1311:29:52","","/users/43","Paul Fisher","taverna 1","/users/43, /users/567,","Paul Fisher, Saeedeh,","This workflow takes in a CEL file and a normalisation method then returns a series of images/graphs which represent the same output obtained using the MADAT software package (MicroArray Data Analysis Tool) [ <a href=http://www.bioinf.manchester.ac.uk/MADAT/index.html>http://www.bioinf.manchester.ac.uk/MADAT/index.html</a> ]. Also retruned by this workflow are a list of the top differentialy expressed genes (size dependant on the number specified as input - geneNumber), which are then used to find the candidate pathways which may be influencing the observed changes in the microarray data. By identifying the candidate pathways, more detailed insights into the gene expression data can be obtained.  NOTE - You will also need to install R and Rserv on your machine and install the libaries required by the R script into you R library directory, see for basic info: www. cs. man. ac. uk/ ~fisherp/ rlib.html &nbsp; The example inputs for this workflow are as follows: Samples1 = one or more CEL files for cross-correlating with Samples2 CEL files (new line separated):  Liver_Day1_Mouse.CEL Liver_Day2_Mouse.CEL  Samples2 = one or more CEL files for cross-correlating with Samples1 CEL files (new line separated): Kideny_Day1_Mouse.CEL Kidney_Day2_Mouse.CEL  geneNumber = the number of differentialy expressed gene to be returned above a given p-value, e.g. 20 arrayTypeAffy = the name of the Mouse AffyMetrix array used, e.g. mouse4302 path = the direct path to the CEL file location, e.g. C:/Microarray_Data/CEL_FILES/ - note the forward slashes NormalizationMethod = the type of normalisation to perfrom, e.g. rma, gcrma or mmgmos testMethod = e.g. limma, mmtest or pplr p-value = the p-value cut-off value for the array data, e.g. 0.05 foldChange = the fold change value for the microarray data, e.g. 1 (means greater than 1 or less than -1)",
"http://www.myexperiment.org/workflows/142/versions/2.html","Microarray CEL file to candidate pathways","2008-02-0814:17:23","2009-02-1311:29:52","","/users/43","Paul Fisher","taverna 1","/users/43, /users/567,","Paul Fisher, Saeedeh,","This workflow takes in a CEL file and a normalisation method then returns a series of images/graphs which represent the same output obtained using the MADAT software package (MicroArray Data Analysis Tool)  <a href=http://www.bioinf.manchester.ac.uk/MADAT/index.html>http://www.bioinf.manchester.ac.uk/MADAT/index.html</a> . Also retruned by this workflow are a list of the top differentialy expressed genes (size dependant on the number specified as input - geneNumber), which are then used to find the candidate pathways which may be influencing the observed changes in the microarray data. By identifying the candidate pathways, more detailed insights into the gene expression data can be obtained. NOTE - You will also need to install R and Rserv on your machine and install the libaries required by the R script into you R library directory. For basic info:  <a href=http://www.cs.man.ac.uk/~fisherp/rlib.html>http://www.cs.man.ac.uk/~fisherp/rlib.html</a> . The example inputs for this workflow are as follows: Samples1 = one or more CEL files for cross-correlating with Samples2 CEL files (new line separated): Liver_Day1_Mouse.CEL Liver_Day2_Mouse.CEL Samples2 = one or more CEL files for cross-correlating with Samples1 CEL files (new line separated): Kideny_Day1_Mouse.CEL Kidney_Day2_Mouse.CEL geneNumber = the number of differentialy expressed gene to be returned above a given p-value, e.g. 20 arrayTypeAffy = the name of the Mouse AffyMetrix array used, e.g. mouse4302 path = the direct path to the CEL file location, e.g. C:\Microarray_Data\CEL_FILES\ - note the forward slashes NormalizationMethod = the type of normalisation to perfrom, e.g. rma, gcrma or mmgmos testMethod = e.g. limma, mmtest or pplr p-value = the p-value cut-off value for the array data, e.g. 0.05 foldChange = the fold change value for the microarray data, e.g. 1 (means greater than 1 or less than -1)",
"http://www.myexperiment.org/workflows/143/versions/1.html","Human Microarray Analysis","2008-02-0814:30:17","2009-12-0316:50:29","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow takes in probesets from and AffyMetrix&nbsp; Affy HG U133A micorarray experiment and returns: genes ; gene start and end positions; chromosome where genes reside; ensembl trasncripts; SwissProt ids. The final output of the workflow is a list of candidate pathways which are linked to the genes expressed in the microarray data. &nbsp; Example input for this workflow is: 212283_at 221634_at 220399_at &nbsp;",
"http://www.myexperiment.org/workflows/144/versions/1.html","FLOSS Communication Centralization Plot, Exponentially Weighted","2009-02-0718:50:44","","http://www.myexperiment.org/workflows/144/download/FLOSS_Communication_Centralization_Plot__Exponentially_Weighted-v1.xml?version=1","/users/384","Andrea Wiggins","taverna 1","/users/384, /users/551, /users/550,","Andrea Wiggins, Crowston, James Howison,","The analysis in this workflow represents the basis of the analysis in our paper,  <a href=http://floss.syr.edu/StudyP/>Social dynamics of FLOSS team communication across channels</a> . This workflow uses WSDL components to select periodized data from the FLOSSmole database and generate sociomatrices. The workflow parses the threaded list structure into a communication network based on reply-to relationships.&nbsp; In the analysis process, an edge weighting is applied so that older messages receive less weight using an exponential decay function; this is intended to moderate the effects of using a sliding window of observations for dynamic analysis. The weighted sociomatrices are then dichotomized according to a threshold, and their centralities are calculated using R's sna package, and plotted in a time series. The final output demonstrates communication centralization trends over time in a FLOSS project. The analysis workflow allows users to set parameter values for the size of the sliding window, the date ranges covered, and the communication venues analyzed.&nbsp; Data for the analysis in the paper examined dynamics in different communication channels; the data sets included up to 90 periods (with a 90-day sliding window) and 10K's of email messages or forum posts. Date periods are currently only in months, and exception handling for empty periods is implemented both in the WSDL components and the RShell scripts. There are a couple of inelegant solutions involving temporary output files, which are configured based on a standard Mac file structure. Future development effort could focus on solving these issues and on optimizing performance.",22, 3, Calculate_weight, step, delist_dates, Calculate_Centralization, Centralization_Plot, delist_from, Split_to_single_events, delist_to, Remove_duplicate_strings, Extract_To, delist_period_end, Extract_period_end, Extract_From, split_periods, GetPeriods, EventsForProjectsInPeriod, MatrixBuilderR, MergeProjectNames, delist_period_start, delist_event_date, Extract_period_start, Extract_event_date, ,
"http://www.myexperiment.org/workflows/144/versions/2.html","FLOSS Communication Centralization Plot, Exponentially Weighted","2009-02-0718:50:44","","http://www.myexperiment.org/workflows/144/download/FLOSS_Communication_Centralization_Plot__Exponentially_Weighted-v2.xml?version=2","/users/384","Andrea Wiggins","taverna 1","/users/384, /users/551, /users/550,","Andrea Wiggins, Crowston, James Howison,",,22, 3, step, delist_from, delist_period_start, MergeProjectNames, delist_to, delist_event_date, delist_period_end, delist_dates, Remove_duplicate_strings, Extract_period_end, Extract_From, Centralization_Plot, Calculate_Centralization, Split_to_single_events, Extract_period_start, Extract_event_date, Extract_To, Calculate_weight, split_periods, EventsForProjectsInPeriod, MatrixBuilderR, GetPeriods, ,
"http://www.myexperiment.org/workflows/144/versions/3.html","FLOSS Communication Centralization Plot, Exponentially Weighted","2009-02-0718:50:44","","http://www.myexperiment.org/workflows/144/download/FLOSS_Communication_Centralization_Plot__Exponentially_Weighted-v3.xml?version=3","/users/384","Andrea Wiggins","taverna 1","/users/384, /users/551, /users/550,","Andrea Wiggins, Crowston, James Howison,","The analysis in this workflow represents the basis of the analysis in our paper, Social dynamics of FLOSS team communication across channels. This workflow uses WSDL components to select periodized data from the FLOSSmole database and generate sociomatrices. The workflow parses the threaded list structure into a communication network based on reply-to relationships.  In the analysis process, an edge weighting is applied so that older messages receive less weight using an exponential decay function; this is intended to moderate the effects of using a sliding window of observations for dynamic analysis. The weighted sociomatrices are then dichotomized according to a threshold, and their centralities are calculated using R&rsquo;s sna package, and plotted in a time series. The final output demonstrates communication centralization trends over time in a FLOSS project.  The analysis workflow allows users to set parameter values for the size of the sliding window, the date ranges covered, and the communication venues analyzed.  Data for the analysis in the paper examined dynamics in different communication channels; the data sets included up to 90 periods (with a 90-day sliding window) and 10K&rsquo;s of email messages or forum posts. Date periods are currently only in months, and exception handling for empty periods is implemented both in the WSDL components and the RShell scripts. Future development effort could focus on extending periodization options and optimizing performance.",22, 3, step, Calculate_Centralization, Centralization_Plot, Extract_period_start, Extract_From, Extract_event_date, Remove_duplicate_strings, Extract_To, delist_period_start, Split_to_single_events, MergeProjectNames, delist_event_date, delist_dates, delist_from, delist_period_end, Extract_period_end, delist_to, Calculate_weight, split_periods, GetPeriods, MatrixBuilderR, EventsForProjectsInPeriod, ,
"http://www.myexperiment.org/workflows/144/versions/4.html","FLOSS Communication Centralization Plot, Exponentially Weighted","2009-02-0718:50:44","","http://www.myexperiment.org/workflows/144/download/FLOSS_Communication_Centralization_Plot__Exponentially_Weighted-v4.xml?version=4","/users/384","Andrea Wiggins","taverna 1","/users/384, /users/551, /users/550,","Andrea Wiggins, Crowston, James Howison,",,22, 3, step, Centralization_Plot, Calculate_Centralization, Extract_period_end, Extract_From, Extract_period_start, delist_dates, Extract_To, delist_period_end, MergeProjectNames, delist_to, Extract_event_date, delist_from, delist_event_date, Split_to_single_events, delist_period_start, Remove_duplicate_strings, Calculate_weight, split_periods, EventsForProjectsInPeriod, MatrixBuilderR, GetPeriods, ,
"http://www.myexperiment.org/workflows/146/versions/1.html","Get weather information","2008-02-1523:17:07","2008-02-1523:21:19","http://www.myexperiment.org/workflows/146/download/Get_weather_information-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Get the weather forcast of the day for you city.Info display:  wind, visibility, temperature, sky conditions and pressure.The default value is my home town.To find out any supported city run the 'Get cities by country name' workflow",5, 1, GetWeather, CountryAndCity, GetWeatherResult, CountryName, CityName, ,
"http://www.myexperiment.org/workflows/147/versions/1.html","Get cities by country name","2008-02-1523:20:04","","http://www.myexperiment.org/workflows/147/download/Get_cities_by_country_name-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Get all the cities supported by the 'Get Weather info' workflow.... just enter your country name as input.",3, 1, GetCitiesByCountry, GetCitiesResult, CountryName, ,
"http://www.myexperiment.org/workflows/148/versions/1.html","Polling","2008-02-1915:10:38","2010-11-2217:07:18","http://www.myexperiment.org/workflows/148/download/Polling-v1.xml?version=1","/users/208","Stuart Owen","taverna 1","/users/208,","Stuart Owen,",,3, 2, startJob, PollStatus, jobResult, ,
"http://www.myexperiment.org/workflows/149/versions/1.html","GeneIlluminator_Disambiguate","2008-02-2700:43:33","2008-03-0322:11:50","http://www.myexperiment.org/workflows/149/download/GeneIlluminator_Disambiguate-v1.xml?version=1","/users/621","Pieter Neerincx","taverna 1","/users/621, /users/640,","Pieter Neerincx, Alako,","Example workflow demonstrating how to use GeneIlluminator_Disambiguate, a synchronous BioMOBY service for gene symbol disambiguation. If a gene symbol is ambiguous this service provides GI_Clusters describing which different genes, sharing the same symbol, exist in different parts of the tree of life. Provides also gene symbol aliases associated to the input gene symbol. (This is the same output as the one from the GeneIlluminator_GetClusters service.) In addition this service takes an Organism object as input and disambiguates the gene symbol in the context of that organism by assigning the gene symbol for the given organism to one of the GI_Clusters. Visit  <a href=http://www.bioinformatics.nl/gi/>http://www.bioinformatics.nl/gi/</a>  for more info about GeneIlluminator.",5, 1, GeneIlluminator_Disambiguate, Parse_Moby_Data_GI_ClusterAssignment, Organism, Object, Parse_Moby_Data_GI_Cluster, ,
"http://www.myexperiment.org/workflows/149/versions/2.html","GeneIlluminator_Disambiguate","2008-02-2700:43:33","2008-03-0322:11:50","http://www.myexperiment.org/workflows/149/download/GeneIlluminator_Disambiguate-v2.xml?version=2","/users/621","Pieter Neerincx","taverna 1","/users/621, /users/640,","Pieter Neerincx, Alako,","Example workflow demonstrating how to use GeneIlluminator_Disambiguate, a synchronous BioMOBY service for gene symbol disambiguation. If a gene symbol is ambiguous this service provides GI_Clusters describing which different genes, sharing the same symbol, exist in different parts of the tree of life. Provides also gene symbol aliases associated to the input gene symbol. (This is the same output as the one from the GeneIlluminator_GetClusters service.) In addition this service takes an Organism object as input and disambiguates the gene symbol in the context of that organism by assigning the gene symbol for the given organism to one of the GI_Clusters. Visit  <a href=http://www.bioinformatics.nl/gi/>http://www.bioinformatics.nl/gi/</a>  for more info about GeneIlluminator. GeneIlluminator services use a secure connection over HTTPS. To make this work you *must* import our SSL certificates in your local Java keystores. More information can be found on  <a href=https://www.bioinformatics.nl/phenolink/home/>https://www.bioinformatics.nl/phenolink/home/</a>",4, 1, GeneIlluminator_Disambiguate, Parse_Moby_Data_GI_ClusterAssignment, Organism, Object, ,
"http://www.myexperiment.org/workflows/150/versions/1.html","GeneIlluminator_GetClusters","2008-02-2700:46:22","2008-03-0322:11:17","http://www.myexperiment.org/workflows/150/download/GeneIlluminator_GetClusters-v1.xml?version=1","/users/621","Pieter Neerincx","taverna 1","/users/621, /users/640,","Pieter Neerincx, Alako,","Example workflow demonstrating how to use GeneIlluminator_GetClusters, a synchronous BioMOBY service for gene symbol disambiguation. If a gene symbol is ambiguous this service provides GI_Clusters describing which different genes, sharing the same symbol, exist in different parts of the tree of life. Provides also gene symbol aliases associated to the input gene symbol. (Use GeneIlluminator_GetGraph for a graphical representation of the clusters or GeneIlluminator_Disambiguate to get the most likely cluster for a certain species of interest in addition to the clusters.) Visit  <a href=http://www.bioinformatics.nl/gi/>http://www.bioinformatics.nl/gi/</a>  for more info about GeneIlluminator.",2, 1, GeneIlluminator_GetClusters, Object, ,
"http://www.myexperiment.org/workflows/150/versions/2.html","GeneIlluminator_GetClusters","2008-02-2700:46:22","2008-03-0322:11:17","http://www.myexperiment.org/workflows/150/download/GeneIlluminator_GetClusters-v2.xml?version=2","/users/621","Pieter Neerincx","taverna 1","/users/621, /users/640,","Pieter Neerincx, Alako,","Example workflow demonstrating how to use GeneIlluminator_GetClusters, a synchronous BioMOBY service for gene symbol disambiguation. If a gene symbol is ambiguous this service provides GI_Clusters describing which different genes, sharing the same symbol, exist in different parts of the tree of life. Provides also gene symbol aliases associated to the input gene symbol. (Use GeneIlluminator_GetGraph for a graphical representation of the clusters or GeneIlluminator_Disambiguate to get the most likely cluster for a certain species of interest in addition to the clusters.) Visit  <a href=http://www.bioinformatics.nl/gi/>http://www.bioinformatics.nl/gi/</a>  for more info about GeneIlluminator. GeneIlluminator services use a secure connection over HTTPS. To make this work you *must* import our SSL certificates in your local Java keystores. More information can be found on  <a href=https://www.bioinformatics.nl/phenolink/home/>https://www.bioinformatics.nl/phenolink/home/</a>",2, 1, GeneIlluminator_GetClusters, Object, ,
"http://www.myexperiment.org/workflows/151/versions/1.html","GeneIlluminator_GetGraph","2008-02-2700:48:39","2008-03-0322:10:54","http://www.myexperiment.org/workflows/151/download/GeneIlluminator_GetGraph-v1.xml?version=1","/users/621","Pieter Neerincx","taverna 1","/users/621, /users/640,","Pieter Neerincx, Alako,","Example workflow demonstrating how to use GeneIlluminator_GetGraph, a synchronous BioMOBY service for gene symbol disambiguation. If a gene symbol is ambiguous this service uses GeneIlluminator to create clusters describing which different genes, sharing the same symbol, exist in different parts of the tree of life. GeneIlluminator provides also aliases associated to the input gene symbol. Finally, a graphical overview of the clusters and gene symbols is created in SVG format and returned to the client. For technical reasons the image is transferred over the wire in ZIPped and Base64 encoded format. On the client-side a Beanshell processor takes care of base64 decoding and unZIPping resulting in the Scalable Vector Graphics (SVG) image. (Use GeneIlluminator_GetClusters to fetch the raw data instead of a graphical representation of the clusters or GeneIlluminator_Disambiguate to get the most likely cluster for a certain species of interest in addition to the clusters.) Visit  <a href=http://www.bioinformatics.nl/gi/>http://www.bioinformatics.nl/gi/</a>  for more info about GeneIlluminator.",4, 1, Beanshell_scripting_host, GeneIlluminator_GetGraph, Object, Parse_Moby_Data_b64_encoded_svgz, ,
"http://www.myexperiment.org/workflows/151/versions/2.html","GeneIlluminator_GetGraph","2008-02-2700:48:39","2008-03-0322:10:54","http://www.myexperiment.org/workflows/151/download/GeneIlluminator_GetGraph-v2.xml?version=2","/users/621","Pieter Neerincx","taverna 1","/users/621, /users/640,","Pieter Neerincx, Alako,","Example workflow demonstrating how to use GeneIlluminator_GetGraph, a synchronous BioMOBY service for gene symbol disambiguation. If a gene symbol is ambiguous this service uses GeneIlluminator to create clusters describing which different genes, sharing the same symbol, exist in different parts of the tree of life. GeneIlluminator provides also aliases associated to the input gene symbol. Finally, a graphical overview of the clusters and gene symbols is created in SVG format and returned to the client. For technical reasons the image is transferred over the wire in ZIPped and Base64 encoded format. On the client-side a Beanshell processor takes care of base64 decoding and unZIPping resulting in the Scalable Vector Graphics (SVG) image. (Use GeneIlluminator_GetClusters to fetch the raw data instead of a graphical representation of the clusters or GeneIlluminator_Disambiguate to get the most likely cluster for a certain species of interest in addition to the clusters.) Visit  <a href=http://www.bioinformatics.nl/gi/>http://www.bioinformatics.nl/gi/</a>  for more info about GeneIlluminator. GeneIlluminator services use a secure connection over HTTPS. To make this work you *must* import our SSL certificates in your local Java keystores. More information can be found on  <a href=https://www.bioinformatics.nl/phenolink/home/>https://www.bioinformatics.nl/phenolink/home/</a>",4, 1, Beanshell_scripting_host, GeneIlluminator_GetGraph, Object, Parse_Moby_Data_b64_encoded_svgz, ,
"http://www.myexperiment.org/workflows/152/versions/1.html","GeneIlluminator_GetPubMedQuery","2008-02-2700:49:44","2008-03-0322:08:39","http://www.myexperiment.org/workflows/152/download/GeneIlluminator_GetPubMedQuery-v1.xml?version=1","/users/621","Pieter Neerincx","taverna 1","/users/621, /users/640,","Pieter Neerincx, Alako,","Example workflow demonstrating how to use GeneIlluminator_GetPubMedQuery, a synchronous BioMOBY service for gene symbol disambiguation. If a gene symbol is ambiguous this service uses GeneIlluminator to create clusters describing which different genes, sharing the same symbol, exist in different parts of the tree of life. GeneIlluminator provides also aliases associated to the input gene symbol. Finally, using the cluster characteristics it creates a boolean PubMed query that could be used to unambiguously retrieve documents related to the gene from the cluster the input gene symbol was assigned to. Please note that GeneIlluminator_GetPubMedQuery provides a query string that can be used to query PubMed, but it does not query PubMed itself. You'll have to do that by other means. When you do query PubMed at the NCBI using some automated procedure, make sure to throttle your queries! Otherwise you'll have your university/institute/company disconnected from the NCBI servers in no time. Visit  <a href=http://www.ncbi.nlm.nih.gov/>http://www.ncbi.nlm.nih.gov/</a>  for guidelines for automated/scripted acces to NCBI resources like PubMed. Visit  <a href=http://www.bioinformatics.nl/gi/>http://www.bioinformatics.nl/gi/</a>  for more info about GeneIlluminator.",4, 1, GeneIlluminator_GetPubMedQuery, Organism, Object, Parse_Moby_Data_BooleanQueryString, ,
"http://www.myexperiment.org/workflows/152/versions/2.html","GeneIlluminator_GetPubMedQuery","2008-02-2700:49:44","2008-03-0322:08:39","http://www.myexperiment.org/workflows/152/download/GeneIlluminator_GetPubMedQuery-v2.xml?version=2","/users/621","Pieter Neerincx","taverna 1","/users/621, /users/640,","Pieter Neerincx, Alako,","Example workflow demonstrating how to use GeneIlluminator_GetPubMedQuery, a synchronous BioMOBY service for gene symbol disambiguation. If a gene symbol is ambiguous this service uses GeneIlluminator to create clusters describing which different genes, sharing the same symbol, exist in different parts of the tree of life. GeneIlluminator provides also aliases associated to the input gene symbol. Finally, using the cluster characteristics it creates a boolean PubMed query that could be used to unambiguously retrieve documents related to the gene from the cluster the input gene symbol was assigned to. Please note that GeneIlluminator_GetPubMedQuery provides a query string that can be used to query PubMed, but it does not query PubMed itself. You'll have to do that by other means. When you do query PubMed at the NCBI using some automated procedure, make sure to throttle your queries! Otherwise you'll have your university/institute/company disconnected from the NCBI servers in no time. Visit  <a href=http://www.ncbi.nlm.nih.gov/>http://www.ncbi.nlm.nih.gov/</a>  for guidelines for automated/scripted acces to NCBI resources like PubMed. Visit  <a href=http://www.bioinformatics.nl/gi/>http://www.bioinformatics.nl/gi/</a>  for more info about GeneIlluminator. GeneIlluminator services use a secure connection over HTTPS. To make this work you *must* import our SSL certificates in your local Java keystores. More information can be found on  <a href=https://www.bioinformatics.nl/phenolink/home/>https://www.bioinformatics.nl/phenolink/home/</a>",4, 1, GeneIlluminator_GetPubMedQuery, Organism, Object, Parse_Moby_Data_BooleanQueryString, ,
"http://www.myexperiment.org/workflows/154/versions/1.html","BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html","2009-05-2812:21:05","","http://www.myexperiment.org/workflows/154/download/BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18, /users/68,","Marco Roos, Martijn Schuemie,","This workflow finds proteins relevant to the query string via the following steps: <ol><li>A user query: a single gene/protein name. E.g.: (EZH2 OR Enhancer of Zeste).</li><li>Retrieve documents: finds 'maximumNumberOfHits' relevant documents (abstract+title) based on query (the AIDA service inside is based on Apache's Lucene)</li><li>Discover proteins: extract proteins discovered in the set of relevant abstracts with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe. This subworkflow also 'filters' false positives from the discovered protein by requiring a discovery has a valid UniProt ID. Martijn Schuemie's service to do that contains only human UniProt IDs, which is why this workflow only works for human proteins.</li></ol> Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org>http://adaptivedisclosure.org</a> ) Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam). Changes to our original BioAID_DiseaseDiscovery workflow: * Stops at protein discovery* Use of Martijn Schuemie's synsets service to* add synonyms to the query.* provide uniprot ids to discovered proteins* filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)* Counting of results in various ways, but no outputs defined in this simplified workflow.* Output into simple html table.",15, 0, PubMedURLstub, Document_index, search_field, Concatenate_URLstub_ID, CountProteins, CountDocuments, Discover_HumanUniProt_proteins, Retrieve_documents, htmlize_table, ConcatenateLists, SliceOutListLevel, Clone, SliceOutListLevel_doc_ids, default_max_hits, SynonymsToQuery, ,
"http://www.myexperiment.org/workflows/154/versions/2.html","BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html","2009-05-2812:21:05","","http://www.myexperiment.org/workflows/154/download/BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html-v2.xml?version=2","/users/18","Marco Roos","taverna 1","/users/18, /users/68,","Marco Roos, Martijn Schuemie,","This workflow finds proteins relevant to the query string via the following steps: <ol><li>A user query: a single gene/protein name. E.g.: (EZH2 OR Enhancer of Zeste).</li><li>Retrieve documents: finds 'maximumNumberOfHits' relevant documents (abstract+title) based on query (the AIDA service inside is based on Apache's Lucene)</li><li>Discover proteins: extract proteins discovered in the set of relevant abstracts with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe. This subworkflow also 'filters' false positives from the discovered protein by requiring a discovery has a valid UniProt ID. Martijn Schuemie's service to do that contains only human UniProt IDs, which is why this workflow only works for human proteins.</li></ol> Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org>http://adaptivedisclosure.org</a> ) Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam). Changes to our original BioAID_DiseaseDiscovery workflow: * Stops at protein discovery* Use of Martijn Schuemie's synsets service to* add synonyms to the query.* provide uniprot ids to discovered proteins* filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)* Counting of results in various ways, but no outputs defined in this simplified workflow.* Output into simple html table.",18, 2, DummyRankScore, Document_index, search_field, default_max_hits, CountDocuments, Concatenate_URLstub_ID, Clone, SliceOutListLevel_doc_ids, CountProteins, Flatten_list, PubMedURLstub, Flatten_list2, Flatten_list1, Retrieve_documents, Discover_HumanUniProt_proteins, SynonymsToQuery, StructureLists, DiscoveredProteinsToHtmlTable, ,
"http://www.myexperiment.org/workflows/154/versions/3.html","BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html","2009-05-2812:21:05","","http://www.myexperiment.org/workflows/154/download/BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html-v3.xml?version=3","/users/18","Marco Roos","taverna 1","/users/18, /users/68,","Marco Roos, Martijn Schuemie,","This workflow finds proteins relevant to the query string via the following steps: <ol><li>A user query: a single gene/protein name. E.g.: (EZH2 OR Enhancer of Zeste).</li><li>Retrieve documents: finds 'maximumNumberOfHits' relevant documents (abstract+title) based on query (the AIDA service inside is based on Apache's Lucene)</li><li>Discover proteins: extract proteins discovered in the set of relevant abstracts with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe. This subworkflow also 'filters' false positives from the discovered protein by requiring a discovery has a valid UniProt ID. Martijn Schuemie's service to do that contains only human UniProt IDs, which is why this workflow only works for human proteins.</li></ol> Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org>http://adaptivedisclosure.org</a> ) Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam). Changes to our original BioAID_DiseaseDiscovery workflow: * Stops at protein discovery* Use of Martijn Schuemie's synsets service to* add synonyms to the query.* provide uniprot ids to discovered proteins* filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)* Counting of results in various ways, but no outputs defined in this simplified workflow.* Output into simple html table.",19, 2, default_max_hits, ExampleOutput, Document_index, search_field, PubMedURLstub, Flatten_list2, Flatten_list1, DummyRankScore, Flatten_list, Concatenate_URLstub_ID, CountProteins, CountDocuments, SliceOutListLevel_doc_ids, Clone, Retrieve_documents, SynonymsToQuery, StructureLists, DiscoveredProteinsToHtmlTable, Discover_HumanUniProt_proteins, ,
"http://www.myexperiment.org/workflows/154/versions/4.html","BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html","2009-05-2812:21:05","","http://www.myexperiment.org/workflows/154/download/BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html-v4.xml?version=4","/users/18","Marco Roos","taverna 1","/users/18, /users/68,","Marco Roos, Martijn Schuemie,","This workflow finds proteins relevant to the query string via the following steps: <ol><li>A user query: a single gene/protein name. E.g.: (EZH2 OR Enhancer of Zeste).</li><li>Retrieve documents: finds 'maximumNumberOfHits' relevant documents (abstract+title) based on query (the AIDA service inside is based on Apache's Lucene)</li><li>Discover proteins: extract proteins discovered in the set of relevant abstracts with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe. This subworkflow also 'filters' false positives from the discovered protein by requiring a discovery has a valid UniProt ID. Martijn Schuemie's service to do that contains only human UniProt IDs, which is why this workflow only works for human proteins.</li></ol> Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org>http://adaptivedisclosure.org</a> ) Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam). Changes to our original BioAID_DiseaseDiscovery workflow: * Stops at protein discovery* Use of Martijn Schuemie's synsets service to* add synonyms to the query.* provide uniprot ids to discovered proteins* filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)* Counting of results in various ways, but no outputs defined in this simplified workflow.* Output into simple html table.",20, 3, default_max_hits, ExampleOutput, Document_index, search_field, PubMedURLstub, Flatten_list2, Flatten_list1, DummyRankScore, Flatten_list, Concatenate_URLstub_ID, CountProteins, CountDocuments, SliceOutListLevel_doc_ids, Clone, Retrieve_documents, SynonymsToQuery, StructureLists, DiscoveredProteinsToHtmlTable, Discover_HumanUniProt_proteins, file_html_doc, ,
"http://www.myexperiment.org/workflows/154/versions/5.html","BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html","2009-05-2812:21:05","","http://www.myexperiment.org/workflows/154/download/BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html-v5.xml?version=5","/users/18","Marco Roos","taverna 1","/users/18, /users/68,","Marco Roos, Martijn Schuemie,","This workflow finds proteins relevant to the query string via the following steps: <ol><li>A user query: a single gene/protein name. E.g.: (EZH2 OR Enhancer of Zeste).</li><li>Retrieve documents: finds 'maximumNumberOfHits' relevant documents (abstract+title) based on query (the AIDA service inside is based on Apache's Lucene)</li><li>Discover proteins: extract proteins discovered in the set of relevant abstracts with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe. This subworkflow also 'filters' false positives from the discovered protein by requiring a discovery has a valid UniProt ID. Martijn Schuemie's service to do that contains only human UniProt IDs, which is why this workflow only works for human proteins.</li></ol> Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org>http://adaptivedisclosure.org</a> ) Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam). Changes to our original BioAID_DiseaseDiscovery workflow: * Stops at protein discovery* Use of Martijn Schuemie's synsets service to* add synonyms to the query.* provide uniprot ids to discovered proteins* filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)* Counting of results in various ways, but no outputs defined in this simplified workflow.* Output into simple html table.",22, 4, default_max_hits, ExampleOutput, Document_index, search_field, PubMedURLstub, Flatten_list2, Flatten_list1, DummyRankScore, Flatten_list, Concatenate_URLstub_ID, CountProteins, CountDocuments, SliceOutListLevel_doc_ids, Clone, Retrieve_documents, SynonymsToQuery, StructureLists, DiscoveredProteinsToHtmlTable, Discover_HumanUniProt_proteins, file_html_doc, file_html_doc_init, Results_pending_html_doc, ,
"http://www.myexperiment.org/workflows/154/versions/6.html","BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html","2009-05-2812:21:05","","http://www.myexperiment.org/workflows/154/download/BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html-v6.xml?version=6","/users/18","Marco Roos","taverna 1","/users/18, /users/68,","Marco Roos, Martijn Schuemie,","This workflow finds proteins relevant to the query string via the following steps: <ol><li>A user query: a single gene/protein name. E.g.: (EZH2 OR Enhancer of Zeste).</li><li>Retrieve documents: finds 'maximumNumberOfHits' relevant documents (abstract+title) based on query (the AIDA service inside is based on Apache's Lucene)</li><li>Discover proteins: extract proteins discovered in the set of relevant abstracts with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe. This subworkflow also 'filters' false positives from the discovered protein by requiring a discovery has a valid UniProt ID. Martijn Schuemie's service to do that contains only human UniProt IDs, which is why this workflow only works for human proteins.</li></ol> Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org>http://adaptivedisclosure.org</a> ) Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam). Changes to our original BioAID_DiseaseDiscovery workflow: * Stops at protein discovery* Use of Martijn Schuemie's synsets service to* add synonyms to the query.* provide uniprot ids to discovered proteins* filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)* Counting of results in various ways, but no outputs defined in this simplified workflow.* Output into simple html table.",22, 4, default_max_hits, ExampleOutput, Document_index, search_field, PubMedURLstub, Flatten_list2, Flatten_list1, DummyRankScore, Flatten_list, Concatenate_URLstub_ID, CountProteins, CountDocuments, SliceOutListLevel_doc_ids, Clone, Retrieve_documents, SynonymsToQuery, StructureLists, DiscoveredProteinsToHtmlTable, Discover_HumanUniProt_proteins, file_html_doc, file_html_doc_init, Results_pending_html_doc, ,
"http://www.myexperiment.org/workflows/154/versions/7.html","BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html","2009-05-2812:21:05","","http://www.myexperiment.org/workflows/154/download/BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html-v7.xml?version=7","/users/18","Marco Roos","taverna 1","/users/18, /users/68,","Marco Roos, Martijn Schuemie,","This workflow finds proteins relevant to the query string via the following steps: <ol><li>A user query: a single gene/protein name. E.g.: (EZH2 OR Enhancer of Zeste).</li><li>Retrieve documents: finds 'maximumNumberOfHits' relevant documents (abstract+title) based on query (the AIDA service inside is based on Apache's Lucene)</li><li>Discover proteins: extract proteins discovered in the set of relevant abstracts with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe. This subworkflow also 'filters' false positives from the discovered protein by requiring a discovery has a valid UniProt ID. Martijn Schuemie's service to do that contains only human UniProt IDs, which is why this workflow only works for human proteins.</li></ol> Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org>http://adaptivedisclosure.org</a> ) Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam). Changes to our original BioAID_DiseaseDiscovery workflow: * Stops at protein discovery* Use of Martijn Schuemie's synsets service to* add synonyms to the query.* provide uniprot ids to discovered proteins* filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)* Counting of results in various ways, but no outputs defined in this simplified workflow.* Output into simple html table.",23, 4, default_max_hits, ExampleOutput, DummyRankScore, Results_pending_html_doc, PubMedURLstub, Document_index, search_field, Concatenate_URLstub_ID, CountProteins, CountDocuments, Clone, SynonymsToQuery, Retrieve_documents, Discover_HumanUniProt_proteins, save_html_init, NotAppendHtmlDoc, AppendToHtmlDoc, save_html, Proteins_to_html_table, html_top, html_bottom, save_html_top, save_html_bottom, ,
"http://www.myexperiment.org/workflows/154/versions/8.html","BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html","2009-05-2812:21:05","","http://www.myexperiment.org/workflows/154/download/BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html-v8.xml?version=8","/users/18","Marco Roos","taverna 1","/users/18, /users/68,","Marco Roos, Martijn Schuemie,","This workflow finds proteins relevant to the query string via the following steps: 1. A user query: a single gene/protein name. E.g.: (EZH2 OR &quot;Enhancer of Zeste&quot;). 2. Retrieve documents: finds 'maximumNumberOfHits' relevant documents (abstract+title) based on query (the AIDA service inside is based on Apache's Lucene) 3. Discover proteins: extract proteins discovered in the set of relevant abstracts with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe. This subworkflow also 'filters' false positives from the discovered protein by requiring a discovery has a valid UniProt ID. Martijn Schuemie's service to do that contains only human UniProt IDs, which is why this workflow only works for human proteins.  Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org>http://adaptivedisclosure.org</a> )  Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam).  Changes to our original BioAID_DiseaseDiscovery workflow:    * Stops at protein discovery    * Use of Martijn Schuemie's synsets service to        * add synonyms to the query.        * provide uniprot ids to discovered proteins        * filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)    * Counting of results in various ways, but no outputs defined in this simplified workflow.    * Output into simple html table.",22, 4, PubMedURLstub, search_field, Concatenate_URLstub_ID, DummyRankScore, Results_pending_html_doc, default_max_hits, NotAppendHtmlDoc, AppendToHtmlDoc, Document_index, Clone, AIDAHtmlScaffold, CountDocuments, CountProteins, Proteins_to_html_table, save_html_top, save_html_bottom, save_html, SynonymsToQuery, Discover_HumanUniProt_proteins, Retrieve_documents, save_html_init, html_ref, ,
"http://www.myexperiment.org/workflows/154/versions/9.html","BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html","2009-05-2812:21:05","","http://www.myexperiment.org/workflows/154/download/BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html-v9.xml?version=9","/users/18","Marco Roos","taverna 1","/users/18, /users/68,","Marco Roos, Martijn Schuemie,","This workflow finds proteins relevant to the query string via the following steps: 1. A user query: a single gene/protein name. E.g.: (EZH2 OR &quot;Enhancer of Zeste&quot;). 2. Retrieve documents: finds 'maximumNumberOfHits' relevant documents (abstract+title) based on query (the AIDA service inside is based on Apache's Lucene) 3. Discover proteins: extract proteins discovered in the set of relevant abstracts with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe. This subworkflow also 'filters' false positives from the discovered protein by requiring a discovery has a valid UniProt ID. Martijn Schuemie's service to do that contains only human UniProt IDs, which is why this workflow only works for human proteins.  Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org>http://adaptivedisclosure.org</a> )  Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam).  Changes to our original BioAID_DiseaseDiscovery workflow:    * Stops at protein discovery    * Use of Martijn Schuemie's synsets service to        * add synonyms to the query.        * provide uniprot ids to discovered proteins        * filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)    * Counting of results in various ways, but no outputs defined in this simplified workflow.    * Output into simple html table.",22, 4, PubMedURLstub, search_field, Concatenate_URLstub_ID, DummyRankScore, Results_pending_html_doc, default_max_hits, NotAppendHtmlDoc, AppendToHtmlDoc, Document_index, Clone, AIDAHtmlScaffold, CountDocuments, CountProteins, Proteins_to_html_table, save_html_top, save_html_bottom, save_html, SynonymsToQuery, Discover_HumanUniProt_proteins, Retrieve_documents, save_html_init, html_ref, ,
"http://www.myexperiment.org/workflows/154/versions/10.html","BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html","2009-05-2812:21:05","","http://www.myexperiment.org/workflows/154/download/BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html-v10.xml?version=10","/users/18","Marco Roos","taverna 1","/users/18, /users/68,","Marco Roos, Martijn Schuemie,","This workflow finds proteins relevant to the query string via the following steps: Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org>http://adaptivedisclosure.org</a> )  Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam).  Changes to our original BioAID_DiseaseDiscovery workflow:      * Stops at protein discovery    * Use of Martijn Schuemie's synsets service to        * add synonyms to the query.        * provide uniprot ids to discovered proteins        * filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)    * Counting of results in various ways, but no outputs defined in this simplified workflow.    * Output into simple html table.",22, 4, Results_pending_html_doc, save_html_bottom, Proteins_to_html_table, html_ref, Document_index, CountProteins, AppendToHtmlDoc, default_max_hits, save_html_init, save_html, save_html_top, Clone, PubMedURLstub, DummyRankScore, CountDocuments, Concatenate_URLstub_ID, NotAppendHtmlDoc, AIDAHtmlScaffold, search_field, Discover_HumanUniProt_proteins, SynonymsToQuery, Retrieve_documents, ,
"http://www.myexperiment.org/workflows/154/versions/11.html","BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html","2009-05-2812:21:05","","http://www.myexperiment.org/workflows/154/download/BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html-v11.xml?version=11","/users/18","Marco Roos","taverna 1","/users/18, /users/68,","Marco Roos, Martijn Schuemie,","This workflow finds proteins relevant to the query string via the following steps: <ol><li>A user query: a single gene/protein name. E.g.: (EZH2 OR Enhancer of Zeste).</li><li>Retrieve documents: finds 'maximumNumberOfHits' relevant documents (abstract+title) based on query (the AIDA service inside is based on Apache's Lucene)</li><li>Discover proteins: extract proteins discovered in the set of relevant abstracts with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe. This subworkflow also 'filters' false positives from the discovered protein by requiring a discovery has a valid UniProt ID. Martijn Schuemie's service to do that contains only human UniProt IDs, which is why this workflow only works for human proteins.</li></ol> Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam;  <a href=http://adaptivedisclosure.org>http://adaptivedisclosure.org</a> ) Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam). Changes to our original BioAID_DiseaseDiscovery workflow: * Stops at protein discovery* Use of Martijn Schuemie's synsets service to* add synonyms to the query.* provide uniprot ids to discovered proteins* filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)* Counting of results in various ways, but no outputs defined in this simplified workflow.* Output into simple html table.",22, 4, Results_pending_html_doc, save_html_bottom, Proteins_to_html_table, html_ref, Document_index, CountProteins, AppendToHtmlDoc, default_max_hits, save_html_init, save_html, save_html_top, Clone, PubMedURLstub, DummyRankScore, CountDocuments, Concatenate_URLstub_ID, NotAppendHtmlDoc, AIDAHtmlScaffold, search_field, Discover_HumanUniProt_proteins, SynonymsToQuery, Retrieve_documents, ,
"http://www.myexperiment.org/workflows/155/versions/1.html","Html output test","2008-03-0412:59:14","2008-09-0814:59:27","","/users/2","David Withers","taverna 1","/users/2,","David Withers,","Workflow for testing the html rendering on myExperiment",
"http://www.myexperiment.org/workflows/157/versions/1.html","Example of a conditional execution workflow","2008-03-0513:55:45","2012-05-2311:18:50","http://www.myexperiment.org/workflows/157/download/Example_of_a_conditional_execution_workflow-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/297,","Tomoinn,","If the input is true then the string 'foo' is emited, if false then 'bar'. Just a simple example to show how the monster works, so to speak. <b>Note that this type of workflow is not suitable for Taverna 2.</b>  An  <a href=http://www.myexperiment.org/workflows/2561.html rel=nofollow>alternative</a>  mechanism is recommended.",5, 0, Fail_if_false, Fail_if_true, foo, bar, Echo_list, ,
"http://www.myexperiment.org/workflows/158/versions/1.html","BiomartAndEMBOSSAnalysis","2009-09-1515:11:11","2015-01-2613:03:32","http://www.myexperiment.org/workflows/158/download/BiomartAndEMBOSSAnalysis-v1.xml?version=1","/users/30","Alan Williams","taverna 1","","","Previous versions of this workflow only returned sequences with an ID mapped to a MIM_morbid_accession. This was primarily to reduce the number of alignments returned becuase it is an example workflow. This option is no longer available through BioMart, so this version returns all sequences on your chosen chromosome. To reduce the number of sequences returned during testing, try changing the filter on the hsapiens_gene_ensembl to the Y chromosome, or change the base pair range. &nbsp; &nbsp;",10, 3, GetUniqueHomolog, FlattenImageList, CreateFasta, getRNsequence, getMMsequence, getHSsequence, hsapiens_gene_ensembl, seqret, plot, emma, ,
"http://www.myexperiment.org/workflows/158/versions/2.html","BiomartAndEMBOSSAnalysis","2009-09-1515:11:11","2015-01-2613:03:32","http://www.myexperiment.org/workflows/158/download/BiomartAndEMBOSSAnalysis-v2.xml?version=2","/users/30","Alan Williams","taverna 1","","","Using Biomart and EMBOSS soaplab services, This workflow retrieves a number of sequences from 3 species: mouse, human, rat; align them, and returns a plot of the alignment result. Corresponding sequence ids are also returned.",10, 3, FlattenImageList, getHSsequence, getMMsequence, getRNsequence, hsapiens_gene_ensembl, GetUniqueHomolog, CreateFasta, seqret, plot, emma, ,
"http://www.myexperiment.org/workflows/158/versions/3.html","BiomartAndEMBOSSAnalysis","2009-09-1515:11:11","2015-01-2613:03:32","http://www.myexperiment.org/workflows/158/download/BiomartAndEMBOSSAnalysis-v3.xml?version=3","/users/30","Alan Williams","taverna 1","","","Using Biomart and EMBOSS soaplab services, This workflow retrieves a number of sequences from 3 species: mouse, human, rat; align them, and returns a plot of the alignment result. Corresponding sequence ids are also returned.",10, 3, FlattenImageList, getHSsequence, getMMsequence, getRNsequence, hsapiens_gene_ensembl, GetUniqueHomolog, CreateFasta, seqret, plot, emma, ,
"http://www.myexperiment.org/workflows/158/versions/4.html","BiomartAndEMBOSSAnalysis","2009-09-1515:11:11","2015-01-2613:03:32","http://www.myexperiment.org/workflows/158/download/BiomartAndEMBOSSAnalysis-v4.xml?version=4","/users/30","Alan Williams","taverna 1","","","Using Biomart and EMBOSS soaplab services, This workflow retrieves a number of sequences from 3 species: mouse, human, rat; align them, and returns a plot of the alignment result. Corresponding sequence ids are also returned.",10, 3, FlattenImageList, GetUniqueHomolog, CreateFasta, seqret, plot, emma, hsapiensGeneEnsembl, getMMusSequence, getRNorSequence, getHSapSequence, ,
"http://www.myexperiment.org/workflows/159/versions/1.html","A workflow version of the EMBOSS tutorial","2008-03-0514:05:20","2008-03-2514:43:35","http://www.myexperiment.org/workflows/159/download/A_workflow_version_of_the_EMBOSS_tutorial-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/297,","Tomoinn,","Designed to show the use of EMBOSS based Soaplab services from Taverna, this workflow has no inputs as all initial values are specified as string constants. A sequence set is fetched using the seqret tool, then simultaneously scanned for predicted transmembrane regions and subjected to a multiple alignment using emma. This alignment is then plotted to a set of PNG images and also used to build a profile using the prophecy and prophet tools.",15, 8, sequenceid, prophecyType, prophecyName, send, sbegin, msfFormat, transeqSequenceID, prophet, prophecy, tmap, seqret1, transeq, formatSequences, emma, plot, ,
"http://www.myexperiment.org/workflows/161/versions/1.html","Fetch today&#39;s xkcd comic","2008-03-0514:08:52","2008-04-0713:54:04","http://www.myexperiment.org/workflows/161/download/Fetch_today_s_xkcd_comic-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/297, /users/5,","Tomoinn, Stian Soiland-Reyes,","Use the local java plugins and some filtering operations to fetch the comic strip image from  <a href=http://xkcd.com/>http://xkcd.com/</a> Based on the FetchDailyDilbert workflow.",6, 0, comicURLRegex, xkcdURL, getImageLinks, getComicStrip, findComicURL, getPage, ,
"http://www.myexperiment.org/workflows/162/versions/1.html","Fetch Dragon images from BioMoby","2008-03-0514:09:35","2010-07-1416:46:37","http://www.myexperiment.org/workflows/162/download/Fetch_Dragon_images_from_BioMoby-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/297,","Tomoinn,","Use the local java plugins and some filtering operations to fetch the comic strip image from  <a href=http://www.dilbert.com>http://www.dilbert.com</a>",8, 2, id, namespace, Decode_base64_to_byte, getJpegFromAnnotatedImage, getDragonSimpleAnnotatedImages, Object, Parse_Moby_Data_JPEGImage, Parse_Moby_Data_SimpleAnnotatedJPEGImage, ,
"http://www.myexperiment.org/workflows/162/versions/2.html","Fetch Dragon images from BioMoby","2008-03-0514:09:35","2010-07-1416:46:37","http://www.myexperiment.org/workflows/162/download/Fetch_Dragon_images_from_BioMoby-v2.xml?version=2","/users/30","Alan Williams","taverna 1","/users/297,","Tomoinn,","Fetch images and annotations of snapdragons",8, 2, id, namespace, Decode_base64_to_byte, getJpegFromAnnotatedImage, getDragonSimpleAnnotatedImages, Object, Parse_Moby_Data_JPEGImage, Parse_Moby_Data_SimpleAnnotatedJPEGImage, ,
"http://www.myexperiment.org/workflows/162/versions/3.html","Fetch Dragon images from BioMoby","2008-03-0514:09:35","2010-07-1416:46:37","http://www.myexperiment.org/workflows/162/download/Fetch_Dragon_images_from_BioMoby-v3.xml?version=3","/users/30","Alan Williams","taverna 1","/users/297,","Tomoinn,","Fetch images and annotations of snapdragons",8, 2, namespace, id, Decode_base64_to_byte, getDragonSimpleAnnotatedImages, getJpegFromAnnotatedImage, Object, Parse_Moby_Data_JPEGImage, Parse_Moby_Data_SimpleAnnotatedJPEGImage, ,
"http://www.myexperiment.org/workflows/164/versions/1.html","Demonstration of configurable iteration","2008-03-0514:10:51","2008-03-2514:40:27","http://www.myexperiment.org/workflows/164/download/Demonstration_of_configurable_iteration-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/297,","Tomoinn,","This workflow shows the use of the iteration strategy editor to ensure that only relevant combinations of inputs are used during an implicit iteration.",8, 0, Colours, ShapeAnimals, ColourAnimals, ShapesList, AnimalsList, ColoursList, Shapes, Animals, ,
"http://www.myexperiment.org/workflows/165/versions/1.html","Retrieve sequence in EMBL format","2009-06-1716:51:32","","http://www.myexperiment.org/workflows/165/download/Retrieve_sequence_in_EMBL_format-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/62, /users/297, /users/208,","Franck Tanoh, Tomoinn, Stuart Owen,",,4, 1, String_Constant, String_Constant1, String_Constant2, seqret, ,
"http://www.myexperiment.org/workflows/165/versions/2.html","Retrieve sequence in EMBL format","2009-06-1716:51:32","","http://www.myexperiment.org/workflows/165/download/Retrieve_sequence_in_EMBL_format-v2.xml?version=2","/users/30","Alan Williams","taverna 1","/users/62, /users/297, /users/208,","Franck Tanoh, Tomoinn, Stuart Owen,","This workflow retrieves a sequence associated with its features in embl format given a sequence id.",4, 1, sequence_id, sequence_feature, sequence_format, seqret, ,
"http://www.myexperiment.org/workflows/165/versions/3.html","Retrieve sequence in EMBL format","2009-06-1716:51:32","","http://www.myexperiment.org/workflows/165/download/Retrieve_sequence_in_EMBL_format-v3.xml?version=3","/users/30","Alan Williams","taverna 1","/users/62, /users/297, /users/208,","Franck Tanoh, Tomoinn, Stuart Owen,","This workflow retrieves a sequence associated with its features in embl format",4, 1, sequence_id, sequence_feature, sequence_format, seqret, ,
"http://www.myexperiment.org/workflows/167/versions/1.html","Fetch PDB flatfile from RCSB server","2008-03-0514:13:24","2008-03-3116:01:41","http://www.myexperiment.org/workflows/167/download/Fetch_PDB_flatfile_from_RCSB_server-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/297,","Tomoinn,","Given an identifier such as '1crn' fetches the PDB format flatfile and returns the corresponding 3D image of the protein.",5, 0, RCSBSuffix, RCSBPrefix, FetchPage, AddSuffix, AddPrefixToID, ,
"http://www.myexperiment.org/workflows/168/versions/1.html","GBSeq test","2008-03-0514:15:35","2008-03-3115:55:09","http://www.myexperiment.org/workflows/168/download/GBSeq_test-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/62,","Franck Tanoh,",,10, 0, nuc_id, protein_id, Get_Nucleotide_GBSeq_XML, Get_Nucleotide_TinySeq_XML, Get_Protein_GBSeq_XML, Get_Protein_FASTA, Get_Nucleotide_FASTA, Get_Nucleotide_INSDSeq_XML, Get_Protein_INSDSeq_XML, Get_Protein_TinySeq_XML, ,
"http://www.myexperiment.org/workflows/168/versions/2.html","GBSeq test","2008-03-0514:15:35","2008-03-3115:55:09","http://www.myexperiment.org/workflows/168/download/GBSeq_test-v2.xml?version=2","/users/30","Alan Williams","taverna 1","/users/62,","Franck Tanoh,","This workflow retrieves nucleotide and protein sequences with the literature and references associatedto them given a protein and a nucleotide id.",10, 0, protein_id, Get_Nucleotide_GBSeq_XML, nuc_id, Get_Nucleotide_TinySeq_XML, Get_Protein_FASTA, Get_Protein_GBSeq_XML, Get_Nucleotide_FASTA, Get_Protein_INSDSeq_XML, Get_Nucleotide_INSDSeq_XML, Get_Protein_TinySeq_XML, ,
"http://www.myexperiment.org/workflows/169/versions/1.html","myExperimentBeanshellCollection","2008-03-0611:46:11","2008-03-2516:23:24","http://www.myexperiment.org/workflows/169/download/myExperimentBeanshellCollection-v1.xml?version=1","/users/621","Pieter Neerincx","taverna 1","","","Public collection of generic Beanshells curated by the myExperimentBeanshellCollection group on myExperiment. Visit  <a href=http://www.myexperiment.org>http://www.myexperiment.org</a>  for details and updates. To use this collection of beanshells in Taverna: <ul><li>Right click Available Processors in the Design Perspective</li><li>Choose Add new Workflow scavenger...</li><li>Provide the URL to this beanshell collection on <a href=http://www.myExperiment.org>www.myExperiment.org</a> or if you downloaded this to your hard disk, provide a file URL to the absolute path of this file   (On Linux/Unix/Mac: file:///some/path/on/my/disk/myExperimentBeanshellCollection.xml)   (On Windows:             file:///drive_letter:/My%20Documents/myExperimentBeanshellCollection.xml) </li></ul> * You can select Beanshells from this scavenger now and add them to your workflow like any other processor.",2, 0, DecodeBase64EncodedSVGZ, DownloadToDiskFromURLWithBasicAuth, ,
"http://www.myexperiment.org/workflows/169/versions/2.html","myExperimentBeanshellCollection","2008-03-0611:46:11","2008-03-2516:23:24","http://www.myexperiment.org/workflows/169/download/myExperimentBeanshellCollection-v2.xml?version=2","/users/621","Pieter Neerincx","taverna 1","","","Public collection of generic Beanshells curated by the myExperimentBeanshellCollection group on myExperiment. Visit  <a href=http://www.myexperiment.org>http://www.myexperiment.org</a>  for details and updates. To use this collection of beanshells in Taverna: <ul><li>Right click Available Processors in the Design Perspective</li><li>Choose Add new Workflow scavenger...</li><li>Provide the URL to this beanshell collection on <a href=http://www.myExperiment.org>www.myExperiment.org</a> or if you downloaded this to your hard disk, provide a file URL to the absolute path of this file   (On Linux/Unix/Mac: file:///some/path/on/my/disk/myExperimentBeanshellCollection.xml)   (On Windows:             file:///drive_letter:/My%20Documents/myExperimentBeanshellCollection.xml) </li></ul> * You can select Beanshells from this scavenger now and add them to your workflow like any other processor.",3, 0, DecodeBase64EncodedSVGZ, DownloadToDiskFromURLWithBasicAuth, SelectItemsFromList, ,
"http://www.myexperiment.org/workflows/170/versions/1.html","FLOSS Communication Centralization Plot, Unit Weighted","2009-02-0718:49:47","","http://www.myexperiment.org/workflows/170/download/FLOSS_Communication_Centralization_Plot__Unit_Weighted-v1.xml?version=1","/users/384","Andrea Wiggins","taverna 1","/users/384, /users/551, /users/550,","Andrea Wiggins, Crowston, James Howison,","The analysis in this workflow represents the basis of the analysis in our paper, Social dynamics of FLOSS team communication across channels. This workflow uses WSDL components to select periodized data from the FLOSSmole database and generate sociomatrices. The workflow parses the threaded list structure into a communication network based on reply-to relationships.  In the analysis process, an unit weighting is applied to the edges. The weighted sociomatrices are then dichotomized according to a threshold, and their centralities are calculated using R&rsquo;s sna package, and plotted in a time series. The final output demonstrates communication centralization trends over time in a FLOSS project.  The analysis workflow allows users to set parameter values for the size of the sliding window, the date ranges covered, and the communication venues analyzed.  Data for the analysis in the paper examined dynamics in different communication channels; the data sets include up to 90 periods (with a 90-day sliding window) and 10K&rsquo;s of email messages or forum posts. Date periods are currently only in months, and exception handling for empty periods is implemented both in the WSDL components and the RShell scripts.",18, 3, step, Unit_weight, delist_dates, Calculate_Centralization, Centralization_Plot, delist_from, Split_to_single_events, delist_to, delist_period_end, Extract_period_end, Remove_duplicate_strings, Extract_From, Extract_To, split_periods, EventsForProjectsInPeriod, MergeProjectNames, GetPeriods, MatrixBuilderR, ,
"http://www.myexperiment.org/workflows/170/versions/2.html","FLOSS Communication Centralization Plot, Unit Weighted","2009-02-0718:49:47","","http://www.myexperiment.org/workflows/170/download/FLOSS_Communication_Centralization_Plot__Unit_Weighted-v2.xml?version=2","/users/384","Andrea Wiggins","taverna 1","/users/384, /users/551, /users/550,","Andrea Wiggins, Crowston, James Howison,",,18, 3, step, delist_dates, Unit_weight, delist_from, Centralization_Plot, Split_to_single_events, Calculate_Centralization, delist_to, Extract_period_end, delist_period_end, Remove_duplicate_strings, Extract_From, MergeProjectNames, GetPeriods, MatrixBuilderR, split_periods, EventsForProjectsInPeriod, Extract_To, ,
"http://www.myexperiment.org/workflows/171/versions/1.html","SannaWorkflow","2008-03-0712:33:13","","","/users/668","Sanna aizad","taverna 1","/users/668,","Sanna aizad,",,
"http://www.myexperiment.org/workflows/173/versions/1.html","Unique tags","2008-03-1116:52:42","2008-03-1116:53:13","http://www.myexperiment.org/workflows/173/download/Unique_tags-v1.xml?version=1","/users/22","Don Cruickshank","taverna 1","/users/22,","Don Cruickshank,","This workflow takes a comma separated list of tags and removes duplicate entries.  Tags may have multiple words in them.  An example string is carrots,handbags,carrots,cheese.",4, 0, Comma, Split_on_commas, Remove_duplicates, Merge_with_commas, ,
"http://www.myexperiment.org/workflows/173/versions/2.html","Unique tags","2008-03-1116:52:42","2008-03-1116:53:13","http://www.myexperiment.org/workflows/173/download/Unique_tags-v2.xml?version=2","/users/22","Don Cruickshank","taverna 1","/users/22,","Don Cruickshank,","This workflow takes a comma separated list of tags and removes duplicate entries.  Tags may have multiple words in them.  An example string is carrots,handbags,carrots,cheese.",4, 0, Comma, Split_on_commas, Remove_duplicates, Merge_with_commas, ,
"http://www.myexperiment.org/workflows/174/versions/1.html","AffyArrayQualityAnalysis","2008-03-1314:38:03","2009-02-1616:41:29","http://www.myexperiment.org/workflows/174/download/AffyArrayQualityAnalysis-v1.xml?version=1","/users/621","Pieter Neerincx","taverna 1","/users/621, /users/705,","Pieter Neerincx, Philipg,","The AffyArrayQualityAnalysis web services provide quality control for raw Affymetrix GeneChip data. They are wrappers around Philip de Groot's quality control R script to provide remote programmatic access. This example workflow demonstrates the use of the AffyArrayQualityAnalysis services. The flow is as follows: <ul><li>A client executes the AffyArrayQualityAnalysis_submit service with two inputs: a User object and a collection of URLs to CEL files.     o The User object contains a user ID, a password and an e-mail address. Currently the user ID and password can be any characters [a-zA-Z0-9]. Just pick something, there's no need to register them first. They are only used to make sure that the one who tries to download the results is the same person as the one who submitted the job.     o Your job will be submitted to the SUN Grid Engine on the NuGO R-server. The e-mail address is used by the Sun Grid Engine to notify you when your job is done. We might also use it to send you feedback in case something goes wrong with your job, but it won't be used for anything else and will only be stored for a maximum of 7 days (together with your job's results).     o The URLs to the CEL files must use either the http or https protocol. You can restrict access to these URLs using basic authentication and putting the username and password in the URL. For example if the user is pieter and the password is test you could have a URL like this: <a href=https://pieter>https://pieter</a>:<a href=mailto:test@lab5.bioinformatics.nl>test@lab5.bioinformatics.nl</a>/phenolink/home/TisMix_mix5a_01_v1_U133plus2.CEL. Hence you have to put the CEL files somewhere on a web server, so the AffyArrayQualityAnalysis_submit service can download them. </li><li>The AffyArrayQualityAnalysis_submit service returns a job ID and a link to the results. Once the job is done this link can be used to download the results. Results will be available for 7 days after which they will be deleted automatically. </li><li>The job ID is used to execute the AffyArrayQualityAnalysis_poll service inside a nested workflow. AffyArrayQualityAnalysis_poll returns the job status and unless the status is finished the entire nested workflow will fail. If the nested CheckStatus workflow fails, Taverna will automatically retry until it succeeds and hence the job has finished (or until the maximum number of retries is reached).</li><li>The nested DownloadFile workflow depends on successful completion of the nested CheckStatus workflow. The name says it all: It downloads the result, which is a single ZIP file. This workflow does not take care of unzipping the archive. You have to do that yourself.</li></ul> AffyArrayQualityAnalysis services use a secure connection over HTTPS. To make this work you *must* import our SSL certificates in your local Java keystores. More information can be found on  <a href=https://www.bioinformatics.nl/phenolink/home/>https://www.bioinformatics.nl/phenolink/home/</a>",11, 1, DownloadFile, Parse_Moby_Data_URL, Parse_Moby_Data_Object_job_id, Password, Email, URL3, User, AffyArrayQualityAnalysis_submit, URL1, CheckStatus, URL2, ,
"http://www.myexperiment.org/workflows/174/versions/2.html","AffyArrayQualityAnalysis","2008-03-1314:38:03","2009-02-1616:41:29","http://www.myexperiment.org/workflows/174/download/AffyArrayQualityAnalysis-v2.xml?version=2","/users/621","Pieter Neerincx","taverna 1","/users/621, /users/705,","Pieter Neerincx, Philipg,","The AffyArrayQualityAnalysis web services provide quality control for raw Affymetrix GeneChip data. They are wrappers around Philip de Groot's quality control R script to provide remote programmatic access. This example workflow demonstrates the use of the AffyArrayQualityAnalysis services.  The flow is as follows: AffyArrayQualityAnalysis uses a secure connection over HTTPS. To make this work you *must* import our SSL certificates in your local Java keystores. You can do this either manually as described at  <a href=https://www.bioinformatics.nl/phenolink/home/JavaAndHTTPS.html>https://www.bioinformatics.nl/phenolink/home/JavaAndHTTPS.html</a>  or use a Java tool to do the job as described at  <a href=http://www.myexperiment.org/files/148>http://www.myexperiment.org/files/148</a>",11, 1, DownloadFile, Parse_Moby_Data_URL, Parse_Moby_Data_Object_job_id, Password, Email, URL3, User, AffyArrayQualityAnalysis_submit, URL1, CheckStatus, URL2, ,
"http://www.myexperiment.org/workflows/175/versions/1.html","AffyArrayNormalization","2009-02-1616:32:36","2009-02-1616:42:10","http://www.myexperiment.org/workflows/175/download/AffyArrayNormalization-v1.xml?version=1","/users/621","Pieter Neerincx","taverna 1","/users/621, /users/705,","Pieter Neerincx, Philipg,","The AffyArrayNormalization web services normalise raw Affymetrix GeneChip data. They are wrappers around Philip de Groot's normalization R script to provide remote programmatic access. This example workflow demonstrates the use of the AffyArrayNormalization services. The flow is as follows: <ul><li>A client executes the AffyArrayNormalization_submit service with two inputs: a User object and a collection of URLs to CEL files.</li><li>The User object contains a user ID, a password and an e-mail address. Currently the user ID and password can be any characters [a-zA-Z0-9]. Just pick something, there's no need to register them first. They are only used to make sure that the one who tries to download the results is the same person as the one who submitted the job.</li><li>Your job will be submitted to the SUN Grid Engine on the NuGO R-server. The e-mail address is used by the Sun Grid Engine to notify you when your job is done. We might also use it to send you feedback in case something goes wrong with your job, but it won't be used for anything else and will only be stored for a maximum of 7 days (together with your job's results).</li><li>The URLs to the CEL files must use either the http or https protocol. You can restrict access to these URLs using basic authentication and putting the username and password in the URL. For example if the user is pieter and the password is test you could have a URL like this: <a href=https://pieter>https://pieter</a>:<a href=mailto:test@lab5.bioinformatics.nl>test@lab5.bioinformatics.nl</a>/phenolink/home/TisMix_mix5a_01_v1_U133plus2.CEL. Hence you have to put the CEL files somewhere on a web server, so the AffyArrayNormalization_submit service can download them.</li><li>The AffyArrayNormalization_submit service returns a job ID and a link to the results. Once the job is done this link can be used to download the results. Results will be available for 7 days after which they will be deleted automatically. </li><li>The job ID is used to execute the AffyArrayNormalization_poll service inside a nested workflow. AffyArrayNormalization_poll returns the job status and unless the status is finished the entire nested workflow will fail. If the nested CheckStatus workflow fails, Taverna will automatically retry until it succeeds and hence the job has finished (or until the maximum number of retries is reached).</li><li>The nested DownloadFile workflow depends on successful completion of the nested CheckStatus workflow. The name says it all: It downloads the result, which is a single ZIP file. This workflow does not take care of unzipping the archive. You have to do that yourself.</li></ul> AffyArrayNormalization services use a secure connection over HTTPS. To make this work you *must* import our SSL certificates in your local Java keystores. More information can be found on  <a href=https://www.bioinformatics.nl/phenolink/home/>https://www.bioinformatics.nl/phenolink/home/</a>",11, 1, DownloadFile, Parse_Moby_Data_URL, Password, User, URL3, URL2, Parse_Moby_Data_Object_job_id, Email, URL1, AffyArrayNormalization_submit, CheckStatus, ,
"http://www.myexperiment.org/workflows/175/versions/2.html","AffyArrayNormalization","2009-02-1616:32:36","2009-02-1616:42:10","http://www.myexperiment.org/workflows/175/download/AffyArrayNormalization-v2.xml?version=2","/users/621","Pieter Neerincx","taverna 1","/users/621, /users/705,","Pieter Neerincx, Philipg,","The AffyArrayNormalization web services normalise raw Affymetrix GeneChip data. They are wrappers around Philip de Groot's normalization R script to provide remote programmatic access. This example workflow demonstrates the use of the AffyArrayNormalization services.  The flow is as follows: AffyArrayNormalization uses a secure connection over HTTPS. To make this work you *must* import our SSL certificates in your local Java keystores. You can do this either manually as described at  <a href=https://www.bioinformatics.nl/phenolink/home/JavaAndHTTPS.html>https://www.bioinformatics.nl/phenolink/home/JavaAndHTTPS.html</a>  or use a Java tool to do the job as described at  <a href=http://www.myexperiment.org/files/148>http://www.myexperiment.org/files/148</a>",11, 1, DownloadFile, Parse_Moby_Data_URL, Password, User, URL3, URL2, Parse_Moby_Data_Object_job_id, Email, URL1, AffyArrayNormalization_submit, CheckStatus, ,
"http://www.myexperiment.org/workflows/176/versions/1.html","feat","2008-03-1816:40:42","2008-05-1915:56:35","","/users/648","Glatard","taverna 1","/users/648,","Glatard,","This is an attempt to implement the feat application from the fsl fMRI package  <a href=http://www.fmrib.ox.ac.uk/fsl/fsl/whatsnew.html>www.fmrib.ox.ac.uk/fsl/fsl/whatsnew.html</a>  into a Scufl workflow. Details are still being polished but the general structure is here. The main problem that we have with such workflows concerns data provenance. Each of the services is typically iterated on hundreds of data sets and keeping track of the produced files is a pain.",
"http://www.myexperiment.org/workflows/176/versions/2.html","feat","2008-03-1816:40:42","2008-05-1915:56:35","","/users/648","Glatard","taverna 1","/users/648,","Glatard,","This is an attempt to implement the feat application from the fsl fMRI package  <a href=http://www.fmrib.ox.ac.uk/fsl/fsl/whatsnew.html>www.fmrib.ox.ac.uk/fsl/fsl/whatsnew.html</a>  into a Scufl workflow. Details are still being polished but the general structure is here. The main problem that we have with such workflows concerns data provenance. Each of the services is typically iterated on hundreds of data sets and keeping track of the produced files is a pain.",
"http://www.myexperiment.org/workflows/176/versions/3.html","feat","2008-03-1816:40:42","2008-05-1915:56:35","","/users/648","Glatard","taverna 1","/users/648,","Glatard,","This is an attempt to implement the feat application from the fsl fMRI package  <a href=http://www.fmrib.ox.ac.uk/fsl/fsl/whatsnew.html>www.fmrib.ox.ac.uk/fsl/fsl/whatsnew.html</a>  into a Scufl workflow. Details are still being polished but the general structure is here. The main problem that we have with such workflows concerns data provenance. Each of the services is typically iterated on hundreds of data sets and keeping track of the produced files is a pain.",
"http://www.myexperiment.org/workflows/178/versions/1.html","selectworker","2008-03-2510:01:38","2008-03-2510:23:34","http://www.myexperiment.org/workflows/178/download/selectworker-v1.xml?version=1","/users/221","Peter Li","taverna 1","/users/221,","Peter Li,","This workflow shows how the selectData beanshell script can be used to select items from a given list for analysis by downstream processors. Use Control and left mouse click to select multiple items.",3, 0, selectData, data, split, ,
"http://www.myexperiment.org/workflows/179/versions/1.html","blast_test","2008-04-1515:12:49","","","/users/786","Ian","taverna 1","/users/786,","Ian,",,
"http://www.myexperiment.org/workflows/180/versions/1.html","blast_test","2008-04-1515:13:54","","","/users/786","Ian","taverna 1","/users/786,","Ian,",,
"http://www.myexperiment.org/workflows/181/versions/1.html","Identification of differential genes using t-tests by R","2008-04-1515:37:42","2008-07-0117:21:18","http://www.myexperiment.org/workflows/181/download/Identification_of_differential_genes_using_t-tests_by_R-v1.xml?version=1","/users/221","Peter Li","taverna 1","/users/221,","Peter Li,","This workflow starts by retrieving the names of microarray datasets from the maxdLoad2 database. The user has to select sets of control and test data for analysis using t-tests by R. A list of significant differentially expressed genes is then analysed using the Go Term Finder tool which generates a PDF file containing list of common GO terms associated with the genes. A CSV file containing the list of significant genes is also generated. <span style=color: #ff0000>This workflow requires access to R deployed as a service using RServe for the RShell processor to run successfully.</span>",20, 7, flatten, performT_tests, getNamesUsingXPath, GoTermFinder_pvalue, Ttest_pvalue, getAffyIds, mergeOutput2, createFinalCSV, cleanCSV, selectControlData, selectTestData, cleanGenenames, mergeOutput1, getGeneName, getTargetDescription, queryMaxd2, getMeasurementNames, queryMaxd1, getTranscriptId, analyseGenesPDFOutput, ,
"http://www.myexperiment.org/workflows/181/versions/2.html","Identification of differential genes using t-tests by R","2008-04-1515:37:42","2008-07-0117:21:18","http://www.myexperiment.org/workflows/181/download/Identification_of_differential_genes_using_t-tests_by_R-v2.xml?version=2","/users/221","Peter Li","taverna 1","/users/221,","Peter Li,","This workflow starts by retrieving the names of microarray datasets from the Maxd database. The user has to select sets of control and test data for analysis using t-tests by R. A list of significant differentially expressed genes is then analysed using the Go Term Finder tool which generates a list of GO terms associated with the genes. A CSV file containing the list of significant genes is also generated.",20, 7, Ttest_pvalue, GoTermFinder_pvalue, getNamesUsingXPath, flatten, performT_tests, mergeOutput1, createFinalCSV, cleanCSV, createGeneList, selectTestData, getAffyIds, mergeOutput2, selectControlData, getMeasurementNames, queryMaxd1, getGeneName, analyseGenesPDFOutput, getTargetDescription, getTranscriptId, queryMaxd2, ,
"http://www.myexperiment.org/workflows/182/versions/1.html","fetchEnsemblSeqsAndBlast","2008-04-1811:53:19","2008-04-1811:58:30","http://www.myexperiment.org/workflows/182/download/fetchEnsemblSeqsAndBlast-v1.xml?version=1","/users/412","Bela","taverna 1","/users/412,","Bela,","This workflow allows you to configure a BioMart query to fetch sequences you want from Ensembl. These sequences are retrieved and a blast database of them is created (by default, in the directory you ran taverna from). Warning: This workflow assumes that you have blastall and formatdb installed on the machine, and that by default, these are both found or linked in /usr/local/bin. It also assumes that you have write permission to the directory you have run taverna from. The beanshells create_blastall_cmdArgs and create_formatdb_cmdArgs are what you need to edit if the default locations are not appropriate for you. Shortcomings: The names of all the files created and used is hard coded in this workflow. This means that if you run this workflow more than once without editing anything, you will overwrite files you have previously created. All files created in the working directory are not yet coded to be deleted via the workflow. Ideally there would be an option that a user could choose that would set the files to be kept or deleted after use.",6, 0, local_create_blastdb, runBlastSearch, create_blastall_cmdArgs, create_formatdb_cmdArgs, fetch_seqs_from_ensembl, Write_Fasta_File, ,
"http://www.myexperiment.org/workflows/183/versions/1.html","GlobPlotExample","2008-04-3013:14:43","2008-04-3014:45:47","","/users/75","Niall Haslam","taverna 1","/users/75,","Niall Haslam,","This is a sample for how to get the new GlobPlot native disorder and globularity prediction webservice working. At the moment it seems you need all the parameters - even the optional ones filled in, to work in taverna.",
"http://www.myexperiment.org/workflows/184/versions/1.html","Fetch today&#39;s xkcd comic","2008-05-0517:53:21","2008-05-0517:54:41","","/users/287","paul groth","taverna 1","/users/30,","Alan Williams,","Use the local java plugins and some filtering operations to fetch the comic strip image from  <a href=http://xkcd.com/>http://xkcd.com/</a>   Based on the FetchDailyDilbert workflow.&nbsp; I just uploaded this example so I can play around with the myexperiment api.",
"http://www.myexperiment.org/workflows/185/versions/1.html","Staged iteration strategy","2008-05-0712:10:27","2008-05-0712:32:36","http://www.myexperiment.org/workflows/185/download/Staged_iteration_strategy-v1.xml?version=1","/users/5","Stian Soiland-Reyes","taverna 1","/users/5,","Stian Soiland-Reyes,","Consider two lists  <em>A</em>  and  <em>B</em> , of equal size 3. <code>A[1]</code>  corresponds to  <code>B[1]</code> ,  <code>A[2]</code>  to <code>B[2]</code> , etc, for instance  <em>A</em>  are image scans from2007 and  <em>B</em>  from 2008, and the index indicates the patientnumber. There's then two lists of possible parameters  <em>P</em>  and  <em>Q</em> ,of different lengths,  <em>P</em>  has 2 and  <em>Q</em>  has 4 items. Each of the  <em>A</em>  items should be processed in  <em>ap</em>  usingeach of the  <em>P</em>  parameters, and each of the  <em>B</em>  itemsprocessed in  <em>bq</em>  using each of the  <em>Q</em>  parameters.   The problem then is how to compare  <em>AnPp</em>  against the all <em>BnQq</em>  - but notice that  <em>An</em>  and  <em>Bn</em>  have tomatch. The normal crossproduct would compare all  <em>AaPp</em>  againstall  <em>BbQq</em>  - but we want to restrict the iteration strategy. Wecan't use the  <strong>dot product</strong>  directly because for a givenpatient n we want to compare all  <em>P</em> s against all  <em>Q</em> susing the  <strong>cross product</strong> .   This is solved in t2 using  <strong>staged iteration</strong> , but hereis a hack showing how this can be achieved in t1 using a  <strong>nestedworkflow</strong> . The nested workflow basically &quot;stops&quot; theiteration at list level, due to the  <em>echo_lists</em>  inside thatmakes the nested workflow excpect lists. There's explicit  <code>crossproduct(p,a)</code>  strategy set on <em>ap</em>  and  <code>crossproduct(q,b)</code>  on  <em>bq</em>  to makesure they output with the  <em>a</em> / <em>b</em>  iteration at the highestlevel lists, ie.  <em>ap</em>  outputs: So the top level lists from  <em>ap</em>  corresponds to each item of <em>A</em> . The same trick applies to  <em>bq</em>  - if we don't specifythis the implicit iteration might output the opposite with the highestlist corresponding to the  <em>P</em> s and  <em>Q</em> s.  <em>(Hint: Simplydrag </em> p <em> or </em> a <em> within the iteration strategy editor tochange the order)</em>   The second part is to use a nested workflow that takes the outputs from <em>ap</em>  and  <em>bq</em> , but through the  <em>Echo list</em>  localworker. This worker doesn't do anything except it forces the nestedworkflow to take a list of items as inputs instead of single inputs. Hence we can set a  <code>dotproduct(pq, ap)</code>  on the processor forthe nested workflow  <em>apbq_iter</em>  - since  <strong>this nestedworkflow consumes lists</strong>  at both ports this means it will beiterated over with these inputs:  Inside the nested workflow there's the normal  <code>crossproduct(pq,ap)</code>  so that it can do an all-to-all comparison. <em>(The beanshell inside </em> apbq <em> here actually only returnsthe string <code>ap+bq</code>, </em> ap <em> returns <code>a+p</code> and</em> bq <em> returns <code>p+q</code>, but assume that instead there wasreal services invoked for each of these processors doing some kind offiltering/comparison operation using the given parameters, and that<code>a0p0</code> etc. are the outputs of those operations.)</em> With this hack we can run a  <strong>dotproduct</strong>  for the <strong>outer</strong>  list, and a  <strong>crossproduct</strong>  for the <strong>inner</strong>  list. The output of running this workflow should be: So in the final output  <code>{}</code>  (depth=3) there's three big <code>[]</code>  lists of depth 2, corresponding to <code>a0/</code> <code>b0</code> ,  <code>a1</code> / <code>b1</code>  and <code>b2</code> / <code>b2</code> . Within each of these are two <code> ()</code>  lists of depth 1 corresponding to  <code>p0</code>  and <code>p1</code> . The content of these lists (depth 0) are theactual items returned from  <em>apbq</em>  - one for eachof  <code>q0,q1,q2,q3</code> .",9, 0, P, A, Q, B, bq, ap, apbq_iter, Flatten_list, Merge_string_list_to_string, ,
"http://www.myexperiment.org/workflows/187/versions/1.html","Escherichia coli : From cDNA Microarray Raw Data to Pathways and Published Abstracts","2008-05-0815:25:29","2008-05-1209:01:37","http://www.myexperiment.org/workflows/187/download/Escherichia_coli___From_cDNA_Microarray_Raw_Data_to_Pathways_and_Published_Abstracts-v1.xml?version=1","/users/567","Saeedeh","taverna 1","/users/567, /users/43,","Saeedeh, Paul Fisher,","This workflow takes in a CDNA raw file and a normalisation method then returns a series of images/graphs which represent the same output obtained using the R and bioconductor.  Also retruned by this workflow are a list of the top differentialy expressed genes (size dependant on the number specified as input - geneNumber), which are then used to find the candidate pathways which may be influencing the observed changes in the microarray data. By identifying the candidate pathways, more detailed insights into the gene expression data can be obtained.  These pathways are subsequently used to obtain a corpus of published abstracts (from the PubMed database) relating to each biological pathway identified. These pathways are subsequently used to obtain a corpus of published abstracts (from the PubMed database) relating to each biological pathway identified.Also it generates a  pie chart which, indicates the number of genes in a dataset that are regulated by a known transcriptional regulator, or by combination of regulators, and can suggest previously unknown regulatory interactions. The information for each regulon comes from files that are created manually from the EcoCyc database. NOTE - You will also need to install R and Rserv on your machine and install the libaries required by the R script into you R library directory The example inputs for this workflow are as follows: geneNumber = the number of differentialy expressed gene to be returned above a given p-value, e.g. 20path = the direct path to the raw data file location, e.g. C:/Microarray_Data/FILES/ - note the forward slashesp-value = the p-value cut-off value for the array data, e.g. 0.05foldChange = the fold change value for the microarray data, e.g. 1 (means greater than 1 or less than -1)regulonDir =  the direct path to the regulon file.",33, 3, regex, merge_pathway_ids, merge_pathway_desc_2, megre_pathway_desc_1, split_by_regex_2, split_search_terms, merge_ids, remove_pathway_nulls_2, split_by_regex, merge_outputs_2, merge_descriptions, removeEcofromGeneId, merge_genes_pathways, regular_exp, pathway_and_abstract, extract_kegg_gene_id, extract_terms, concat_pathway_ids, add_eco_to_string, remove_gene_nulls_2, add_MeSH_to_string, split_by_regex_3, concat_gene_pathways, merge_GeneID, remove_gene_nulls_1, remove_nulls, remove_gene_pathway_nulls, cDNADataAnalysis, pieChart, gene_descriptons, get_pathways_by_genes, pathway_desc, Search_PubMed, ,
"http://www.myexperiment.org/workflows/192/versions/1.html","Termine Webservice","2008-05-1917:02:05","2008-05-1917:24:12","http://www.myexperiment.org/workflows/192/download/Termine_Webservice-v1.xml?version=1","/users/884","Brian Rea","taverna 1","/users/884,","Brian Rea,","Termine is a service provided by the National Centre for Text Mining ( <a href=http://www.nactem.ac.uk>NaCTeM</a> ) to assist in the discovery of terms in text. More information on the Termine service can be found  <a href=http://www.nactem.ac.uk/software/termine>here</a> . This workflow represents the simplest method of using Termine. The input represents a text string with the output being an string containing a representation of the list of terms, with their  <a href=http://www.nactem.ac.uk/software/termine>C-Value</a>  scores (representing significance in the text), in a simple xml format. Other variations of this tools will be added shortly opening up the wider options available to users. Please note: The Termine webservice is available from academic sites only by default. If you have any problems accessing it please  <a href=http://www.nactem.ac.uk/requestaccess.php>request access</a>  with details of your proposed usage and IP addresses of the machines you want to use and where allowable we will attempt to grant you access. Terms of use for NaCTeM tools can be found  <a href=http://www.nactem.ac.uk/terms_conditions.php>here</a> .",5, 1, analyze, Input_Format, Output_Format, StopList, Filter, ,
"http://www.myexperiment.org/workflows/194/versions/1.html","dgm_ex6","2008-05-2713:56:39","","","/users/908","Dmelvin","taverna 1","/users/908,","Dmelvin,",,
"http://www.myexperiment.org/workflows/196/versions/1.html","Example of an alternate processor","2008-05-2815:03:29","","","/users/915","Jfogel","taverna 1","/users/915,","Jfogel,","Trivial workflow which will initially fail, retry twice then fall over to the alternative specified for the FailingThing process.",
"http://www.myexperiment.org/workflows/197/versions/1.html","EBI_WU-BLAST","2008-05-3022:47:18","2010-12-0610:51:04","http://www.myexperiment.org/workflows/197/download/EBI_WU-BLAST-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Perform a BLAST search using the EBI's WSWUBlast service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/wublast rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/wublast</a> ). The default parameters search UniProtKB using blastp. To change the job parameters see Job_params. <b>Note</b> : the WSWUBlast service used by this workflow is deprecated as of 21st September 2010 and should not be used in any new development. This service is will be retired during 2011. EBI's replacement WU-BLAST services ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/wu_blast_rest rel=nofollow>REST</a>  or  <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/wu_blast_soap rel=nofollow>SOAP</a> ) should be used instead. &nbsp;",10, 4, runWUBlast, Decode_XML_Result, Job_params, Get_XML_Result, Get_Text_Result, Content_List, Get_Hit_ID_List, Input_Data, Poll_Job, Decode_Text_Result, ,
"http://www.myexperiment.org/workflows/198/versions/1.html","EBI WU-BLAST with program and database selection prompts.","2009-07-0411:39:54","2010-12-0610:56:44","http://www.myexperiment.org/workflows/198/download/EBI_WU-BLAST_with_program_and_database_selection_prompts.-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,",,7, 0, EBI_WU_BLAST, Ask_for_email, Select_program, Select_database, Ask_for_sequence, Make_program_list, Make_database_list, ,
"http://www.myexperiment.org/workflows/198/versions/2.html","EBI WU-BLAST with program and database selection prompts.","2009-07-0411:39:54","2010-12-0610:56:44","http://www.myexperiment.org/workflows/198/download/EBI_WU-BLAST_with_program_and_database_selection_prompts.-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Run a BLAST analysis using the EBI's WSWUBlast service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/wublast>http://www.ebi.ac.uk/Tools/webservices/services/wublast</a> ). This workflow wraps the  EBI_WU-BLAST workflow to provide a basic user interface which prompts for the required inputs: sequence, database, BLAST program and user e-mail. Other parameters (e.g. matrix, sort, gap penalties, etc.) are allowed to default.",7, 0, Ask_for_sequence, Make_database_list, Select_program, Select_database, Ask_for_email, Make_program_list, EBI_WU_BLAST, ,
"http://www.myexperiment.org/workflows/198/versions/3.html","EBI WU-BLAST with program and database selection prompts.","2009-07-0411:39:54","2010-12-0610:56:44","http://www.myexperiment.org/workflows/198/download/EBI_WU-BLAST_with_program_and_database_selection_prompts.-v3.xml?version=3","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Run a BLAST analysis using the EBI's WSWUBlast service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/wublast rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/wublast</a> ). This workflow wraps the  EBI_WU-BLAST workflow to provide a basic user interface which prompts for the required inputs: sequence, database, BLAST program and user e-mail. Other parameters (e.g. matrix, sort, gap penalties, etc.) are allowed to default. The values presented in the selection menus for the program and database are obtained from the service, using  the provided meta-data operations: getPrograms and getDatabases. <b>Note</b> : the WSWUBlast service used by this workflow is  deprecated as of 21st September 2010 and should not be used in any new  development. This service is will be retired during 2011. EBI's  replacement WU-BLAST services ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/wu_blast_rest rel=nofollow>REST</a>  or  <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/wu_blast_soap rel=nofollow>SOAP</a> ) should be used instead. &nbsp;",9, 2, Select_database, Select_program, Ask_for_sequence, Ask_for_email, EBI_WU_BLAST, getPrograms, Extract_program_names, Extract_database_names, getDatabases, ,
"http://www.myexperiment.org/workflows/199/versions/1.html","EBI_FASTA","2008-05-3023:50:46","2010-12-0610:52:25","http://www.myexperiment.org/workflows/199/download/EBI_FASTA-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Run a FASTA or SSEARCH sequence similarity search using the EBI's WSFasta service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/fasta rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/fasta</a> ). <b>Note</b> : the WSFasta service used by this workflow is  deprecated as of 21st September 2010 and should not be used in any new  development. This service is will be retired during 2011. EBI's  replacement FASTA services ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/fasta_rest rel=nofollow>REST</a>  or  <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/fasta_soap rel=nofollow>SOAP</a> ) should be used instead. &nbsp;",10, 4, runFasta, Poll_FASTA_Job, Input_data_list, Input_data, FASTA_job_params, getIds, Get_Text_Result, Get_XML_Result, Unpack_Text_Result, Unpack_XML_Result, ,
"http://www.myexperiment.org/workflows/200/versions/1.html","EBI FASTA with prompts","2008-05-3023:53:16","2010-12-0610:53:23","http://www.myexperiment.org/workflows/200/download/EBI_FASTA_with_prompts-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,",,7, 0, EBI_FASTA, Ask_for_email, Ask_for_sequence, Select_FASTA_program, Make_FASTA_program_list, Make_database_list, Select_database, ,
"http://www.myexperiment.org/workflows/200/versions/2.html","EBI FASTA with prompts","2008-05-3023:53:16","2010-12-0610:53:23","http://www.myexperiment.org/workflows/200/download/EBI_FASTA_with_prompts-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,",,7, 0, Make_database_list, Make_FASTA_program_list, Ask_for_sequence, Ask_for_email, Select_database, Select_FASTA_program, EBI_FASTA, ,
"http://www.myexperiment.org/workflows/200/versions/3.html","EBI FASTA with prompts","2008-05-3023:53:16","2010-12-0610:53:23","http://www.myexperiment.org/workflows/200/download/EBI_FASTA_with_prompts-v3.xml?version=3","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Run a FASTA analysis using the EBI&rsquo;s WSFasta service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/fasta rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/fasta</a> ). This workflow wraps the EBI_FASTA workflow to provide a basic user interface which prompts for the required inputs: sequence, database, FASTA program and user e-mail. Other parameters (e.g. matrix, gap penalties, etc.) are allowed to default. <b>Note</b> : the WSFasta service used by this workflow is  deprecated as of 21st September 2010 and should not be used in any new  development. This service is will be retired during 2011. EBI's  replacement FASTA services ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/fasta_rest rel=nofollow>REST</a>  or  <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/fasta_soap rel=nofollow>SOAP</a> ) should be used instead. &nbsp;",7, 0, Make_database_list, Select_database, Select_FASTA_program, Make_FASTA_program_list, Ask_for_email, Ask_for_sequence, Nested_Workflow, ,
"http://www.myexperiment.org/workflows/201/versions/1.html","EBI_NCBI_BLAST","2008-05-3108:38:46","2010-12-0610:54:16","http://www.myexperiment.org/workflows/201/download/EBI_NCBI_BLAST-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Perform a BLAST search using the EBI&rsquo;s WSNCBIBlast service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/ncbiblast rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/ncbiblast</a> ). The query sequence, database to search and BLAST program to use are inputs, the other parameters for the search (see Job_params) are allowed to default. <b>Note</b> : the WSNCBIBlast service used by this workflow is  deprecated as of 21st September 2010 and should not be used in any new  development. This service is will be retired during 2011. EBI's  replacement NCBI BLAST services ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/ncbi_blast_rest rel=nofollow>REST</a>  or  <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/ncbi_blast_soap rel=nofollow>SOAP</a> ) should be used instead. &nbsp;",10, 4, runNCBIBlast, Job_params, Content_list, Input_data, EBI_NCBI_BLAST_job_poll, getIds, Get_text_result, Get_XML_result, Unpack_text_result, Unpack_XML_result, ,
"http://www.myexperiment.org/workflows/202/versions/1.html","EBI_NCBI_BLAST_with_prompts","2008-05-3108:40:29","2010-12-0610:55:09","http://www.myexperiment.org/workflows/202/download/EBI_NCBI_BLAST_with_prompts-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Run a BLAST analysis using the EBI&rsquo;s WSNCBIBlast service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/ncbiblast rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/ncbiblast</a> ). This workflow wraps the EBI_NCBI_BLAST workflow to provide a basic user interface which prompts for the required inputs: sequence, database, BLAST program and user e-mail. Other parameters (e.g. matrix, sort, gap penalties, etc.) are allowed to default. <b>Note</b> : the WSNCBIBlast service used by this workflow is  deprecated as of 21st September 2010 and should not be used in any new  development. This service is will be retired during 2011. EBI's  replacement NCBI BLAST services ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/ncbi_blast_rest rel=nofollow>REST</a>  or  <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/ncbi_blast_soap rel=nofollow>SOAP</a> ) should be used instead. &nbsp;",7, 0, EBI_NCBI_BLAST, Make_database_list, Make_program_list, Ask_for_email, Ask_for_sequence, Select_database, Select_program, ,
"http://www.myexperiment.org/workflows/203/versions/1.html","EBI_ClustalW2","2009-04-0720:06:03","2010-12-0611:00:19","http://www.myexperiment.org/workflows/203/download/EBI_ClustalW2-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,",,11, 4, runClustalW2, Job_params, Content_list, Input_data, Get_alignment_result, Get_guide_tree_result, Unpack_alignment_result, Unpack_guide_tree_result, EBI_ClustalW2_poll_job, Get_output_result, Unpack_output_result, ,
"http://www.myexperiment.org/workflows/203/versions/2.html","EBI_ClustalW2","2009-04-0720:06:03","2010-12-0611:00:19","http://www.myexperiment.org/workflows/203/download/EBI_ClustalW2-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Perform a ClustalW multiple sequence alignment using the EBI&rsquo;s WSClustalW2 service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/clustalw2 rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/clustalw2</a> ). The set of sequences to align are the input, the other parameters for the search (see Job_params) are allowed to default. <b>Note</b> : the WSClustalW2 service used by this workflow is  deprecated as of 21st September 2010 and should not be used in any new  development. This service is will be retired during 2011. EBI's  replacement ClustalW2 services ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/msa/clustalw2_rest rel=nofollow>REST</a>  or  <a href=http://www.ebi.ac.uk/Tools/webservices/services/msa/clustalw2_soap rel=nofollow>SOAP</a> ) should be used instead. &nbsp;",11, 4, runClustalW2, Job_params, Content_list, Input_data, Get_alignment_result, Get_guide_tree_result, Unpack_alignment_result, Unpack_guide_tree_result, EBI_ClustalW2_poll_job, Get_output_result, Unpack_output_result, ,
"http://www.myexperiment.org/workflows/204/versions/1.html","EBI_InterProScan","2008-10-2620:33:34","2011-04-0108:52:28","http://www.myexperiment.org/workflows/204/download/EBI_InterProScan-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,",,9, 3, runInterProScan, Get_text_result, Get_XML_result, Unpack_text_result, Unpack_XML_result, Content_list, Job_params, Input_data, EBI_InterProScan_poll_job, ,
"http://www.myexperiment.org/workflows/204/versions/2.html","EBI_InterProScan","2008-10-2620:33:34","2011-04-0108:52:28","http://www.myexperiment.org/workflows/204/download/EBI_InterProScan-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,",,10, 3, Input_data, Unpack_XML_result, Content_list, Unpack_text_result, Job_params, Format_as_GFF, Get_text_result, runInterProScan, Get_XML_result, EBI_InterProScan_poll_job, ,
"http://www.myexperiment.org/workflows/204/versions/3.html","EBI_InterProScan","2008-10-2620:33:34","2011-04-0108:52:28","http://www.myexperiment.org/workflows/204/download/EBI_InterProScan-v3.xml?version=3","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Note: the WSInterProScan web service used by this workflow is no longer available haveing been replaced by the EMBL-EBI's InterProScan (REST) ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_rest rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_rest</a> ) and InterProScan (SOAP) ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_soap rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_soap</a> ) web services. Thus the workflow described here no longer works, see the alternative workflows for the InterProScan (SOAP) service for workflows which use the new services. Perform an InterProScan analysis of a protein sequence using the EBI&rsquo;s WSInterProScan service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/interproscan rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/interproscan</a> ). The input sequence to use and the user e-mail address are inputs, the other parameters for the analysis (see Job_params) are allowed to default.  InterProScan searches a protein sequence against the protein family and domain signature databases integrated into InterPro (see  <a href=http://www.ebi.ac.uk/interpro/ rel=nofollow>http://www.ebi.ac.uk/interpro/</a> ). A set of matches to the signatures are returned, which are annotated with the corresponding InterPro and GO term assignments for these signature matches.",10, 3, Input_data, Unpack_XML_result, Content_list, Unpack_text_result, Job_params, Format_as_GFF, Get_text_result, runInterProScan, Get_XML_result, EBI_InterProScan_poll_job, ,
"http://www.myexperiment.org/workflows/205/versions/1.html","EBI_InterProScan_with_prompts","2008-05-3111:40:34","2011-04-0108:57:45","http://www.myexperiment.org/workflows/205/download/EBI_InterProScan_with_prompts-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Note: the WSInterProScan web service used by this workflow is no longer available haveing been replaced by the EMBL-EBI's InterProScan (REST) ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_rest rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_rest</a> ) and InterProScan (SOAP) ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_soap rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_soap</a> ) web services. Thus the workflow described here no longer works, see the alternative workflows for the InterProScan (SOAP) service for workflows which use the new services. Run an InterProScan analysis using the EBI&rsquo;s WSInterProScan service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/interproscan rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/interproscan</a> ). This workflow wraps the EBI_InterProScan workflow to provide a basic user interface which prompts for the required inputs: protien sequence and user e-mail. Other parameters are allowed to default.",3, 0, EBI_InterProScan, Ask_for_email, Ask_for_sequence, ,
"http://www.myexperiment.org/workflows/206/versions/1.html","EBI_ClustalW2_phylogentic_tree","2009-04-0720:09:32","","http://www.myexperiment.org/workflows/206/download/EBI_ClustalW2_phylogentic_tree-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Create a Neighbor-joining phylogenetic tree, with Kimura distance corrections, from a sequence alignment using the EBI's WSClustalW2 service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/clustalw2>http://www.ebi.ac.uk/Tools/webservices/services/clustalw2</a> ).",11, 4, runClustalW2, Job_params, Contents_list, Input_data, Get_output, Get_phylip_tree_result, Unpack_output, Unpack_phylip_tree, Unpack_nj_tree, Get_nj_tree_result, EBI_ClustalW2_poll_job, ,
"http://www.myexperiment.org/workflows/206/versions/2.html","EBI_ClustalW2_phylogentic_tree","2009-04-0720:09:32","","http://www.myexperiment.org/workflows/206/download/EBI_ClustalW2_phylogentic_tree-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Create a Neighbor-joining phylogenetic tree, with Kimura distance corrections, from a sequence alignment using the EBI's WSClustalW2 service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/clustalw2>http://www.ebi.ac.uk/Tools/webservices/services/clustalw2</a> ).",11, 4, runClustalW2, Job_params, Contents_list, Input_data, Get_output, Get_phylip_tree_result, Unpack_output, Unpack_phylip_tree, Unpack_nj_tree, Get_nj_tree_result, EBI_ClustalW2_poll_job, ,
"http://www.myexperiment.org/workflows/207/versions/1.html","EBI_ClustalW_alignment_tree","2008-05-3113:53:04","2010-12-0313:34:43","http://www.myexperiment.org/workflows/207/download/EBI_ClustalW_alignment_tree-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Given a set of sequences perform an multiple sequence alignment and from the multiple alignment derive a phylogenetic tree. The popular ClustalW program (see  <a href=http://www.clustal.org/>http://www.clustal.org/</a> ), as implemented in the EBI's WSClustalW2 service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/clustalw2>http://www.ebi.ac.uk/Tools/webservices/services/clustalw2</a> ) is used to perform both tasks.",2, 0, ClustalW_alignment, ClustalW_phylogenetic_tree, ,
"http://www.myexperiment.org/workflows/207/versions/2.html","EBI_ClustalW_alignment_tree","2008-05-3113:53:04","2010-12-0313:34:43","http://www.myexperiment.org/workflows/207/download/EBI_ClustalW_alignment_tree-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Given a set of sequences perform an multiple sequence alignment and from the multiple alignment derive a phylogenetic tree. The popular ClustalW program (see  <a href=http://www.clustal.org/ rel=nofollow>http://www.clustal.org/</a> ), as implemented in the EBI's WSClustalW2 service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/clustalw2 rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/clustalw2</a> ) is used to perform both tasks.",2, 0, ClustalW_alignment, ClustalW_phylogenetic_tree, ,
"http://www.myexperiment.org/workflows/208/versions/1.html","EBI_blastpgp_PSI-BLAST","2008-05-3114:39:22","","http://www.myexperiment.org/workflows/208/download/EBI_blastpgp_PSI-BLAST-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,",,10, 4, runBlastpgp, Job_params, Contents_list, Get_text_result, Get_XML_result, Unpack_text_result, Unpack_XML_result, Input_data, EBI_blastpgp_poll_job, getIds, ,
"http://www.myexperiment.org/workflows/209/versions/1.html","EBI_dbfetch_fetchBatch","2008-05-3120:59:46","","http://www.myexperiment.org/workflows/209/download/EBI_dbfetch_fetchBatch-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","From a list of sequence entry identifiers and a database name, fetch the sequences in fasta format using EBI's WSDbfetch service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/wsdl/WSDbfetch.wsdl>http://www.ebi.ac.uk/Tools/webservices/wsdl/WSDbfetch.wsdl</a> ).",2, 1, fetchBatch, Format_list_for_dbfetch, ,
"http://www.myexperiment.org/workflows/210/versions/1.html","Protein_search_fetch_align_tree","2009-04-0720:13:19","","http://www.myexperiment.org/workflows/210/download/Protein_search_fetch_align_tree-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","An implmentation of the classical sequence analysis workflow: <ol><li>Find homologues (sequence similarity search)</li><li>Fetch homologues</li><li>Align homologues (multiple sequence alignment)</li><li>Produce phylogenetic tree</li></ol> In this implementation the EBI webservices are used: <ol><li>WU-BLAST (WSWUBlast) blastp vs. UniProtKB</li><li>dbfetch (WSDbfetch)</li><li>ClustalW (WSClustalW2)</li><li>ClustalW (WSClustalW2)</li></ol> Note: this version does not add the inital query sequence to the alignment, and so is most useful when used with the identifers of existing database entries.",6, 0, SSS_program, Search_database, Fetch_sequences, Phylogenetic_tree, SSS, MSA, ,
"http://www.myexperiment.org/workflows/210/versions/2.html","Protein_search_fetch_align_tree","2009-04-0720:13:19","","http://www.myexperiment.org/workflows/210/download/Protein_search_fetch_align_tree-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","An implmentation of the classical sequence analysis workflow: <ol><li>Find homologues (sequence similarity search)</li><li>Fetch homologues</li><li>Align homologues (multiple sequence alignment)</li><li>Produce phylogenetic tree</li></ol> In this implementation the EBI webservices are used: <ol><li>WU-BLAST (WSWUBlast) blastp vs. UniProtKB</li><li>dbfetch (WSDbfetch)</li><li>ClustalW (WSClustalW2)</li><li>ClustalW (WSClustalW2)</li></ol> Note: this version does not add the inital query sequence to the alignment, and so is most useful when used with the identifers of existing database entries.",6, 0, SSS_program, Search_database, Fetch_sequences, Phylogenetic_tree, SSS, MSA, ,
"http://www.myexperiment.org/workflows/211/versions/1.html","EBI_Phobius","2008-06-0111:08:45","2008-06-0221:39:06","http://www.myexperiment.org/workflows/211/download/EBI_Phobius-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","The Phobius tool predicts transmembrane domains and signal peptide region from a protein sequence. This workflow uses the EBI's WSPhobius web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/phobius>http://www.ebi.ac.uk/Tools/webservices/services/phobius</a> ) to access the tool. The predicted features are returned in a UniProtKB style feature listing.",7, 2, runPhobius, Contents_list, Input_data, Job_params, EBI_Phobius_poll_job, Get_text_result, Unpack_text_output, ,
"http://www.myexperiment.org/workflows/211/versions/2.html","EBI_Phobius","2008-06-0111:08:45","2008-06-0221:39:06","http://www.myexperiment.org/workflows/211/download/EBI_Phobius-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","The Phobius tool predicts transmembrane domains and signal peptide region from a protein sequence. This workflow uses the EBI's WSPhobius web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/phobius>http://www.ebi.ac.uk/Tools/webservices/services/phobius</a> ) to access the tool. The predicted features are returned in a UniProtKB style feature listing.",8, 2, Contents_list, runPhobius, Job_params, Input_data, Unpack_text_output, Get_text_result, EBI_Phobius_poll_job, Format_as_GFF, ,
"http://www.myexperiment.org/workflows/212/versions/1.html","EBI_InterProScan_tmhmm_signalp","2008-10-2620:50:10","2011-04-0108:56:37","http://www.myexperiment.org/workflows/212/download/EBI_InterProScan_tmhmm_signalp-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Use the TMHMM and SignalP methods of InterProScan to perform transmembrane and signal peptide prediction. The EBI's InterProScan web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/interproscan>http://www.ebi.ac.uk/Tools/webservices/services/interproscan</a> ) is used.",9, 3, Unpack_XML_result, Job_params, Unpack_text_result, Content_list, Input_data, Get_text_result, runInterProScan, EBI_InterProScan_poll_job, Get_XML_result, ,
"http://www.myexperiment.org/workflows/212/versions/2.html","EBI_InterProScan_tmhmm_signalp","2008-10-2620:50:10","2011-04-0108:56:37","http://www.myexperiment.org/workflows/212/download/EBI_InterProScan_tmhmm_signalp-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Use the TMHMM and SignalP methods of InterProScan to perform transmembrane and signal peptide prediction. The EBI's InterProScan web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/interproscan>http://www.ebi.ac.uk/Tools/webservices/services/interproscan</a> ) is used.",10, 3, Unpack_XML_result, Job_params, Get_XML_result, Get_text_result, runInterProScan, Input_data, Content_list, Unpack_text_result, EBI_InterProScan_poll_job, Format_as_GFF, ,
"http://www.myexperiment.org/workflows/212/versions/3.html","EBI_InterProScan_tmhmm_signalp","2008-10-2620:50:10","2011-04-0108:56:37","http://www.myexperiment.org/workflows/212/download/EBI_InterProScan_tmhmm_signalp-v3.xml?version=3","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Use the TMHMM and SignalP methods of InterProScan to perform transmembrane and signal peptide prediction. The EBI's InterProScan web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/interproscan>http://www.ebi.ac.uk/Tools/webservices/services/interproscan</a> ) is used.",10, 3, Unpack_XML_result, Job_params, Get_XML_result, Get_text_result, runInterProScan, Input_data, Content_list, Unpack_text_result, EBI_InterProScan_poll_job, Format_as_GFF, ,
"http://www.myexperiment.org/workflows/212/versions/4.html","EBI_InterProScan_tmhmm_signalp","2008-10-2620:50:10","2011-04-0108:56:37","http://www.myexperiment.org/workflows/212/download/EBI_InterProScan_tmhmm_signalp-v4.xml?version=4","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Note: the WSInterProScan web service used by this workflow is no longer available haveing been replaced by the EMBL-EBI's InterProScan (REST) ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_rest rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_rest</a> ) and InterProScan (SOAP) ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_soap rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_soap</a> ) web services. Thus the workflow described here no longer works, see the alternative workflows for the InterProScan (SOAP) service for workflows which use the new services. Use the TMHMM and SignalP methods of InterProScan to perform transmembrane and signal peptide prediction. The EBI's InterProScan web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/interproscan rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/interproscan</a> ) is used.",10, 3, Unpack_XML_result, Job_params, Get_XML_result, Get_text_result, runInterProScan, Input_data, Content_list, Unpack_text_result, EBI_InterProScan_poll_job, Format_as_GFF, ,
"http://www.myexperiment.org/workflows/213/versions/1.html","Protein_alignment_transmembrane","2008-06-0112:20:29","","http://www.myexperiment.org/workflows/213/download/Protein_alignment_transmembrane-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Transmembrane domain prediction using EMBOSS tmap with an input sequence alignment of homolouges: <ol><li>Sequence similarity search (SSS) to find homologues</li><li>Fetch sequences of hits</li><li>Multiple sequence alignment (MSA) of hit sequences</li><li>EMBOSS tmap with alignment from 3.</li></ol> Uses the EBI web services: <ol><li>WSFasta (see <a href=http://www.ebi.ac.uk/Tools/webservices/services/fasta>http://www.ebi.ac.uk/Tools/webservices/services/fasta</a>)</li><li>WSDbfetch (see <a href=http://www.ebi.ac.uk/Tools/webservices/services/dbfetch>http://www.ebi.ac.uk/Tools/webservices/services/dbfetch</a>)</li><li>WSClustalW2 (see <a href=http://www.ebi.ac.uk/Tools/webservices/services/clustalw2>http://www.ebi.ac.uk/Tools/webservices/services/clustalw2</a>)</li><li>Soaplab EMBOSS tmap</li></ol> Note: currently this workflow does not attempt to add the query sequence into the set of sequences passed to the multiple alignment. Thus it is most suitable for searches using entires which are persent in the searched database (i.e. will be included via the self hit).",6, 1, SSS, Fetch_hits, Database, SSS_program, MSA, tmap, ,
"http://www.myexperiment.org/workflows/214/versions/1.html","Sequence_or_ID","2008-06-0114:15:12","","http://www.myexperiment.org/workflows/214/download/Sequence_or_ID-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Given a sequence or sequence entry identifer (e.g. uniprot:wap_rat), return the sequence in fasta format. If a sequence identifier, in database:identifier format, is input the EBI's WSDbfetch web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/dbfetch>http://www.ebi.ac.uk/Tools/webservices/services/dbfetch</a> ) is used to retrive the sequence in fasta format. Otherwise the input is assumed to be a sequence and if passed through the Soaplab EMBOSS seqret service to force the sequence into fasta format.",5, 2, Is_sequence, Fail_if_identifer, Fail_if_sequence, fetchData, seqret, ,
"http://www.myexperiment.org/workflows/215/versions/1.html","tmap_single_sequence","2008-06-0114:27:12","2008-06-0221:38:13","http://www.myexperiment.org/workflows/215/download/tmap_single_sequence-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Simple workflow using tmap to find transmembrane regions, using a single sequence as input.",2, 1, tmap, Sequence_or_ID, ,
"http://www.myexperiment.org/workflows/215/versions/2.html","tmap_single_sequence","2008-06-0114:27:12","2008-06-0221:38:13","http://www.myexperiment.org/workflows/215/download/tmap_single_sequence-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Simple workflow using tmap to find transmembrane regions, using a single sequence as input.",3, 1, tmap, Sequence_or_ID, Format_as_GFF, ,
"http://www.myexperiment.org/workflows/216/versions/1.html","Protein_transmembrane_prediction","2008-10-2621:16:10","2011-04-0108:57:10","http://www.myexperiment.org/workflows/216/download/Protein_transmembrane_prediction-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Transmembrane and signal peptide prediction using three methods: <ol><li>EMBOSS tmap with a single sequence. Uses Soaplab tmap.</li><li>Phobius. Uses EBI's WSPhobius web service.</li><li>TMHMM and SignalP. Uses the TMHMM and SignalP methods of InterProScan via the EBI's WSInterProScan service.</li></ol> The results of the three methods are converted into GFF format and collated.",4, 0, EBI_Phobius, EBI_InterProScan_tmhmm_signalp, tmap_single_seq, Merge_GFF, ,
"http://www.myexperiment.org/workflows/216/versions/2.html","Protein_transmembrane_prediction","2008-10-2621:16:10","2011-04-0108:57:10","http://www.myexperiment.org/workflows/216/download/Protein_transmembrane_prediction-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Note: the WSInterProScan web service used by this workflow is no longer available haveing been replaced by the EMBL-EBI's InterProScan (REST) ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_rest rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_rest</a> ) and InterProScan (SOAP) ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_soap rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_soap</a> ) web services. Thus the workflow described here no longer works, see the alternative workflows for the InterProScan (SOAP) service for workflows which use the new services. Transmembrane and signal peptide prediction using three methods: The results of the three methods are converted into GFF format and collated.",4, 0, EBI_Phobius, EBI_InterProScan_tmhmm_signalp, tmap_single_seq, Merge_GFF, ,
"http://www.myexperiment.org/workflows/217/versions/1.html","EBI_Kalign","2008-06-0221:28:56","2010-12-0611:39:52","http://www.myexperiment.org/workflows/217/download/EBI_Kalign-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Multiple sequence alignment using the Kalign tool. This workflow uses the EBI's WSKalign service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/kalign rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/kalign</a> ) to access the Kalign tool. The set of sequences to align and the molecule type (protein or nucleic acid) are the input, the other parameters for the search (see Job_params) are allowed to default. <b>Note</b> : the WSKalign service used by this workflow is  deprecated as of 21st September 2010 and should not be used in any new  development. This service is will be retired during 2011. EBI's  replacement Kalign services ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/msa/kalign_rest rel=nofollow>REST</a>  or  <a href=http://www.ebi.ac.uk/Tools/webservices/services/msa/kalign_soap rel=nofollow>SOAP</a> ) should be used instead.",7, 2, runKalign, Get_alignment, Job_params, Contents_list, Input_data, Unpack_alignment, EBI_Kalign_poll_job, ,
"http://www.myexperiment.org/workflows/218/versions/1.html","EBI_MPsrch","2008-06-0221:49:11","2010-12-0610:38:42","http://www.myexperiment.org/workflows/218/download/EBI_MPsrch-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Run a Smith-Waterman sequence search using the EBI&rsquo;s WSMPsrch service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/mpsrch rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/mpsrch</a> ). <b>Note</b> : the WSMPsrch service used by this workflow was retired 27th January 2010. Equivalent functionality is available in the EBI's FASTA ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/fasta_soap rel=nofollow>REST</a>  or  <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/fasta_soap rel=nofollow>SOAP</a> ) and PSI-Search ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/psisearch_rest rel=nofollow>REST</a>  or  <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/psisearch_soap rel=nofollow>SOAP</a> ) services. &nbsp;",7, 2, Job_params, Unpack_text_result, Input_data, Content_list, runMPsrch, Get_text_result, EBI_MPsrch_poll_job, ,
"http://www.myexperiment.org/workflows/219/versions/1.html","EBI_MAFFT","2008-06-0305:55:43","2010-12-0611:38:58","http://www.myexperiment.org/workflows/219/download/EBI_MAFFT-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Perform a multiple sequence alignment using the MAFFT tool (see  <a href=http://align.bmr.kyushu-u.ac.jp/mafft/software/ rel=nofollow>http://align.bmr.kyushu-u.ac.jp/mafft/software/</a> ). The EBI's WSMafft web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/mafft rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/mafft</a> ) is used to access to tool. <b>Note</b> : the WSMafft service used by this workflow is  deprecated as of 21st September 2010 and should not be used in any new  development. This service is will be retired during 2011. EBI's  replacement MAFFT services ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/msa/mafft_rest rel=nofollow>REST</a>  or  <a href=http://www.ebi.ac.uk/Tools/webservices/services/msa/mafft_soap rel=nofollow>SOAP</a> ) should be used instead.",7, 2, runMafft, Job_params, Contents_list, Input_data, Get_alignment, Unpack_alignment, EBI_MAFFT_poll_job, ,
"http://www.myexperiment.org/workflows/220/versions/1.html","EBI_ScanPS","2008-06-0305:57:09","2010-12-0610:37:50","http://www.myexperiment.org/workflows/220/download/EBI_ScanPS-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Perform a Smith-Waterman sequence similarity search using the ScanPS tool (see  <a href=http://www.compbio.dundee.ac.uk/Software/Scanps/scanps.html rel=nofollow>http://www.compbio.dundee.ac.uk/Software/Scanps/scanps.html</a> ). In the case the EBI's WSScanPS web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/scanps rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/scanps</a> ) is used to run the tool. <b>Note</b> : the WSScanPS service used by this workflow was retired 27th January 2010. Equivalent functionality is available in the EBI's FASTA ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/fasta_soap rel=nofollow>REST</a>  or  <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/fasta_soap rel=nofollow>SOAP</a> ) and PSI-Search ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/psisearch_rest rel=nofollow>REST</a>  or  <a href=http://www.ebi.ac.uk/Tools/webservices/services/sss/psisearch_soap rel=nofollow>SOAP</a> ) services. &nbsp;",7, 2, runScanPS, Contents_list, Input_data, Job_params, Get_output, Unpack_output, EBI_ScanPS_poll_job, ,
"http://www.myexperiment.org/workflows/221/versions/1.html","EBI_MUSCLE","2008-06-0306:16:22","2010-12-0611:04:03","http://www.myexperiment.org/workflows/221/download/EBI_MUSCLE-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Perform a multiple sequence alignment using the MUSCLE tool (see  <a href=http://www.drive5.com/muscle/ rel=nofollow>http://www.drive5.com/muscle/</a> ). The EBI's WSMuscle web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/muscle rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/muscle</a> ) is used. <b>Note</b> : the WSMuscle service used by this workflow is  deprecated as of 21st September 2010 and should not be used in any new  development. This service is will be retired during 2011. EBI's  replacement MUSCLE services ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/msa/muscle_rest rel=nofollow>REST</a>  or  <a href=http://www.ebi.ac.uk/Tools/webservices/services/msa/muscle_soap rel=nofollow>SOAP</a> ) should be used instead. &nbsp;",7, 2, runMuscle, Job_params, Contents_list, Input_data, Get_alignment, Unpack_alignment, EBI_MUSCLE_poll_job, ,
"http://www.myexperiment.org/workflows/222/versions/1.html","EBI_TCoffee","2008-06-0306:31:37","2010-12-0611:02:53","http://www.myexperiment.org/workflows/222/download/EBI_TCoffee-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Perform a multiple sequence alignment using T-Coffee (see  <a href=http://www.tcoffee.org/ rel=nofollow>http://www.tcoffee.org/</a> ). The EBI's WSTCoffee web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/tcoffee rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/tcoffee</a> ) is used. <b>Note</b> : the WSTCoffee service used by this workflow is  deprecated as of 21st September 2010 and should not be used in any new  development. This service is will be retired during 2011. EBI's  replacement T-COFFEE services ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/msa/tcoffee_rest rel=nofollow>REST</a>  or  <a href=http://www.ebi.ac.uk/Tools/webservices/services/msa/tcoffee_soap rel=nofollow>SOAP</a> ) should be used instead. &nbsp;",7, 2, runTCoffee, Job_params, Contents_list, Input_data, EBI_TCoffee_poll_job, Get_alignment, Unpack_alignment, ,
"http://www.myexperiment.org/workflows/223/versions/1.html","getInchIfromMassBankPeaklist_ChemSpider_workflow_withImage","2008-06-0516:00:38","2008-06-1611:40:46","http://www.myexperiment.org/workflows/223/download/getInchIfromMassBankPeaklist_ChemSpider_workflow_withImage-v1.xml?version=1","/users/937","Michael Gerlich","taverna 1","/users/937,","Michael Gerlich,","workflow that queries MassBank DB with peaklist of m/z and intensity values and retrieves SMILES codes for results after that, it converts these SMILES into ChemSpider's own identifier CSID and queries ChemSpider to get extended compound info according to SMILES/CSID",11, 4, parametersXML2, parametersXML3, parametersXML5, parametersXML, parametersXML4, parametersXML1, SimpleSearch, GetCompoundThumbnail, GetExtendedCompoundInfoArray, MassBank_Query_PeakList, Parse_Moby_Data_ArrayString, ,
"http://www.myexperiment.org/workflows/223/versions/2.html","getInchIfromMassBankPeaklist_ChemSpider_workflow_withImage","2008-06-0516:00:38","2008-06-1611:40:46","http://www.myexperiment.org/workflows/223/download/getInchIfromMassBankPeaklist_ChemSpider_workflow_withImage-v2.xml?version=2","/users/937","Michael Gerlich","taverna 1","/users/937,","Michael Gerlich,","uses InChI's retrieved from a MassBank peaklist query to get compound information about those compounds via querying ChemSpider for information and displaying those results with image",11, 4, parametersXML1, parametersXML4, parametersXML3, parametersXML5, parametersXML, parametersXML2, GetExtendedCompoundInfoArray, GetCompoundThumbnail, SimpleSearch, getInChIfromMassBankPeaklist, Parse_Moby_Data_ArrayString, ,
"http://www.myexperiment.org/workflows/224/versions/1.html","EBI_MaxSprout","2008-06-0521:44:00","2008-06-0605:58:16","http://www.myexperiment.org/workflows/224/download/EBI_MaxSprout-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Generation of protein backbone and side chain co-ordinates from a C(alpha) trace using the MaxSprout tool. The EBI's WSMaxsprout service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/maxsprout>http://www.ebi.ac.uk/Tools/webservices/services/maxsprout</a> ) is used to access the tool.",7, 2, runMaxsprout, Get_result, Job_params, Contents_list, Input_data, Unpack_result, EBI_MaxSprout_poll_job, ,
"http://www.myexperiment.org/workflows/224/versions/2.html","EBI_MaxSprout","2008-06-0521:44:00","2008-06-0605:58:16","http://www.myexperiment.org/workflows/224/download/EBI_MaxSprout-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Generation of protein backbone and side chain co-ordinates from a C(alpha) trace using the MaxSprout tool. The EBI's WSMaxsprout service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/maxsprout>http://www.ebi.ac.uk/Tools/webservices/services/maxsprout</a> ) is used to access the tool.",8, 2, Contents_list, Input_data, Job_params, Unpack_result, runMaxsprout, EBI_MaxSprout_poll_job, Get_result, Structure_or_ID, ,
"http://www.myexperiment.org/workflows/225/versions/1.html","Structure_or_ID","2008-06-0605:57:31","","http://www.myexperiment.org/workflows/225/download/Structure_or_ID-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Given a structure or structure entry identifer (e.g. PDB:1crn), return the structure in PDB format. If a structure identifier, in database:identifier format, is input the EBI's WSDbfetch web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/dbfetch>http://www.ebi.ac.uk/Tools/webservices/services/dbfetch</a> ) is used to retrive the structure in PDB format. Otherwise the input is assumed to be a formated structure and is passed through to the output.",5, 1, Fail_if_identifer, Fail_if_structure, Is_structure, fetchData, Use_structure, ,
"http://www.myexperiment.org/workflows/226/versions/1.html","getUPIForSequence workflow","2008-06-0609:59:59","2008-06-0610:07:06","","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,",,
"http://www.myexperiment.org/workflows/226/versions/2.html","getUPIForSequence workflow","2008-06-0609:59:59","2008-06-0610:07:06","","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Given a sequence retrieve the UPI (UniProt Archive (UniParc)) identifier.",
"http://www.myexperiment.org/workflows/227/versions/1.html","Nucleotide_ORF_translation","2008-06-0620:13:04","","http://www.myexperiment.org/workflows/227/download/Nucleotide_ORF_translation-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","From a nucleotide sequence get the protein translations of the open reading frames (stop to stop) that are longer than a specifed minimum length. EMBOSS getorf is used to find the ORFs and perform the translations. The getorf tool is accessed via Soaplab (see  <a href=http://www.ebi.ac.uk/Tools/webservices/soaplab/overview>http://www.ebi.ac.uk/Tools/webservices/soaplab/overview</a> ).",2, 1, getorf, Sequence_or_ID, ,
"http://www.myexperiment.org/workflows/228/versions/1.html","Fasta_string_to_fasta_list","2008-06-0621:41:28","","http://www.myexperiment.org/workflows/228/download/Fasta_string_to_fasta_list-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Split a string containing a set of sequences in fasta format into a list for fasta formated sequences.",2, 0, Split_into_sequences, Add_angle, ,
"http://www.myexperiment.org/workflows/229/versions/1.html","Nucleotide_InterProScan","2008-10-2621:10:09","2011-04-0108:54:21","http://www.myexperiment.org/workflows/229/download/Nucleotide_InterProScan-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Run InterProScan using a nucleotide sequence as input.",3, 0, Nucleotide_ORF_translation, EBI_NCBI_BLAST, EBI_InterProScan, ,
"http://www.myexperiment.org/workflows/229/versions/2.html","Nucleotide_InterProScan","2008-10-2621:10:09","2011-04-0108:54:21","http://www.myexperiment.org/workflows/229/download/Nucleotide_InterProScan-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Run InterProScan using a nucleotide sequence as input.",3, 0, Nucleotide_ORF_translation, EBI_NCBI_BLAST, EBI_InterProScan, ,
"http://www.myexperiment.org/workflows/229/versions/3.html","Nucleotide_InterProScan","2008-10-2621:10:09","2011-04-0108:54:21","http://www.myexperiment.org/workflows/229/download/Nucleotide_InterProScan-v3.xml?version=3","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Run InterProScan using a nucleotide sequence as input. The InterProScan tool ( <a href=http://www.ebi.ac.uk/Tools/InterProScan/>http://www.ebi.ac.uk/Tools/InterProScan/</a> ) searches a protein sequence against a selection of protein domain, feature and family signature databases, and integrates the results giving potential assignments to InterPro entries and Gene Ontology terms. Since InterProScan is a protein search tool to use it with a nucleotide sequence, the sequence must be translated into a protein sequence. There are a number of ways of doing this, depending on the properties of the nucleotide sequence, in this case a simple open reading frame (ORF) model is used to obtain the candidate translations. These translations are filtered for length (&gt;80aa) and a search against UniProtKB ( <a href=http://www.uniprot.org/>http://www.uniprot.org/</a> ) is performed to ensure that only sequences which have some relationship with known protein space, on which the signatures used are based, are passed to InterProScan. Once the set of translations has been filtered the remaining sequences as passed on to InterProScan for analysis. Note: the coordinates in the InterProScan output are in protein coordinates relative to the input translated sequence, to map these on to the input nucleotide sequence see the fasta header of the corresponding translated ORF where the nucleotide coordinates are shown. This implementation uses: <ol><li>EBI's WSDbfetch web service (<a href=http://www.ebi.ac.uk/Tools/webservices/services/dbfetch>http://www.ebi.ac.uk/Tools/webservices/services/dbfetch</a>) to retreive enties specified by database identifer.</li><li>EMBOSS seqret tool  (<a href=http://emboss.sourceforge.net/apps/release/5.0/emboss/apps/getorf.html>http://emboss.sourceforge.net/apps/release/5.0/emboss/apps/getorf.html</a>) via Soaplab (<a href=http://www.ebi.ac.uk/Tools/webservices/soaplab/overview>http://www.ebi.ac.uk/Tools/webservices/soaplab/overview</a>) to ensure input sequences are in an appropriate format (i.e. fasta format).</li><li>EMBOSS getorf tool (<a href=http://emboss.sourceforge.net/apps/release/5.0/emboss/apps/getorf.html>http://emboss.sourceforge.net/apps/release/5.0/emboss/apps/getorf.html</a>) via Soaplab (<a href=http://www.ebi.ac.uk/Tools/webservices/soaplab/overview>http://www.ebi.ac.uk/Tools/webservices/soaplab/overview</a>) to find the ORFs, perform the translation and filter the translations for length.</li><li>EBI's WSNCBIBlast web service (<a href=http://www.ebi.ac.uk/Tools/webservices/services/ncbiblast>http://www.ebi.ac.uk/Tools/webservices/services/ncbiblast</a>) to perform the filtering BLAST search against UniProtKB.</li><li>EBI's WSInterProScan web service (<a href=http://www.ebi.ac.uk/Tools/webservices/services/interproscan>http://www.ebi.ac.uk/Tools/webservices/services/interproscan</a>) to access InterProScan for the final search.</li></ol> and is based on the proceedure described for nucleotide InterProScan searches described on the WSInterProScan web pages (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/interproscan>http://www.ebi.ac.uk/Tools/webservices/services/interproscan</a> ).",3, 0, EBI_InterProScan, EBI_NCBI_BLAST, Nucleotide_ORF_translation, ,
"http://www.myexperiment.org/workflows/229/versions/4.html","Nucleotide_InterProScan","2008-10-2621:10:09","2011-04-0108:54:21","http://www.myexperiment.org/workflows/229/download/Nucleotide_InterProScan-v4.xml?version=4","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Note: the WSInterProScan web service used by this workflow is no longer available haveing been replaced by the EMBL-EBI's InterProScan (REST) ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_rest rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_rest</a> ) and InterProScan (SOAP) ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_soap rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_soap</a> ) web services. Thus the workflow described here no longer works, see the alternative workflows for the InterProScan (SOAP) service for workflows which use the new services. Run InterProScan using a nucleotide sequence as input.  The InterProScan tool ( <a href=http://www.ebi.ac.uk/Tools/InterProScan/ rel=nofollow>http://www.ebi.ac.uk/Tools/InterProScan/</a> ) searches a protein sequence against a selection of protein domain, feature and family signature databases, and integrates the results giving potential assignments to InterPro entries and Gene Ontology terms. Since InterProScan is a protein search tool to use it with a nucleotide sequence, the sequence must be translated into a protein sequence. There are a number of ways of doing this, depending on the properties of the nucleotide sequence, in this case a simple open reading frame (ORF) model is used to obtain the candidate translations. These translations are filtered for length (&gt;80aa) and a search against UniProtKB ( <a href=http://www.uniprot.org/ rel=nofollow>http://www.uniprot.org/</a> ) is performed to ensure that only sequences which have some relationship with known protein space, on which the signatures used are based, are passed to InterProScan. Once the set of translations has been filtered the remaining sequences as passed on to InterProScan for analysis.  Note: the coordinates in the InterProScan output are in protein coordinates relative to the input translated sequence, to map these on to the input nucleotide sequence see the fasta header of the corresponding translated ORF where the nucleotide coordinates are shown.  This implementation uses: and is based on the proceedure described for nucleotide InterProScan searches described on the WSInterProScan web pages (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/interproscan rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/interproscan</a> ).",3, 0, EBI_InterProScan, EBI_NCBI_BLAST, Nucleotide_ORF_translation, ,
"http://www.myexperiment.org/workflows/230/versions/1.html","EBI_Blast2InterPro","2008-10-2620:45:45","2012-08-2211:22:43","http://www.myexperiment.org/workflows/230/download/EBI_Blast2InterPro-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,",,4, 0, EBI_InterProScan, EBI_WUBLAST, EBI_dbfetch_fetchBatch, Fasta_string_to_fasta_list, ,
"http://www.myexperiment.org/workflows/230/versions/2.html","EBI_Blast2InterPro","2008-10-2620:45:45","2012-08-2211:22:43","http://www.myexperiment.org/workflows/230/download/EBI_Blast2InterPro-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Note: the WSInterProScan web service used by this workflow is no longer available haveing been replaced by the EMBL-EBI's InterProScan (REST) ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_rest rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_rest</a> ) and InterProScan (SOAP) ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_soap rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/pfa/iprscan_soap</a> ) web services. Thus the workflow described here no longer works, see the alternative workflows for the InterProScan (SOAP) service for workflows which use the new services. Perform a BLAST search add information about the InterPro matches associated with the hits.  This implementation uses: 3. EBI&rsquo;s WSInterProScan web service ( <a href=http://www.ebi.ac.uk/Tools/webservices/services/interproscan rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/interproscan</a> ) to get the InterPro matches for the BLAST hits.",4, 0, EBI_dbfetch_fetchBatch, Fasta_string_to_fasta_list, EBI_InterProScan, EBI_WUBLAST, ,
"http://www.myexperiment.org/workflows/231/versions/1.html","NCBI_QBLAST","2008-06-0715:05:00","2008-06-0717:11:36","http://www.myexperiment.org/workflows/231/download/NCBI_QBLAST-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Perform an NCBI BLAST sequence similarity search using NCBI's QBLAST service (see  <a href=http://www.ncbi.nlm.nih.gov/BLAST/Doc/urlapi.html>http://www.ncbi.nlm.nih.gov/BLAST/Doc/urlapi.html</a> ). The query sequence, database to search and BLAST program to use are inputs, the other parameters for the search are allowed to default.",2, 0, QBLAST_Put, QBLAST_Get, ,
"http://www.myexperiment.org/workflows/231/versions/2.html","NCBI_QBLAST","2008-06-0715:05:00","2008-06-0717:11:36","http://www.myexperiment.org/workflows/231/download/NCBI_QBLAST-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Perform an NCBI BLAST sequence similarity search using NCBI's QBLAST service (see  <a href=http://www.ncbi.nlm.nih.gov/BLAST/Doc/urlapi.html>http://www.ncbi.nlm.nih.gov/BLAST/Doc/urlapi.html</a> ). The query sequence, database to search and BLAST program to use are inputs, the other parameters for the search are allowed to default.",4, 0, QBLAST_Put, QBLAST_Get, Sequence_or_ID_or_GI, Reformat_sequence, ,
"http://www.myexperiment.org/workflows/232/versions/1.html","Sequence_or_ID_or_GI","2008-06-0716:58:14","","http://www.myexperiment.org/workflows/232/download/Sequence_or_ID_or_GI-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Get a sequence in fasta format given one of: <ol><li>An NCBI GI number (e.g. 75251068).</li><li>An entry identifier in database:identifier format (e.g. uniprot:Q96247).</li></ol> 3. A sequence entry in a format supported by EMBOSS seqret.",5, 0, Sequence_or_ID, Get_fasta_from_GI, Is_GI, Fail_if_GI, Fail_if_sequence_or_id, ,
"http://www.myexperiment.org/workflows/233/versions/1.html","EBI_DaliLite","2008-06-0717:16:37","","http://www.myexperiment.org/workflows/233/download/EBI_DaliLite-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Pairwise structure comparison using the DaliLite tool. The EBI's WSDaliLite web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/dalilite>http://www.ebi.ac.uk/Tools/webservices/services/dalilite</a> ) is used to access the tool.",5, 2, runDaliLite, Job_params, EBI_DaliLite_poll_job, Get_output, Unpack_output, ,
"http://www.myexperiment.org/workflows/235/versions/1.html","EBI_PICR_Sequence_to_UniParc_and_InterPro","2008-06-0813:53:39","2008-06-0814:10:02","http://www.myexperiment.org/workflows/235/download/EBI_PICR_Sequence_to_UniParc_and_InterPro-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Given a protein sequence get some information about it: <ol><li>Does this protein sequence occur in any of the protein databases (e.g. UniProtKB, PDB, etc.). Using the PICR web service (see <a href=http://www.ebi.ac.uk/Tools/picr/>http://www.ebi.ac.uk/Tools/picr/</a>) map the sequence to a UniParc identifer.</li><li>Which entries in the protein databases have this sequence. Using the UniParc database (see <a href=http://www.ebi.ac.uk/uniprot/database/DBDescription.html#uniparc>http://www.ebi.ac.uk/uniprot/database/DBDescription.html#uniparc</a>) a summary of the databases and the entries in those databases which have this sequence is obtained.</li></ol> 3. Does any protein domain or family information exist for this sequence. Using the InterPro Matches UniParc database (see  <a href=http://srs.ebi.ac.uk/srsbin/cgi-bin/wgetz?-page+LibInfo+-lib+IPRMC_UNIPARC>http://srs.ebi.ac.uk/srsbin/cgi-bin/wgetz?-page+LibInfo+-lib+IPRMC_UNIPARC</a> ) a summary of the known signature matches is obtained.",4, 0, Spit_PICR_result, EBI_dbfetch_UniParc, EBI_Fetch_InterPro_Matches_UniParc, EBI_PICR_sequence_to_ID, ,
"http://www.myexperiment.org/workflows/235/versions/2.html","EBI_PICR_Sequence_to_UniParc_and_InterPro","2008-06-0813:53:39","2008-06-0814:10:02","http://www.myexperiment.org/workflows/235/download/EBI_PICR_Sequence_to_UniParc_and_InterPro-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Given a protein sequence get some information about it: <ol><li>Does this protein sequence occur in any of the protein databases (e.g. UniProtKB, PDB, etc.). Using the PICR web service (see <a href=http://www.ebi.ac.uk/Tools/picr/>http://www.ebi.ac.uk/Tools/picr/</a>) map the sequence to a UniParc identifer.</li><li>Which entries in the protein databases have this sequence. Using the UniParc database (see <a href=http://www.ebi.ac.uk/uniprot/database/DBDescription.html#uniparc>http://www.ebi.ac.uk/uniprot/database/DBDescription.html#uniparc</a>) a summary of the databases and the entries in those databases which have this sequence is obtained.</li></ol> 3. Does any protein domain or family information exist for this sequence. Using the InterPro Matches UniParc database (see  <a href=http://srs.ebi.ac.uk/srsbin/cgi-bin/wgetz?-page+LibInfo+-lib+IPRMC_UNIPARC>http://srs.ebi.ac.uk/srsbin/cgi-bin/wgetz?-page+LibInfo+-lib+IPRMC_UNIPARC</a> ) a summary of the known signature matches is obtained.",4, 0, Spit_PICR_result, EBI_dbfetch_UniParc, EBI_Fetch_InterPro_Matches_UniParc, EBI_PICR_sequence_to_ID, ,
"http://www.myexperiment.org/workflows/236/versions/1.html","EBI_PICR_Sequence_to_ID","2008-06-0814:03:07","","http://www.myexperiment.org/workflows/236/download/EBI_PICR_Sequence_to_ID-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Map a protein sequence to the known identifiers of identical sequences. Uses the EBI's PICR web service (see  <a href=http://www.ebi.ac.uk/Tools/picr/>http://www.ebi.ac.uk/Tools/picr/</a> ) to perform the mapping.",3, 1, getUPIForSequence, PICR_input_params, Unwrap_PICR_result, ,
"http://www.myexperiment.org/workflows/237/versions/1.html","EBI_dbfetch_UniParc","2008-06-0814:05:40","","http://www.myexperiment.org/workflows/237/download/EBI_dbfetch_UniParc-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","From a list of UniParc entry identifers get the complete entries using the EBI's WSDbfetch service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/dbfetch>http://www.ebi.ac.uk/Tools/webservices/services/dbfetch</a> ).",3, 1, Extract_entries, Format_list_for_dbfetch, fetchBatch, ,
"http://www.myexperiment.org/workflows/238/versions/1.html","EBI_Fetch_InterPro_Matches_UniParc","2008-06-0814:08:47","","http://www.myexperiment.org/workflows/238/download/EBI_Fetch_InterPro_Matches_UniParc-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","For a UniParc (see  <a href=http://www.ebi.ac.uk/uniprot/database/DBDescription.html#uniparc>http://www.ebi.ac.uk/uniprot/database/DBDescription.html#uniparc</a> ) identifier/accession fetch the assocated InterPro Matches from SRS@EBI (see  <a href=http://srs.ebi.ac.uk/srsbin/cgi-bin/wgetz?-page+LibInfo+-lib+IPRMC_UNIPARC>http://srs.ebi.ac.uk/srsbin/cgi-bin/wgetz?-page+LibInfo+-lib+IPRMC_UNIPARC</a> ).",3, 0, Get_entry_from_SRS, Build_InterPro_Matches_UniParc_URL, Check_for_SRS_error, ,
"http://www.myexperiment.org/workflows/239/versions/1.html","Download from ChemSpider using Accurate Mass revised","2008-06-1112:13:36","2008-06-1112:15:21","http://www.myexperiment.org/workflows/239/download/Download_from_ChemSpider_using_Accurate_Mass_revised-v1.xml?version=1","/users/937","Michael Gerlich","taverna 1","/users/937, /users/286,","Michael Gerlich, Egon Willighagen,","updated version of Download from ChemSpider using Accurate Mass to make use of the new ChemSpider services",5, 2, parametersXML2, parametersXML, parametersXML1, GetExtendedCompoundInfoArray, SearchByMass2, ,
"http://www.myexperiment.org/workflows/240/versions/1.html","countryExammple_unfinished","2008-06-1614:09:22","","","/users/13","Katy Wolstencroft","taverna 1","/users/13,","Katy Wolstencroft,","This Workflow is unfinished, but when connected up, it will allow you to find a list of the cities in a particular country, the time zone that country is in, the conversion rate of that country and yours and the international dialling code for that country",
"http://www.myexperiment.org/workflows/241/versions/1.html","countryExample_working","2008-06-1614:10:10","","","/users/13","Katy Wolstencroft","taverna 1","/users/13,","Katy Wolstencroft,","This Workflow allows you to find a list of the cities in a particular country, the time zone that country is in, the conversion rate of the currency in that country and yours and the international dialling code for that country",
"http://www.myexperiment.org/workflows/242/versions/1.html","Get weather information","2008-06-1716:25:49","2008-06-2014:48:32","http://www.myexperiment.org/workflows/242/download/Get_weather_information-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62, /users/5,","Franck Tanoh, Stian Soiland-Reyes,","Get the weather forcast of the day for you city.Info display:  wind, visibility, temperature, sky conditions and pressure.The default value is my home town.To find out any supported city run the 'Get cities by country name' workflow",7, 1, CountryName, ExtractTemperature, GetWeatherResult, CountryAndCity, GetWeather, FindCitiesByCountry, SelectFirstCities, ,
"http://www.myexperiment.org/workflows/242/versions/2.html","Get weather information","2008-06-1716:25:49","2008-06-2014:48:32","http://www.myexperiment.org/workflows/242/download/Get_weather_information-v2.xml?version=2","/users/62","Franck Tanoh","taverna 1","/users/62, /users/5,","Franck Tanoh, Stian Soiland-Reyes,","Get the weather forcast of the day from the first 6 cities of a country.  Info display:  wind, visibility, temperature, sky conditions and pressure.  The default value is my home country.",7, 1, CountryName, ExtractTemperature, GetWeatherResult, CountryAndCity, GetWeather, FindCitiesByCountry, SelectFirstCities, ,
"http://www.myexperiment.org/workflows/242/versions/3.html","Get weather information","2008-06-1716:25:49","2008-06-2014:48:32","http://www.myexperiment.org/workflows/242/download/Get_weather_information-v3.xml?version=3","/users/62","Franck Tanoh","taverna 1","/users/62, /users/5,","Franck Tanoh, Stian Soiland-Reyes,","Get the weather forcast of the day for you city.  Info display:  wind, visibility, temperature, sky conditions and pressure.  The default value Stian's home country.",7, 1, GetWeatherResult, GetWeather, SelectFirstCities, CountryName, CountryAndCity, ExtractTemperature, FindCitiesByCountry, ,
"http://www.myexperiment.org/workflows/244/versions/1.html","EBI_CENSOR","2008-06-1720:42:46","2008-06-2506:16:03","http://www.myexperiment.org/workflows/244/download/EBI_CENSOR-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","The CENSOR tool identifies and masks simple and complex sequence repeats found in nucleotide and protein sequences. This workflow uses the EBI's WSCensor web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/censor>http://www.ebi.ac.uk/Tools/webservices/services/censor</a> ) to access the tool.",11, 4, Unpack_table, Unpack_masked_sequence, Unpack_alignment, Contents_list, Input_data, Job_params, runCensor, Get_alignment, Get_table, Get_masked_sequence, EBI_CENSOR_poll_job, ,
"http://www.myexperiment.org/workflows/244/versions/2.html","EBI_CENSOR","2008-06-1720:42:46","2008-06-2506:16:03","http://www.myexperiment.org/workflows/244/download/EBI_CENSOR-v2.xml?version=2","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","The CENSOR tool identifies and masks simple and complex sequence repeats found in nucleotide and protein sequences. This workflow uses the EBI's WSCensor web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/censor>http://www.ebi.ac.uk/Tools/webservices/services/censor</a> ) to access the tool.",11, 4, Unpack_alignment, Contents_list, Job_params, Input_data, Unpack_masked_sequence, Unpack_table, Get_table, Get_alignment, runCensor, EBI_CENSOR_poll_job, Get_masked_sequence, ,
"http://www.myexperiment.org/workflows/245/versions/1.html","tRNAscan","2008-06-2809:57:33","","http://www.myexperiment.org/workflows/245/download/tRNAscan-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Search a nucleotide sequence for tRNA genes using the tRNAscan-SE tool (see  <a href=http://wiki.bioinformatics.org/TRNAscan-SE>http://wiki.bioinformatics.org/TRNAscan-SE</a> ). This workflow uses the tRNAscan service at VBI PathPort (see  <a href=http://pathport.vbi.vt.edu/services/#predict_7>http://pathport.vbi.vt.edu/services/#predict_7</a> ).",2, 1, getTRNA, Sequence_or_ID_or_GI, ,
"http://www.myexperiment.org/workflows/246/versions/1.html","Identification of differential genes using the LIMMA Bioconductor package within R","2008-07-0211:24:12","2008-07-0211:28:21","http://www.myexperiment.org/workflows/246/download/Identification_of_differential_genes_using_the_LIMMA_Bioconductor_package_within_R-v1.xml?version=1","/users/221","Peter Li","taverna 1","/users/221,","Peter Li,","This workflow starts by retrieving the names of microarray datasets from the Maxd database. The user has to select sets of control and test data which are then analysed by the LIMMA Bioconductor package in an R script.&nbsp;This&nbsp;produces a&nbsp;list of significant differentially expressed genes&nbsp;which is&nbsp;then analysed using the Go Term Finder tool&nbsp;to generate a&nbsp;PDF report&nbsp;of the common&nbsp;GO terms associated with the genes. A CSV file containing the list of significant genes is also generated.",19, 7, flatten, GoTermFinder_pvalue, performT_testsUsingLIMMA, getNamesUsingXPath, createFinalCSV, cleanCSV, createGeneList, selectTestData, getAffyIds, mergeOutput2, selectControlData, mergeOutput1, queryMaxd2, queryMaxd1, getGeneName, analyseGenesPDFOutput, getMeasurementNames, getTargetDescription, getTranscriptId, ,
"http://www.myexperiment.org/workflows/248/versions/1.html","EBI_CiteXplore","2008-07-0904:53:56","","http://www.myexperiment.org/workflows/248/download/EBI_CiteXplore-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Perform a literature search using the EBI's CiteXplore service ( <a href=http://www.ebi.ac.uk/citexplore/>http://www.ebi.ac.uk/citexplore/</a> ), and get the results in a minimal XML format containing the citation information (i.e. title, author, journal, etc.), the identifier of the citation in the source database (PubMed/Medline, Agricola, Patent Abstracts, CBA, CiteSeer, etc.) and information about abstract and full article availablity including URLs.",3, 1, searchCitations, Search_Parameters, Unwrap_result, ,
"http://www.myexperiment.org/workflows/249/versions/1.html","EBI_Whatizit","2008-07-0905:14:28","","http://www.myexperiment.org/workflows/249/download/EBI_Whatizit-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Perform a text-mining analysis of an input text document using the EBI's Whatizit tool ( <a href=http://www.ebi.ac.uk/webservices/whatizit/info.jsf>http://www.ebi.ac.uk/webservices/whatizit/info.jsf</a> ). Whatizit provides a number of text-mining pipelines which can can detect various terms of biological interest in text documents. For example finding gene names and mapping them to UniProtKB identifiers, finding chemical terms and mapping them to ChEBI, etc.",3, 1, contact, Input_params, Unwrap_result, ,
"http://www.myexperiment.org/workflows/250/versions/1.html","EBI_OLS_TermInfo","2008-07-0905:36:40","","http://www.myexperiment.org/workflows/250/download/EBI_OLS_TermInfo-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Get details of an ontology term given its identifer. This workflow uses the EBI's Ontology Lookup Service (OLS) to get the details of the ontology term. The OLS suports a wide range of biological and bioinformatic ontologies. See  <a href=http://www.ebi.ac.uk/ontology-lookup/>http://www.ebi.ac.uk/ontology-lookup/</a>  for more information.",3, 1, getTermMetadata, Input_parameters, Unwrap_result, ,
"http://www.myexperiment.org/workflows/251/versions/1.html","EBI_IntAct","2008-07-0906:01:17","","http://www.myexperiment.org/workflows/251/download/EBI_IntAct-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,","Find protein binary interactions using the EBI's IntAct service. See  <a href=http://www.ebi.ac.uk/intact/>http://www.ebi.ac.uk/intact/</a>  for further details.",3, 1, findBinaryInteractions, Input_parameters, Unwrap_result, ,
"http://www.myexperiment.org/workflows/252/versions/1.html","maxdBrowse_upreg.xml","2008-07-1209:08:24","2008-07-1211:44:21","http://www.myexperiment.org/workflows/252/download/maxdBrowse_upreg.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,1, 1, maxdBrowse_query, ,
"http://www.myexperiment.org/workflows/253/versions/1.html","qtl_pathway_3.xml","2008-07-1209:10:15","2008-07-1211:44:53","http://www.myexperiment.org/workflows/253/download/qtl_pathway_3.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,24, 6, species, start, regex, end, remove_Nulls, add_uniproti_to_string, parse_swiss, options, chromo, split_by_regex, getGeneInfo, split_gene_ids, Kegg_gene_ids, parse_ddbj_gene_info, getcurrentdatabase, getgenesbyspecies, Split_string_into_string_list_by_regular_expression, regex_2, NestedWorkflow, merge_swiss_ids, merge_genes_and_pathways, btit, Concatenate_two_strings, Merge_string_list_to_string, ,
"http://www.myexperiment.org/workflows/254/versions/1.html","unnested_qtl_pathway_4.xml","2008-07-1209:11:08","2008-07-1220:21:50","http://www.myexperiment.org/workflows/254/download/unnested_qtl_pathway_4.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,7, 2, String_Constant, Split_string_into_string_list_by_regular_expression, Merge_string_list_to_string, get_pathways_by_genes1, Concatenate_two_strings, lister, Merge_string_list_to_string1, ,
"http://www.myexperiment.org/workflows/255/versions/1.html","unnested_qtl_pathway.xml","2008-07-1209:12:44","2008-07-1211:45:59","http://www.myexperiment.org/workflows/255/download/unnested_qtl_pathway.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,24, 7, start, merge_swissprot, regex, species, end, remove_Nulls, add_ncbi_to_string, merge_gene_pathways, chromo, merge_pathways_2, options, parse_swiss, merge_pathways, split_genes, split_by_regex, split_gene_ids, Concatenate_two_strings, lister, get_pathways_by_genes, getcurrentdatabase, parse_ddbj_gene_info, getgenesbyspecies, getGeneInfo, Kegg_gene_ids, ,
"http://www.myexperiment.org/workflows/256/versions/1.html","unnested_qtl_pathway_3.xml","2008-07-1209:14:19","2008-07-1220:21:22","http://www.myexperiment.org/workflows/256/download/unnested_qtl_pathway_3.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,6, 3, get_pathways_by_genes, String_Constant, Merge_string_list_to_string, Split_string_into_string_list_by_regular_expression, lister, get_pathways_by_genes1, ,
"http://www.myexperiment.org/workflows/257/versions/1.html","unnested_qtl_pathway_2.xml","2008-07-1209:15:13","2008-07-1220:20:52","http://www.myexperiment.org/workflows/257/download/unnested_qtl_pathway_2.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,23, 7, species, end, regex, split_by_regex, getGeneInfo, parse_swiss, remove_Nulls, start, chromo, options, add_uniprot_to_string, merge_swissprot, split_uniprot_strings, Kegg_gene_ids, merge_pathways, getgenesbyspecies, parse_ddbj_gene_info, getcurrentdatabase, get_pathways_by_genes, parse_gene_id, merge_gene_ids, remove_nulls_2, lister, ,
"http://www.myexperiment.org/workflows/258/versions/1.html","geneId_to_pathway.xml","2008-07-1209:16:00","2008-07-1211:48:03","http://www.myexperiment.org/workflows/258/download/geneId_to_pathway.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,7, 3, merge_pathways, mergePathways_2, lister, split_gene_ids, get_pathways_by_genes, Kegg_gene_ids_all_species, Add_ncbi_to_string, ,
"http://www.myexperiment.org/workflows/259/versions/1.html","blast_simplifier.xml","2008-07-1209:17:40","2008-07-1220:20:20","http://www.myexperiment.org/workflows/259/download/blast_simplifier.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,2, 1, blastsimplifier, gi_option, ,
"http://www.myexperiment.org/workflows/260/versions/1.html","add_ncbi_to_string.xml","2008-07-1209:18:36","2008-07-1211:49:23","http://www.myexperiment.org/workflows/260/download/add_ncbi_to_string.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,1, 0, add_ncbi_to_string, ,
"http://www.myexperiment.org/workflows/262/versions/1.html","Gi_to_pathway.xml","2008-07-1209:20:04","2008-07-1220:07:57","http://www.myexperiment.org/workflows/262/download/Gi_to_pathway.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,7, 2, GETPATHWAYS, GETIMAGE, KEGGBASEURL, add_ncbi_string, Kegg_id_conv, parse_result, Gi_number, ,
"http://www.myexperiment.org/workflows/263/versions/1.html","parse_swiss.xml","2008-07-1209:21:29","2008-07-1211:54:06","http://www.myexperiment.org/workflows/263/download/parse_swiss.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,3, 1, parse_swiss, options, parse_ddbj_gene_info, ,
"http://www.myexperiment.org/workflows/264/versions/1.html","geneHunt.xml","2008-07-1209:22:10","2008-07-1220:14:04","http://www.myexperiment.org/workflows/264/download/geneHunt.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,4, 1, geneNames, ColumnType, MeasurementIDs, query, ,
"http://www.myexperiment.org/workflows/265/versions/1.html","ensembl_gene_info.xml","2008-07-1209:25:59","2008-07-1209:26:15","http://www.myexperiment.org/workflows/265/download/ensembl_gene_info.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,1, 1, getGeneInfo, ,
"http://www.myexperiment.org/workflows/266/versions/1.html","parse_gene_info.xml","2008-07-1209:27:06","2008-07-1209:27:22","http://www.myexperiment.org/workflows/266/download/parse_gene_info.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,2, 1, parse_ddbj_gene_info, swiss_option, ,
"http://www.myexperiment.org/workflows/267/versions/1.html","ensembl_genes_to_go_terms.xml","2008-07-1209:27:59","2008-07-1209:28:18","http://www.myexperiment.org/workflows/267/download/ensembl_genes_to_go_terms.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,11, 1, regex_2, split_by_regex_2, Ensembl_gene_info, Remove_swiss_nulls, Uniprot_record_search, Parse_swiss_ids, Parse_uniprot, parse_go_term, split_go_terms, Remove_Go_nulls, getTree, ,
"http://www.myexperiment.org/workflows/268/versions/1.html","parse_uniprot_2.xml","2008-07-1209:29:12","2008-07-1209:29:26","http://www.myexperiment.org/workflows/268/download/parse_uniprot_2.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,1, 1, parse_uniprot, ,
"http://www.myexperiment.org/workflows/269/versions/1.html","gene_ontology_analysis_2.xml","2008-07-1209:30:11","2008-07-1209:30:26","http://www.myexperiment.org/workflows/269/download/gene_ontology_analysis_2.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,5, 2, fieldName, Swissprot_Id, parse_uniprot, Uniprot_search, parse_go_term, ,
"http://www.myexperiment.org/workflows/270/versions/1.html","gene_ontology_analysis.xml","2008-07-1209:31:13","2008-07-1209:32:55","http://www.myexperiment.org/workflows/270/download/gene_ontology_analysis.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,1, 1, getTree, ,
"http://www.myexperiment.org/workflows/271/versions/1.html","complete_2_text_mining.xml","2008-07-1209:33:56","2008-07-1209:35:15","http://www.myexperiment.org/workflows/271/download/complete_2_text_mining.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,29, 2, end, regex1, split_by_regex_2, comma, split_by_regex_3, array_name, chromosome, comma_separated, split_by_regex_4, start, getcurrentdatabase, Remove_duplicates, Parse_swiss_ids, split_by_regex, merge_list_2, regex_2, species, merge_string_list, merge_list_3, Remove_gene_nulls, Probesets_to_genes, Remove_swiss_nulls, Ensembl_gene_info, Uniprot_record_search, getgenesbyspecies, Probeset_in_QTL, Text_mining, Parse_gene_name, remove_genes_from_probesets, ,
"http://www.myexperiment.org/workflows/272/versions/1.html","sub_gene_info_to_uniprot.xml","2008-07-1209:36:15","2008-07-1209:36:33","http://www.myexperiment.org/workflows/272/download/sub_gene_info_to_uniprot.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,11, 1, regex_2, Concatenate_two_strings2, split_by_regex_2, Remove_gene_nulls, Remove_swiss_nulls, Parse_gene_name, Uniprot_record_search, Ensembl_gene_info, Parse_swiss_ids, parse_uniprot, ID_input, ,
"http://www.myexperiment.org/workflows/273/versions/1.html","complete_3.1.xml","2008-07-1209:37:32","2008-07-1209:38:10","http://www.myexperiment.org/workflows/273/download/complete_3.1.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,17, 2, chromosome, comma, regex1, array_name, split_by_regex, regex_2, end, start, species, Ensembl_gene_info, merge_string_list, Remove_duplicates, getcurrentdatabase, Probesets_to_genes, getgenesbyspecies, Probeset_in_QTL, parse_genes_form_probesets, ,
"http://www.myexperiment.org/workflows/274/versions/1.html","extract_uniprot_embl_gi.xml","2008-07-1209:38:57","2008-07-1209:39:12","http://www.myexperiment.org/workflows/274/download/extract_uniprot_embl_gi.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,4, 2, parse_embl_id, fieldName, parse_uniprot, Uniprot_search, ,
"http://www.myexperiment.org/workflows/275/versions/1.html","maxdBrowse_geneHunt.xml","2008-07-1209:40:38","2008-07-1209:40:52","http://www.myexperiment.org/workflows/275/download/maxdBrowse_geneHunt.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,2, 2, maxdbrowse_expressions, maxdBrowse_geneHunt, ,
"http://www.myexperiment.org/workflows/276/versions/1.html","Probeset_id_2_Swissport_id.xml","2008-07-1209:41:31","2008-07-1220:19:45","http://www.myexperiment.org/workflows/276/download/Probeset_id_2_Swissport_id.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,12, 3, options, split_by_regex, parse_swiss, regex, parse_ddbj_gene_info, probeset_to_gene, getGeneInfo, chromosome, database, probeset_ids, start, stop, ,
"http://www.myexperiment.org/workflows/277/versions/1.html","text_mining.xml","2008-07-1209:42:44","2008-07-1209:43:00","http://www.myexperiment.org/workflows/277/download/text_mining.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,2, 1, email, chilibot, ,
"http://www.myexperiment.org/workflows/278/versions/1.html","complete_2.xml","2008-07-1209:44:05","2008-07-1209:44:22","http://www.myexperiment.org/workflows/278/download/complete_2.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,24, 2, end, regex1, regex_2, merge_string_list, chromosome, split_by_regex_2, merge_list_2, species, array_name, comma, start, split_by_regex, split_by_regex_3, Ensembl_gene_info, Remove_duplicates, getcurrentdatabase, Uniprot_record_search, getgenesbyspecies, Probesets_to_genes, Parse_gene_name, Parse_swiss_ids, Probeset_in_QTL, Remove_swiss_nulls, Remove_gene_nulls, ,
"http://www.myexperiment.org/workflows/279/versions/1.html","remove_nulls.xml","2008-07-1209:45:02","2008-07-1209:45:21","http://www.myexperiment.org/workflows/279/download/remove_nulls.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,1, 0, remove_Nulls, ,
"http://www.myexperiment.org/workflows/280/versions/1.html","linking.xml","2008-07-1209:45:59","2008-07-1209:46:13","http://www.myexperiment.org/workflows/280/download/linking.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,5, 1, fieldname, searchterm, xref_databank, databank, srslinks, ,
"http://www.myexperiment.org/workflows/281/versions/1.html","lister.xml","2008-07-1209:46:59","2008-07-1209:47:42","http://www.myexperiment.org/workflows/281/download/lister.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,7, 3, end, chromosome, start, database, getgenesbyspecies, getGeneInfo, lister, ,
"http://www.myexperiment.org/workflows/282/versions/1.html","Ensembl_id_2_Swissport_id.xml","2008-07-1209:48:28","2008-07-1209:48:42","http://www.myexperiment.org/workflows/282/download/Ensembl_id_2_Swissport_id.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,6, 2, parse_swiss, split_by_regex, options, regex, parse_ddbj_gene_info, getGeneInfo, ,
"http://www.myexperiment.org/workflows/283/versions/1.html","parse_uniprot.xml","2008-07-1209:49:45","2008-07-1209:50:26","http://www.myexperiment.org/workflows/283/download/parse_uniprot.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,4, 2, fieldName, Uniprot_search, parse_uniprot, Swissprot_Id, ,
"http://www.myexperiment.org/workflows/284/versions/1.html","complete.xml","2008-07-1209:51:09","2008-07-1209:51:36","http://www.myexperiment.org/workflows/284/download/complete.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,21, 2, end, array_name, regex1, chromosome, species, start, regex_2, split_by_regex_2, comma, split_by_regex, merge_string_list, merge_list_2, Ensembl_gene_info, getgenesbyspecies, getcurrentdatabase, Probeset_in_QTL, Parse_gene_name, Uniprot_record_search, Parse_swiss_ids, Probesets_to_genes, Remove_duplicates, ,
"http://www.myexperiment.org/workflows/285/versions/1.html","complete_deleted.xml","2008-07-1209:52:27","2008-07-1209:52:42","http://www.myexperiment.org/workflows/285/download/complete_deleted.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,21, 2, regex1, start, split_by_regex, chromosome, regex_2, merge_string_list, split_by_regex_2, end, comma, array_name, species, merge_list_2, Remove_duplicates, getcurrentdatabase, getgenesbyspecies, Parse_gene_name, Probesets_to_genes, Parse_swiss_ids, Probeset_in_QTL, Uniprot_record_search, Ensembl_gene_info, ,
"http://www.myexperiment.org/workflows/286/versions/1.html","maxdBrowse.xml","2008-07-1209:53:37","2008-07-1209:54:51","http://www.myexperiment.org/workflows/286/download/maxdBrowse.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,2, 1, result_type, query, ,
"http://www.myexperiment.org/workflows/287/versions/1.html","remove_duplicates_full.xml","2008-07-1209:55:38","2008-07-1209:55:52","http://www.myexperiment.org/workflows/287/download/remove_duplicates_full.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,14, 3, database, end, array_name, split_by_regex1, Merge_string_list1, start, chromosome, comma1, regex1, getgenesbyspecies, probeset_in_qtl, probeset_to_gene, Concatenate_two_strings, Remove_duplicate_strings, ,
"http://www.myexperiment.org/workflows/288/versions/1.html","remove_duplicates.xml","2008-07-1209:56:46","2008-07-1209:57:40","http://www.myexperiment.org/workflows/288/download/remove_duplicates.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,2, 0, Remove_duplicate_strings, Concatenate_two_strings, ,
"http://www.myexperiment.org/workflows/289/versions/1.html","complete_test.xml","2008-07-1209:58:25","2008-07-1209:58:43","http://www.myexperiment.org/workflows/289/download/complete_test.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,15, 2, array_name, regex1, chromosome, comma, merge_string_list, remove_duplicates, end, start, species, Ensembl_gene_info, split_by_regex, getcurrentdatabase, getgenesbyspecies, Probeset_in_QTL, Probesets_to_genes, ,
"http://www.myexperiment.org/workflows/290/versions/1.html","qtl_analysis.xml","2008-07-1209:59:53","2008-07-1210:00:11","http://www.myexperiment.org/workflows/290/download/qtl_analysis.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,18, 2, array_name, merge_string_list, species, end, start, chromosome, regex1, split_by_regex, comma, Ensembl_gene_info, getgenesbyspecies, getcurrentdatabase, Parse_gene_name, Probesets_to_genes, Probeset_in_QTL, Parse_swiss_ids, maxdBrowse_expressions, return_type, ,
"http://www.myexperiment.org/workflows/291/versions/1.html","uniprot_search.xml","2008-07-1210:00:53","2008-07-1210:01:18","http://www.myexperiment.org/workflows/291/download/uniprot_search.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,2, 1, Uniprot_search, fieldName, ,
"http://www.myexperiment.org/workflows/292/versions/1.html","interpro_scan.xml","2008-07-1210:02:03","2008-07-1210:02:17","http://www.myexperiment.org/workflows/292/download/interpro_scan.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,1, 1, InterProScan_proteinraw, ,
"http://www.myexperiment.org/workflows/293/versions/1.html","interpro_url.xml","2008-07-1210:03:35","2008-07-1220:19:04","http://www.myexperiment.org/workflows/293/download/interpro_url.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,","An example of how a more complex workflow can federate multiple resources to perform data mining. In this case a single input data item in the form of a probe set identifier is cross referenced to data sets in multiple locations to answer a kind of 'show me everything about this data' question.",6, 0, REGEX_GROUP, INTERPRO_REGEX, INTERPRO_URL, INTERPRO_RESULT_FILTER, interpro_ids, CONCAT_INTERPRO_URL, ,
"http://www.myexperiment.org/workflows/294/versions/1.html","parse_sequence.xml","2008-07-1210:05:17","2008-07-1210:05:32","http://www.myexperiment.org/workflows/294/download/parse_sequence.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,6, 2, split_by_regex, regex, getGeneInfo, parse_sequence, options3, parse_gene_info_3, ,
"http://www.myexperiment.org/workflows/295/versions/1.html","swiss_and_name_seq.xml","2008-07-1210:07:42","2008-07-1210:07:57","http://www.myexperiment.org/workflows/295/download/swiss_and_name_seq.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,12, 4, options, getGeneInfo, split_by_regex, parse_gene_name, parse_swiss, options2, regex, parse_ddbj_gene_info, parse_gene_info_2, parse_gene_info_3, options3, parse_sequence, ,
"http://www.myexperiment.org/workflows/296/versions/1.html","swiss_and_name.xml","2008-07-1210:10:10","2008-07-1210:10:34","http://www.myexperiment.org/workflows/296/download/swiss_and_name.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,9, 3, options, parse_swiss, getGeneInfo, parse_gene_name, options2, split_by_regex, regex, parse_ddbj_gene_info, parse_gene_info_2, ,
"http://www.myexperiment.org/workflows/297/versions/1.html","expression_values.xml","2008-07-1210:11:18","2008-07-1210:11:38","http://www.myexperiment.org/workflows/297/download/expression_values.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,10, 1, start, chromosome, comma, end, comma_separated, array_name, database, spit_by_regex, regex, probeset_in_qtl, ,
"http://www.myexperiment.org/workflows/298/versions/1.html","parse_gene_name.xml","2008-07-1210:12:36","2008-07-1210:12:55","http://www.myexperiment.org/workflows/298/download/parse_gene_name.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,3, 1, options2, parse_gene_info_2, parse_gene_info, ,
"http://www.myexperiment.org/workflows/299/versions/1.html","metabolic_pathway.xml","2008-07-1210:13:37","2008-07-1210:13:50","http://www.myexperiment.org/workflows/299/download/metabolic_pathway.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,","A list of Kegg entires are supplied to the Kegg database which then retrieves the associated metabolic pathways for each entry supplied. e.g. Ids takes in a value of 351, whilst abbr takes in a value of hsa. Thus hsa:351 corresponds to neurodegenerative disorders and alzheimers disease pathways. [ <a href=mailto:fisherp@cs.man.ac.uk>fisherp@cs.man.ac.uk</a> ]",3, 1, GETIMAGE, KEGGBASEURL, GETPATHWAYS, ,
"http://www.myexperiment.org/workflows/300/versions/1.html","ACC_to_GI.xml","2008-07-1210:14:43","2008-07-1210:15:28","http://www.myexperiment.org/workflows/300/download/ACC_to_GI.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,5, 0, Acc, TitleFromGi, GOIDFromGi, FindAcc, MuidFromGi, ,
"http://www.myexperiment.org/workflows/301/versions/1.html","Ensembl_genes_to_swiss_id.xml","2008-07-1210:16:31","2008-07-1210:16:48","http://www.myexperiment.org/workflows/301/download/Ensembl_genes_to_swiss_id.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,10, 3, getGeneInfo, comma2, parse_swiss, spit_by_regex2, lister, regex2, FindNameList, comma_separated2, parsing_options, parse_ddbj_gene_info, ,
"http://www.myexperiment.org/workflows/302/versions/1.html","string_complete.xml","2008-07-1210:17:40","2008-07-1210:18:27","http://www.myexperiment.org/workflows/302/download/string_complete.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,21, 6, database, start, end, chromosome, getgenesbyspecies, probeset_in_qtl, array_name, probeset_to_gene, split_by_regex1, regex1, Merge_string_list1, comma1, parse_gene_name, regex_2, getGeneInfo, options, split_by_regex_2, parse_ddbj_gene_info, parsing_options, parse_swiss, parse_ddbj_gene_info2, ,
"http://www.myexperiment.org/workflows/303/versions/1.html","gene_info_to_gene_name.xml","2008-07-1210:19:16","2008-07-1210:19:48","http://www.myexperiment.org/workflows/303/download/gene_info_to_gene_name.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,6, 2, options, parse_gene_name, parse_ddbj_gene_info, getGeneInfo, regex_2, split_by_regex_2, ,
"http://www.myexperiment.org/workflows/304/versions/1.html","SUB_genes_info_names.xml","2008-07-1210:20:46","2008-07-1210:21:18","http://www.myexperiment.org/workflows/304/download/SUB_genes_info_names.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,8, 2, chromosome, end, species, start, Get_Gene_Info, getgenesbyspecies, getcurrentdatabase, NestedWorkflow, ,
"http://www.myexperiment.org/workflows/305/versions/1.html","bind-idsearch.xml","2008-07-1210:22:13","2008-07-1210:22:29","http://www.myexperiment.org/workflows/305/download/bind-idsearch.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,4, 1, BindIdSearch, Id, IdType, returnType, ,
"http://www.myexperiment.org/workflows/306/versions/1.html","bind-text.xml","2008-07-1210:23:10","2008-07-1210:23:23","http://www.myexperiment.org/workflows/306/download/bind-text.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,10, 1, String_Constant, String_Constant1, String_Constant2, idSearchAttachment, split, regex, regex2, split2, filter, regex3, ,
"http://www.myexperiment.org/workflows/307/versions/1.html","genes_from_probesets.xml","2008-07-1210:24:11","2008-07-1210:24:26","http://www.myexperiment.org/workflows/307/download/genes_from_probesets.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,1, 1, probeset_to_gene, ,
"http://www.myexperiment.org/workflows/308/versions/1.html","probeset_in_qtl.xml","2008-07-1210:25:08","2008-07-1210:25:22","http://www.myexperiment.org/workflows/308/download/probeset_in_qtl.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,1, 1, probeset_in_qtl, ,
"http://www.myexperiment.org/workflows/309/versions/1.html","database_and_genes.xml","2008-07-1210:26:05","2008-07-1210:26:25","http://www.myexperiment.org/workflows/309/download/database_and_genes.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,6, 2, getcurrentdatabase, getgenesbyspecies, chromosome, start, end, species, ,
"http://www.myexperiment.org/workflows/310/versions/1.html","protein_protein_interactions.xml","2008-07-1210:27:05","2008-07-1210:27:18","http://www.myexperiment.org/workflows/310/download/protein_protein_interactions.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,4, 2, idSearch, lister, id_type, return_type, ,
"http://www.myexperiment.org/workflows/311/versions/1.html","gene_by_species.xml","2008-07-1210:28:19","2008-07-1210:28:52","http://www.myexperiment.org/workflows/311/download/gene_by_species.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,7, 3, start, lister, end, database, chromosome, getgenesbyspecies, getGeneInfo, ,
"http://www.myexperiment.org/workflows/312/versions/1.html","blast_GO.xml","2008-07-1210:29:41","2008-07-1210:29:58","http://www.myexperiment.org/workflows/312/download/blast_GO.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,7, 1, GOIDFromGiList, gi_number, Merge_string_list_to_string, separator, blastsimplifier, split_by_regex, regex, ,
"http://www.myexperiment.org/workflows/313/versions/1.html","BlastComparer.xml","2008-07-1210:30:46","2008-07-1210:32:11","http://www.myexperiment.org/workflows/313/download/BlastComparer.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,","Perform a blastp search on protein sequence and extract information based on the user input, e.g. a list of GI numbers. N.B. this workflow does not function correctly as it is designed for use with NCBI blast scripts. Some errors may occur. Please use two blast text file inputs for a secure result output.",4, 2, species_filter, chromosome_filter, blast_ddbj, blastfilecomparer, ,
"http://www.myexperiment.org/workflows/314/versions/1.html","stringList.xml","2008-07-1210:33:04","2008-07-1210:33:27","http://www.myexperiment.org/workflows/314/download/stringList.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,2, 0, Merge_string_list_to_string, String_Constant, ,
"http://www.myexperiment.org/workflows/315/versions/1.html","maxdBrowse_strings.xml","2008-07-1210:35:17","2008-07-1210:36:46","http://www.myexperiment.org/workflows/315/download/maxdBrowse_strings.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,3, 1, result_type, arguments, query, ,
"http://www.myexperiment.org/workflows/316/versions/1.html","getgenesbyspecies.xml","2008-07-1210:37:57","2008-07-1210:38:21","http://www.myexperiment.org/workflows/316/download/getgenesbyspecies.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,5, 1, getgenesbyspecies, database, chromosome, start, end, ,
"http://www.myexperiment.org/workflows/317/versions/1.html","gene_ontology_diagram.xml","2008-07-1210:39:09","2008-07-1210:39:32","http://www.myexperiment.org/workflows/317/download/gene_ontology_diagram.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,","This workflow builds up a subgraph of the Gene Ontology ( <a href=http://www.geneontology.org>http://www.geneontology.org</a> ) to show the context for a supplied term or terms. It shows this context by colouring all ancestors of the term, all children and all siblings. By default, ancestors of the supplied term or terms are coloured orange, siblings purple and direct children teal. Other terms appear in the default wheat colour.",15, 12, childColour, getChildren, getresults, getAncestry, markAncestors, getParents, add, colourChildren, colourInputTerm, addImmediateChildren, finish, create, getImmediateChildren, inputTermColour, ancestorColour, ,
"http://www.myexperiment.org/workflows/318/versions/1.html","affy_ids.xml","2008-07-1210:40:21","2008-07-1210:40:43","http://www.myexperiment.org/workflows/318/download/affy_ids.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,4, 2, result_type, arguments, query, affy_ids, ,
"http://www.myexperiment.org/workflows/319/versions/1.html","example.xml","2008-07-1210:41:23","2008-07-1210:41:40","http://www.myexperiment.org/workflows/319/download/example.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,11, 4, affy_probeset_in_region, markers, organism, getcurrentdatabase, chromosome, measurementNames, format, hunt, arguments, query, result_type, ,
"http://www.myexperiment.org/workflows/320/versions/1.html","metabolic.xml","2008-07-1210:42:42","2008-07-1210:42:56","http://www.myexperiment.org/workflows/320/download/metabolic.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,","An example of how a more complex workflow can federate multiple resources to perform data mining. In this case a single input data item in the form of a probe set identifier is cross referenced to data sets in multiple locations to answer a kind of 'show me everything about this data' question.",18, 13, DatabaseId1, childColour, getChildren, ProbeSetId, ancestorColour, inputTermColour, GetSwissprotId, finish, add, addImmediateChildren, getGoIds, getresults, colourChildren, markAncestors, getAncestry, colourInputTerm, getParents, create, ,
"http://www.myexperiment.org/workflows/321/versions/1.html","interpro_scan_3.xml","2008-07-1210:44:19","2008-07-1210:45:22","http://www.myexperiment.org/workflows/321/download/interpro_scan_3.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,2, 1, String_Constant, callInterpro, ,
"http://www.myexperiment.org/workflows/323/versions/1.html","interpro_scan_2.xml","2008-07-1210:48:08","2008-07-1210:48:29","http://www.myexperiment.org/workflows/323/download/interpro_scan_2.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,2, 1, sequence, doIprscan, ,
"http://www.myexperiment.org/workflows/325/versions/1.html","linking1.xml","2008-07-1210:51:05","2008-07-1210:51:21","http://www.myexperiment.org/workflows/325/download/linking1.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,5, 1, srslinks, databank, xref_databank, searchterm, fieldname, ,
"http://www.myexperiment.org/workflows/326/versions/1.html","genomic_sequence.xml","2008-07-1210:52:14","2008-07-1210:52:34","http://www.myexperiment.org/workflows/326/download/genomic_sequence.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,1, 0, mmusculus_gene_ensembl, ,
"http://www.myexperiment.org/workflows/327/versions/1.html","linking3.xml","2008-07-1210:53:12","2008-07-1210:53:27","http://www.myexperiment.org/workflows/327/download/linking3.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,","This workflow links between a specified EMBL accesion number to corresponding identifiers in the MEDLINE database.",5, 1, searchterm, xrefDatabank, fieldname, databank, srslinks, ,
"http://www.myexperiment.org/workflows/328/versions/1.html","protein2dna.xml","2008-07-1210:54:27","2008-07-1210:54:44","http://www.myexperiment.org/workflows/328/download/protein2dna.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,2, 1, protein_seq, backtranseq, ,
"http://www.myexperiment.org/workflows/329/versions/1.html","blast_to_fasta.xml","2008-07-1210:55:37","2008-07-1210:55:52","http://www.myexperiment.org/workflows/329/download/blast_to_fasta.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,8, 2, blastsimplifier, blast_ddbj, gi_number, query_seq, database, program, GetFasta, MoleculeType, ,
"http://www.myexperiment.org/workflows/330/versions/1.html","blast.xml","2008-07-1210:56:39","2008-07-1210:56:54","http://www.myexperiment.org/workflows/330/download/blast.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,1, 1, blast_ddbj, ,
"http://www.myexperiment.org/workflows/331/versions/1.html","DDBJ_BLAST.xml","2008-07-1210:59:33","2008-07-1211:00:38","http://www.myexperiment.org/workflows/331/download/DDBJ_BLAST.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/43,","Paul Fisher,",,1, 1, blast_ddbj, ,
"http://www.myexperiment.org/workflows/333/versions/1.html","AffyidToGeneAnnotationnoGOIDandPepstats.xml","2008-07-1221:14:58","2008-07-1221:16:01","http://www.myexperiment.org/workflows/333/download/AffyidToGeneAnnotationnoGOIDandPepstats.xml-v1.xml?version=1","/users/61","Antoon Goderis","taverna 1","/users/221,","Peter Li,",,12, 9, ProbeSetId, DatabaseId1, DatabaseId2, GetMeldineIds, GetSwissprotRecord, getDotFromViz, destroyVizSession, GetEmblAccNumber, createVizSession, GetSwissprotId, addTermToViz, getGoIds, ,
"http://www.myexperiment.org/workflows/335/versions/1.html","simple_xcms_pipeline","2008-07-1415:17:25","2008-07-1415:19:02","http://www.myexperiment.org/workflows/335/download/simple_xcms_pipeline-v1.xml?version=1","/users/1028","Markf","taverna 1","/users/1028,","Markf,","A (very) simple demo pipeline that takes an experiment ID, gets the data from the (currently in beta) metware metabolomics datawarehouse and runs XCMS.",4, 2, MetwareGetExperimentRaw, String, MetwareExperimentId, abwur_test_xcms, ,
"http://www.myexperiment.org/workflows/336/versions/1.html","file_fetching_workflow","2008-07-1417:09:56","2008-07-1417:25:15","http://www.myexperiment.org/workflows/336/download/file_fetching_workflow-v1.xml?version=1","/users/420","Tim Booth","taverna 1","/users/420,","Tim Booth,","This workflow demonstrates interaction with an instance of an omixed server (omixed.org) hosting a very simple model and containing some sequence files.&nbsp; The server is available for public access so you should be able to try this out. Notes: With the versions of Taverna and Axis2 I am using, I had to massage the WSDL emitted by Axis2 in order to keep Taverna happy.&nbsp; This involved removing the sections relating to SOAP12. The workflow first connects to the server and obtains a session token which is fed to all other processors. An XML splitter is needed on the front of each call to omixed. File downloading is done via the rest API, which involves constructing a URL and fetching it with the 'get a web page' widget. The workflow does not currently log off at the end, which is a bit naughty.",18, 4, connect, connectionParams, connectionResult, getItemTypes, getItemTypesParams, getItemTypesResult, getItems, getItemsParams, seq1_Sequence, getDomainName, getDomainNameParameters, partialItemIDForSequence, getDomainNameResult, extractFileIdentifiers, fetchSequenceFiles, makeFileURL1, makeFileURL2, makeFileURL3, ,
"http://www.myexperiment.org/workflows/343/versions/1.html","BLASTP with simplified results returned","2008-07-2215:53:06","2008-07-2216:29:55","","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Perform a blastp search on protein sequence and extract information based on the user input, e.g. a list of GI numbers.",
"http://www.myexperiment.org/workflows/345/versions/1.html","RSworkflow slide 32","2008-07-2414:51:31","","http://www.myexperiment.org/workflows/345/download/RSworkflow_slide_32-v1.xml?version=1","/users/1084","Ranjan","taverna 1","/users/1084,","Ranjan,",,4, 1, program, database, Get_Protein_FASTA, searchSimple, ,
"http://www.myexperiment.org/workflows/349/versions/1.html","yangliu","2008-07-2415:07:58","","http://www.myexperiment.org/workflows/349/download/yangliu-v1.xml?version=1","/users/1087","281238088","taverna 1","/users/1087,","281238088,",,2, 1, Get_Protein_FASTA, searchSimple, ,
"http://www.myexperiment.org/workflows/350/versions/1.html","get seq and blast","2008-07-2415:14:01","2008-07-2415:18:32","http://www.myexperiment.org/workflows/350/download/get_seq_and_blast-v1.xml?version=1","/users/1077","Daniel Zadik","taverna 1","/users/1077,","Daniel Zadik,",,4, 1, Get_Protein_FASTA, searchSimple, program, database, ,
"http://www.myexperiment.org/workflows/354/versions/1.html","BLASTerasysbio","2008-07-3012:40:40","","http://www.myexperiment.org/workflows/354/download/BLASTerasysbio-v1.xml?version=1","/users/1121","Thomas Burkard","taverna 1","/users/1121,","Thomas Burkard,",,4, 1, Get_Protein_FASTA, searchSimple, program, database, ,
"http://www.myexperiment.org/workflows/356/versions/1.html","WE_Melanie","2008-07-3014:23:11","","http://www.myexperiment.org/workflows/356/download/WE_Melanie-v1.xml?version=1","/users/1133","Melaniez","taverna 1","/users/1133,","Melaniez,",,5, 1, Get_Protein_FASTA, searchSimple, program, database, geneIdentifier, ,
"http://www.myexperiment.org/workflows/358/versions/1.html","taverna PJ exc5","2008-07-3014:30:43","","","/users/1137","Peterjuv1","taverna 1","/users/1137,","Peterjuv1,",,
"http://www.myexperiment.org/workflows/359/versions/1.html","ex5","2008-07-3014:31:36","","http://www.myexperiment.org/workflows/359/download/ex5-v1.xml?version=1","/users/1139","Antares","taverna 1","/users/1139,","Antares,",,4, 1, Get_Protein_FASTA, searchSimple, program, database, ,
"http://www.myexperiment.org/workflows/364/versions/1.html","genscan_shim_example.xml","2008-07-3015:05:06","2008-07-3015:11:53","http://www.myexperiment.org/workflows/364/download/genscan_shim_example.xml-v1.xml?version=1","/users/1121","Thomas Burkard","taverna 1","/users/13,","Katy Wolstencroft,",,5, 3, searchSimple, database, program, genscan, patmatmotifs, ,
"http://www.myexperiment.org/workflows/365/versions/1.html","genscan_shim_example2.xml","2008-07-3015:05:38","2008-07-3015:12:19","http://www.myexperiment.org/workflows/365/download/genscan_shim_example2.xml-v1.xml?version=1","/users/1121","Thomas Burkard","taverna 1","/users/13,","Katy Wolstencroft,",,6, 4, searchSimple, database, program, genscansplitter, genscan, patmatmotifs, ,
"http://www.myexperiment.org/workflows/366/versions/1.html","ex5","2008-07-3015:39:48","","http://www.myexperiment.org/workflows/366/download/ex5-v1.xml?version=1","/users/1139","Antares","taverna 1","/users/1139,","Antares,",,5, 1, searchSimple, program, database, Get_Protein_FASTA, PDB_sequence_ID_input, ,
"http://www.myexperiment.org/workflows/368/versions/1.html","Retrieve Protein Sequence","2008-07-3016:36:55","2009-12-0316:54:02","http://www.myexperiment.org/workflows/368/download/Retrieve_Protein_Sequence-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","/users/13,","Katy Wolstencroft,","Retrieves a protein sequence in Fasta format from GenBank, given a GenBank identifier. Example input for this workflow is: EDL10223.1",4, 1, Get_Protein_FASTA, searchSimple, database, program, ,
"http://www.myexperiment.org/workflows/376/versions/1.html","Data Set Metadata Generator","2008-08-1921:17:14","2008-08-1921:25:53","http://www.myexperiment.org/workflows/376/download/Data_Set_Metadata_Generator-v1.xml?version=1","/users/384","Andrea Wiggins","taverna 1","/users/384,","Andrea Wiggins,","This workflow generates ePrints XML import files with data set metadata for the FLOSSmole project. It reads in an input file generated from a Notre Dame SourceForge dump SQL query and uses regular expressions to parse the filename for the data set's source repository, download URL, and basic description. It also translates the epoch date into a sql format suitable for import, and the file size from bytes into larger units, e.g. GB, MB, etc. These data are inserted into an XML eprint record template (specific to the FLOSSmole ePrints repository configuration at wp.floss.syr.edu) and the individual eprints are aggregated into an XML import file. Unfortunately, I'm not sure that I can provide the input file due to license restrictions. I can provide the SQL query, however, so that anyone who has signed a license agreement for access to the ND SourceForge data can retrieve the same input: SELECT f.filename, f.file_id, f.file_size, f.post_date FROM sf0508.frs_file as f, sf0508.groups as g WHERE g.unix_group_name = 'ossmole' AND f.group_id=g.group_id ORDER BY f.post_date",13, 0, read_input, file_location, split_rows, split_more, parse_filename_for_description, parse_filename_for_source, aggregate_eprints, change_date_format, format_filesize, build_URL_from_filename, parse_filename_for_filetype, split_fields, generate_xml_record, ,
"http://www.myexperiment.org/workflows/377/versions/1.html","mustang provides structural alignment of two proteins","2008-08-2014:41:21","2008-08-2515:40:45","http://www.myexperiment.org/workflows/377/download/mustang_provides_structural_alignment_of_two_proteins-v1.xml?version=1","/users/1169","Steffen MÃ¶ller","taverna 1","/users/1169,","Steffen MÃ¶ller,",,
"http://www.myexperiment.org/workflows/377/versions/2.html","mustang provides structural alignment of two proteins","2008-08-2014:41:21","2008-08-2515:40:45","http://www.myexperiment.org/workflows/377/download/mustang_provides_structural_alignment_of_two_proteins-v2.xml?version=2","/users/1169","Steffen MÃ¶ller","taverna 1","/users/1169,","Steffen MÃ¶ller,",,
"http://www.myexperiment.org/workflows/377/versions/3.html","mustang provides structural alignment of two proteins","2008-08-2014:41:21","2008-08-2515:40:45","http://www.myexperiment.org/workflows/377/download/mustang_provides_structural_alignment_of_two_proteins-v3.xml?version=3","/users/1169","Steffen MÃ¶ller","taverna 1","/users/1169,","Steffen MÃ¶ller,","This workflow experiments with the partial execution of jobs on a computational grid. The workflow elements mustang and boxshade are executed on grid nodes. Access to these resources is orchestrated with the plugin available on  <a href=http://grid.inb.uni-luebeck.de>http://grid.inb.uni-luebeck.de</a> . Please contact the author of this workflow for access permissions.",
"http://www.myexperiment.org/workflows/379/versions/1.html","BioAID_EnirchBioModelWithProteinsFromText","2009-05-1601:06:26","2009-05-1601:13:18","http://www.myexperiment.org/workflows/379/download/BioAID_EnirchBioModelWithProteinsFromText-v1.xml?version=1","/users/18","Marco Roos","taverna 1","/users/18, /users/343, /users/37, /users/14, /users/344, /users/231, /users/68,","Marco Roos, Sophia katrenko, Andrew Gibson, M. Scott Marshall, Willem van Hage, Edgar, Martijn Schuemie,","This workflow extracts proteins and protein relations from from a subset of Medline that is about Homo Sapiens according to mesh annotation. Protein names (symbols of at least 3 characters) are validated against human UniProt symbols. This workflow follows the following basic steps: <ol><li>it retrieves documents relevant for the query string (documents tagged with mesh term 'Humans' only)</li><li>it discovers proteins in those documents, considered relevant to the query string (colocation in text mining terms)</li><li>it extract protein-protein relations (slightly stronger than colocation)</li></ol> Protein discoveries are filtered on their presence in UniProt (human only) Acknowledgements: Synonyms and Uniprot services: Martijn Scheumie, BioSemantics Group, University of Rotterdam, The Netherlands (BioRange project)",18, 0, false, true, Timestamp, s06_AddProteinRelationToSemanticModel, s07_AddScoreToSemanticModel, s04_AddDocToSemanticModel, s05_AddProteinToSemanticModel, s03_AddExpandedQueryToSemanticModel, s02_AddOriginalQueryToSemanticModel, 06_UniProtXrefURLs, s03_AddExpandedQueryToSemanticModel_Obsolete, s01_AddBiologicalModelToSemanticModel, s00_InitializeSemanticStorage, 02_RetrieveDocumentsFromMedline, 04_ExtractProteinRelations_HomoSapiens, 05_ScoreExtractedProteins, 01_ProcessQuery, 03_ExtractProteins_HomoSapiens, ,
"http://www.myexperiment.org/workflows/379/versions/2.html","BioAID_EnirchBioModelWithProteinsFromText","2009-05-1601:06:26","2009-05-1601:13:18","http://www.myexperiment.org/workflows/379/download/BioAID_EnirchBioModelWithProteinsFromText-v2.xml?version=2","/users/18","Marco Roos","taverna 1","/users/18, /users/343, /users/37, /users/14, /users/344, /users/231, /users/68,","Marco Roos, Sophia katrenko, Andrew Gibson, M. Scott Marshall, Willem van Hage, Edgar, Martijn Schuemie,","This workflow extracts proteins and protein relations from from a subset of Medline that is about Homo Sapiens according to mesh annotation. Protein names (symbols of at least 3 characters) are validated against human UniProt symbols.  This workflow follows the following basic steps: 1. it retrieves documents relevant for the query string (documents tagged with mesh term 'Humans' only) 2. it discovers proteins in those documents, considered relevant to the query string (colocation in text mining terms) 3. it extract protein-protein relations (slightly stronger than colocation)  Protein discoveries are filtered on their presence in UniProt (human only)  Acknowledgements: Synonyms and Uniprot services: Martijn Scheumie, BioSemantics Group, University of Rotterdam, The Netherlands (BioRange project)",18, 0, false, true, Timestamp, s06_AddProteinRelationToSemanticModel, s07_AddScoreToSemanticModel, s04_AddDocToSemanticModel, s05_AddProteinToSemanticModel, s03_AddExpandedQueryToSemanticModel, s02_AddOriginalQueryToSemanticModel, 06_UniProtXrefURLs, s03_AddExpandedQueryToSemanticModel_Obsolete, s01_AddBiologicalModelToSemanticModel, s00_InitializeSemanticStorage, 02_RetrieveDocumentsFromMedline, 04_ExtractProteinRelations_HomoSapiens, 05_ScoreExtractedProteins, 01_ProcessQuery, 03_ExtractProteins_HomoSapiens, ,
"http://www.myexperiment.org/workflows/379/versions/3.html","BioAID_EnirchBioModelWithProteinsFromText","2009-05-1601:06:26","2009-05-1601:13:18","http://www.myexperiment.org/workflows/379/download/BioAID_EnirchBioModelWithProteinsFromText-v3.xml?version=3","/users/18","Marco Roos","taverna 1","/users/18, /users/343, /users/37, /users/14, /users/344, /users/231, /users/68,","Marco Roos, Sophia katrenko, Andrew Gibson, M. Scott Marshall, Willem van Hage, Edgar, Martijn Schuemie,","This workflow extracts proteins and protein relations from Medline. Extracted protein  names (symbols of at least 3 characters) are validated against mouse, rat, and human UniProt symbols, so the results are limited to these species. This workflow follows the following basic steps: <ol><li>it retrieves documents relevant for the query string</li><li>it discovers proteins in those documents, considered relevant to the query string (colocation in text mining terms)</li><li>it extract protein-protein relations (slightly stronger than colocation)</li></ol> In addition, the results are added to a biological model to support hypthesis formation and  a procedural model to log trails to evidence. The models are based on description logic (RDF/OWL format). Acknowledgements: Synonyms and Uniprot services: Martijn Scheumie, BioSemantics Group, University of Rotterdam, The Netherlands (BioRange project)",18, 0, false, Timestamp, true, s07_AddScoreToSemanticModel, s06_AddProteinRelationToSemanticModel, 06_UniProtXrefURLs, s01_AddBiologicalModelToSemanticModel, s03_AddExpandedQueryToSemanticModel_Obsolete, s05_AddProteinToSemanticModel, 02_RetrieveDocumentsFromMedline, s03_AddExpandedQueryToSemanticModel, s02_AddOriginalQueryToSemanticModel, 05_ScoreExtractedProteins, 04_ExtractProteinRelations_HomoSapiens, 01_ProcessQuery, s04_AddDocToSemanticModel, 03_ExtractProteins_HomoSapiens, s00_InitializeSemanticStorage, ,
"http://www.myexperiment.org/workflows/379/versions/4.html","BioAID_EnirchBioModelWithProteinsFromText","2009-05-1601:06:26","2009-05-1601:13:18","http://www.myexperiment.org/workflows/379/download/BioAID_EnirchBioModelWithProteinsFromText-v4.xml?version=4","/users/18","Marco Roos","taverna 1","/users/18, /users/343, /users/37, /users/14, /users/344, /users/231, /users/68,","Marco Roos, Sophia katrenko, Andrew Gibson, M. Scott Marshall, Willem van Hage, Edgar, Martijn Schuemie,","This workflow extracts proteins and protein relations from Medline. Extracted protein  names (symbols of at least 3 characters) are validated against mouse, rat, and human UniProt symbols, so the results are limited to these species. This workflow follows the following basic steps: <ol><li>it retrieves documents relevant for the query string</li><li>it discovers proteins in those documents, considered relevant to the query string (colocation in text mining terms)</li><li>it extract protein-protein relations (slightly stronger than colocation)</li></ol> In addition, the results are added to a biological model to support hypthesis formation and  a procedural model to log trails to evidence. The models are based on description logic (RDF/OWL format). Acknowledgements: Synonyms and Uniprot services: Martijn Scheumie, BioSemantics Group, University of Rotterdam, The Netherlands (BioRange project)",21, 0, true, false, Timestamp, s07_AddProteinRelationToSemanticModel, s08_AddScoreToSemanticModel, s02_AddBiologicalModelToSemanticModel, 04_ExtractProteinRelations_HomoSapiens, s03_AddOriginalQueryToSemanticModel, 02_RetrieveDocumentsFromMedline, 01_ProcessQuery, s05_AddDocToSemanticModel, 06_UniProtXrefURLs, 05_ScoreExtractedProteins, s06_AddProteinToSemanticModel, s09_AddRdfToRepository, 03_ExtractProteins_HomoSapiens, s04_AddExpandedQueryToSemanticModel, s00_InitializeSemanticStorage, s01_AddWorkflowToSemanticModel, CloneDocumentInstances, CountProteinsPerDocument, ,
"http://www.myexperiment.org/workflows/379/versions/5.html","BioAID_EnirchBioModelWithProteinsFromText","2009-05-1601:06:26","2009-05-1601:13:18","http://www.myexperiment.org/workflows/379/download/BioAID_EnirchBioModelWithProteinsFromText-v5.xml?version=5","/users/18","Marco Roos","taverna 1","/users/18, /users/343, /users/37, /users/14, /users/344, /users/231, /users/68,","Marco Roos, Sophia katrenko, Andrew Gibson, M. Scott Marshall, Willem van Hage, Edgar, Martijn Schuemie,","<span style=color: rgb(255, 0, 0);><b>This workflow is for demonstration purposes only. Please contact the authors if you wish to try it. We will gladly cooperate with you to address your requirements.</b></span> <b>Summary</b> This workflow extracts proteins and protein relations from Medline. Extracted protein  names (symbols of at least 3 characters) are validated against mouse, rat, and human UniProt symbols, so the results are limited to these species.  This workflow follows the following basic steps: To support hypothesis formation, the results are added to a repository containing proto-ontologies with biological classes and procedural classes to log evidence. The models are based on RDF and OWL. <b>Acknowledgements:   </b> Synonyms and Uniprot services: Martijn Scheumie, BioSemantics Group, University of Rotterdam, The Netherlands (BioRange project) <b>Known issues</b> Occasionally the workflow will fail on intermediate results that return no results (e.g. on a time out or a bug in the workflow). This problem will be addressed in Taverna 2 using its more strict list iteration mechanism and the AIDA plugin for Taverna 2. The workflow contains some elements that are not yet functional. This will show as failed when run. This can be ignored. <b>Please contact us if you have any questions about the workflow, our approach, or if you experience technical difficulties.</b>",22, 0, true, false, Timestamp, s07_AddProteinRelationToSemanticModel, s08_AddScoreToSemanticModel, s02_AddBiologicalModelToSemanticModel, 04_ExtractProteinRelations_HomoSapiens, s03_AddOriginalQueryToSemanticModel, 02_RetrieveDocumentsFromMedline, 01_ProcessQuery, s05_AddDocToSemanticModel, 06_UniProtXrefURLs, 05_ScoreExtractedProteins, s06_AddProteinToSemanticModel, s09_AddRdfToRepository, 03_ExtractProteins_HomoSapiens, s04_AddExpandedQueryToSemanticModel, s00_InitializeSemanticStorage, s01_AddWorkflowToSemanticModel, CloneDocumentInstances, CountProteinsPerDocument, FlattenDocInstanceClonesList, ,
"http://www.myexperiment.org/workflows/379/versions/6.html","BioAID_EnirchBioModelWithProteinsFromText","2009-05-1601:06:26","2009-05-1601:13:18","http://www.myexperiment.org/workflows/379/download/BioAID_EnirchBioModelWithProteinsFromText-v6.xml?version=6","/users/18","Marco Roos","taverna 1","/users/18, /users/343, /users/37, /users/14, /users/344, /users/231, /users/68,","Marco Roos, Sophia katrenko, Andrew Gibson, M. Scott Marshall, Willem van Hage, Edgar, Martijn Schuemie,","This workflow extracts proteins and protein relations from Medline. Extracted protein  names (symbols of at least 3 characters) are validated against mouse, rat, and human UniProt symbols, so the results are limited to these species. This workflow follows the following basic steps: <ol><li>it retrieves documents relevant for the query string</li><li>it discovers proteins in those documents, considered relevant to the query string (colocation in text mining terms)</li><li>it extract protein-protein relations (slightly stronger than colocation)</li></ol> In addition, the results are added to a biological model to support hypthesis formation and  a procedural model to log trails to evidence. The models are based on description logic (RDF/OWL format). Acknowledgements: Synonyms and Uniprot services: Martijn Scheumie, BioSemantics Group, University of Rotterdam, The Netherlands (BioRange project)",32, 0, false, MedLineTotalDocCount, MinLogLikelhoodScoreDescription, true, Fail, s06_AddProteinRelationToSemanticModel, negate, CountProteinsPerDocument, CloneStringToList_NERserviceRunInstance, CloneStringToList_DocumentInstance, CloneStringToList_NERprocessRunInstance, Timestamp, s07_AddScoreToSemanticModel, s02_AddOriginalQueryToSemanticModel, 02_RetrieveDocumentsFromMedline, p03_AddProteinDiscoveryToSemanticModel, p02_AddDocumentDiscoveryToSemanticModel, s03b_AddQueryProteinsToSemanticModel, 01b_UniProtXrefURLs, s03_AddExpandedQueryToSemanticModel, p01_AddWorkflowToSemanticModel, 05_ScoreExtractedProteins, s08_AddRdfToRepository, 01b_CalculateQueryFrequency, s01_AddBiologicalModelToSemanticModel, s00_InitializeSemanticStorage, 06_UniProtXrefURLs_iHopBYPASS, 04_ExtractProteinRelations_HomoSapiens, s05_AddDiscoveredProteinToSemanticModel, s04_AddDocToSemanticModel, 01_ProcessQuery, 03_ExtractProteins_UniProtValidation, ,
"http://www.myexperiment.org/workflows/379/versions/7.html","BioAID_EnirchBioModelWithProteinsFromText","2009-05-1601:06:26","2009-05-1601:13:18","http://www.myexperiment.org/workflows/379/download/BioAID_EnirchBioModelWithProteinsFromText-v7.xml?version=7","/users/18","Marco Roos","taverna 1","/users/18, /users/343, /users/37, /users/14, /users/344, /users/231, /users/68,","Marco Roos, Sophia katrenko, Andrew Gibson, M. Scott Marshall, Willem van Hage, Edgar, Martijn Schuemie,","<span><b>This workflow is for demonstration purposes only. Please contact the authors if you wish to try it. We will gladly collaborate with you.</b></span> <b>Summary</b> This workflow extracts proteins and protein relations from Medline. Extracted protein names (symbols of at least 3 characters) are validated against mouse, rat, and human UniProt symbols, so the results are limited to these species. This workflow follows the following basic steps: To support hypothesis formation, the results are added to a repository containing proto-ontologies with biological classes and procedural classes to log evidence. The models are based on RDF and OWL. <b>Acknowledgements:   </b> Synonyms and Uniprot services: Martijn Scheumie, BioSemantics Group, University of Rotterdam, The Netherlands (BioRange project) <b>Known issues</b> Occasionally the workflow will fail on intermediate results that return no results (e.g. on a time out or a bug in the workflow). This problem will be addressed in Taverna 2 using its more strict list iteration mechanism and the AIDA plugin for Taverna 2. The workflow contains some elements that are not yet functional. This will show as failed when run. This can be ignored. <b>Please contact us if you have any questions about the workflow, our approach, or if you experience technical difficulties.</b>",32, 0, false, MedLineTotalDocCount, MinLogLikelhoodScoreDescription, true, Fail, s06_AddProteinRelationToSemanticModel, negate, CountProteinsPerDocument, CloneStringToList_NERserviceRunInstance, CloneStringToList_DocumentInstance, CloneStringToList_NERprocessRunInstance, Timestamp, s07_AddScoreToSemanticModel, s02_AddOriginalQueryToSemanticModel, 02_RetrieveDocumentsFromMedline, p03_AddProteinDiscoveryToSemanticModel, p02_AddDocumentDiscoveryToSemanticModel, s03b_AddQueryProteinsToSemanticModel, 01b_UniProtXrefURLs, s03_AddExpandedQueryToSemanticModel, p01_AddWorkflowToSemanticModel, 05_ScoreExtractedProteins, s08_AddRdfToRepository, 01b_CalculateQueryFrequency, s01_AddBiologicalModelToSemanticModel, s00_InitializeSemanticStorage, 06_UniProtXrefURLs_iHopBYPASS, 04_ExtractProteinRelations_HomoSapiens, s05_AddDiscoveredProteinToSemanticModel, s04_AddDocToSemanticModel, 01_ProcessQuery, 03_ExtractProteins_UniProtValidation, ,
"http://www.myexperiment.org/workflows/380/versions/1.html","Retrieve Single Molecule from ZINC - structure and figure","2008-08-2422:52:25","2008-08-2521:57:16","http://www.myexperiment.org/workflows/380/download/Retrieve_Single_Molecule_from_ZINC_-_structure_and_figure-v1.xml?version=1","/users/1169","Steffen MÃ¶ller","taverna 1","/users/1169,","Steffen MÃ¶ller,","The ZINC database (http;//zinc.docking.org) is a collection of substances with known structures and some chemical characterisation that are commercially available. It is freely available and a much respected resource for computational screening for functional compounds. With the ZINC ID at hand, the ZINC web site is contacted and from there the URL parsed the refence to the real data. This workflow does not scale for regular docking applications.  One would retrieve a collection of data instead. However, this workflow might find its audience for some experimental workflows towards docking experiments and their interpretation.",20, 0, Form_URL_Image, Retrieve_ZINC_Molecule_Figure, Retrieve_ZINC_Molecular_Summary_Page, Form_URL_Summary, ZINC_URL_Single_Molecule_Figure, Regex_for_internal_id, Split_string_into_string_list_by_regular_expression, LineBreak, Filter_list_of_strings_by_regex, ZINC_URL_Fetch, ZINC_Fetch_Param_SMILE, ZINC_Fetch_Param_MOL2, Retrieve_Internal_ID, ZINC_URL_Single_Molecule, ZINC_URL_Fetch_Prefix, ZINC_URL_SMILES, ZINC_URL_MOL2, Regex_for_internal_id_with_group, Fetch_MOL2_Data_from_URL, Fetch_SMILES_Data_from_URL, ,
"http://www.myexperiment.org/workflows/381/versions/1.html","missingOutputSplitter","2008-08-2710:40:08","","http://www.myexperiment.org/workflows/381/download/missingOutputSplitter-v1.xml?version=1","/users/5","Stian Soiland-Reyes","taverna 1","/users/5,","Stian Soiland-Reyes,",,2, 1, GetResourceProperty, GetResourcePropertyResponseXML, ,
"http://www.myexperiment.org/workflows/384/versions/1.html","What&#39;s On Next","2008-08-2815:23:58","2008-08-2815:27:48","http://www.myexperiment.org/workflows/384/download/What_s_On_Next-v1.xml?version=1","/users/438","Sean Bechhofer","taverna 1","/users/438,","Sean Bechhofer,","Queries the BBC to find out what's on next for a particular channel.",21, 0, method, Concat1, channel, limit, ProgrammeTitleQuery, DetailsURL, ProgrammeIdQuery, SynopsisQuery, Concat2, Concat3, TitleXPath, Concat4, GetProgrammeDetails, IdXPath, GetProgrammeSynopsis, FlattenList, bbcAPI, GetSchedule, ProgrammeStartQuery, StartXPath, FlattenList2, ,
"http://www.myexperiment.org/workflows/385/versions/1.html","Insert Molecules into Database","2008-08-2909:59:06","2008-08-2910:17:02","http://www.myexperiment.org/workflows/385/download/Insert_Molecules_into_Database-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow reads the molecules form the an MDL SD File and stores them into a database. The database used here is a Postgres SQL database which uses the PGChem::Tigress chemoinformtic extension. To run this workflow you have to install the CDK-Taverna Plug-in for Taverna 1.7.1.0 from  <a href=http://cdk-taverna.de/plugin>http://cdk-taverna.de/plugin</a>",
"http://www.myexperiment.org/workflows/386/versions/1.html","QSAR workflow to measure the time used for calculating different qsar properties","2008-08-2913:31:12","2008-08-2913:40:52","http://www.myexperiment.org/workflows/386/download/QSAR_workflow_to_measure_the_time_used_for_calculating_different_qsar_properties-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow loads molecules from a database. Each molecule goes through the atom typing, gets its explecite hydrogens and the detection of the hueckel aromaticity. After that different qsar properties will be calculated. The output of this workflow will be a qsar vector as a csv file and a file which contains the time needed to calculate each qsar property.",
"http://www.myexperiment.org/workflows/387/versions/1.html","Structural alignment of arbitrary number of protein structures.","2008-09-0214:59:23","","http://www.myexperiment.org/workflows/387/download/Structural_alignment_of_arbitrary_number_of_protein_structures.-v1.xml?version=1","/users/1169","Steffen MÃ¶ller","taverna 1","/users/1169, /users/1202,","Steffen MÃ¶ller, Fxtentacle,","This grid-executed Mustang application performs a structural alignment of protein sequences. The number of arguments is variable, in principle, but is shown here for three. The application is executed via the Taverna-ARC plugin on a machine of the NorduGrid. Although your machine can be a part of it, you may prefer to wait for a later version of that interface that does not require grid certificates.",
"http://www.myexperiment.org/workflows/388/versions/1.html","Pathway to Pubmed","2008-09-0220:53:53","2008-09-0815:35:53","http://www.myexperiment.org/workflows/388/download/Pathway_to_Pubmed-v1.xml?version=1","/users/5","Stian Soiland-Reyes","taverna 1","/users/5, /users/43,","Stian Soiland-Reyes, Paul Fisher,","This workflow takes in a list of KEGG pathway descriptions and searches the PubMed database for corresponding articles. Any matches to the pathways are then retrieved (abstracts only). These abstracts are then returned to the user.",8, 0, regex, merge_outputs_2, remove_nulls, split_search_terms, pathway_and_abstract, extract_terms, add_MeSH_to_string, Search_PubMed, ,
"http://www.myexperiment.org/workflows/389/versions/1.html","Atom typing of molecules from database","2008-09-0611:08:43","","http://www.myexperiment.org/workflows/389/download/Atom_typing_of_molecules_from_database-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow loads molecules from a database. For each molecule the atom type gets perceived. The output of this workflow are a couple of text files. The frist text file contains all molecule id's which are loaded from the database. The second text file contains all molecules which had problems with the atom typing. This file contains the molecule id and the atom which caused the problem. The last output file, a pdf, contains all structures of the molecules which caused problems during the atom typing to visual inspect the molecules.",
"http://www.myexperiment.org/workflows/391/versions/1.html","Get pathways by external reference","2010-01-1312:21:59","","http://www.myexperiment.org/workflows/391/download/Get_pathways_by_external_reference-v1.xml?version=1","/users/1253","Thomask...","taverna 1","/users/1253,","Thomaskelder,","Finds pathways on WikiPathways by an external gene/protein/metabolite reference. See  <a href=http://www.pathvisio.org/Help_1.1#Supported_database_systems>http://www.pathvisio.org/Help_1.1#Supported_database_systems</a>  for a list of supported database systems.",4, 1, getSpecies, getNames, findPathwaysByXrefInput, findPathwaysByXref, ,
"http://www.myexperiment.org/workflows/391/versions/2.html","Get pathways by external reference","2010-01-1312:21:59","","http://www.myexperiment.org/workflows/391/download/Get_pathways_by_external_reference-v2.xml?version=2","/users/1253","Thomask...","taverna 1","/users/1253,","Thomaskelder,","Finds pathways on WikiPathways by an external gene/protein/metabolite reference. See  <a href=http://www.pathvisio.org/Help_1.1#Supported_database_systems>http://www.pathvisio.org/Help_1.1#Supported_database_systems</a>  for a list of supported database systems.",5, 1, getId, getNames, getSpecies, findPathwaysByXrefInput, findPathwaysByXref, ,
"http://www.myexperiment.org/workflows/391/versions/3.html","Get pathways by external reference","2010-01-1312:21:59","","http://www.myexperiment.org/workflows/391/download/Get_pathways_by_external_reference-v3.xml?version=3","/users/1253","Thomask...","taverna 1","/users/1253,","Thomaskelder,","Finds pathways on WikiPathways by an external gene/protein/metabolite reference. See  <a href=http://www.pathvisio.org/Help_1.1#Supported_database_systems rel=nofollow>http://www.pathvisio.org/Help_1.1#Supported_database_systems</a>  for a list of supported database systems.",5, 1, getId, getSpecies, getNames, findPathwaysByXref, findPathwaysByXrefInput, ,
"http://www.myexperiment.org/workflows/392/versions/1.html","Write pathway to disk","2008-11-1414:21:12","2008-11-1414:21:13","http://www.myexperiment.org/workflows/392/download/Write_pathway_to_disk-v1.xml?version=1","/users/1253","Thomask...","taverna 1","/users/1253,","Thomaskelder,","Downloads and writes a pathway from WikiPathways to a local disk in the given file type.",6, 1, concat_filetype, concat_dot, writeFile, getPathwayAsOutput, getPathwayAsInput, getPathwayAs, ,
"http://www.myexperiment.org/workflows/392/versions/2.html","Write pathway to disk","2008-11-1414:21:12","2008-11-1414:21:13","http://www.myexperiment.org/workflows/392/download/Write_pathway_to_disk-v2.xml?version=2","/users/1253","Thomask...","taverna 1","/users/1253,","Thomaskelder,","Downloads and writes a pathway from WikiPathways to a local disk in the given file type.",6, 1, concat_filetype, concat_dot, writeFile, getPathwayAsOutput, getPathwayAs, getPathwayAs_input, ,
"http://www.myexperiment.org/workflows/393/versions/1.html","Download pathways for external references list","2008-11-1414:38:31","","http://www.myexperiment.org/workflows/393/download/Download_pathways_for_external_references_list-v1.xml?version=1","/users/1253","Thomask...","taverna 1","/users/1253,","Thomaskelder,","Takes a list of external references to genes/proteins/metabolites, finds all pathways on WikiPathways that contain one of the given genes/proteins/metabolites and downloads them in a given file format. An example of an input file containing a list of protein references can be found  <a href=http://www.myexperiment.org/files/132>here</a> .",8, 0, splitLines, count, createPath, createFileName, readXrefList, clone_list, find_pathways_by_xref, write_pathway, ,
"http://www.myexperiment.org/workflows/393/versions/2.html","Download pathways for external references list","2008-11-1414:38:31","","http://www.myexperiment.org/workflows/393/download/Download_pathways_for_external_references_list-v2.xml?version=2","/users/1253","Thomask...","taverna 1","/users/1253,","Thomaskelder,","Takes a list of external references to genes/proteins/metabolites, finds all pathways on WikiPathways that contain one of the given genes/proteins/metabolites and downloads them in a given file format.",8, 0, createFileName, createPath, count, readXrefList, splitLines, clone_list, write_pathway, find_pathways_by_xref, ,
"http://www.myexperiment.org/workflows/394/versions/1.html","Retrieve_abstract_from_Medline","2008-09-1715:22:56","2008-09-1715:24:22","http://www.myexperiment.org/workflows/394/download/Retrieve_abstract_from_Medline-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","This workflow retrieves Medline Abstracts given PMIDs (PubMed id) You can use: 9879 as input example to test this workflow",4, 1, queryPmid, InputParameters, Outputparameters, PipelineName, ,
"http://www.myexperiment.org/workflows/395/versions/1.html","echo","2008-09-1814:44:53","","http://www.myexperiment.org/workflows/395/download/echo-v1.xml?version=1","/users/1169","Steffen MÃ¶ller","taverna 1","/users/1169,","Steffen MÃ¶ller,","The workflow tests the standard-compliance of web service descriptions of ARC-1, a development of the EU project KnowARC to modernise the grid infrastructure ARC of the NorduGrid. Learn more about it on  <a href=http://www.knowarc.eu>http://www.knowarc.eu</a>  and  <a href=http://www.nordugrid.org>http://www.nordugrid.org</a> . If you have computers in spare - join us - and help you very own and many other sciences. And you make many interesting contacts just en passent. No authorisation is required for this very experimental service.",3, 1, echo, echoRequestXML, echoResponseXML, ,
"http://www.myexperiment.org/workflows/397/versions/1.html","dbfetch tutorial","2008-09-2201:05:36","","http://www.myexperiment.org/workflows/397/download/dbfetch_tutorial-v1.xml?version=1","/users/1169","Steffen MÃ¶ller","taverna 1","/users/1169,","Steffen MÃ¶ller,","This workflow eases entry in the world of Taverna with one of the key tasks - the retrieval of plain data. The dbfetch offers sequence and structure data from a large variety of sources. A first execution of this workflow informs about these in the getSupportedDBs output. Also the formats and styles are listed.  The two inputs allow for the specification of a query that leaves the format with default (which is different for every database, native would be a better fit), the style is always raw. With the output being presented as a list of strings, which is very slow for larger entries, the list of lines are merged into single strings for each entry prior to the display.",5, 4, getSupportedDBs, getSupportedFormats, getSupportedStyles, fetchBatch, Merge_string_list_to_string, ,
"http://www.myexperiment.org/workflows/398/versions/1.html","Ask - no parameters","2008-09-2716:33:03","","http://www.myexperiment.org/workflows/398/download/Ask_-_no_parameters-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The ask service displays a prompt with no title and no prompt message.  If the user presses cancel, then a service failure is generated.  If the user presses OK then their input, even if it is empty, is passed to the answer port of the ask service and so to the output of the workflow.",1, 0, Ask, ,
"http://www.myexperiment.org/workflows/399/versions/1.html","Ask - just title parameter","2008-09-2716:33:49","","http://www.myexperiment.org/workflows/399/download/Ask_-_just_title_parameter-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The ask service displays a prompt with the title 'Some title' but no prompt message.  If the user presses cancel, then a service failure is generated.  If the user presses OK then their input, even if it is empty, is passed to the answer port of the ask service and so to the output of the workflow.",1, 0, Ask, ,
"http://www.myexperiment.org/workflows/400/versions/1.html","Ask - just message parameter","2008-09-2716:34:35","","http://www.myexperiment.org/workflows/400/download/Ask_-_just_message_parameter-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The ask service displays a prompt with no title but with the prompt message 'Some message'.  If the user presses cancel, then a service failure is generated.  If the user presses OK then their input, even if it is empty, is passed to the answer port of the ask service and so to the output of the workflow.",1, 0, Ask, ,
"http://www.myexperiment.org/workflows/401/versions/1.html","Ask - title and message parameters","2008-09-2716:35:15","","http://www.myexperiment.org/workflows/401/download/Ask_-_title_and_message_parameters-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The ask service displays a prompt with 'Some title' and the prompt message 'Some message'.  If the user presses cancel, then a service failure is generated.  If the user presses OK then their input, even if it is empty, is passed to the answer port of the ask service and so to the output of the workflow.",1, 0, Ask, ,
"http://www.myexperiment.org/workflows/402/versions/1.html","Byte[] to string - non empty value","2008-09-2716:36:09","","http://www.myexperiment.org/workflows/402/download/Byte___to_string_-_non_empty_value-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The beanshell converts the string 'hello' to a byte array which is then converted back to the string 'hello' by the Byte[]_to_string service.",2, 0, Byte___to_String, String_to_byte_array, ,
"http://www.myexperiment.org/workflows/403/versions/1.html","Byte[] to string - empty value","2008-09-2716:37:04","","http://www.myexperiment.org/workflows/403/download/Byte___to_string_-_empty_value-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The beanshell converts the empty string '' to a byte array which is then converted back to the empty string '' by the Byte[]_to_string service.",2, 0, Byte___to_String, String_to_byte_array, ,
"http://www.myexperiment.org/workflows/404/versions/1.html","Choose - no title or message parameters","2008-09-2716:37:50","","http://www.myexperiment.org/workflows/404/download/Choose_-_no_title_or_message_parameters-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The split_string_into_string_list_by_regular_expression parses the string 'a,b,c,d,e' and outputs the list ['a','b','c','d','e']. The choose service displays a dialog with no title or message.  The user is able to choose from the values ['a','b','c','d',e'].  When the user presses OK the value the user chose is passed to the answer port of the choose service and so to the output of the workflow.",2, 0, Choose, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/405/versions/1.html","Choose - title parameter","2008-09-2716:38:43","","http://www.myexperiment.org/workflows/405/download/Choose_-_title_parameter-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The split_string_into_string_list_by_regular_expression parses the string 'a,b,c,d,e' and outputs the list ['a','b','c','d','e']. The choose service displays a dialog with 'Some title' but no message.  The user is able to choose from the values ['a','b','c','d',e'].  When the user presses OK the value the user chose is passed to the answer port of the choose service and so to the output of the workflow.",2, 0, Choose, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/407/versions/1.html","Choose - title and message parameters","2008-09-2716:40:10","","http://www.myexperiment.org/workflows/407/download/Choose_-_title_and_message_parameters-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The split_string_into_string_list_by_regular_expression parses the string 'a,b,c,d,e' and outputs the list ['a','b','c','d','e']. The choose service displays a dialog with 'Some title' and with 'Some message'.  The user is able to choose from the values ['a','b','c','d',e'].  When the user presses OK the value the user chose is passed to the answer port of the choose service and so to the output of the workflow.",2, 0, Split_string_into_string_list_by_regular_expression, Choose, ,
"http://www.myexperiment.org/workflows/408/versions/1.html","Choose - single element list","2008-09-2716:40:51","","http://www.myexperiment.org/workflows/408/download/Choose_-_single_element_list-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The split_string_into_string_list_by_regular_expression parses the string 'a' and outputs the list ['a']. The choose service displays a dialog with 'Some title' and 'Some message'.  The user is only able to choose the value 'a'.  When the user presses OK 'a' is passed to the answer port of the choose service and so to the output of the workflow.",2, 0, Choose, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/409/versions/1.html","Concatenate files - echo results and multiple files","2008-09-2716:41:51","","http://www.myexperiment.org/workflows/409/download/Concatenate_files_-_echo_results_and_multiple_files-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The workflow splits the string 'a,b,c,d,e' into its five elements and saves the individual strings to five temporary files.  The file paths to those files are then output by the create_and_populate_temporary_file beanshell. The create_temporary_file beanshell creates a file to which the concatentation can be written. The concatenate_files service concatenates the five files and writes the result to the temporary output file.  Because the displayresults port has been given a default value of 'true', the results are also copied to the results port of concatenate_files. The temporary file to which the results were written is read by the read_text_file service and its contents output. Both of the workflow outputs contain 'abcde' i.e. the contents of the concatenated files separated by a newline.",5, 0, Concatenate_Files, Create_and_populate_temporary_file, Create_temporary_file, Read_Text_File, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/410/versions/1.html","Concatenate files - echo results but no files","2008-09-2716:42:40","","http://www.myexperiment.org/workflows/410/download/Concatenate_files_-_echo_results_but_no_files-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The split_string_into_string_list_by_regular_expresson outputs an empty list since the string to be split is defaulted to ''.  As there are no input values, the create_and_populate_temporary_file generates an empty list. The create_temporary_file beanshell creates a file to which the concatentation can be written. The concatenate_files service does not write anything to the temporary output file.  Because the displayresults port has been given a default value of 'true', the empty string is also copied to the results port of concatenate_files. The temporary file to which the results were written is read by the read_text_file service and its contents output. Both of the workflow outputs contain '' i.e. the empty string.",5, 0, Create_temporary_file, Concatenate_Files, Read_Text_File, Create_and_populate_temporary_file, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/411/versions/1.html","Concatenate files - multiple files","2008-09-2716:43:43","","http://www.myexperiment.org/workflows/411/download/Concatenate_files_-_multiple_files-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The workflow splits the string 'a,b,c,d,e' into its five elements and saves the individual strings to five temporary files.  The file paths to those files are then output by the create_and_populate_temporary_file beanshell. The create_temporary_file beanshell creates a file to which the concatentation can be written. The concatenate_files service concatenates the five files and writes the result to the temporary output file.  Because the displayresults port has no value, the results are not output by the service. The temporary file to which the results were written is read by the read_text_file service and its contents output. The workflow output contains 'abcde' i.e. the contents of the concatenated files separated by a newline.",5, 0, Concatenate_Files, Create_and_populate_temporary_file, Split_string_into_string_list_by_regular_expression, Read_Text_File, Create_temporary_file, ,
"http://www.myexperiment.org/workflows/412/versions/1.html","Concatenate two strings","2008-09-2716:45:08","","http://www.myexperiment.org/workflows/412/download/Concatenate_two_strings-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The concatenate two strings service takes the strings 'good' and 'bye' and returns the result 'goodbye'.",1, 0, Concatenate_two_strings, ,
"http://www.myexperiment.org/workflows/413/versions/1.html","Concatenate two strings - empty strings","2008-09-2716:45:57","","http://www.myexperiment.org/workflows/413/download/Concatenate_two_strings_-_empty_strings-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The concatenate two strings service takes two empty strings and returns an empty string.",1, 0, Concatenate_two_strings, ,
"http://www.myexperiment.org/workflows/414/versions/1.html","Create lots of strings","2008-09-2716:46:38","2008-09-2716:48:00","http://www.myexperiment.org/workflows/414/download/Create_lots_of_strings-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The create lots of strings service returns a list containing a large number of strings.",1, 0, Create_lots_of_strings, ,
"http://www.myexperiment.org/workflows/415/versions/1.html","Decode base64 to byte[]","2008-09-2716:50:22","","http://www.myexperiment.org/workflows/415/download/Decode_base64_to_byte__-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The decode base64 to byte[] service decodes the base64 string.  The byte array is then converted into the string 'Hello world'.",2, 0, Decode_base64_to_byte, Byte___to_String, ,
"http://www.myexperiment.org/workflows/416/versions/1.html","Encode byte[] to base64","2008-09-2716:51:08","","http://www.myexperiment.org/workflows/416/download/Encode_byte___to_base64-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The encode byte[] to base 64 service encodes the bytes representing (in the local character set) 'hello'.",2, 0, String_to_byte_array, Encode_byte___to_base64, ,
"http://www.myexperiment.org/workflows/417/versions/1.html","Execute cmd line app - unix - /bin/ls of temporary directory","2008-09-2716:52:16","","http://www.myexperiment.org/workflows/417/download/Execute_cmd_line_app_-_unix_-__bin_ls_of_temporary_directory-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","Note that this workflow only works on Unix systems. The get_temporary_directory beanshell returns the path to the directory in which temporary files are held.  This value is passed to the args port of the execute_cmd_line_app service.  The command port of that service has been defaulted to '/bin/ls'. The execute_cmd_line_app service runs the /bin/ls command on the temporary directory.  The result is passed to its result port and then to the out port of the workflow.",2, 0, Execute_cmd_line_app, Get_temporary_directory, ,
"http://www.myexperiment.org/workflows/418/versions/1.html","Execute cmd line app - unix - /bin/ls -R of temporary directory","2008-09-2716:52:59","","http://www.myexperiment.org/workflows/418/download/Execute_cmd_line_app_-_unix_-__bin_ls_-R_of_temporary_directory-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","Note that this workflow only works on Unix systems. The get_temporary_directory beanshell returns the path to the directory in which temporary files are held.  This value is passed to the create_and_populate_list beanshell which creates a list of '-R' and the path.  The resultant list is passed to the args port of the Execute_cmd_line_app service.  The command port of that service has been defaulted to '/bin/ls'. The execute_cmd_line_app service runs the /bin/ls -R command on the temporary directory.  The result is passed to its result port and then to the out port of the workflow.",3, 0, Execute_cmd_line_app, Get_temporary_directory, Create_and_populate_list, ,
"http://www.myexperiment.org/workflows/419/versions/1.html","Fail if false - false value","2008-09-2716:54:07","","http://www.myexperiment.org/workflows/419/download/Fail_if_false_-_false_value-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The fail if true service throws an exception if given the value 'false'.",1, 0, Fail_if_false, ,
"http://www.myexperiment.org/workflows/420/versions/1.html","Fail if false - true value","2008-09-2716:54:53","","http://www.myexperiment.org/workflows/420/download/Fail_if_false_-_true_value-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The fail if true service executes without an exception if given the value 'true'.",1, 0, Fail_if_false, ,
"http://www.myexperiment.org/workflows/421/versions/1.html","Fail if false - non false value","2008-09-2716:55:35","","http://www.myexperiment.org/workflows/421/download/Fail_if_false_-_non_false_value-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The fail if true service executes without an exception if given a non-false value such as 'fred'.",1, 0, Fail_if_false, ,
"http://www.myexperiment.org/workflows/422/versions/1.html","Fail if true - true value","2008-09-2716:56:32","","http://www.myexperiment.org/workflows/422/download/Fail_if_true_-_true_value-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The fail if true service throws an exception when passed the value true.",1, 0, Fail_if_true, ,
"http://www.myexperiment.org/workflows/423/versions/1.html","Fail if true - false value","2008-09-2716:57:09","","http://www.myexperiment.org/workflows/423/download/Fail_if_true_-_false_value-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The fail if true service executes without an exception if given the value 'false'.",1, 0, Fail_if_true, ,
"http://www.myexperiment.org/workflows/424/versions/1.html","Fail if true - non true value","2008-09-2716:57:48","","http://www.myexperiment.org/workflows/424/download/Fail_if_true_-_non_true_value-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The fail if true service executes without an exception if given a value that is not true e.g. 'fred'.",1, 0, Fail_if_true, ,
"http://www.myexperiment.org/workflows/425/versions/1.html","FIlter list of strings by regex with a suitable regular expression","2008-09-2716:58:25","","http://www.myexperiment.org/workflows/425/download/FIlter_list_of_strings_by_regex_with_a_suitable_regular_expression-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The workflow filters the five element list split from the first service and returns the three elements that match the regular expression.",2, 0, Split_string_into_string_list_by_regular_expression, Filter_list_of_strings_by_regex, ,
"http://www.myexperiment.org/workflows/426/versions/1.html","FIlter list of strings by regex with an unsuitable regular expression","2008-09-2716:59:01","","http://www.myexperiment.org/workflows/426/download/FIlter_list_of_strings_by_regex_with_an_unsuitable_regular_expression-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The workflow filters the five element list split from the first service and returns an empty list as no elements match.",2, 0, Split_string_into_string_list_by_regular_expression, Filter_list_of_strings_by_regex, ,
"http://www.myexperiment.org/workflows/427/versions/1.html","FIlter list of strings by regex extracting the specified group in the matches","2008-09-2716:59:41","","http://www.myexperiment.org/workflows/427/download/FIlter_list_of_strings_by_regex_extracting_the_specified_group_in_the_matches-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The workflow examines the five element list split from the first service.  For each element, if it contains an 'a' followed by two characters, then that triple is included in the output.  Thus, for the input  ['a','b','abcde','cdef','axy'], only 'abcde' and 'axy' contain a match and so ['abc', 'axy'] is output.",2, 0, Split_string_into_string_list_by_regular_expression, Filter_list_of_strings_extracting_match_to_a_regex, ,
"http://www.myexperiment.org/workflows/428/versions/1.html","FIlter list of strings by regex extracting the specified group in the matches","2008-09-2717:00:19","","http://www.myexperiment.org/workflows/428/download/FIlter_list_of_strings_by_regex_extracting_the_specified_group_in_the_matches-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The workflow examines the five element list split from the first service.  For each element, if it contains an 'a' followed by two characters, then the two characters after the 'a' are included in the output.  Thus, for the input  ['a','b','abcde','cdef','axy'], only 'abcde' and 'axy' contain a match and so ['bc', 'xy'] is output.",2, 0, Split_string_into_string_list_by_regular_expression, Filter_list_of_strings_extracting_match_to_a_regex, ,
"http://www.myexperiment.org/workflows/429/versions/1.html","FIlter list of strings by regex extracting the specified group in the matches","2008-09-2717:01:08","","http://www.myexperiment.org/workflows/429/download/FIlter_list_of_strings_by_regex_extracting_the_specified_group_in_the_matches-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The workflow examines the five element list split from the first service.  For each element, if it contains an 'a' followed by two characters, the second character after the 'a' is included in the output.  Thus, for the input  ['a','b','abcde','cdef','axy'], only 'abcde' and 'axy' contain a match and so ['c', 'y'] is output.",2, 0, Split_string_into_string_list_by_regular_expression, Filter_list_of_strings_extracting_match_to_a_regex, ,
"http://www.myexperiment.org/workflows/430/versions/1.html","Get image from URL - only url specified","2008-09-2717:02:41","","http://www.myexperiment.org/workflows/430/download/Get_image_from_URL_-_only_url_specified-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","Retrieve the image at  <a href=http://www.mygrid.org.uk/files/2008/09/dragon-workflow.png rel=nofollow>http://www.mygrid.org.uk/files/2008/09/dragon-workflow.png</a>  using just the url parameter",1, 0, Get_image_from_URL, ,
"http://www.myexperiment.org/workflows/431/versions/1.html","Get image from URL - url and base specified","2008-09-2717:03:20","","http://www.myexperiment.org/workflows/431/download/Get_image_from_URL_-_url_and_base_specified-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","Retrieve the image at  <a href=http://www.mygrid.org.uk/files/2008/09/dragon-workflow.png rel=nofollow>http://www.mygrid.org.uk/files/2008/09/dragon-workflow.png</a>  using both the url and base parameters",1, 0, Get_image_from_URL, ,
"http://www.myexperiment.org/workflows/432/versions/1.html","Get image URLs from HTTP document","2008-09-2717:03:55","","http://www.myexperiment.org/workflows/432/download/Get_image_URLs_from_HTTP_document-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","Retrieve the web page at  <a href=http://www.mygrid.org.uk/usermanual1.7/user_gettings_started.html rel=nofollow>http://www.mygrid.org.uk/usermanual1.7/user_gettings_started.html</a>  and examine it for images.  The workflow should return an empty list.",2, 0, Get_image_URLs_from_HTTP_document, Get_web_page_from_URL, ,
"http://www.myexperiment.org/workflows/433/versions/1.html","Get image URLs from HTML document and output the results","2008-09-2717:05:30","","http://www.myexperiment.org/workflows/433/download/Get_image_URLs_from_HTML_document_and_output_the_results-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","Retrieve the web page at  <a href=http://www.mygrid.org.uk rel=nofollow>http://www.mygrid.org.uk</a> , examine it for images and output the images.",3, 0, Get_image_URLs_from_HTTP_document, Get_web_page_from_URL, Get_image_from_URL, ,
"http://www.myexperiment.org/workflows/434/versions/1.html","Get web page from URL - just url","2008-09-2717:06:26","","http://www.myexperiment.org/workflows/434/download/Get_web_page_from_URL_-_just_url-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","Fetches a web page from  <a href=http://www.mygrid.org.uk/tools rel=nofollow>http://www.mygrid.org.uk/tools</a>  using just the url parameter of the service.  Note that when viewed, the HTML may not be rendered correctly.  However, the HTML may be viewed by rendering the result as plain text.",1, 0, Get_web_page_from_URL, ,
"http://www.myexperiment.org/workflows/435/versions/1.html","Get web page from URL - url and base","2008-09-2717:07:08","","http://www.myexperiment.org/workflows/435/download/Get_web_page_from_URL_-_url_and_base-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","Fetches a web page from  <a href=http://www.mygrid.org.uk/tools rel=nofollow>http://www.mygrid.org.uk/tools</a>  with the base parameter as http://www.mygrid.org.uk and the url as /tools.  Note that when viewed, the HTML may not be rendered correctly.  However, the HTML may be viewed by rendering the result as plain text.",1, 0, Get_web_page_from_URL, ,
"http://www.myexperiment.org/workflows/436/versions/1.html","List files by extension - several answers","2008-09-2717:07:44","","http://www.myexperiment.org/workflows/436/download/List_files_by_extension_-_several_answers-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory. The populate_directory beanshell creates several files within the temporary directory. Once the directory has been populated, it is examined by the List_files_by_extension service and the file paths to the three files ending in .png are output.",3, 0, create_temporary_directory, populate_directory, List_Files_By_Extension, ,
"http://www.myexperiment.org/workflows/437/versions/1.html","List files by extension - single answer","2008-09-2717:08:34","","http://www.myexperiment.org/workflows/437/download/List_files_by_extension_-_single_answer-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory. The populate_directory beanshell creates several files within the temporary directory. Once the directory has been populated, it is examined by the List_files_by_extension service and the file path to the one file ending in .bin is output.",3, 0, create_temporary_directory, populate_directory, List_Files_By_Extension, ,
"http://www.myexperiment.org/workflows/438/versions/1.html","List files by extension - no answer","2008-09-2717:09:11","","http://www.myexperiment.org/workflows/438/download/List_files_by_extension_-_no_answer-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory. The populate_directory beanshell creates several files within the temporary directory. Once the directory has been populated, it is examined by the List_files_by_extension service.  Since no files end in .fred, an empty list is output.",3, 0, create_temporary_directory, populate_directory, List_Files_By_Extension, ,
"http://www.myexperiment.org/workflows/439/versions/1.html","List files by extension - empty directory","2008-09-2717:09:50","","http://www.myexperiment.org/workflows/439/download/List_files_by_extension_-_empty_directory-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory. The empty directory is examined by the List_files_by_extension service.  Since no files end in .png, an empty list is output.",2, 0, create_temporary_directory, List_Files_By_Extension, ,
"http://www.myexperiment.org/workflows/440/versions/1.html","List files by regex - several answers","2008-09-2717:11:01","","http://www.myexperiment.org/workflows/440/download/List_files_by_regex_-_several_answers-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory. The populate_directory beanshell creates several files within the temporary directory. Once the directory has been populated, it is examined by the List_files_by_regex service and the file paths matching the regular expression '.*i.*', i.e. those containing an 'i', are output.",3, 0, create_temporary_directory, populate_directory, List_Files_By_Regex, ,
"http://www.myexperiment.org/workflows/441/versions/1.html","List files by regex - single answer","2008-09-2717:11:34","","http://www.myexperiment.org/workflows/441/download/List_files_by_regex_-_single_answer-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory. The populate_directory beanshell creates several files within the temporary directory. Once the directory has been populated, it is examined by the List_files_by_regex service and the file path to the one file matching 'c.*' i.e. starting with 'c' is output.",3, 0, create_temporary_directory, populate_directory, List_Files_By_Regex, ,
"http://www.myexperiment.org/workflows/442/versions/1.html","List files by regex - no answer","2008-09-2717:12:08","","http://www.myexperiment.org/workflows/442/download/List_files_by_regex_-_no_answer-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory. The populate_directory beanshell creates several files within the temporary directory. Once the directory has been populated, it is examined by the List_files_by_regex service.  Since no files match the regular expression 'x.*' i.e. no files have a name that starts with 'x', an empty list is output.",3, 0, create_temporary_directory, populate_directory, List_Files_By_Regex, ,
"http://www.myexperiment.org/workflows/443/versions/1.html","List files by regex - empty directory","2008-09-2717:12:38","","http://www.myexperiment.org/workflows/443/download/List_files_by_regex_-_empty_directory-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory. The empty directory is examined by the List_files_by_regex service.  Since there are no files, an empty list is output.",2, 0, create_temporary_directory, List_Files_By_Regex, ,
"http://www.myexperiment.org/workflows/444/versions/1.html","Merge string list to string - default separator","2008-09-2717:13:27","","http://www.myexperiment.org/workflows/444/download/Merge_string_list_to_string_-_default_separator-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The merge string list to string service takes the list ['a','b','c'] and outputs the string 'abc'.",2, 0, Split_string_into_string_list_by_regular_expression, Merge_string_list_to_string, ,
"http://www.myexperiment.org/workflows/445/versions/1.html","Merge string list to string - colon separator","2008-09-2717:13:59","","http://www.myexperiment.org/workflows/445/download/Merge_string_list_to_string_-_colon_separator-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The merge string list to string service takes the list ['a','b','c'] and using the separator ':' outputs the string 'a:b:c'.",2, 0, Split_string_into_string_list_by_regular_expression, Merge_string_list_to_string, ,
"http://www.myexperiment.org/workflows/446/versions/1.html","Merge string list to string - empty list","2008-09-2717:14:32","","http://www.myexperiment.org/workflows/446/download/Merge_string_list_to_string_-_empty_list-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The merge string list to string service takes an empty list [] and outputs an empty string ''.",2, 0, Split_string_into_string_list_by_regular_expression, Merge_string_list_to_string, ,
"http://www.myexperiment.org/workflows/447/versions/1.html","Pad numeral with leading 0s - default targetlength","2008-09-2717:15:02","","http://www.myexperiment.org/workflows/447/download/Pad_numeral_with_leading_0s_-_default_targetlength-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The pad numeral with leading 0s takes the input '12' and pads it to the default target length of 7, yielding the output '0000012'.",1, 0, Pad_numeral_with_leading_0s, ,
"http://www.myexperiment.org/workflows/448/versions/1.html","Pad numeral with leading 0s - specified targetlength","2008-09-2717:15:38","","http://www.myexperiment.org/workflows/448/download/Pad_numeral_with_leading_0s_-_specified_targetlength-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The pad numeral with leading 0s takes the input '12' and pads it to the specified target length of 4, yielding the output '0012'.",1, 0, Pad_numeral_with_leading_0s, ,
"http://www.myexperiment.org/workflows/449/versions/1.html","Pad numeral with leading 0s - too short targetlength","2008-09-2717:16:08","","http://www.myexperiment.org/workflows/449/download/Pad_numeral_with_leading_0s_-_too_short_targetlength-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The pad numeral with leading 0s takes the input '12' and because the specified target length of 1 is too short, yields the output '12'.",1, 0, Pad_numeral_with_leading_0s, ,
"http://www.myexperiment.org/workflows/450/versions/1.html","Read GenBank file","2008-09-2717:16:45","","http://www.myexperiment.org/workflows/450/download/Read_GenBank_file-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The Get_web_page_from_URL downloads a file from myExperiment that contains GenBank data.  That data is then saved to a temporary file generated by the create_and_populate_temporary_file beanshell.  The path to the temporary file is then passed to the Read_GenBank_file service.  That service reads the file and converts the GenBank data into Agave format.  The result is then sent to the workflow's out port.",3, 0, Read_GenBank_file, Create_and_populate_temporary_file, Get_web_page_from_URL, ,
"http://www.myexperiment.org/workflows/451/versions/1.html","Read SwissProt file","2008-09-2717:17:24","","http://www.myexperiment.org/workflows/451/download/Read_SwissProt_file-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The Get_web_page_from_URL downloads a file from myExperiment that contains SwissProt data.  That data is then saved to a temporary file generated by the create_and_populate_temporary_file beanshell.  The path to the temporary file is then passed to the Read_SwissProt_file service.  That service reads the file and converts the SwissProt data into Agave format.  The result is then sent to the workflow's out port.",3, 0, Create_and_populate_temporary_file, Get_web_page_from_URL, Read_SwissProt_file, ,
"http://www.myexperiment.org/workflows/452/versions/1.html","Read text file","2008-09-2717:18:07","","http://www.myexperiment.org/workflows/452/download/Read_text_file-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The beanshell write the string 'hello' to a temporary file.  The filepath to the temporary file is then passed to the Read_text_file service which reads the file and outputs the string 'hello'.",2, 0, Create_and_populate_temporary_file, Read_Text_File, ,
"http://www.myexperiment.org/workflows/453/versions/1.html","Read text file - several lines","2008-09-2717:18:46","","http://www.myexperiment.org/workflows/453/download/Read_text_file_-_several_lines-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The beanshell write the string 'hello' four times separated by a new lineto a temporary file.  The filepath to the temporary file is then passed to the Read_text_file service which reads the file and outputs the string 'hellohellohellohello'.",2, 0, Read_Text_File, Create_and_populate_temporary_file, ,
"http://www.myexperiment.org/workflows/454/versions/1.html","Read text file - empty file","2008-09-2717:19:17","","http://www.myexperiment.org/workflows/454/download/Read_text_file_-_empty_file-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The beanshell creates an empty temporary file.  The filepath to the temporary file is then passed to the Read_text_file service which reads the file and outputs the empty string ''.",2, 0, Read_Text_File, Create_and_populate_temporary_file, ,
"http://www.myexperiment.org/workflows/455/versions/1.html","Remove duplicate strings","2008-09-2717:19:50","","http://www.myexperiment.org/workflows/455/download/Remove_duplicate_strings-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The remove duplicate strings service takes the list ['a','b','c','b','a','d'], strips out duplicate strings and outputs the result ['a','b','c','d'].",2, 0, Split_string_into_string_list_by_regular_expression, Remove_duplicate_strings, ,
"http://www.myexperiment.org/workflows/456/versions/1.html","Remove duplicate strings - empty list","2008-09-2717:20:32","","http://www.myexperiment.org/workflows/456/download/Remove_duplicate_strings_-_empty_list-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The remove duplicate strings service takes the empty list [] and outputs the result [].",2, 0, Split_string_into_string_list_by_regular_expression, Remove_duplicate_strings, ,
"http://www.myexperiment.org/workflows/457/versions/1.html","Reverse complement DNA","2008-09-2717:21:03","","http://www.myexperiment.org/workflows/457/download/Reverse_complement_DNA-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The Reverse Complement DNA service takes the DNA sequence, here defaulted to 'gatcctccat' and outputs the corresponding reverse complement sequence, in this example, 'atggaggatc'.",1, 0, Reverse_Complement_DNA, ,
"http://www.myexperiment.org/workflows/458/versions/1.html","Select - no title or message parameters","2008-09-2717:21:37","","http://www.myexperiment.org/workflows/458/download/Select_-_no_title_or_message_parameters-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The split_string_into_string_list_by_regular_expression parses the string 'a,b,c,d,e' and outputs the list ['a','b','c','d','e']. The select service displays a dialog with no title or message.  The user is able to select from the values ['a','b','c','d',e'].  When the user presses OK the value the user selected is passed to the answer port of the select service and so to the output of the workflow.  If the user clicks Cancel then a service failure is generated.",2, 0, Select, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/459/versions/1.html","Select - title parameter","2008-09-2717:22:04","","http://www.myexperiment.org/workflows/459/download/Select_-_title_parameter-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The split_string_into_string_list_by_regular_expression parses the string 'a,b,c,d,e' and outputs the list ['a','b','c','d','e']. The select service displays a dialog with 'Some title' but no message.  The user is able to select from the values ['a','b','c','d',e'].  When the user presses OK the value the user selected is passed to the answer port of the select service and so to the output of the workflow.  If the user clicks Cancel then a service failure is generated.",2, 0, Select, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/460/versions/1.html","Select - message parameter","2008-09-2717:22:32","","http://www.myexperiment.org/workflows/460/download/Select_-_message_parameter-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The split_string_into_string_list_by_regular_expression parses the string 'a,b,c,d,e' and outputs the list ['a','b','c','d','e']. The select service displays a dialog with no title but with 'Some message'.  The user is able to select from the values ['a','b','c','d',e'].  When the user presses OK the value the user selected is passed to the answer port of the select service and so to the output of the workflow.  If the user clicks Cancel then a service failure is generated.",2, 0, Select, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/461/versions/1.html","Select - title and message parameters","2008-09-2717:23:04","","http://www.myexperiment.org/workflows/461/download/Select_-_title_and_message_parameters-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The split_string_into_string_list_by_regular_expression parses the string 'a,b,c,d,e' and outputs the list ['a','b','c','d','e']. The select service displays a dialog with ''Some title' and 'Some message'.  The user is able to select from the values ['a','b','c','d',e'].  When the user presses OK the value the user selected is passed to the answer port of the select service and so to the output of the workflow.  If the user clicks Cancel then a service failure is generated.",2, 0, Select, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/462/versions/1.html","Select - single element list","2008-09-2717:23:38","","http://www.myexperiment.org/workflows/462/download/Select_-_single_element_list-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The split_string_into_string_list_by_regular_expression parses the string 'a' and outputs the list ['a']. The select service displays a dialog with 'Some title' and 'Some message'.  The user is only able to select the value 'a'.  When the user presses OK 'a' is passed to the answer port of the select service and so to the output of the workflow.  If the user clicks Cancel then a service failure is generated.",2, 0, Select, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/463/versions/1.html","Split string into string list by regular expression - default regex","2008-09-2717:24:13","","http://www.myexperiment.org/workflows/463/download/Split_string_into_string_list_by_regular_expression_-_default_regex-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The split string into string list by regular expression takes the string 'a,b,c' and using the default regular expression ',' splits it into the list ['a','b','c']",1, 0, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/464/versions/1.html","Split string into string list by regular expression - colon regex","2008-09-2717:24:44","","http://www.myexperiment.org/workflows/464/download/Split_string_into_string_list_by_regular_expression_-_colon_regex-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The split string into string list by regular expression takes the string 'boo:and:foo' and using the specified regular expression ':' splits it into the list ['boo','and','foo']",1, 0, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/465/versions/1.html","Split string into string list by regular expression - character regex","2008-09-2717:25:20","","http://www.myexperiment.org/workflows/465/download/Split_string_into_string_list_by_regular_expression_-_character_regex-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The split string into string list by regular expression takes the string 'boo:and:foo' and using the specified regular expression 'o' splits it into the list ['b','',':and:f']",1, 0, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/466/versions/1.html","String list difference - yielding non-empty list","2008-09-2717:25:57","","http://www.myexperiment.org/workflows/466/download/String_list_difference_-_yielding_non-empty_list-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The string list difference service takes in ['a','b','c'] and ['a','e','c'] and returns the  list ['b','e'].",3, 0, list1, list2, String_list_difference, ,
"http://www.myexperiment.org/workflows/467/versions/1.html","String list difference - yielding empty list","2008-09-2717:26:37","","http://www.myexperiment.org/workflows/467/download/String_list_difference_-_yielding_empty_list-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The string list difference service takes in ['a','b','c'] and ['a','c','b'] and returns the  empty list [].",3, 0, list1, list2, String_list_difference, ,
"http://www.myexperiment.org/workflows/468/versions/1.html","String list intersection - yielding non empty list","2008-09-2717:27:21","","http://www.myexperiment.org/workflows/468/download/String_list_intersection_-_yielding_non_empty_list-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The string list intersection service takes in ['a','b','c'] and ['a','e','c] and returns the list ['a','c'].",3, 0, list1, list2, String_list_intersection, ,
"http://www.myexperiment.org/workflows/469/versions/1.html","String list intersection - yielding empty list","2008-09-2717:28:04","","http://www.myexperiment.org/workflows/469/download/String_list_intersection_-_yielding_empty_list-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The string list intersection service takes in ['a','b','c'] and ['x','y','z'] and returns the empty list [].",3, 0, list1, list2, String_list_intersection, ,
"http://www.myexperiment.org/workflows/470/versions/1.html","String list union - yielding non-empty list","2008-09-2717:28:46","","http://www.myexperiment.org/workflows/470/download/String_list_union_-_yielding_non-empty_list-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The string list union service takes in ['a','b','c'] and ['a','e','c'] and returns a list equivalent to ['a','b','c','e'].",3, 0, list1, list2, String_list_union, ,
"http://www.myexperiment.org/workflows/471/versions/1.html","String list union - yielding empty list","2008-09-2717:29:15","","http://www.myexperiment.org/workflows/471/download/String_list_union_-_yielding_empty_list-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The string list union service takes in two empty lists [] and [] and returns an empty list [].",3, 0, list1, list2, String_list_union, ,
"http://www.myexperiment.org/workflows/472/versions/1.html","Tell - no parameters","2008-09-2717:29:45","","http://www.myexperiment.org/workflows/472/download/Tell_-_no_parameters-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The tell service displays an informative dialog with no title or message.  When the user presses OK the string 'answer' is passed to the answer port of the tell service and so to the output of the workflow.",1, 0, Tell, ,
"http://www.myexperiment.org/workflows/473/versions/1.html","Tell - title parameter","2008-09-2717:30:13","","http://www.myexperiment.org/workflows/473/download/Tell_-_title_parameter-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The tell service displays an informative dialog with 'Some title' but no message.  When the user presses OK the string 'answer' is passed to the answer port of the tell service and so to the output of the workflow.",1, 0, Tell, ,
"http://www.myexperiment.org/workflows/474/versions/1.html","Tell - message parameter","2008-09-2717:30:42","","http://www.myexperiment.org/workflows/474/download/Tell_-_message_parameter-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The tell service displays an informative dialog with no title but with message 'Some message'.  When the user presses OK the string 'answer' is passed to the answer port of the tell service and so to the output of the workflow.",1, 0, Tell, ,
"http://www.myexperiment.org/workflows/475/versions/1.html","Tell - title and message parameters","2008-09-2717:31:37","","http://www.myexperiment.org/workflows/475/download/Tell_-_title_and_message_parameters-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The tell service displays an informative dialog with no title but with message 'Some message'.  When the user presses OK the string 'answer' is passed to the answer port of the tell service and so to the output of the workflow.",1, 0, Tell, ,
"http://www.myexperiment.org/workflows/476/versions/1.html","Test always fails - no parameters","2008-09-2717:32:53","","http://www.myexperiment.org/workflows/476/download/Test_always_fails_-_no_parameters-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The test always fails service generates a service failure when no parameter values are supplied.",1, 0, TEST___always_fails, ,
"http://www.myexperiment.org/workflows/477/versions/1.html","Test always fails - one parameter","2008-09-2717:33:33","","http://www.myexperiment.org/workflows/477/download/Test_always_fails_-_one_parameter-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The test always fails service generates a service failure when one parameter value is supplied.",1, 0, TEST___always_fails, ,
"http://www.myexperiment.org/workflows/478/versions/1.html","Test always fails - two parameters","2008-09-2717:34:09","","http://www.myexperiment.org/workflows/478/download/Test_always_fails_-_two_parameters-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The test always fails service generates a service failure when two parameter values are supplied.",1, 0, TEST___always_fails, ,
"http://www.myexperiment.org/workflows/479/versions/1.html","Transcribe DNA","2008-09-2717:34:40","","http://www.myexperiment.org/workflows/479/download/Transcribe_DNA-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The Transcribe DNA service takes the DNA sequence, here defaulted to 'gatcctccat' and outputs the corresponding transcribed RNA  sequence, in this example, 'gauccuccau'.",1, 0, Transcribe_DNA, ,
"http://www.myexperiment.org/workflows/480/versions/1.html","Transform XML - no output file","2008-09-2717:35:33","","http://www.myexperiment.org/workflows/480/download/Transform_XML_-_no_output_file-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The get_xml_file_from_web service downloads an example xml from myExperiment.  The content of that file is then saved to a temporary file by create_and_populate_xml_file.  The path to the temporary file is passed to the inFileURL port of Transform_XML. The get_xslt_file_from_web service downloads an example xslt file from myExperiment.  The content of that file is then saved to a temporary file by create_and_populate_xslt_file.  The path to the temporary file is passed to the xslFileURL port of Transform_XML. The Transform_XML service transforms the XML using the specified XSLT and sends the resultant XML document to its outputStr port and so to the workflow's out port.",5, 0, Transform_XML, Create_and_populate_XML_file, Create_and_populate_xslt_file, Get_xml_file_from_web, Get_xslt_file_from_web, ,
"http://www.myexperiment.org/workflows/481/versions/1.html","Transform XML - explicit output file","2008-09-2717:36:13","","http://www.myexperiment.org/workflows/481/download/Transform_XML_-_explicit_output_file-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The get_xml_file_from_web service downloads an example xml from myExperiment.  The content of that file is then saved to a temporary file by create_and_populate_xml_file.  The path to the temporary file is passed to the inFileURL port of Transform_XML. The get_xslt_file_from_web service downloads an example xslt file from myExperiment.  The content of that file is then saved to a temporary file by create_and_populate_xslt_file.  The path to the temporary file is passed to the xslFileURL port of Transform_XML. The create_temporary_file beanshell creates a temporary file to which the transformed XML is to be written.  The file path to this file is passed to the outFileURL port of Transform_XML. The Transform_XML service transforms the XML using the specified XSLT and sends the resultant XML document to its outputStr port and so to the workflow's out port.  The transformed XML document is also written to the file whose path is passed to the outFileURL port. To check the content of the output file, its file path is passed to the Read_Text_File service.  Once the Transform_XML service has finished, the Read_Text_File service reads the output file and echoes its content to the contents_of_output_file port of the workflow.",7, 0, Transform_XML, Create_and_populate_XML_file, Create_and_populate_xslt_file, Get_xml_file_from_web, Get_xslt_file_from_web, Create_temporary_file, Read_Text_File, ,
"http://www.myexperiment.org/workflows/482/versions/1.html","Transform XML - output file by extension","2008-09-2717:36:43","","http://www.myexperiment.org/workflows/482/download/Transform_XML_-_output_file_by_extension-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The get_xml_file_from_web service downloads an example xml from myExperiment.  The content of that file is then saved to a temporary file by create_and_populate_xml_file.  The path to the temporary file is passed to the inFileURL port of Transform_XML. The get_xslt_file_from_web service downloads an example xslt file from myExperiment.  The content of that file is then saved to a temporary file by create_and_populate_xslt_file.  The path to the temporary file is passed to the xslFileURL port of Transform_XML. The Transform_XML service transforms the XML using the specified XSLT and sends the resultant XML document to its outputStr port and so to the workflow's out port.  The Transform_XML_service has the default for outputExt set to 'out' so the transformed XML document is also written to the file whose path is the same as that of the inFileURL but with '.out' as the extension. To check the content of the output file, its file path is calculated by calls of Filter_list_of_strings_extracting_match_to_a_regex and Concatenate_two_strings.  The file path is passed to the Read_Text_File service.  Once the Transform_XML service has finished, the Read_Text_File service reads the output file and echoes its content to the contents_of_output_file port of the workflow.",8, 0, Transform_XML, Create_and_populate_XML_file, Create_and_populate_xslt_file, Get_xml_file_from_web, Get_xslt_file_from_web, Read_Text_File, Filter_list_of_strings_extracting_match_to_a_regex, Concatenate_two_strings, ,
"http://www.myexperiment.org/workflows/483/versions/1.html","Warn - no parameters","2008-09-2717:37:28","","http://www.myexperiment.org/workflows/483/download/Warn_-_no_parameters-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The warn service displays a prompt with no title or message.  When the user presses OK the string 'answer' is passed to the answer port of the warn service and so to the output of the workflow.",1, 0, Warn, ,
"http://www.myexperiment.org/workflows/484/versions/1.html","Warn - title parameter","2008-09-2717:37:54","","http://www.myexperiment.org/workflows/484/download/Warn_-_title_parameter-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The warn service displays a warning dialog with 'Some title' but no message.  When the user presses OK the string 'answer' is passed to the answer port of the warn service and so to the output of the workflow.",1, 0, Warn, ,
"http://www.myexperiment.org/workflows/485/versions/1.html","Warn - message parameter","2008-09-2717:38:20","","http://www.myexperiment.org/workflows/485/download/Warn_-_message_parameter-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The warn service displays a warning dialog with no title but message 'Some message'.  When the user presses OK the string 'answer' is passed to the answer port of the warn service and so to the output of the workflow.",1, 0, Warn, ,
"http://www.myexperiment.org/workflows/486/versions/1.html","Warn - title and message parameters","2008-09-2717:38:47","","http://www.myexperiment.org/workflows/486/download/Warn_-_title_and_message_parameters-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The warn service displays a warning dialog with 'Some title' and message 'Some message'.  When the user presses OK the string 'answer' is passed to the answer port of the warn service and so to the output of the workflow.",1, 0, Warn, ,
"http://www.myexperiment.org/workflows/487/versions/1.html","Write text file - specified value","2008-09-2717:40:07","","http://www.myexperiment.org/workflows/487/download/Write_text_file_-_specified_value-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The beanshell creates an empty temporary file.  The filepath to the temporary file is then passed to the Write_text_file service which writes 'hello' into the file.  'hello' is also output by the service.",2, 0, Create_temporary_file, Write_Text_File, ,
"http://www.myexperiment.org/workflows/488/versions/1.html","Write text file - empty string value","2008-09-2717:40:48","","http://www.myexperiment.org/workflows/488/download/Write_text_file_-_empty_string_value-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The beanshell creates an empty temporary file.  The filepath to the temporary file is then passed to the Write_text_file service which writes the empty string '' into the file.  '' is also output by the service.",2, 0, Create_temporary_file, Write_Text_File, ,
"http://www.myexperiment.org/workflows/489/versions/1.html","Write text file - overwriting content","2008-09-2717:41:23","","http://www.myexperiment.org/workflows/489/download/Write_text_file_-_overwriting_content-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The beanshell creates an empty temporary file.  The filepath to the temporary file is then passed to the Write_text_file A service which writes the string 'hello' into the file.  After service A has run, service B writes 'goodbye' into the file.  The file is then read by the Read_Text_File service and its content, 'goodbye', output by the workflow.",4, 0, Create_temporary_file, Read_Text_File, Write_Text_File_B, Write_Text_File_A, ,
"http://www.myexperiment.org/workflows/490/versions/1.html","Echo_with_occasional_failure-1","2008-09-2910:52:54","","http://www.myexperiment.org/workflows/490/download/Echo_with_occasional_failure-1-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The echo_with_occasional_failure service mostly echoes the string 'hello' to the out port.  Sometimes, it throws a service failure.",1, 0, Echo_with_occasional_failure, ,
"http://www.myexperiment.org/workflows/491/versions/1.html","Flatten list - two depth","2008-09-2911:46:16","","http://www.myexperiment.org/workflows/491/download/Flatten_list_-_two_depth-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The flatten_list service takes the list [[['a']], [['b']], [['c']], [['d']]] and, using the default flatten depth of 2, outputs the list [['a'], ['b'], ['c'], ['d'], ['e']].",2, 0, Beanshell_scripting_host, Flatten_list, ,
"http://www.myexperiment.org/workflows/492/versions/1.html","Flatten list - three depth","2008-09-2911:47:05","2008-09-3014:38:09","http://www.myexperiment.org/workflows/492/download/Flatten_list_-_three_depth-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The flatten_list service takes the list [[['a']], [['b']], [['c']], [['d']]] and, using a flatten depth of 3, outputs the list ['a', 'b', 'c', 'd', 'e'].",2, 0, Beanshell_scripting_host, Flatten_list, ,
"http://www.myexperiment.org/workflows/492/versions/2.html","Flatten list - three depth","2008-09-2911:47:05","2008-09-3014:38:09","http://www.myexperiment.org/workflows/492/download/Flatten_list_-_three_depth-v2.xml?version=2","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The flatten_list service takes the list [[['a']], [['b']], [['c']], [['d']],[['e']]] and, using a flatten depth of 3, outputs the list ['a', 'b', 'c', 'd','e'].",2, 0, Beanshell_scripting_host, Flatten_list, ,
"http://www.myexperiment.org/workflows/493/versions/1.html","bconv","2008-09-2912:13:41","2008-09-2912:29:01","http://www.myexperiment.org/workflows/493/download/bconv-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Converts external IDs to KEGG IDs.External database:&nbsp; NCBI GI, NCBI GeneID, GenBank , UniGene , OMIM. Database prefix: ncbi-gi:, ncbi-geneid:, genbank: ,unigene: , uniprot: , omim: Example of input parameter: ncbi-gi:10047090 ncbi-geneid:14751",1, 1, bconv, ,
"http://www.myexperiment.org/workflows/494/versions/1.html","bfind","2008-09-2913:21:12","2008-09-2913:23:39","http://www.myexperiment.org/workflows/494/download/bfind-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Used for searching entries by keywords. User needs to specify a database from those which are supported by DBGET system before keywords. List of databases available at :&nbsp; <a href=http://www.genome.jp/dbget/>http://www.genome.jp/dbget/</a> Example of input parameter:  gb E-cadherin human",1, 1, bfind, ,
"http://www.myexperiment.org/workflows/495/versions/1.html","Extract elements from a list - full extraction","2008-09-2913:27:21","","http://www.myexperiment.org/workflows/495/download/Extract_elements_from_a_list_-_full_extraction-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The extract_elements_from_a_list is passed the list ['a','b','c','d','e'].  The fromIndex is 0 and the toIndex is 5, so the service outputs an identical list.",2, 0, Extract_elements_from_a_list, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/496/versions/1.html","Extract elements from a list - single element extraction","2008-09-2913:27:51","","http://www.myexperiment.org/workflows/496/download/Extract_elements_from_a_list_-_single_element_extraction-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The extract_elements_from_a_list is passed the list ['a','b','c','d','e'].  The fromIndex is 2 and the toIndex is 3, so the service outputs the single element list ['c'].",2, 0, Extract_elements_from_a_list, Split_string_into_string_list_by_regular_expression, ,
"http://www.myexperiment.org/workflows/497/versions/1.html","Extract elements from a list - extraction in nested lists","2008-09-2913:28:23","","http://www.myexperiment.org/workflows/497/download/Extract_elements_from_a_list_-_extraction_in_nested_lists-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The extract_elements_from_a_list is passed the list [['a','b','c', 'd'], ['e','f','g','h'],['i','j','k','l'],['m','n','o','p']]  with fromIndex of 1 and toIndex of 3 and the default depth of 1, will output the list [['b','c'], ['f','g'],['j','k'],['n','o'']] as it is the list with depth 1 e.g. ['e','f','g','h'] that are considered.",6, 0, Extract_elements_from_a_list, a_b_c_d, e_f_g_h, i_j_k_l, m_n_o_p, Create_two_deep_list, ,
"http://www.myexperiment.org/workflows/498/versions/1.html","Extract elements from a list - extraction of nested lists","2008-09-2913:28:49","","http://www.myexperiment.org/workflows/498/download/Extract_elements_from_a_list_-_extraction_of_nested_lists-v1.xml?version=1","/users/30","Alan Williams","taverna 1","/users/30,","Alan Williams,","The extract_elements_from_a_list is passed the list [['a','b','c', 'd'], ['e','f','g','h'],['i','j','k','l'],['m','n','o','p']]  with fromIndex of 1 and toIndex of 3  and  depth 2, will output the list [['e','f','g','h'],['i','j','k','l']] as it is the outermost list i.e. that with depth 2 that is considered.",6, 0, Extract_elements_from_a_list, a_b_c_d, e_f_g_h, i_j_k_l, m_n_o_p, Create_two_deep_list, ,
"http://www.myexperiment.org/workflows/499/versions/1.html","bget","2008-09-2913:58:00","","http://www.myexperiment.org/workflows/499/download/bget-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Retrieve database entries specified by a list of entry_id. Number of entry_id retrieves at a time is restricted up to 100 Example of input:eco:b0002 hin:tRNA-Cys-1",1, 1, bget, ,
"http://www.myexperiment.org/workflows/501/versions/1.html","binfo","2008-09-3014:30:08","2008-09-3014:31:27","http://www.myexperiment.org/workflows/501/download/binfo-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Show the version information of a specificied database. &nbsp;Example of input:  <br /> &quot;gb&quot; &nbsp;for Genbank database  <br /> &quot;sp&quot; for swissprot database  <br /> &quot;emb&quot; for embl database",1, 1, binfo, ,
"http://www.myexperiment.org/workflows/502/versions/1.html","btit","2008-09-3017:44:11","2008-09-3017:46:34","http://www.myexperiment.org/workflows/502/download/btit-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Retrieve definitions of given database entries available on GenomeNet database.  <br /> Example of input: <br /> hsa:1798  <br /> mmu:13478",1, 1, btit, ,
"http://www.myexperiment.org/workflows/503/versions/1.html","color_pathway_by_elements","2008-09-3018:13:47","2008-10-0117:11:38","http://www.myexperiment.org/workflows/503/download/color_pathway_by_elements-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Color the objects (rectangles and circles on a pathway map) corresponding to the given 'element_id_list' with the specified colors and return the URL of the colored image. Example of inputs: pathway_id:  <br /> path:bsu00010 element_list: <br /> 78  <br /> 79 fg_color_llist:  <br /> red  <br /> orange <br /> <br /> bg_color_list:  <br /> green  <br /> blue",1, 1, color_pathway_by_elements, ,
"http://www.myexperiment.org/workflows/503/versions/2.html","color_pathway_by_elements","2008-09-3018:13:47","2008-10-0117:11:38","http://www.myexperiment.org/workflows/503/download/color_pathway_by_elements-v2.xml?version=2","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Color the objects (rectangles and circles on a pathway map) corresponding to the given 'element_id_list' with the specified colors and return the URL of the colored image. Example of inputs: pathway_id: <br /> path:bsu00010 element_list:&nbsp;(to add as list) <br /> 78  <br /> 79 fg_color_list:(to add as list) <br /> red  <br /> blue bg_color_list:&nbsp;(to add as list) <br /> green  <br /> yellow",2, 1, color_pathway_by_elements, Get_image_from_URL, ,
"http://www.myexperiment.org/workflows/506/versions/1.html","workflow1","2008-10-0112:00:42","","http://www.myexperiment.org/workflows/506/download/workflow1-v1.xml?version=1","/users/1306","Chris","taverna 1","/users/1306,","Chris,",,4, 1, Get_Protein_FASTA, searchSimple, program, database, ,
"http://www.myexperiment.org/workflows/510/versions/1.html","color_pathway_by_objects","2008-10-0117:03:41","2008-10-0117:06:10","http://www.myexperiment.org/workflows/510/download/color_pathway_by_objects-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Color  given objects on a pathway map with  specified colors and return the URL of the colored image. In the KEGG pathway maps, a gene or enzyme is represented by a rectangle and a compound is shown as a small circle. Example of input: pathway_id: <br /> path:eco00260  <br /> <br /> object_list:&nbsp;(to add as list) <br /> eco:b0514  <br /> eco:b2913 fg_color:&nbsp;(to add as list) <br /> blue  <br /> orange bg_color: (to add as list) <br /> red  <br /> orange",2, 1, Get_image_from_URL, color_pathway_by_objects, ,
"http://www.myexperiment.org/workflows/511/versions/1.html","get_best_best_neighbors_by_gene","2008-10-0213:41:05","","http://www.myexperiment.org/workflows/511/download/get_best_best_neighbors_by_gene-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Search the best-best neighbor of a gene in all organisms. Example of input: gene_id: eco:b0002 offset: 1 limit: 10",1, 1, get_best_best_neighbors_by_gene, ,
"http://www.myexperiment.org/workflows/512/versions/1.html","runFunCUT","2008-10-0310:54:45","2008-10-0311:49:17","","/users/1056","JosÃ© Manuel RodrÃ­guez","taverna 1","/users/1056,","JosÃ© Manuel RodrÃ­guez,","MOBY Web Services (synchronous and asynchronous) that describe the FunCUT method. Is recommended use asynchronous MOBY services because the method needs huge range of time. &nbsp; <em>Short Description:</em>  Annotates homologous sequences and includes new features related to the specific identification of protein subfamilies (orthologous groups) FunCUT  ( <a href=http://ubio.bioinfo.cnio.es/biotools/FunCUT/docs/Automatic_Annotation_of_Protein_Function_Based_on_Family_Identification.pdf class=linkPage>Abascal and Valencia, 2003</a> . PROTEINS: Structure, Function, and Genetics 53:683&ndash; 692 (2003)) is application based on the study of the annotations of homologous sequences and includes new features related to the specific identification of protein subfamilies (orthologous groups). The workflow of the method proceeds as follows: A sequence similitary search is carried out to find proteins related to the query sequence. A clustering algorithm is applied in order to identity closely related sequence groups in the set of similar proteins. More related sequences are more likely to share a common function. In some cases, recursive sequence similitary searches lead to better representation of the related subfamilies, which facilitates the clustering. The local alignments with the closely related proteins clusteres together with the query protein are classified in different categories depending on the extent to which the alignments cover the length of the query and target sequences (alignment categories). Key functional annotations of the corresponding proteins are analyzed, including functional descriptions, enzymatic activity codes, and Swiss-Prot style keywords. The transference of information is carried out starting from the alignment categories with a better coverage. A confidence level is assigned to each one of the annotations. This level is derived from the alignment categories. The FunCUT results, as we said, includes key functional annotations of the corresponding proteins as the functional descriptions, enzymatic activity codes, and Swiss-Prot style keywords. Also, the results includes the clusters of the query protein and the hits of Blast. Created by Federico Abascal and Alfonso Valencia. Mantained by Jos&eacute; Mar&iacute;a Fern&aacute;ndez and Jos&eacute; Manuel Rodr&iacute;guez. <a href=http://ubio.bioinfo.cnio.es/biotools/FunCUT>http://ubio.bioinfo.cnio.es/biotools/FunCUT</a>",
"http://www.myexperiment.org/workflows/514/versions/1.html","Example of a conditional execution workflow","2008-10-0610:26:40","","http://www.myexperiment.org/workflows/514/download/Example_of_a_conditional_execution_workflow-v1.xml?version=1","/users/987","hong nguyen","taverna 1","/users/987,","hong nguyen,","If the input is true then the string 'foo' is emited, if false then 'bar'. Just a simple example to show how the monster works, so to speak.",5, 0, Fail_if_false, Fail_if_true, foo, bar, Echo_list, ,
"http://www.myexperiment.org/workflows/518/versions/1.html","get_compounds_by_pathway","2008-10-0716:49:18","","http://www.myexperiment.org/workflows/518/download/get_compounds_by_pathway-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Retrieves all compounds on the specified pathway Example of input:path:eco00020",1, 1, get_compounds_by_pathway, ,
"http://www.myexperiment.org/workflows/519/versions/1.html","get_compounds_by_reaction","2008-10-0716:58:38","","http://www.myexperiment.org/workflows/519/download/get_compounds_by_reaction-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Retrieve all compounds which have a link to a given reaction_id Example on input:rn:R00100",1, 1, get_compounds_by_reaction, ,
"http://www.myexperiment.org/workflows/520/versions/1.html","get_drugs_by_pathways","2008-10-0717:05:11","","http://www.myexperiment.org/workflows/520/download/get_drugs_by_pathways-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Retrieves all drugs on the specified pathway.input example: path:map07025 ;  path:eco00020",1, 1, get_drugs_by_pathway, ,
"http://www.myexperiment.org/workflows/522/versions/1.html","get_element_relations_by_pathway","2008-10-0816:19:51","","http://www.myexperiment.org/workflows/522/download/get_element_relations_by_pathway-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Retrieve all objects and relations on specified pathway Input example:path:bsu00010",1, 1, get_element_relations_by_pathway, ,
"http://www.myexperiment.org/workflows/523/versions/1.html","get_elements_by_pathway","2008-10-0816:25:59","","http://www.myexperiment.org/workflows/523/download/get_elements_by_pathway-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Retrieve all objects on specified pathway get_elements_by_pathway Input example:path:bsu00010",1, 1, get_elements_by_pathway, ,
"http://www.myexperiment.org/workflows/524/versions/1.html","get_enzymes_by_compound","2008-10-0816:30:58","","http://www.myexperiment.org/workflows/524/download/get_enzymes_by_compound-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Retrieve all enzymes which have a link to a given compound id Input example:cpd:C00345",1, 1, get_enzymes_by_compound, ,
"http://www.myexperiment.org/workflows/525/versions/1.html","get_enzymes_by_gene","2008-10-0816:37:24","","http://www.myexperiment.org/workflows/525/download/get_enzymes_by_gene-v1.xml?version=1","/users/62","Franck Tanoh","taverna 1","/users/62,","Franck Tanoh,","Retrieve all the EC numbers which are assigned to a given gene Input example:eco:b0002",1, 1, get_enzymes_by_gene, ,
"http://www.myexperiment.org/workflows/528/versions/1.html","REST access of xml.nig.ac.jp (WABI)","2008-10-1416:17:58","2008-10-1416:39:03","http://www.myexperiment.org/workflows/528/download/REST_access_of_xml.nig.ac.jp__WABI_-v1.xml?version=1","/users/5","Stian Soiland-Reyes","taverna 1","/users/5,","Stian Soiland-Reyes,","This workflow has a beanshell script for composing the  <a href=http://xml.nig.ac.jp/tutorial/rest/index.html>REST URL</a>  for the  <a href=http://xml.nig.ac.jp/index.html#services>services at xml.nig.ac.jp</a> &nbsp;   (WABI) This URL is passed to the local worker  <i>Get_web_page_from_URL</i>  that fetches the requested data. <b>Note: This is a proof of concept of accessing REST services through Taverna. All of WABI's services can more easily be browsed and used in Taverna by adding their WSDL, for instance </b> <i><b><a href=http://xml.nig.ac.jp/wsdl/GetEntry.wsdl>http://xml.nig.ac.jp/wsdl/GetEntry.wsdl</a></b></i> The example invokes the  <i>getDDBJEntry(accession)</i>  method of the  <a href=http://xml.nig.ac.jp/wabi/Method?serviceName=GetEntry&amp;mode=methodList&amp;lang=en><i>getEntry</i></a>  service at WABI. The workflow can be modified to invoke any other service from  <a href=http://xml.nig.ac.jp/index.html#services>xml.nig.ac.jp/index.html#services</a>  by modifying the  <i>service</i>  and  <i>method</i>  parameters to the beanshell script  <i>compose_URL</i> . Any other input parameters to  <i>compose_URL</i>  are added to the URL as well, so if instead you want to invoke the method  <i>analyzeParamAsync(query, param)</i>  from the  <a href=http://xml.nig.ac.jp/wabi/Method?serviceName=ClustalW&amp;mode=methodList&amp;lang=en>ClustalW</a>  service, first modify the  <i>service</i>  and  <i>method</i>  default parameters to  <i>ClustalW</i>  and  <i>analyzeParamAsync</i> , and then edit the beanshell script's input ports: Remove the  <i>accession</i>  port from  <i>compose_URL</i> , then add two new input ports called  <i>query</i>  and  <i>param</i> .  <i>(You don't need to modify the actual beanshell script as it picks up any declared input parameters.)</i> This pattern could probably be used for many REST services that work like xml.nig.ac.jp - but the disadvantage is that one has to manually read the  <a href=http://xml.nig.ac.jp/tutorial/rest/index.html>documentations</a>  to figure out what the parameters are to be.",2, 0, Get_web_page_from_URL, compose_URL, ,
"http://www.myexperiment.org/workflows/530/versions/1.html","Blast against ENSEMBLE Danio_rerio_Genome","2008-10-1508:43:51","2008-10-1509:21:35","http://www.myexperiment.org/workflows/530/download/Blast_against_ENSEMBLE_Danio_rerio_Genome-v1.xml?version=1","/users/622","Wassinki","taverna 1","/users/622,","Wassinki,","This workflow invokes the blast service provided at  <a href=http://www.bioinformatics.nl>www.bioinformatics.nl</a> , written by Pieter Neerincx. The workflow takes as input a database name (Danio_rerio_Genome for Zebra Fish for example) and a set of sequences in fasta format.  The blast service is invoked (using polling) and the result is a tab separated blast report. &nbsp; To run this workflow, a  <b>certificate </b> to access  <a href=http://www.bioinformatics.nl>www.bioinformatics.nl</a>  needs to installed (Some services use an SSL connection). Look at the link below how to install this certificate. <br /> <br /> <a href=http://www.myexperiment.org/files/148>http://www.myexperiment.org/files/148</a>",13, 1, Flatten_urls, DownloadURLWithBasicAuth, Parse_Moby_Data_URL, Program, MobyBlast_submit, DataBase, Email, String, User, BlastJob, Password, Poll_Job, FASTA, ,
"http://www.myexperiment.org/workflows/531/versions/1.html","BlatBlastCombi","2009-02-0308:20:43","2009-02-0308:28:06","http://www.myexperiment.org/workflows/531/download/BlatBlastCombi-v1.xml?version=1","/users/622","Wassinki","taverna 1","/users/622,","Wassinki,","This workflow combines the blat and blast workflows. It takes as input a database name (Danio_rerio_Genome for Zebra Fish for example) and and a set of Fasta sequences. It first tries to perform a blat (at  <a href=http://www.bioinformatics.nl>www.bioinformatics.nl</a> ). When this service returns nothing, a blast is done (also at  <a href=http://www.bioinformatics.nl>www.bioinformatics.nl</a> ). The resulting reports are combined. &nbsp; To run this workflow, a  <b>certificate </b> to access  <a href=http://www.bioinformatics.nl>www.bioinformatics.nl</a>  needs to installed (Some services use an SSL connection). Look at the link below how to install this certificate. <br /> <br /> <a href=http://www.myexperiment.org/files/148>http://www.myexperiment.org/files/148</a>",10, 0, Create_Sequence_Chunks, Flatten_list, Split_sequences, Merge_string_list_to_string, Chunk_Size, Merge_string_list_to_string1, Write_Text_File, Write_Text_File1, DoBioMart, BlatOrBlast, ,
"http://www.myexperiment.org/workflows/531/versions/2.html","BlatBlastCombi","2009-02-0308:20:43","2009-02-0308:28:06","http://www.myexperiment.org/workflows/531/download/BlatBlastCombi-v2.xml?version=2","/users/622","Wassinki","taverna 1","/users/622,","Wassinki,","This workflow combines the blat and blast workflows. It takes as input a database name (Danio_rerio_Genome for Zebra Fish for example) and and a set of Fasta sequences. It first tries to perform a blat (at  <a href=http://www.bioinformatics.nl>www.bioinformatics.nl</a> ). When this service returns nothing, a blast is done (also at  <a href=http://www.bioinformatics.nl>www.bioinformatics.nl</a> ). The resulting reports are combined. &nbsp; To run this workflow, a  <b>certificate </b> to access  <a href=http://www.bioinformatics.nl/>www.bioinformatics.nl</a>  needs to installed (Some services use an  <span class=caps>SSL</span>  connection). Look at the link below how to install this certificate. <br /> <br /> <a href=../../../files/148>http://www.myexperiment.org/files/148</a>",8, 0, Join_Blat_Blast_Results, isEmpty, Fail_if_true, EmptyList, Fail_if_false, Filter_Sequences_For_Blast, Blast, Blat, ,
"http://www.myexperiment.org/workflows/532/versions/1.html","Blat against ENSEMBLE Danio_rerio_Genome","2008-10-1509:25:43","2008-10-1509:27:23","http://www.myexperiment.org/workflows/532/download/Blat_against_ENSEMBLE_Danio_rerio_Genome-v1.xml?version=1","/users/622","Wassinki","taverna 1","/users/622,","Wassinki,","The blat workflow invokes the blat services provided at  <a href=http://www.bioinformatics.nl>www.bioinformatics.nl</a>  (author Pieter Neerincx).  As input, it takes a database name (for example, Danio_rerio_Genome for Zebra Fish) and one or more sequences in Fasta format. The output will be a tab separated output of the blat. An eValue string constant is added to filter on the e-Value.  Note, the e-Value is not exactly the same as the blast e-Value. To run this workflow, a  <b>certificate </b> to access  <a href=http://www.bioinformatics.nl/>www.bioinformatics.nl</a>  needs to installed (Some services use an  <span class=caps>SSL</span>  connection). Look at the link below how to install this certificate. &nbsp;",12, 1, Flatten_urls, Download_Report_and_Filter, eValue, Parse_Moby_Data_URL, MobyBlat, Email, BlatJob, DataBase, User, FASTA, String, Password, ,
"http://www.myexperiment.org/workflows/533/versions/1.html","Extract lists from a tab-delimited spreadsheet","2008-10-1715:49:50","2008-10-1821:20:52","http://www.myexperiment.org/workflows/533/download/Extract_lists_from_a_tab-delimited_spreadsheet-v1.xml?version=1","/users/37","Andrew Gibson","taverna 1","/users/37,","Andrew Gibson,","This workflow takes a spreadsheet exported as a tab delimited file, such as an Excel spreadsheet. The style is expected as a matrix of data with the first row containing the column names and the first column containing the row names (see below). The top left cell is discarded. The workflow outputs three lists. A list of column names, a list of row names, and a two deep list of data points. The first list is a list of the rows and the sublist is a list of values of the cells from the columns. &nbsp; &nbsp;",6, 0, SplitColumnNamesIntoList, SplitRows, MakeColumnNameList, SplitDataRows, SplitDataPoints, SplitRowNames, ,
"http://www.myexperiment.org/workflows/545/versions/1.html","Sample grid workflow","2008-10-2414:30:25","2008-10-3112:13:23","http://www.myexperiment.org/workflows/545/download/Sample_grid_workflow-v1.scufl?version=1","/users/648","Glatard","taverna 1","/users/648,","Glatard,","This is a sample workflow submitting jobs to the EGEE grid using the Generic Application Service Wrapper (GASW). The job submission service has to be installed locally.",3, 1, hello, empty, helloDescription, ,
"http://www.myexperiment.org/workflows/550/versions/3.html","Liliopsida Protein Alignment","2010-01-1318:42:35","2010-11-1713:46:04","http://www.myexperiment.org/workflows/550/download/Liliopsida_Protein_Alignment-v3.xml?version=3","/users/1369","Carol Lushbough","taverna 1","/users/1369,","Carol Lushbough,","<b> Download this Workflow and import into BioExtract Server at bioextract.org </b> This workflow retrieves Liliopsida chloroplast petb gene sequences from NCBI Nucleotide, removes duplicate sequences and saves the results at BioExtract Server. These results are then converted into GenBank format and fed into Fetch Translation, which removes the translation from the CDS coding region. Translations are then used to build a multiple alignment using ClustalW.",6, 4, query, Xmknr, saveset, FormatConversion, FetchTranslation, ClustalW, ,
"http://www.myexperiment.org/workflows/551/versions/1.html","Iterative loading of molecules from database with aromaticity detection","2008-11-0314:28:31","","http://www.myexperiment.org/workflows/551/download/Iterative_loading_of_molecules_from_database_with_aromaticity_detection-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow loads molecules from a database in an iterative manner using the SQL commands LIMIT and OFFSET.After the loading each molecule goes through an atom typing perception before the Hueckel Aromaticity Detector tries to detect the aromaticity. All id of the aromatic molecules will be written wo a text file.",
"http://www.myexperiment.org/workflows/552/versions/1.html","InsertMoleculesIntoDatabase","2008-11-0510:30:38","","http://www.myexperiment.org/workflows/552/download/InsertMoleculesIntoDatabase-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow load molecules into a database. The molecules originally are stored in a MDL SD file. As workflow input an origin is added to each molecule which gets stored into the database. The output of the workflow shows logs from the database insert process.",
"http://www.myexperiment.org/workflows/553/versions/1.html","Load Molecules from a database and create a PDF file showing the structures of the loaded molecules","2008-11-0516:15:58","","http://www.myexperiment.org/workflows/553/download/Load_Molecules_from_a_database_and_create_a_PDF_file_showing_the_structures_of_the_loaded_molecules-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow loads molecules from a database. The 2D structure of these molecules are shown within a table of a PDF document.",
"http://www.myexperiment.org/workflows/554/versions/1.html","Extraction of atom typing problems after loading of molecules from database","2008-11-0517:30:37","","http://www.myexperiment.org/workflows/554/download/Extraction_of_atom_typing_problems_after_loading_of_molecules_from_database-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow load molecules from the database and than checks whether the perception of the atom types works or not. After the extraction of the database identifier from all molecules which caused problems during this process will the identifier be written to a file.",
"http://www.myexperiment.org/workflows/555/versions/1.html","Substructure Search On Database","2008-11-0612:02:18","","http://www.myexperiment.org/workflows/555/download/Substructure_Search_On_Database-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow takes as input a SMILES. This represents the substructure, for which the database gets searched. The output of this workflow is a PDF showing the 2D structures of the matched structure from the substructure search on the database.",
"http://www.myexperiment.org/workflows/556/versions/1.html","Extract ChEBI molecules from TSV file and upload them into a database","2008-11-0616:11:54","","http://www.myexperiment.org/workflows/556/download/Extract_ChEBI_molecules_from_TSV_file_and_upload_them_into_a_database-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This worklfow load a TSV file from the ChEBI database. (normally structures.tsv) After the extraction of the molecules from the TSV file all non MDL mol files are removed before the valid molecules are inserted into a database.",
"http://www.myexperiment.org/workflows/557/versions/1.html","Topological Substructure Search Workflow","2008-11-0616:59:02","","http://www.myexperiment.org/workflows/557/download/Topological_Substructure_Search_Workflow-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow performs a topological substructure search. The molecules to be searched are loaded from a MDL SD file. The substructure is loaded from a SMILES (workflow input). The matched molecules are converted to CML and for the molecules which do not contain the substructure the InChI is generated.",
"http://www.myexperiment.org/workflows/558/versions/1.html","Analyse the Atom Typing Result","2008-11-0622:25:28","","http://www.myexperiment.org/workflows/558/download/Analyse_the_Atom_Typing_Result-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow is used to analyse the result of the atom typing workflow. It creates a pdf document contains a diagram to visualise the outcome from the atom typing test to detect the for the cdk unknown atom types.",
"http://www.myexperiment.org/workflows/559/versions/1.html","Molecular Weight Distribution","2008-11-0714:18:32","","http://www.myexperiment.org/workflows/559/download/Molecular_Weight_Distribution-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow calculates the molecular weight of molecules stored in a postgres sql database with the Pgchem::tigress chemoinformatics cardridge. The cardridge perform the molecular weight calculation. The get a moleculear weight distribution worker creates a chart of the available data.",
"http://www.myexperiment.org/workflows/560/versions/1.html","AppendToFile","2008-11-1115:11:38","2008-11-1115:14:43","http://www.myexperiment.org/workflows/560/download/AppendToFile-v1.xml?version=1","/users/622","Wassinki","taverna 1","/users/622,","Wassinki,","Processor to add content to a (existing)&nbsp; file. The content is added to the end of the file. It is similar to the following perl code: open STREAM, &quot;&gt;&gt;$Filename&quot;;  <br /> print STREAM $Content; <br /> print STREAM &quot;\n&quot;, if($NewLine); <br /> close STREAM; <br /> <br /> The inputs: <br /> Filename: the file name of a file, if the file does not exists, a new file is added <br /> Content: the string to append <br /> NewLine [default = true]: if true, a newline is added to the end of the line (useful if you want to add a record each time)",1, 0, AppendToFile, ,
"http://www.myexperiment.org/workflows/560/versions/2.html","AppendToFile","2008-11-1115:11:38","2008-11-1115:14:43","http://www.myexperiment.org/workflows/560/download/AppendToFile-v2.xml?version=2","/users/622","Wassinki","taverna 1","/users/622,","Wassinki,","Processor to add content to a (existing)&nbsp; file. The content is added to the end of the file. <br /> <br /> The inputs: <br /> Filename: the file name of a file, if the file does not exists, a new file is added <br /> Content: the string to append <br /> NewLine [default = true]: if true, a newline is added to the end of the line (useful if you want to add a record each time) &nbsp; The processor supports Multi-Threading since version 2.",1, 0, AppendToFile, ,
"http://www.myexperiment.org/workflows/561/versions/1.html","multi-gridsam-gopher","2009-03-0313:49:23","","","/users/1420","Soton sbs","taverna 1","/users/1420,","Soton sbs,","<b><u>G</u></b> eneration of  <b><u>O</u></b> rthologous  <b><u>P</u></b> roteins from  <b><u>H</u></b> igh-Throughput  <b><u>E</u></b> stimation of  <b><u>R</u></b> elationships This workflow uses GOPHER to take in two protein sequence files and generate datasets of orthologous sequence alignments. The first [seqin] sequence set is the 'queries' around which orthologous datasets are to be assembled. This is now optimised for a dataset consisting of one protein per protein-coding gene, although splice variants should be dealt with OK and treated as paralogues. <br /> <br /> The second [orthdb] is the list of proteins from which the orthologues will be extracted. The seqin sequences are then BLASTed against the orthdb and processed to retain putative orthologues using an estimation of the phylogenetic relationships based on pairwise sequences similarities. <br /> <br /> This version of the workflow utilises a GridSAM backend for parallelisation, currently this employs a PBS cluster in Southampton and thus access is restricted to members of the University. More info on GOPHER:  <a href=http://bioinformatics.ucd.ie/shields/software/gopher/index.html>http://bioinformatics.ucd.ie/shields/software/gopher/index.html</a> &nbsp; &nbsp;",
"http://www.myexperiment.org/workflows/561/versions/2.html","multi-gridsam-gopher","2009-03-0313:49:23","","","/users/1420","Soton sbs","taverna 1","/users/1420,","Soton sbs,",,
"http://www.myexperiment.org/workflows/562/versions/1.html","firstwf","2008-11-1320:45:08","","http://www.myexperiment.org/workflows/562/download/firstwf-v1.xml?version=1","/users/1355","Rory","taverna 1","/users/1355,","Rory,",,1, 0, Get_Protein_FASTA, ,
"http://www.myexperiment.org/workflows/563/versions/1.html","Calculation of molecular descriptors for molecules loaded from database","2008-11-1515:12:05","","http://www.myexperiment.org/workflows/563/download/Calculation_of_molecular_descriptors_for_molecules_loaded_from_database-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow loads iteratively molecules from a database. For each molecule the atom typse are perceived before the hydrogens are added and the aromaticity is detected. Than the QSAR worker calculates the selected descriptors. The result of this calculation is stored in database table.",
"http://www.myexperiment.org/workflows/564/versions/1.html","ART2A Classification Workflow","2008-11-1713:48:19","","http://www.myexperiment.org/workflows/564/download/ART2A_Classification_Workflow-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow loads a vector from a database and performs an ART2A classification. The ART2A classificator contains various options which are changeable within the stored workflow configuration file. There is no UI for these content available.",
"http://www.myexperiment.org/workflows/565/versions/1.html","Get ART2A classification result showing the different origins of the vectors","2008-11-1714:21:24","","http://www.myexperiment.org/workflows/565/download/Get_ART2A_classification_result_showing_the_different_origins_of_the_vectors-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow load an ART2A classifcation results and creates a diagram showing the origin allocation within the different cluster or classes. This is usable for performing a chemical diversity analysis. The result is stored within an PDF which contains a diagram and a table of the classification result.",
"http://www.myexperiment.org/workflows/566/versions/1.html","Reaction Enumeration Workflow","2008-11-2115:25:01","","http://www.myexperiment.org/workflows/566/download/Reaction_Enumeration_Workflow-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow performs a reaction enumeration. Therefore it loads a generic reaction rxn file and two educt lists. This SD-Files contains molecules for the enumeration. The products of the enumerated reaction are stored as Mol Files and a PDF will be created which contains the product molecules.",
"http://www.myexperiment.org/workflows/567/versions/1.html","Reaction Enumeration Workflow","2008-11-2216:55:34","","http://www.myexperiment.org/workflows/567/download/Reaction_Enumeration_Workflow-v1.xml?version=1","/users/1214","Thomasku","taverna 1","/users/1214,","Thomasku,","This workflow performs a reaction enumeration. Therefore it loads a generic reaction rxn file and two educt lists. This SD-Files contains molecules for the enumeration. The products of the enumerated reaction are stored as Mol Files and a PDF will be created which contains the product molecules.",
"http://www.myexperiment.org/workflows/581/versions/1.html","blastp using the MRS system","2008-11-2815:13:32","2008-11-2815:34:19","http://www.myexperiment.org/workflows/581/download/blastp_using_the_MRS_system-v1.xml?version=1","/users/586","Bas Vroling","taverna 1","/users/586,","Bas Vroling,","This blastp workflow uses the blast service of MRS ( <a href=http://mrs.cmbi.ru.nl>http://mrs.cmbi.ru.nl</a> ). Inputs are a sequence (only amino acids, not a fasta sequence) and a database name. Valid database names that can be used are &quot;sprot&quot;, &quot;uniprot&quot;, &quot;trembl&quot;, &quot;pdb&quot;, &quot;refseq&quot;, &quot;ipi&quot; and &quot;gpcrdb&quot;. Output is returned in XML.",7, 1, filterHits, castToXml, blastJobResultOut, blastResultParametersIn, BlastJobResult, mrs_blast, mrs_blast_status, ,
"http://www.myexperiment.org/workflows/592/versions/1.html","Basic eSearch/eFetch cycle","2008-12-0422:47:43","2008-12-0422:51:42","http://www.myexperiment.org/workflows/592/download/Basic_eSearch_eFetch_cycle-v1.xml?version=1","/users/45","Giovanni Dall&#39;Olio","taverna 1","/users/45,","Giovanni Dall&#39;Olio,","This is a basic eSearch/eFetch workflow created with taverna and using eUtils from  <span class=caps>NCBI</span> . It accepts a query term as input (at the moment, for testing purposes, this is a fixed string), interrogate eSearch to retrieve the list of related sequences on the Nucleotide database, and use eFetch to retrieve the corresponding sequences. I wrote this workflow one year ago, when I was trying to understand how taverna and eUtils work; I suspect it broken, and of course it could be enhanced, so I am putting it here and you are free to copy and modify it, and any suggestion is highly appreciated. I believe this is a good workflow to study if you want to understand how the eUtils and their mechanism of WebEnv and QueryKey work. I also putted it on my github repository:  <a href=http://github.com/dalloliogm/taverna_workflows/tree/master/eUtils>http://github.com/dalloliogm/taverna_workflows/tree/master/eUtils</a>",3, 0, sample_data, eSearch, eFetch, ,
"http://www.myexperiment.org/workflows/593/versions/1.html","Multi sequences NCBI BLAST","2008-12-0502:57:21","","http://www.myexperiment.org/workflows/593/download/Multi_sequences_NCBI_BLAST-v1.xml?version=1","/users/1343","Whybiocc","taverna 1","/users/1343,","Whybiocc,","Run a BLAST analysis using the EBI's WSNCBIBlast service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/ncbiblast>http://www.ebi.ac.uk/Tools/webservices/services/ncbiblast</a> ). This workflow wraps the EBI_NCBI_BLAST workflow to provide a basic user interface which prompts for the required inputs: sequence file, database, BLAST program and user e-mail. Other parameters (e.g. matrix, sort, gap penalties, etc.) are allowed to default.",6, 0, EBI_ncbiblast, Ask_for_email_address, Search_database_list, Select_database, Blast_program_list, Select_blast_program, ,
"http://www.myexperiment.org/workflows/598/versions/1.html","caDSR metadata query in caGrid","2008-12-0517:45:17","2008-12-0518:20:25","http://www.myexperiment.org/workflows/598/download/caDSR_metadata_query_in_caGrid-v1.xml?version=1","/users/1019","Wei Tan","taverna 1","/users/1019,","Wei Tan,","This workflow shows the coordinated use of two services in CaGrid, i.e., the caDSR (Cancer Data Standards Repository) and EVS (Enterprise Vocabulary Services) services. caDSR is to define a comprehensive set of standardized metadata descriptors for cancer research terminology used in information collection and analysis. EVS provides resources and services to meet NCI needs for controlled terminology, and to facilitate the standardization of terminology and information systems across the Institute and the larger biomedical community. This sample workflow is to find all the concepts related to a given context, for example, caCore. It is made up of four processors, several XML splitters between them, and a beanshell processor to do some XML transformation which can not be done by XML splitters (XML splitter cannot handle XML attributes). To accelerate the demo, we use two local java widgets, extract elements from a list, to filter out some intermediate results so that the workflow will complete quickly. This reduction does not influence the effect of the demo. 1. Use context information to invoke findProjects in caDSR, and get the project(s) information. 2. Use project information to invoke findClassesInProject in caDSR, to get the classes&rsquo; metadata. 3. Use project and classes metadata to invoke findSemanticMetadataForClass in caDSR, to get the semantic data for classes, including conceptName. 4. Use conceptName to invoke searchDescLogicConcept in EVS, to get detailed concept information.",
"http://www.myexperiment.org/workflows/599/versions/1.html","hierarchical microarray clustering","2008-12-0518:31:53","2008-12-0520:33:37","http://www.myexperiment.org/workflows/599/download/hierarchical_microarray_clustering-v1.xml?version=1","/users/1019","Wei Tan","taverna 1","/users/1019,","Wei Tan,","To illustrate our caGrid plug-in&rsquo;s application, we tested it with a microarray hierarchical clustering workflow that involves services hosted at multiple institutions.  <br /> Microarrays are a high-throughput technology used to measure the expression of tens of thousands of genes in different tissues or cells. Scientists represent the data from each microarray via a vector (profile) in which each element represents a gene&rsquo;s expression level. They use clustering analysis to identify similar expression profiles across genes or samples.10 In particular, hierarchical clustering is popular for grouping microarrays into a multilevel hierarchy in which, at each level, arrays in the same cluster are more similar to each other than those in different clusters. To cluster data, the user must identify and retrieve relevant microarrays, preprocess them, and then invoke the hierarchical clustering program. In the past, we might have programmed this sequence of steps using a scripting language such as Perl. Instead, we use Taverna and the caGrid plug-in to identify relevant services, compose those services with additional building blocks (for data transformation), and orchestrate their execution. Our workflow involves three major steps: <br /> 1.&nbsp;&nbsp;&nbsp; Identify and retrieve the microarray data of interest. We used CQL, the query language that caGrid Data Services uses, to specify this data and retrieve it from a caArray data service hosted at Columbia University. ( <a href=http://cagridnode.c2b2.columbia.edu:8080/wsrf/services/cagrid/CaArrayScrub>http://cagridnode.c2b2.columbia.edu:8080/wsrf/services/cagrid/CaArrayScrub</a> ) <br /> 2.&nbsp;&nbsp;&nbsp; &nbsp;Preprocess, or normalize, the microarray data before clustering them. We used a GenePattern analytical service ( <a href=http://node255.broad.mit.edu:6060/wsrf/services/cagrid/PreprocessDatasetMAGEService>http://node255.broad.mit.edu:6060/wsrf/services/cagrid/PreprocessDatasetMAGEService</a> ), which provides normalization, floor and ceiling thresholding, variation filtering, and other preprocessing functions. We used an instance of this service hosted at MIT&rsquo;s Broad Institute. <br /> 3.&nbsp;&nbsp;&nbsp; Run hierarchical clustering on the preprocessed data. We invoked the geWorkbench analytical service Columbia University hosts. ( <a href=http://cagridnode.c2b2.columbia.edu:8080/wsrf/services/cagrid/HierarchicalClusteringMage>http://cagridnode.c2b2.columbia.edu:8080/wsrf/services/cagrid/HierarchicalClusteringMage</a> ). <br /> <br /> The Taverna workflow contains an input processor to store the CQL expression, an output processor to store the clustered microarray data (both input and output processors are blue), three caGrid processors (green) representing the three caGrid services just listed, and a few &ldquo;shim&rdquo; processors, such as XML splitters and beanshell scripts, to deal with data transformation between services.",15, 3, Extract_elements_from_a_list, Merge_string_list_to_string, Beanshell_scripting_host, Beanshell_scripting_host1, parametersXML1, parametersXML, HierarchicalClusteringParameterXML1, PreprocessDatasetParameterSetXML1, preprocessDatasetParameterSetXML, hierarchicalClusteringParameterXML, parametersXML4, parametersXML3, execute, execute2, performAnalysis, ,
"http://www.myexperiment.org/workflows/600/versions/1.html","Using CQL to query protein sequence data","2008-12-0522:03:03","2009-07-1419:32:17","http://www.myexperiment.org/workflows/600/download/Using_CQL_to_query_protein_sequence_data-v1.xml?version=1","/users/1019","Wei Tan","taverna 1","/users/1019,","Wei Tan,","To query protein sequence infomation out of 3 caGrid data services: caBIO, CPAS and GridPIR. <b>Scientific value</b> <b>Steps</b> &nbsp;",12, 3, parametersXML, Beanshell_1, parametersXML1, cqlQueryXML1, parametersXML2, Beanshell_2, parametersXML3, cqlQueryXML, cqlQueryXML2, CPASQuery, GridPIRQuery, caBIOQuery, ,
"http://www.myexperiment.org/workflows/603/versions/1.html","Mapping OligoNucleotides to an assembly","2009-02-1309:05:35","2009-02-1309:08:20","http://www.myexperiment.org/workflows/603/download/Mapping_OligoNucleotides_to_an_assembly-v1.xml?version=1","/users/622","Wassinki","taverna 1","/users/622, /users/621,","Wassinki, Pieter Neerincx,","This workflow maps the input oligo set to an assembly. It first performs an alignment using the BioMoby Blat and Blast service provided by WUR ( <a href=http://www.bioinformatics.nl>www.bioinformatics.nl</a> ). Next, for each hit, tries to find the corresponding transcripts and genes using a biomart webservice. The final task is an analysis task using RShell. It calculates for each oligo to which class it belongs: 1 single hit <br /> 2-4 multiple hits single transcript* <br /> 5-7 mulitple hits multiple transcripts* <br /> 8 single hit, discarded** <br /> 9 multiple hits single transcript, discarded** <br /> 10 multiple transcripts, discarded**  <br /> 11 multi gene, discarded  <br /> 12 no transcript***  <br /> 13 no transcript, discarded* <br /> * classified on the criteria intron spanning only, possible intron spanning and no intron spanning. <br /> ** hit(s) do not meet high stringency threshold <br /> *** no transcript found but hit(s) meet high stringency threshold.",18, 0, BioMartReport_Filename, GeneratePlots, OligosNotFound_Filename, BlastReport_Filename, Chunk_Size, Read_BioMartReport, Read_BlastReport, Read_OligosNotFound, Touch_OligosNotFound_File, Create_Semaphore, Split_Blast_Report, Split_sequences, Create_Sequence_Chunks, Create_Header_BioMartReport, Create_Header_BlastReport, Filter_Sequences_For_Blast, DoBioMart, BlatOrBlast, ,
"http://www.myexperiment.org/workflows/603/versions/2.html","Mapping OligoNucleotides to an assembly","2009-02-1309:05:35","2009-02-1309:08:20","http://www.myexperiment.org/workflows/603/download/Mapping_OligoNucleotides_to_an_assembly-v2.xml?version=2","/users/622","Wassinki","taverna 1","/users/622, /users/621,","Wassinki, Pieter Neerincx,","This workflow maps the input oligo set to an assembly. It first performs an alignment using the BioMoby Blat and Blast service provided by  <span class=caps>WUR</span>  ( <a href=http://www.bioinformatics.nl/>www.bioinformatics.nl</a> ). Next, for each hit, tries to find the corresponding transcripts and genes using a biomart webservice. The final task is an analysis task using RShell. It calculates for each oligo to which class it belongs: 1 single hit <br /> 2-4 multiple hits single transcript <br /> 5-7 mulitple hits multiple transcripts <br /> 8 single hit, discarded <br /> 9 multiple hits single transcript, discarded <br /> 10 multiple transcripts, discarded*  <br /> 11 multi gene, discarded  <br /> 12 no transcript  <br /> 13 no transcript, discarded <br /> * classified on the criteria intron spanning only, possible intron spanning and no intron spanning. <br /> * hit(s) do not meet high stringency threshold <br /> * no transcript found but hit(s) meet high stringency threshold. To run this workflow, a  <b>certificate </b> to access  <a href=http://www.bioinformatics.nl/>www.bioinformatics.nl</a>  needs to installed (Some services use an  <span class=caps>SSL</span>  connection). Look at the link below how to install this certificate. <br /> <br /> <a href=../../../files/148>http://www.myexperiment.org/files/148</a> The myExperiment pack  <a href=http://www.myexperiment.org/packs/45>http://www.myexperiment.org/packs/45</a>  contains the workflow, the input and a test input. The whole input set is large. It takes about 6 hours on a 3 GHz Linux pc with 24 Gig RAM. The test input set can be run on almost any computer with Taverna and R installed. This set takes approximately 10 minutes.",18, 0, BioMartReport_Filename, GeneratePlots, OligosNotFound_Filename, BlastReport_Filename, Chunk_Size, Read_BioMartReport, Read_BlastReport, Read_OligosNotFound, Touch_OligosNotFound_File, Create_Semaphore, Split_Blast_Report, Split_sequences, Create_Sequence_Chunks, Create_Header_BioMartReport, Create_Header_BlastReport, Filter_Sequences_For_Blast, DoBioMart, BlatOrBlast, ,
"http://www.myexperiment.org/workflows/603/versions/3.html","Mapping OligoNucleotides to an assembly","2009-02-1309:05:35","2009-02-1309:08:20","http://www.myexperiment.org/workflows/603/download/Mapping_OligoNucleotides_to_an_assembly-v3.xml?version=3","/users/622","Wassinki","taverna 1","/users/622, /users/621,","Wassinki, Pieter Neerincx,",,18, 0, Chunk_Size, BlastReport_Filename, OligosNotFound_Filename, BioMartReport_Filename, GeneratePlots, Create_Header_BlastReport, Read_BioMartReport, Read_BlastReport, Read_OligosNotFound, Create_Header_BioMartReport, Split_sequences, Touch_OligosNotFound_File, Create_Sequence_Chunks, Filter_Sequences_For_Blast, Create_Semaphore, Split_Blast_Report, DoBioMart, BlatOrBlast, ,
"http://www.myexperiment.org/workflows/603/versions/4.html","Mapping OligoNucleotides to an assembly","2009-02-1309:05:35","2009-02-1309:08:20","http://www.myexperiment.org/workflows/603/download/Mapping_OligoNucleotides_to_an_assembly-v4.xml?version=4","/users/622","Wassinki","taverna 1","/users/622, /users/621,","Wassinki, Pieter Neerincx,","<b>Version info</b> The former version of the workflow expected that results from BioMART only report transcripts when the query (the probe in our <br /> case) are entirely encapsulated in an exon of that transcript. However, the BioMart service also returns transcripts when the query is not or only partially overlapping with an exon in the stretch on the assembly on which a transcript is defined. This resulted in too many oligos classified as having multiple transcripts or having multiple genes. <br /> <br /> <b>Workflow description</b> We used RShell in the design process of a Zebrafish microarray <br /> (supp. info Figure S1 and Figure S2). A microarray with 15k probes <br /> of 60-mer oligonucleotides was designed on gene sequences from <br /> Vega ( <a href=http://vega.sanger.ac.uk/Danio_rerio>http://vega.sanger.ac.uk/Danio_rerio</a> ) and Ensembl <br /> ( <a href=http://www.ensembl.org/Danio_rerio/>http://www.ensembl.org/Danio_rerio/</a> ) that are also known <br /> in the Zebrafish Information Network ( <a href=http://zfin.org>http://zfin.org</a> ) (for zebra <br /> fish, the VEGA set is not a subset of the Ensembl set) of the genome <br /> DNA-sequence assemblies and to judge the agreement that exists between <br /> the different assembly annotations, we mapped the Vega-designed probes <br /> onto the Ensembl assembly It first performs an alignment using the BioMoby Blat and Blast service provided by  <span class=caps><span class=caps>WUR</span></span>  ( <a href=http://www.bioinformatics.nl/>www.bioinformatics.nl</a> ). Next, for each hit, tries to find the corresponding transcripts and genes using a biomart webservice. The final task is an analysis task using RShell. It calculates for each oligo to which class it belongs: 0 no hit <br /> 1 single hit, single transcript, single gene <br /> 2 multiple hits, single transcript, single gene, intron spanning <br /> 3 multiple hits, single transcript, single gene, possible intron spanning <br /> 4 multiple hits, single transcript, single gene, no intron spanning <br /> 5 multiple hits, multiple transcripts, single gene, intron spanning <br /> 6 multiple hits, multiple transcripts, single gene, possible intron spanning <br /> 7 multiple hits, multiple transcripts, single gene, no intron spanning <br /> 8 single hit, does not meet additional criteria ** <br /> 9 multiple hits, single transcript, do not meet additional criteria ** <br /> 10 multiple hits, multiple transcripts, do not meet additional criteria ** <br /> 11 multiple hits, multiple genes <br /> 12 no transcript found but hit(s) meet additional criteria ** <br /> 13 no transcript found and hit(s) do not meet additional criteria ** <br /> 14 multiple hits, single transcript, single gene plus hit without transcript found and hits <br /> meet additional criteria ** <br /> * Oligo below e-value cut-off 1e-12, but also intron spanning criteria met. <br /> ** Additional criteria: either e-value below 1e-12 or intron spanning. To run this workflow, a  <b>certificate </b> to access  <a href=http://www.bioinformatics.nl/>www.bioinformatics.nl</a>  needs to installed (Some services use an  <span class=caps><span class=caps>SSL</span></span>  connection). Look at the link below how to install this certificate. <br /> <br /> <a href=../../../files/148>http://www.myexperiment.org/files/148</a> The myExperiment pack  <a href=../../../packs/45>http://www.myexperiment.org/packs/45</a>  contains the workflow, the input and a test input. The whole input set is large. It takes about 6 hours on a 3 GHz Linux pc with 24 Gig  <span class=caps>RAM</span> . The test input set can be run on almost any computer with Taverna and R installed. This set takes approximately 10 minutes. &nbsp;",20, 0, BioMartReport_Filename, BlastHitsFinished_Filename, OligosNotFound_Filename, BlastReport_Filename, Read_OligosNotFound, GeneratePlots, Chunk_Size, Read_BlastReport, Create_Header_BioMartReport, Create_Header_BlastReport, Split_Blast_Report, Create_Semaphore, Split_sequences, Create_Sequence_Chunks, Touch_OligosNotFound_File, Touch_BlastHitsFinished_File, Filter_Sequences_For_Blast, Read_BioMartReport, DoBioMart, BlatOrBlast, ,
"http://www.myexperiment.org/workflows/603/versions/5.html","Mapping OligoNucleotides to an assembly","2009-02-1309:05:35","2009-02-1309:08:20","http://www.myexperiment.org/workflows/603/download/Mapping_OligoNucleotides_to_an_assembly-v5.xml?version=5","/users/622","Wassinki","taverna 1","/users/622, /users/621,","Wassinki, Pieter Neerincx,","<b>Version info</b> The former version of the workflow expected that results from BioMART only report transcripts when the query (the probe in our <br /> case) are entirely encapsulated in an exon of that transcript. However, the BioMart service also returns transcripts when the query is not or only partially overlapping with an exon in the stretch on the assembly on which a transcript is defined. This resulted in too many oligos classified as having multiple transcripts or having multiple genes. <br /> <br /> <b>Workflow description</b> We used RShell in the design process of a Zebrafish microarray <br /> (supp. info Figure S1 and Figure S2). A microarray with 15k probes <br /> of 60-mer oligonucleotides was designed on gene sequences from <br /> Vega ( <a href=http://vega.sanger.ac.uk/Danio_rerio>http://vega.sanger.ac.uk/Danio_rerio</a> ) and Ensembl <br /> ( <a href=http://www.ensembl.org/Danio_rerio/>http://www.ensembl.org/Danio_rerio/</a> ) that are also known <br /> in the Zebrafish Information Network ( <a href=http://zfin.org>http://zfin.org</a> ) (for zebra <br /> fish, the VEGA set is not a subset of the Ensembl set) of the genome <br /> DNA-sequence assemblies and to judge the agreement that exists between <br /> the different assembly annotations, we mapped the Vega-designed probes <br /> onto the Ensembl assembly It first performs an alignment using the BioMoby Blat and Blast service provided by  <span class=caps><span class=caps>WUR</span></span>  ( <a href=http://www.bioinformatics.nl/>www.bioinformatics.nl</a> ). Next, for each hit, tries to find the corresponding transcripts and genes using a biomart webservice. The final task is an analysis task using RShell. It calculates for each oligo to which class it belongs: 0 no hit <br /> 1 single hit, single transcript, single gene <br /> 2 multiple hits, single transcript, single gene, intron spanning <br /> 3 multiple hits, single transcript, single gene, possible intron spanning <br /> 4 multiple hits, single transcript, single gene, no intron spanning <br /> 5 multiple hits, multiple transcripts, single gene, intron spanning <br /> 6 multiple hits, multiple transcripts, single gene, possible intron spanning <br /> 7 multiple hits, multiple transcripts, single gene, no intron spanning <br /> 8 single hit, does not meet additional criteria ** <br /> 9 multiple hits, single transcript, do not meet additional criteria ** <br /> 10 multiple hits, multiple transcripts, do not meet additional criteria ** <br /> 11 multiple hits, multiple genes <br /> 12 no transcript found but hit(s) meet additional criteria ** <br /> 13 no transcript found and hit(s) do not meet additional criteria ** <br /> 14 multiple hits, single transcript, single gene plus hit without transcript found and hits <br /> meet additional criteria ** <br /> * Oligo below e-value cut-off 1e-12, but also intron spanning criteria met. <br /> ** Additional criteria: either e-value below 1e-12 or intron spanning. To run this workflow, a  <b>certificate </b> to access  <a href=http://www.bioinformatics.nl/>www.bioinformatics.nl</a>  needs to installed (Some services use an  <span class=caps><span class=caps>SSL</span></span>  connection). Look at the link below how to install this certificate. <br /> <br /> <a href=../../../files/148>http://www.myexperiment.org/files/148</a> The myExperiment pack  <a href=../../../packs/45>http://www.myexperiment.org/packs/45</a>  contains the workflow, the input and a test input. The whole input set is large. It takes about 6 hours on a 3 GHz Linux pc with 24 Gig  <span class=caps>RAM</span> . The test input set can be run on almost any computer with Taverna and R installed. This set takes approximately 10 minutes. &nbsp;",20, 0, BlastHitsFinished_Filename, BioMartReport_Filename, OligosNotFound_Filename, BlastReport_Filename, GeneratePlots, Read_BlastReport, Create_Header_BlastReport, Create_Semaphore, Read_OligosNotFound, Chunk_Size, Create_Header_BioMartReport, Create_Sequence_Chunks, Touch_BlastHitsFinished_File, Split_Blast_Report, Read_BioMartReport, Touch_OligosNotFound_File, Filter_Sequences_For_Blast, Split_sequences, DoBioMart, BlatOrBlast, ,
"http://www.myexperiment.org/workflows/603/versions/6.html","Mapping OligoNucleotides to an assembly","2009-02-1309:05:35","2009-02-1309:08:20","http://www.myexperiment.org/workflows/603/download/Mapping_OligoNucleotides_to_an_assembly-v6.xml?version=6","/users/622","Wassinki","taverna 1","/users/622, /users/621,","Wassinki, Pieter Neerincx,","This workflows analyses workflows stored at the myExperiment site. It is used in the paper submitted to the Workshop on Scientific Workflow 2009. The workflow shows the task usage in the Taverna workflows stored at the myExperiment site <ul><li>The amount of services used</li><li>The amount of local processors used</li><li>The amount of scripting tasks</li></ul> * The amount of sub workflows",4, 0, Analyse_Workflows, Create_R_Table, Analyse_Single_Workflow, Generate_URLs, ,
"http://www.myexperiment.org/workflows/603/versions/7.html","Mapping OligoNucleotides to an assembly","2009-02-1309:05:35","2009-02-1309:08:20","http://www.myexperiment.org/workflows/603/download/Mapping_OligoNucleotides_to_an_assembly-v7.xml?version=7","/users/622","Wassinki","taverna 1","/users/622, /users/621,","Wassinki, Pieter Neerincx,","<b>Version info</b> The former version of the workflow expected that results from BioMART only report transcripts when the query (the probe in our <br /> case) are entirely encapsulated in an exon of that transcript. However, the BioMart service also returns transcripts when the query is not or only partially overlapping with an exon in the stretch on the assembly on which a transcript is defined. This resulted in too many oligos classified as having multiple transcripts or having multiple genes. <br /> <br /> <b>Workflow description</b> We used RShell in the design process of a Zebrafish microarray <br /> (supp. info Figure S1 and Figure S2). A microarray with 15k probes <br /> of 60-mer oligonucleotides was designed on gene sequences from <br /> Vega ( <a href=http://vega.sanger.ac.uk/Danio_rerio>http://vega.sanger.ac.uk/Danio_rerio</a> ) and Ensembl <br /> ( <a href=http://www.ensembl.org/Danio_rerio/>http://www.ensembl.org/Danio_rerio/</a> ) that are also known <br /> in the Zebrafish Information Network ( <a href=http://zfin.org/>http://zfin.org</a> ) (for zebra <br /> fish, the  <span class=caps>VEGA</span>  set is not a subset of the Ensembl set) of the genome <br /> <span class=caps>DNA</span> -sequence assemblies and to judge the agreement that exists between <br /> the different assembly annotations, we mapped the Vega-designed probes <br /> onto the Ensembl assembly It first performs an alignment using the BioMoby Blat and Blast service provided by  <span class=caps><span class=caps><span class=caps>WUR</span></span></span>  ( <a href=http://www.bioinformatics.nl/>www.bioinformatics.nl</a> ). Next, for each hit, tries to find the corresponding transcripts and genes using a biomart webservice. The final task is an analysis task using RShell. It calculates for each oligo to which class it belongs: 0 no hit <br /> 1 single hit, single transcript, single gene <br /> 2 multiple hits, single transcript, single gene, intron spanning <br /> 3 multiple hits, single transcript, single gene, possible intron spanning * <br /> 4 multiple hits, single transcript, single gene, no intron spanning <br /> 5 multiple hits, multiple transcripts, single gene, intron spanning <br /> 6 multiple hits, multiple transcripts, single gene, possible intron spanning * <br /> 7 multiple hits, multiple transcripts, single gene, no intron spanning <br /> 8 single hit, does not meet additional criteria  <strong>**<br /></strong>  9 multiple hits, single transcript, do not meet additional criteria ** <br /> 10 multiple hits, multiple transcripts, do not meet additional criteria  <strong>**<br /></strong> 11 multiple hits, multiple genes <br /> 12 no transcript found but hit(s) meet additional criteria ** <br /> 13 no transcript found and hit(s) do not meet additional criteria  <strong>**<br /></strong> 14 multiple hits, single transcript, single gene plus hit without transcript found and hits <br /> meet additional criteria ** <br /> * Oligo below e-value cut-off 1e-12, but also intron spanning criteria met. <br /> ** Additional criteria: either e-value below 1e-12 or intron spanning. To run this workflow, a  <b>certificate </b> to access  <a href=http://www.bioinformatics.nl/>www.bioinformatics.nl</a>  needs to installed (Some services use an  <span class=caps><span class=caps><span class=caps>SSL</span></span></span>  connection). Look at the link below how to install this certificate. <br /> <br /> <a href=../../../files/148>http://www.myexperiment.org/files/148</a> The myExperiment pack  <a href=../../../packs/45>http://www.myexperiment.org/packs/45</a>  contains the workflow, the input and a test input. The whole input set is large. It takes about 6 hours on a 3 GHz Linux pc with 24 Gig  <span class=caps><span class=caps>RAM</span></span> . The test input set can be run on almost any computer with Taverna and R installed. This set takes approximately 10 minutes.",20, 0, BlastHitsFinished_Filename, BioMartReport_Filename, OligosNotFound_Filename, BlastReport_Filename, GeneratePlots, Read_BlastReport, Create_Header_BlastReport, Create_Semaphore, Read_OligosNotFound, Chunk_Size, Create_Header_BioMartReport, Create_Sequence_Chunks, Touch_BlastHitsFinished_File, Split_Blast_Report, Read_BioMartReport, Touch_OligosNotFound_File, Filter_Sequences_For_Blast, Split_sequences, DoBioMart, BlatOrBlast, ,
"http://www.myexperiment.org/workflows/606/versions/1.html","BioMart_hsapiens_gene_ensembl_variation_Noom_Edit_09_12_2551","2008-12-1709:08:50","2008-12-2607:51:00","http://www.myexperiment.org/workflows/606/download/BioMart_hsapiens_gene_ensembl_variation_Noom_Edit_09_12_2551-v1.xml?version=1","/users/169","Kasikrit","taverna 1","/users/169,","Kasikrit,",,14, 0, REG_Split_by_C, REG_Merge_by_C, Flatten_Entrez_ID, Flatten_list, Split_EnsemblID, Remove_dup_ID, Flatten_Ensembl_report, Merge_EnsemblID, Nested_GO_Update, Nested_hsapiens_snp, Nested_EnsemblGeneInformation, Nested_Pathway, Nested_OMIM, Nested_Motif, ,
"http://www.myexperiment.org/workflows/610/versions/1.html","BioMart_hsapiens_gene_ensembl_variation_07_12_2551_GO_outofdate","2008-12-2607:52:41","2008-12-2607:53:11","http://www.myexperiment.org/workflows/610/download/BioMart_hsapiens_gene_ensembl_variation_07_12_2551_GO_outofdate-v1.xml?version=1","/users/169","Kasikrit","taverna 1","/users/169,","Kasikrit,",,15, 0, REG_Split_by_C, REG_Merge_by_C, Flatten_list, Flatten_Ensembl_report, Flatten_Entrez_ID, Flatten_GO_report, Remove_dup_ID, Split_EnsemblID, Merge_EnsemblID, Nested_GO, Nested_EnsemblGeneInformation, Nested_hsapiens_SNP, Nested_KEGG, Nested_OMIM, Nested_Motif, ,
"http://www.myexperiment.org/workflows/611/versions/1.html","Get Kegg Gene information","2009-01-2618:06:12","2009-12-1412:05:21","http://www.myexperiment.org/workflows/611/download/Get_Kegg_Gene_information-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow gets a series of information relating to a list of KEGG genes supplied to it. It also removes any null values from a list of strings.",10, 2, btit, get_pathways_by_genes, merge_descriptions, merge_pathways, split_by_regex, regex, remove_Nulls, remove_nulls_2, merge_pathways_2, Remove_duplicate_pathways, ,
"http://www.myexperiment.org/workflows/611/versions/2.html","Get Kegg Gene information","2009-01-2618:06:12","2009-12-1412:05:21","http://www.myexperiment.org/workflows/611/download/Get_Kegg_Gene_information-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow gets a series of information relating to a list of KEGG genes supplied to it. It also removes any null values from a list of strings. &nbsp; Example input for this workflow is given below (new line separated): mmu:13163 hsa:1616 <a href=http://www.genome.jp/dbget-bin/www_bget?mmu:13163 rel=nofollow><br /></a>",11, 3, btit, get_pathways_by_genes, regex, Remove_duplicate_pathways, merge_descriptions, merge_pathways, split_by_regex, merge_pathways_2, remove_nulls_2, remove_Nulls, btit1, ,
"http://www.myexperiment.org/workflows/612/versions/1.html","BioMart_hsapiens_gene_ensembl_variation_Noom_Edit_06_01_2552","2009-01-0604:00:51","2009-01-0604:01:53","http://www.myexperiment.org/workflows/612/download/BioMart_hsapiens_gene_ensembl_variation_Noom_Edit_06_01_2552-v1.xml?version=1","/users/169","Kasikrit","taverna 1","/users/169,","Kasikrit,",,15, 0, Flatten_Entrez_ID, REG_Merge_by_C, REG_Split_by_C, Flatten_list, Split_EnsemblID, Remove_dup_ID, Flatten_Ensembl_report, Merge_EnsemblID, Nested_GO_Update, Nested_hsapiens_snp, Nested_Motif, Nested_EnsemblGeneInformation, Nested_Pathway, Nested_OMIM, Nested_Entrez, ,
"http://www.myexperiment.org/workflows/630/versions/1.html","Text search within sparql point","2009-01-1916:37:53","","http://www.myexperiment.org/workflows/630/download/Text_search_within_sparql_point-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","This workflow make possible full text search within different sparql point made available by the Bio2RDF project.",-1, 0, ,
"http://www.myexperiment.org/workflows/631/versions/1.html","Run XMPP cloud services.","2009-04-2519:10:52","2010-03-2215:01:30","http://www.myexperiment.org/workflows/631/download/Run_XMPP_cloud_services.-v1.t2flow?version=1","/users/286","Egon Willighagen","taverna 2","/users/286,","Egon Willighagen,","Basic workflow indicating how a XMPP service can be called with XML input and output. Source code for the activity is available from:  <a href=http://github.com/egonw/xws-taverna/tree/master>github.com/egonw/xws-taverna/tree/master</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/631/versions/2.html","Run XMPP cloud services.","2009-04-2519:10:52","2010-03-2215:01:30","http://www.myexperiment.org/workflows/631/download/Run_XMPP_cloud_services.-v2.t2flow?version=2","/users/286","Egon Willighagen","taverna 2","/users/286,","Egon Willighagen,","Basic workflow indicating how a XMPP service can be called with XML input and output. Source code for the activity is available from:  <a href=http://github.com/egonw/xws-taverna/tree/master rel=nofollow>github.com/egonw/xws-taverna/tree/master</a>  That page explains you how to install the plugin you must install on top of Taverna 2.0. The workflow will not work otherwise.",-1, 0, ,
"http://www.myexperiment.org/workflows/634/versions/1.html","Author&#39;s collaborators according to pubmed","2009-01-2002:22:32","2009-01-2003:41:26","http://www.myexperiment.org/workflows/634/download/Author_s_collaborators_according_to_pubmed-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","<span style=font-family: Courier New;><span class=caps>SELECT</span> distinct ?s2<br /></span> <span style=font-family: Courier New;><strong>FROM &lt;</strong></span> <span style=font-family: Courier New;><a href=http://atlas.bio2rdf.org/sparql>http://atlas.bio2rdf.org/sparql</a></span> <span style=font-family: Courier New;><strong>&gt;<br /></strong></span> <span style=font-family: Courier New;><span class=caps>WHERE</span> {<br />&nbsp; ?s1 ?p1 ?o1 .<br />&nbsp; ?o1 bif:contains &quot;<span style=color: rgb(255, 0, 0);>author</span>&quot; .<br />&nbsp; ?s2 ?p2 ?s1 .</span> <span style=font-family: Courier New;><br />&nbsp; FILTER( regex(?s1, &quot;pubmed&quot;) )<br />}<br /><br />followed by</span> <span style=font-family: Courier New;><span class=caps>SELECT</span> ?creator, count(<strong>)<br />FROM &lt;</strong></span> <span style=font-family: Courier New;><a href=http://atlas.bio2rdf.org/sparql>http://localhost:8890/sparql</a></span> <span style=font-family: Courier New;><strong>&gt;<br /><span class=caps>WHERE</span> {<br />&nbsp; ?s1 ?p1 .<br />&nbsp; ?s1 ?p2 ?o2 .<br />&nbsp; <span class=caps>FILTER</span>( regex(?o2, &quot;<span style=color: rgb(255, 0, 0);>author</span>&quot;))<br />&nbsp; ?s1 ?creator .<br />}<br /><span class=caps>ORDER BY DESC</span>(count(</strong>))<br /><br /></span>",0, 0, ,
"http://www.myexperiment.org/workflows/635/versions/1.html","What is Paget&#39;s disease sparql query example","2009-01-2003:34:08","","http://www.myexperiment.org/workflows/635/download/What_is_Paget_s_disease_sparql_query_example-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","SELECT distinct ?s1 <br /> WHERE { <br /> &nbsp; ?s1 ?p1 ?o1 .  <br /> &nbsp; ?o1 bif:contains &quot;paget&quot; . <br /> } &nbsp; SELECT ?type1, count(*) <br /> FROM &lt;&gt; <br /> WHERE { <br /> &nbsp; ?s1 ?p1 ?o1 .  <br /> &nbsp; ?o1 bif:contains &quot;paget&quot; . <br /> &nbsp; ?s1 &lt; <a href=http://www.w3.org/1999/02/22-rdf-syntax-ns#type>http://www.w3.org/1999/02/22-rdf-syntax-ns#type</a> &gt; ?type1 . <br /> &nbsp; FILTER (regex(?type1, &quot; <a href=http://bio2rdf.org/>http://bio2rdf.org/</a> &quot;))  <br /> }",0, 0, ,
"http://www.myexperiment.org/workflows/635/versions/2.html","What is Paget&#39;s disease sparql query example","2009-01-2003:34:08","","http://www.myexperiment.org/workflows/635/download/What_is_Paget_s_disease_sparql_query_example-v2.t2flow?version=2","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","<span style=font-family: Courier New;>SELECT distinct ?s1<br /><span>FROM &lt;</span><span><a href=http://atlas.bio2rdf.org/sparql>http://atlas.bio2rdf.org/sparql</a></span><span>&gt;<br /></span><span>WHERE {<br />&nbsp; ?s1 ?p1 ?o1 . <br />&nbsp; ?o1 bif:contains &quot;paget&quot; .<br />&nbsp; FILTER( regex(?s1, &quot;omim&quot;) </span></span> <span style=font-family: Courier New;><span><br />&nbsp; OR regex(?s1, &quot;geneid&quot;) </span></span> <span style=font-family: Courier New;><span>OR regex(?s1, &quot;uniprot&quot;))<br />}<br /></span></span> &nbsp; <span style=font-family: Courier New;>followed by</span> <span style=font-family: Courier New;>SELECT ?type1, count(*)<br /></span> <span style=font-family: Courier New;>FROM &lt;</span> <span style=font-family: Courier New;><a href=http://localhost:8890/sparql>http://localhost:8890/sparql</a></span> <span style=font-family: Courier New;>&gt;<br /></span> <span style=font-family: Courier New;>WHERE {<br />&nbsp; ?s1 ?p1 ?o1 . <br />&nbsp; ?o1 bif:contains &quot;paget&quot; .<br />&nbsp; ?s1 </span> &nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/635/versions/3.html","What is Paget&#39;s disease sparql query example","2009-01-2003:34:08","","http://www.myexperiment.org/workflows/635/download/What_is_Paget_s_disease_sparql_query_example-v3.t2flow?version=3","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","<span style=font-family: Courier New;>SELECT distinct ?s1<br /><span>FROM &lt;</span><span><a href=http://atlas.bio2rdf.org/sparql>http://atlas.bio2rdf.org/sparql</a></span><span>&gt;<br /></span><span>WHERE {<br />&nbsp; ?s1 ?p1 ?o1 . <br />&nbsp; ?o1 bif:contains &quot;paget&quot; .<br />&nbsp; FILTER( regex(?s1, &quot;omim&quot;) </span></span> <span style=font-family: Courier New;><span><br />&nbsp; OR regex(?s1, &quot;geneid&quot;) </span></span> <span style=font-family: Courier New;><span>OR regex(?s1, &quot;uniprot&quot;))<br />}<br /></span></span> &nbsp; <span style=font-family: Courier New;>followed by</span> <span style=font-family: Courier New;>SELECT ?type1, count(*)<br /></span> <span style=font-family: Courier New;>FROM &lt;</span> <span style=font-family: Courier New;><a href=http://localhost:8890/sparql>http://localhost:8890/sparql</a></span> <span style=font-family: Courier New;>&gt;<br /></span> <span style=font-family: Courier New;>WHERE {<br />&nbsp; ?s1 ?p1 ?o1 . <br />&nbsp; ?o1 bif:contains &quot;paget&quot; .<br />&nbsp; ?s1 </span> &nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/639/versions/1.html","feat_workflow","2009-02-0315:30:15","","http://www.myexperiment.org/workflows/639/download/feat_workflow-v1.scufl?version=1","/users/648","Glatard","taverna 1","/users/648,","Glatard,","This workflow implements feat FSL individual analyses as performed in the experiment detailed in (Soleman et al, &quot;Large scale fMRI parameter study on a production grid&quot;, MICCAI-G'08). An example of inputs (in VBrowser XML dialect) can be found  <a href=http://www.myexperiment.org/files/173>here</a> . In this document, files are represented by their LFNs in vlemed's LFC. Processor &quot;feat&quot;: 1. generates the experiment input (design) file from the parameters 2. calls feat FSL. Processor &quot;convertString&quot; tweaks the output file names so that it fits the user's experiment organization. Below is detailed the meaning of the input parameters. &nbsp; * feat_description: contains a URL to the command-line descriptor used to generate grid jobs. The descriptor contains an LFN-link (in vlemed's LFC) to the executable to run. The executable is a bash script tweaking input files before calling FSL feat. * designFileTemplate: file containing constants for the analysis. Used as a template to fill in varying parameters. &nbsp; &nbsp; * feat_files_1: the fMRI 4D scan (EPI) in .nii.gz format. * PAR file: parameter file from the scanner, used to grab theTR &nbsp;* fmri_custom{1,2,3}: stimuli files associated to the fMRI experiment. &nbsp;* highres_file: the T1 scan of the patient in .nii.gz format. &nbsp; &nbsp; * fmri_regstandard_dof: degrees of freedom for EPI-to-std-brain registration * fmri_regstandard_dof: degrees of freedom for EPI-to-T1 registration * fmri_convolve_phase: HRF delay. Note that it's used 3 times in feat, once for each stimulus. Those 3 inputs are combined with a dot. * fmri_smooth: size of the smoothing kernel &nbsp;",4, 1, feat_description, empty, convertString, feat, ,
"http://www.myexperiment.org/workflows/639/versions/2.html","feat_workflow","2009-02-0315:30:15","","http://www.myexperiment.org/workflows/639/download/feat_workflow-v2.scufl?version=2","/users/648","Glatard","taverna 1","/users/648,","Glatard,",,3, 1, feat_description, empty, feat, ,
"http://www.myexperiment.org/workflows/640/versions/1.html","feat FSL group analysis","2009-01-2817:25:34","2009-01-2817:36:07","http://www.myexperiment.org/workflows/640/download/feat_FSL_group_analysis-v1.scufl?version=1","/users/648","Glatard","taverna 1","/users/648,","Glatard,","This workflow is to be run on results obtained from  <a href=http://www.myexperiment.org/workflows/639>this one</a>  (couldn't manage to find a clean solution for merging those two in Scufl). Processor &quot;feat_group&quot;: 1. builds the experiment intput (design) file from template and input parameters 2. calls feat FSL Processor &quot;roi&quot; reads activation maps produced by feat_group, extract a region of interest and compute the mean, stdev, max and min activation within it. <a href=http://www.myexperiment.org/files/174>Here</a>  is a sample input in VBrowser's XML dialect. Below is detailed the meaning of input parameters. &nbsp; &lt;h1&gt;Files to be swept on (thus iterated with a cross pdct)&lt;/h1&gt; * designFile_template: template for input design file. * region_of_interest: binary mask of the ROI in .nii.gz format &lt;h1&gt;Analysis-related files (to be combined with a dot)&lt;/h1&gt; * feat_files{1-11}: output of feat individual analysis for patient 1 to 11. Archive in tgz format. &nbsp; &nbsp; &nbsp;",6, 2, empty, feat_group_description, roi_stats_description, convertString, roi_stats, feat_group, ,
"http://www.myexperiment.org/workflows/642/versions/1.html","Download pathways for external references list (Taverna 2)","2009-02-0312:46:13","","http://www.myexperiment.org/workflows/642/download/Download_pathways_for_external_references_list__Taverna_2_-v1.t2flow?version=1","/users/1253","Thomask...","taverna 2","/users/1253,","Thomaskelder,","Takes a list of external references to genes/proteins/metabolites, finds all pathways on WikiPathways that contain one of the given genes/proteins/metabolites and downloads them in a given file format.",0, 0, ,
"http://www.myexperiment.org/workflows/642/versions/2.html","Download pathways for external references list (Taverna 2)","2009-02-0312:46:13","","http://www.myexperiment.org/workflows/642/download/Download_pathways_for_external_references_list__Taverna_2_-v2.t2flow?version=2","/users/1253","Thomask...","taverna 2","/users/1253,","Thomaskelder,","Takes a list of external references to genes/proteins/metabolites, finds all pathways on WikiPathways that contain one of the given genes/proteins/metabolites and downloads them in a given file format.",0, 0, ,
"http://www.myexperiment.org/workflows/643/versions/1.html","Rich Get Richer","2009-02-0502:42:42","","http://www.myexperiment.org/workflows/643/download/Rich_Get_Richer-v1.xml?version=1","/users/384","Andrea Wiggins","taverna 1","/users/384,","Andrea Wiggins,","This workflow is a replication of the analysis from an OSCon 2004 presentation by Megan Conklin, entitled Do the Rich Get Richer? to demonstrate scale-free distribution of FLOSS developers among projects. The workflow retrieves the current number of active developers (for the most recent calculation of said statistic) from the FLOSSmole database. It summarizes and plots the distribution of developers to projects, on both a straight and log-log scale. It also generates a flat list of the developer counts for visualization in other software.",7, 0, delist_dev_numbers, get_developer_data, flatten_dev_numbers, output_points, plot_distribution, log_plot, distribution_summary, ,
"http://www.myexperiment.org/workflows/644/versions/1.html","What is known about HIV using Bio2RDF&#39;s SPARQL endpoints ?","2009-02-0506:13:53","2009-02-0506:15:22","http://www.myexperiment.org/workflows/644/download/What_is_known_about_HIV_using_Bio2RDF_s_SPARQL_endpoints__-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","To answer this question Bio2RDF Atlas about mouse and human genome sparql endpoint available at  <a href=http://atlas.bio2rdf.org/sparql>http://atlas.bio2rdf.org/sparql</a>  is searched.&nbsp; The selected URIs are then loaded into your local Virtuoso triplestore at  <a href=http://localhost:8890/sparql>http://localhost:8890/sparql</a> . You must enable insert mode into the graph. <br /> <br /> Once the mashup is built, two SPARQL queries analyze the obtained graph.&nbsp; Finally you can submit queries to the RDF mashup about HIV as you like.&nbsp; Enjoy. <br /> <br /> This is the queries present in this workflow : <br /> <br /> <span style=font-family: Courier New;>CONSTRUCT {<br />&nbsp; ?s ?p ?o .<br />}<br />FROM &lt;geneid,uniprot,omim,pubmed,go&gt;<br />WHERE {<br />&nbsp; ?s ?p ?o . <br />&nbsp; ?o bif:contains &quot;hiv&quot; .<br />}</span> <br /> <br /> then <span style=font-family: Courier New;>SELECT * <br />WHERE {</span> <span style=font-family: Courier New;><br />&nbsp; ?s ?p ?o</span> <span style=font-family: Courier New;><br />}</span> <br /> <br /> then <br /> <br /> <span style=font-family: Courier New;>SELECT ?type, count(*) <br />WHERE {<br />&nbsp; ?s &lt;<a href=http://www.w3.org/1999/02/22-rdf-syntax-ns#type>http://www.w3.org/1999/02/22-rdf-syntax-ns#type</a>&gt; ?type .<br />}</span>",1, 0, ,
"http://www.myexperiment.org/workflows/644/versions/2.html","What is known about HIV using Bio2RDF&#39;s SPARQL endpoints ?","2009-02-0506:13:53","2009-02-0506:15:22","http://www.myexperiment.org/workflows/644/download/What_is_known_about_HIV_using_Bio2RDF_s_SPARQL_endpoints__-v2.t2flow?version=2","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","To answer this question Bio2RDF Atlas about mouse and human genome sparql endpoint available at  <a href=http://atlas.bio2rdf.org/sparql>http://atlas.bio2rdf.org/sparql</a>  is searched.&nbsp; The selected URIs are then loaded into your local Virtuoso triplestore at  <a href=http://localhost:8890/sparql>http://localhost:8890/sparql</a> . You must enable insert mode into the graph. <br /> <br /> Once the mashup is built, two SPARQL queries analyze the obtained graph.&nbsp; Finally you can submit queries to the RDF mashup about HIV as you like.&nbsp; Enjoy. <br /> <br /> This is the queries present in this workflow : <br /> <br /> <span style=font-family: Courier New;>CONSTRUCT {<br />&nbsp; ?s ?p ?o .<br />}<br />FROM &lt; geneid,uniprot,omim,pubmed,go &gt;<br />WHERE {<br />&nbsp; ?s ?p ?o . <br />&nbsp; ?o bif:contains &quot;hiv&quot; .<br />}<br /><br />then<br /><br />SELECT * WHERE {?s ?p ?o}<br /><br />then<br /><br />SELECT ?type, count(*) <br />WHERE {<br />?s &lt;rdf:type&gt; ?type .<br />}<br /></span>",1, 0, ,
"http://www.myexperiment.org/workflows/647/versions/1.html","Pubmed mashup demo in a Virtuoso triplestore","2009-02-1106:26:27","","http://www.myexperiment.org/workflows/647/download/Pubmed_mashup_demo_in_a_Virtuoso_triplestore-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","This workflow build a mashup in your local virtuoso server (available at  <a href=http://localhost:8890/sparql>http://localhost:8890/sparql</a> ) by downloading the needed pubmed documents from NCBI and by converting them into N3 format.&nbsp; Once all documents loaded into the triplestore you can query them with SPARQL. For example try those queries : <span style=font-family: Courier New;>SELECT count(*) WHERE {?s ?p ?o}</span> <span style=font-family: Courier New;>SELECT ?o, count(*) <br />WHERE {?s &lt;<a href=http://www.w3.org/1999/02/22-rdf-syntax-ns#type>http://www.w3.org/1999/02/22-rdf-syntax-ns#type</a>&gt; ?o}</span> Dr Labrie's MeSH subject of interest : <span style=font-family: Courier New;>SELECT ?o, count(*) <br />WHERE {?s &lt;<a href=http://bio2rdf.org/ns/bio2drf#xMeSH>http://bio2rdf.org/ns/bio2drf#xMeSH</a>&gt; ?o}<br />ORDER BY DESC(count(*))</span> and is main collaborators : <span style=font-family: Courier New;>SELECT ?o2, count(*) <br />WHERE {<br />&nbsp; ?s &lt;<a href=http://purl.org/dc/elements/1.1/creator>http://purl.org/dc/elements/1.1/creator</a>&gt; ?o1 .&nbsp; <br />&nbsp; FILTER (regex(?o1, &quot;Labrie,F&quot;)) .<br />&nbsp; ?s &lt;<a href=http://purl.org/dc/elements/1.1/creator>http://purl.org/dc/elements/1.1/creator</a>&gt; ?o2 .<br />}<br />ORDER BY DESC(count(*))<br />LIMIT 30</span> Some questions that cannot be asked at Entrez ;-) PS For the Pubmed rdfiser to work you will need to download the Pubmed rdfiser :  <a href=http://www.myexperiment.org/files/178>http://www.myexperiment.org/files/178</a> &nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/648/versions/1.html","Analysing workflows","2009-05-0608:49:59","2009-05-0608:50:29","http://www.myexperiment.org/workflows/648/download/Analysing_workflows-v1.xml?version=1","/users/622","Wassinki","taverna 1","/users/622, /users/621, /users/13, /users/18,","Wassinki, Pieter Neerincx, Katy Wolstencroft, Marco Roos,","This workflow analyses workflows stored at the myExperiment site. It is used in the paper submitted to the Workshop on Scientific Workflow 2009.&nbsp;  The workflow uses the RShell processor to classify the tasks used in the workflows. The workflow shows the workflow sizes and the task usage of the Taverna workflows stored at the myExperiment site. It classifies these tasks among the following categories: Furthermore it classifies the local services based on their intended function. The workflow has two inputs: firstID and lastID. These id's are the id's used in myExperiment to identify the workflows. For example, this workflow has id 648. One has to enter the firstID and the lastID to specify the workflows to be analysed. In the case of the submitted paper, firstID=0, lastID=600. Workflows that do not exists or are not stored as scufl files will automatically be skipped. One can determine the last workflow available at the &quot;latest workflow&quot; section at the myExperiment site. The URL to&nbsp; the workflow &quot;betrays&quot; the id ;).",4, 0, Analyse_Workflows, Create_R_Table, Analyse_Single_Workflow, Generate_URLs, ,
"http://www.myexperiment.org/workflows/648/versions/2.html","Analysing workflows","2009-05-0608:49:59","2009-05-0608:50:29","http://www.myexperiment.org/workflows/648/download/Analysing_workflows-v2.xml?version=2","/users/622","Wassinki","taverna 1","/users/622, /users/621, /users/13, /users/18,","Wassinki, Pieter Neerincx, Katy Wolstencroft, Marco Roos,","This workflows analyses workflows stored at the myExperiment site. It is used in the paper submitted to the Workshop on Scientific Workflow 2009.  The workflow shows the task usage in the Taverna workflows stored at the myExperiment site Furthermore it classifies the local services based on their intended function. <br /> <br /> The workflow has two inputs: firstID and lastID. These id's are the id's used in myExperiment to identify the workflows. For example, this workflow has id 648. One has to enter the firstID and the lastID to specify the workflows to be analysed. In the case of the submitted paper, firstID=0, lastID=600. Workflows that do not exists or are not stored as scufl files will automatically be skipped. One can determine the last workflow available at the &quot;latest workflow&quot; section at the myExperiment site. The URL to&nbsp; the workflow &quot;betrays&quot; the id ;).",2, 0, Generate_IDs, Generate_URL, ,
"http://www.myexperiment.org/workflows/648/versions/3.html","Analysing workflows","2009-05-0608:49:59","2009-05-0608:50:29","http://www.myexperiment.org/workflows/648/download/Analysing_workflows-v3.xml?version=3","/users/622","Wassinki","taverna 1","/users/622, /users/621, /users/13, /users/18,","Wassinki, Pieter Neerincx, Katy Wolstencroft, Marco Roos,","This workflows analyses workflows stored at the myExperiment site. It is used in the paper submitted to the Workshop on Scientific Workflow 2009. The workflow shows the task usage in the Taverna workflows stored at the myExperiment site Furthermore it classifies the local services based on their intended function. <br /> <br /> The workflow has two inputs: firstID and lastID. These id's are the id's used in myExperiment to identify the workflows. For example, this workflow has id 648. One has to enter the firstID and the lastID to specify the workflows to be analysed. In the case of the submitted paper, firstID=0, lastID=600. Workflows that do not exists or are not stored as scufl files will automatically be skipped. One can determine the last workflow available at the &quot;latest workflow&quot; section at the myExperiment site. The URL to&nbsp; the workflow &quot;betrays&quot; the id ;).",4, 0, Create_R_Table, Generate_URLs, Analyse_Workflows, Analyse_Single_Workflow, ,
"http://www.myexperiment.org/workflows/650/versions/1.html","Initialize triplestore with Murin&#39;s protocol ontology","2009-02-1704:40:17","2009-02-1704:42:28","http://www.myexperiment.org/workflows/650/download/Initialize_triplestore_with_Murin_s_protocol_ontology-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","This workflow initialize the Sesame triplestore with initial data.&nbsp; The 5 rdfiser in JSP are needed, they are executed on localhost.",-1, 0, ,
"http://www.myexperiment.org/workflows/651/versions/1.html","Load affymetrix experiments results into Sesame triplestore for a specific tissue","2009-02-1704:54:30","","http://www.myexperiment.org/workflows/651/download/Load_affymetrix_experiments_results_into_Sesame_triplestore_for_a_specific_tissue-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","The affymetrix data source is not public.",-1, 0, ,
"http://www.myexperiment.org/workflows/652/versions/1.html","Sesame triplestore loader from a dereferenced URI","2009-02-1905:02:34","2009-02-1905:03:08","http://www.myexperiment.org/workflows/652/download/Sesame_triplestore_loader_from_a_dereferenced_URI-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","Load triples obtained from an URL in N3 or XML format and load them into your local Sesame Triplestore locally installed and available at  <a href=http://localhost/sesame.&lt;/p>http://localhost/sesame.</a> The  <a href=http://localhost/sesame/servlets/uploadURL>http://localhost/sesame/servlets/uploadURL</a>  service of Sesame is used in HTTP POST mode.",-1, 0, ,
"http://www.myexperiment.org/workflows/652/versions/2.html","Sesame triplestore loader from a dereferenced URI","2009-02-1905:02:34","2009-02-1905:03:08","http://www.myexperiment.org/workflows/652/download/Sesame_triplestore_loader_from_a_dereferenced_URI-v2.t2flow?version=2","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","Load triples obtained from an URL in N3 or XML format and load them into your local Sesame Triplestore locally installed and available at  <a href=http://localhost/sesame.&lt;/p>http://localhost/sesame.</a> The  <a href=http://localhost/sesame/servlets/uploadURL>http://localhost/sesame/servlets/uploadURL</a>  service of Sesame is used in HTTP POST mode.",0, 0, ,
"http://www.myexperiment.org/workflows/653/versions/1.html","Bio2RDF: Sesame triplestore loader from triples","2009-02-1907:00:03","2009-02-1907:25:39","http://www.myexperiment.org/workflows/653/download/Bio2RDF__Sesame_triplestore_loader_from_triples-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,",,0, 0, ,
"http://www.myexperiment.org/workflows/653/versions/2.html","Bio2RDF: Sesame triplestore loader from triples","2009-02-1907:00:03","2009-02-1907:25:39","http://www.myexperiment.org/workflows/653/download/Bio2RDF__Sesame_triplestore_loader_from_triples-v2.t2flow?version=2","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","INSERT IN GRAPH",0, 0, ,
"http://www.myexperiment.org/workflows/654/versions/1.html","Bio2rdf: Bind search, rdfise and load demo","2009-02-1905:07:30","2009-02-1905:39:51","http://www.myexperiment.org/workflows/654/download/Bio2rdf__Bind_search__rdfise_and_load_demo-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","INSERT IN GRAPH &lt; <a href=http://localhost/sesame/mem_rdf_db>http://localhost/sesame/mem_rdf_db</a> &gt; { <br /> &nbsp;&nbsp; &nbsp;CONSTRUCT { ?s, ?p, ?o . } <br /> &nbsp;&nbsp; &nbsp;FROM &lt; <a href=http://soap.bind.ca/wsdl/bind.wsdl>http://soap.bind.ca/wsdl/bind.wsdl</a> &gt; <br /> &nbsp;&nbsp; &nbsp;WHERE {  <br /> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;SELECT ?s <br /> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;FROM &lt; <a href=http://soap.bind.ca/wsdl/bind.wsdl>http://soap.bind.ca/wsdl/bind.wsdl</a> &gt; <br /> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;WHERE { <br /> &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;?s, ?p, ?o . <br /> &nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;FILTER ( regex(?o, &quot;query&quot;)) . <br /> &nbsp;&nbsp; &nbsp;} <br /> &nbsp;&nbsp; &nbsp;, ?p, ?o . } <br /> }",2, 0, ,
"http://www.myexperiment.org/workflows/655/versions/1.html","Bio2RDF: Rdfiser for Bind protein interaction.","2009-02-1905:10:23","2009-02-1905:24:29","http://www.myexperiment.org/workflows/655/download/Bio2RDF__Rdfiser_for_Bind_protein_interaction.-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","CONSTRUCT{ &lt;bmuri&gt;, ?p, ?o . } <br /> FROM &lt; <a href=http://soap.bind.ca/wsdl/bind.wsdl>http://soap.bind.ca/wsdl/bind.wsdl</a> &gt; <br /> WHERE { &lt;bmuri&gt;, ?p, ?o . }",1, 0, ,
"http://www.myexperiment.org/workflows/656/versions/1.html","Bio2RDF: Bind fulltext search service returning bmuris.","2009-02-1905:18:44","2009-02-1905:26:17","http://www.myexperiment.org/workflows/656/download/Bio2RDF__Bind_fulltext_search_service_returning_bmuris.-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","SELECT ?s <br /> FROM &lt; <a href=http://soap.bind.ca/wsdl/bind.wsdl>http://soap.bind.ca/wsdl/bind.wsdl</a> &gt; <br /> WHERE { <br /> &nbsp; ?s, ?p, ?o . <br /> &nbsp; FILTER ( regex(?o, &quot;query&quot;)) . <br /> }",3, 0, ,
"http://www.myexperiment.org/workflows/657/versions/1.html","Bio2RDF: CPath search, rdfise and load demo (step 1)","2009-02-1907:06:58","2009-02-1907:08:28","http://www.myexperiment.org/workflows/657/download/Bio2RDF__CPath_search__rdfise_and_load_demo__step_1_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","Search for a list of genes into the Pathway Commons interaction database and load the fetched triples into a triplestore. <br /> <br /> INSERT IN GRAPH &lt;  <a href=http://localhost/sesame/mem_rdf_db>http://localhost/sesame/mem_rdf_db</a> &gt; { <br /> &nbsp;&nbsp; &nbsp;CONSTRUCT{ ?s, ?p, ?o . } <br /> &nbsp;&nbsp; &nbsp;FROM &lt;  <a href=http://www.pathwaycommons.org/pc/webservice.do>http://www.pathwaycommons.org/pc/webservice.do</a> &gt; <br /> &nbsp;&nbsp; &nbsp;WHERE { <br /> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; SELECT ?s <br /> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; FROM &lt; <a href=http://www.pathwaycommons.org/pc/webservice.do>http://www.pathwaycommons.org/pc/webservice.do</a> &gt; <br /> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; WHERE { <br /> &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; ?s, ?p, ?o . <br /> &nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; FILTER ( regex(?o, &quot;QUERY&quot;)) . <br /> &nbsp;&nbsp; &nbsp;} <br /> &nbsp;&nbsp; &nbsp;, ?p, ?o . } <br /> }",5, 0, ,
"http://www.myexperiment.org/workflows/658/versions/1.html","Bio2RDF: CPath search, rdfise and load demo (step 2)","2009-02-1907:14:23","","http://www.myexperiment.org/workflows/658/download/Bio2RDF__CPath_search__rdfise_and_load_demo__step_2_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,",,4, 0, ,
"http://www.myexperiment.org/workflows/659/versions/1.html","Bio2RDF: CPath describe interaction","2009-02-1907:16:24","","http://www.myexperiment.org/workflows/659/download/Bio2RDF__CPath_describe_interaction-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,",,0, 0, ,
"http://www.myexperiment.org/workflows/660/versions/1.html","Bio2RDF: CPath reverse links","2009-02-1907:18:17","","http://www.myexperiment.org/workflows/660/download/Bio2RDF__CPath_reverse_links-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,",,1, 0, ,
"http://www.myexperiment.org/workflows/661/versions/1.html","Bio2RDF: CPath search in taxon","2009-02-1907:20:36","","http://www.myexperiment.org/workflows/661/download/Bio2RDF__CPath_search_in_taxon-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,",,1, 0, ,
"http://www.myexperiment.org/workflows/664/versions/1.html","CDK Example","2009-02-2616:31:21","","http://www.myexperiment.org/workflows/664/download/CDK_Example-v1.xml?version=1","/users/47","Paul Dobson","taverna 1","/users/47,","Paul Dobson,","This workflow reads a library from an SD file (change the default value of Read_MDL_SD_File) and identifies those structures that conform to Lipinski's Rule of Five. It then performs a substructure query, represented as SMILES (change the default value on Parse_SMILES), on the structures that pass Lipinski, and creates PNG images of those structures that contain the substructure. The image results will be found in your Taverna Data folder.",
"http://www.myexperiment.org/workflows/688/versions/1.html","omim and pathways","2009-03-0313:17:27","2009-11-0210:13:38","http://www.myexperiment.org/workflows/688/download/omim_and_pathways-v1.xml?version=1","/users/13","Katy Wolstencroft","taverna 1","/users/13, /users/43,","Katy Wolstencroft, Paul Fisher,","This workflow searches OMIM for entries associated with MArfan syndrome, returns the IDs and maps them to Kegg Gene IDs. For each gene, it then gets the description and any corresponding pathways those genes are involved with",8, 2, Filter_KeggGenes, Concatenate_two_strings, Filter_list_of_strings_extracting_match_to_a_regex, Split_string_into_string_list_by_regular_expression, Remove_duplicate_strings, bconv, KeggGenestoPathways, OMIM, ,
"http://www.myexperiment.org/workflows/688/versions/2.html","omim and pathways","2009-03-0313:17:27","2009-11-0210:13:38","http://www.myexperiment.org/workflows/688/download/omim_and_pathways-v2.xml?version=2","/users/13","Katy Wolstencroft","taverna 1","/users/13, /users/43,","Katy Wolstencroft, Paul Fisher,","This workflow searches OMIM for entries associated with a particular disease in OMIM, returns the IDs and maps them to Kegg Gene IDs. For each gene, it then gets the description and any corresponding pathways those genes are involved with",8, 2, Remove_duplicate_strings, Filter_KeggGenes, Filter_list_of_strings_extracting_match_to_a_regex, Split_string_into_string_list_by_regular_expression, Concatenate_two_strings, bconv, KeggGenestoPathways, OMIM, ,
"http://www.myexperiment.org/workflows/695/versions/1.html","Get Concepts","2009-02-2716:33:39","","http://www.myexperiment.org/workflows/695/download/Get_Concepts-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow gets all the concepts in an Ondex graph, using a given graph id",3, 1, getConcepts, parametersXML, parametersXML1, ,
"http://www.myexperiment.org/workflows/701/versions/1.html","Get CVs","2009-02-2716:38:39","","http://www.myexperiment.org/workflows/701/download/Get_CVs-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow lets users retrive all controlled vocabularies for a given Ondex graph",3, 1, getCVs, parametersXML, parametersXML1, ,
"http://www.myexperiment.org/workflows/703/versions/1.html","Get Evidence Types","2009-02-2716:40:22","","http://www.myexperiment.org/workflows/703/download/Get_Evidence_Types-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow gets all the evidence types within a specified Ondex graph",3, 1, getEvidenceTypes, parametersXML, parametersXML1, ,
"http://www.myexperiment.org/workflows/705/versions/1.html","Get graphs","2009-11-0512:38:22","","http://www.myexperiment.org/workflows/705/download/Get_graphs-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","Thiw workflow simply returns all the Ondex graphs that are present on a given server (where the web service is)",2, 1, getGraphs, parametersXML, ,
"http://www.myexperiment.org/workflows/705/versions/2.html","Get graphs","2009-11-0512:38:22","","http://www.myexperiment.org/workflows/705/download/Get_graphs-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","Thiw workflow simply returns all the Ondex graphs that are present on a given server (where the web service is)",5, 1, getGraphs, parametersXML, combine_name_id, graphsXML, merge_graph_name_ids, ,
"http://www.myexperiment.org/workflows/706/versions/1.html","Get Graphs of Name","2009-02-2716:42:35","","http://www.myexperiment.org/workflows/706/download/Get_Graphs_of_Name-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow gets the Ondex graphs relating to a specified name",3, 1, getGraphsOfName, parametersXML, parametersXML1, ,
"http://www.myexperiment.org/workflows/710/versions/1.html","Get relations","2009-02-2716:45:39","","http://www.myexperiment.org/workflows/710/download/Get_relations-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow gets all the realtions from a given Ondex graph",3, 1, getRelations, parametersXML, parametersXML1, ,
"http://www.myexperiment.org/workflows/726/versions/1.html","Pathways and Gene annotations for Arabidopsis affy data","2009-03-0617:18:13","2009-12-0316:59:11","","/users/43","Paul Fisher","taverna 1","/users/43, /users/221,","Paul Fisher, Peter Li,","This workflow searches for genes obtained from affymetrix probeset identifiers.  The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",
"http://www.myexperiment.org/workflows/726/versions/2.html","Pathways and Gene annotations for Arabidopsis affy data","2009-03-0617:18:13","2009-12-0316:59:11","","/users/43","Paul Fisher","taverna 1","/users/43, /users/221,","Paul Fisher, Peter Li,","This workflow searches for genes obtained from affy_ath1 affymetrix probeset identifiers.  The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",
"http://www.myexperiment.org/workflows/727/versions/1.html","Fetch PDB flatfile from RCSB server","2009-03-0816:23:17","","http://www.myexperiment.org/workflows/727/download/Fetch_PDB_flatfile_from_RCSB_server-v1.xml?version=1","/users/1775","Pvilaca","taverna 1","/users/1775,","Pvilaca,","Given an identifier such as '1crn' fetches the PDB format flatfile from the RCSB",5, 0, RCSBSuffix, RCSBPrefix, FetchPage, AddSuffix, AddPrefixToID, ,
"http://www.myexperiment.org/workflows/728/versions/1.html","Biomart Protein Sequence Retrieval","2009-03-0911:38:10","","http://www.myexperiment.org/workflows/728/download/Biomart_Protein_Sequence_Retrieval-v1.xml?version=1","/users/227","Kieren Lythgow","taverna 1","/users/227,","Kieren Lythgow,","This workflow queries Biomart to retrieve the Ensembl gene id, protein id, gene name, description and amino acid sequence from the Ensembl Homo sapiens dataset. The user needs to specify a defined chromosomal region i.e. Chromo = 1, Start = 100000000, End = 250000000. This returns all unique entries in FASTA format.",1, 0, hsapiens_gene_ensembl, ,
"http://www.myexperiment.org/workflows/730/versions/1.html","Kegg_DrugID","2009-03-1814:49:02","2009-03-1814:51:28","http://www.myexperiment.org/workflows/730/download/Kegg_DrugID-v1.xml?version=1","/users/1355","Rory","taverna 1","/users/1355,","Rory,","&nbsp;This workflow accepts&nbsp;looks up&nbsp;drug identifiers from KEGG given a pathway identifier. You can enter a&nbsp;pathway ID in the form&nbsp;path:map07026",1, 1, get_drugs_by_pathway, ,
"http://www.myexperiment.org/workflows/732/versions/1.html","fetch_fasta","2009-03-2011:22:45","2009-03-2011:29:16","http://www.myexperiment.org/workflows/732/download/fetch_fasta-v1.xml?version=1","/users/1807","Jumblej...","taverna 1","/users/1807,","Jumblejumble,","This work flow is designed to take an EMBL file containing the genomic data for an identified bacterium.  From this information the workflow can determine whether or not that this strain is an MRSA type of bug.  This can be determined based on the MecA profile of the given strain. <br /> <br /> Blast is utilised to find a relationship with given proteins and that of know S. aureus strains.  This phylogenic output is generated from a ClustalW algorithm that plots a phylogenic tree. <br /> <br /> The output is presented in a pdf format detailing this strain. Details include: putative identification, presence of MecA and phylogenic tree and ID of it and its neighbour strains. <br /> <br /> This workflow is useful as it can easily be adapted to other projects with only minor modification to its processes. <br /> &nbsp;",18, 3, Get_Nucleotide_FASTA, Write_Text_File, run_blastall, Read_FASTA, splitIDs, local_create_blastdb, ClustalW, Merge_FASTA, create_blastall_cmd_args, create_formatdb_cmdArgs, parametersXML2, Neighbours, getNeighbours, addSequenceToFasta, getSequences, isMRSA, EBI_TCoffee, draw_tree, ,
"http://www.myexperiment.org/workflows/733/versions/1.html","Identify_strain_and_phylogenetic_tree","2009-03-2015:20:36","2009-03-2015:22:25","http://www.myexperiment.org/workflows/733/download/Identify_strain_and_phylogenetic_tree-v1.xml?version=1","/users/1796","Aailyso","taverna 1","/users/1796, /users/925,","Aailyso, Hamish McWilliam,",,10, 2, Tree_View, Write_Text_File, mecASearch, strainRecognizer, Get_Protein_FASTA, run_Clustalw, Get_Embl_File, Fetch_Seq, Blast_localDB, WUBlast_Protein, ,
"http://www.myexperiment.org/workflows/737/versions/1.html","Download Entries from PubChem","2009-03-3009:20:42","2009-03-3009:34:37","http://www.myexperiment.org/workflows/737/download/Download_Entries_from_PubChem-v1.xml?version=1","/users/937","Michael Gerlich","taverna 1","/users/937,","Michael Gerlich,","Given a list of identifiers (e.g. CID) and their appropriate type (eID_CID - note that these differ slightly from the original identifier name -&gt; CID &lt;-&gt; eID_CID), this workflow queries PubChem via PUG to retrieve a download URL for the resulting XML file containing the results. Adding support for downloading this XML file and writing it to filesystem is planned.",12, 3, Compression, Format, Download_out, GetDownloadUrl_in, InputListText_in, GetDownloadUrl_out, InputListText_out, Download_in, GetDownloadUrl, InputListText, Download, Status_Check, ,
"http://www.myexperiment.org/workflows/738/versions/1.html","Retrieve Pathways and Compound information from KEGG","2009-03-3009:22:36","2009-03-3009:39:23","http://www.myexperiment.org/workflows/738/download/Retrieve_Pathways_and_Compound_information_from_KEGG-v1.xml?version=1","/users/937","Michael Gerlich","taverna 1","/users/937,","Michael Gerlich,","Given a KEGG compound identifier (e.g. cpd:C00905), this workflow queries KEGG DB for pathways and compound information for each of these compounds. As the KEGG pathway service tries to find pathways which contain all input compounds, the input list is split up to circumvent this behaviour and to search for only one compound in a pathway at a time. Compounds identified in pathways are marked as red in the resulting pathway image.",9, 3, bget, get_pathways_by_compounds, Convert_list_of_KeggIDs_into_1element_list_of_lists, Flatten_list, Flatten_list1, Remove_duplicate_strings, Split_string_into_string_list_by_regular_expression, mark_pathway_by_objects, Get_image_from_URL, ,
"http://www.myexperiment.org/workflows/739/versions/1.html","Search InChI in ChemSpider","2009-03-3009:24:33","2009-03-3009:43:07","http://www.myexperiment.org/workflows/739/download/Search_InChI_in_ChemSpider-v1.xml?version=1","/users/937","Michael Gerlich","taverna 1","/users/937,","Michael Gerlich,","This workflows queries ChemSpider for compound information and compound images. Note that a Chemspider security token is needed in order to access some of the ChemSpider services (receive one by registering at ChemSpider). Possible search terms might be InChI codes, ChemSpider identifiers or names.",8, 3, SimpleSearch, SimpleSearch_in, SimpleSearch_out, GetCompoundThumbnail, GetExtendedCompoundInfoArray, GetInfoArray_in, GetCompoundThumbnail_in, GetCompoundThumbnail_out, ,
"http://www.myexperiment.org/workflows/740/versions/1.html","Search InChI in NCBI eSearch (pccompound)","2009-03-3009:26:25","2009-03-3009:47:00","http://www.myexperiment.org/workflows/740/download/Search_InChI_in_NCBI_eSearch__pccompound_-v1.xml?version=1","/users/937","Michael Gerlich","taverna 1","/users/937,","Michael Gerlich,","This workflow takes in a search term (e.g. InChI) for search in PubChem pccompound database. The result is an xml file containing summary information about the search term and also a compound image and the compound webpage fetched from Pubchem.",8, 2, NCBI_eSearch, fetch_compound_info, fetch_compound_image, Beanshell_scripting_host, parametersXML, run_eSummary, requestXML, NCBI_database, ,
"http://www.myexperiment.org/workflows/741/versions/1.html","MassBank to KEGG","2009-03-3009:30:32","2009-03-3009:49:13","","/users/937","Michael Gerlich","taverna 1","/users/937,","Michael Gerlich,","Workflow that queries MassBank DB to retrieve database identifiers (KEGG, PubChem, InChI) and continue search with them  to retrieve pathways from KEGG for given compound identifier,searches PubChem via eutils and PUG,  queries ChemSpider for compound information and image. Note:  Usage of ChemSpider web services requires a valid security token - receive one by registering at ChemSpider (look at your profile to see your token)",
"http://www.myexperiment.org/workflows/746/versions/1.html","Lymphoma type prediction based on microarray data","2010-05-1119:04:30","2010-05-1119:04:32","http://www.myexperiment.org/workflows/746/download/_Lymphoma_type_prediction_based_on_microarray_data_-v1.t2flow?version=1","/users/1019","Wei Tan","taverna 2","/users/1019, /users/298, /users/5,","Wei Tan, Ravi, Stian Soiland-Reyes,","<span style=color: rgb(255, 0, 0);><span style=font-size: large;>Scientific value</span></span> <span style=color: rgb(255, 0, 0);><span style=font-size: large;>Steps</span></span>",0, 0, ,
"http://www.myexperiment.org/workflows/746/versions/2.html","Lymphoma type prediction based on microarray data","2010-05-1119:04:30","2010-05-1119:04:32","http://www.myexperiment.org/workflows/746/download/_Lymphoma_type_prediction_based_on_microarray_data_-v2.t2flow?version=2","/users/1019","Wei Tan","taverna 2","/users/1019, /users/298, /users/5,","Wei Tan, Ravi, Stian Soiland-Reyes,","<span style=color: rgb(255, 0, 0);><span style=font-size: large;>Scientific value</span></span> <span style=color: rgb(255, 0, 0);><span style=font-size: large;>Steps</span></span>",-1, 0, ,
"http://www.myexperiment.org/workflows/746/versions/3.html","Lymphoma type prediction based on microarray data","2010-05-1119:04:30","2010-05-1119:04:32","http://www.myexperiment.org/workflows/746/download/_Lymphoma_type_prediction_based_on_microarray_data_-v3.t2flow?version=3","/users/1019","Wei Tan","taverna 2","/users/1019, /users/298, /users/5,","Wei Tan, Ravi, Stian Soiland-Reyes,","<span style=color: rgb(255, 0, 0);><span style=font-size: large;>Scientific value</span></span> <span style=color: rgb(255, 0, 0);><span style=font-size: large;>Steps</span></span>",0, 0, ,
"http://www.myexperiment.org/workflows/746/versions/4.html","Lymphoma type prediction based on microarray data","2010-05-1119:04:30","2010-05-1119:04:32","http://www.myexperiment.org/workflows/746/download/_Lymphoma_type_prediction_based_on_microarray_data_-v4.t2flow?version=4","/users/1019","Wei Tan","taverna 2","/users/1019, /users/298, /users/5,","Wei Tan, Ravi, Stian Soiland-Reyes,","<span style=color: rgb(255, 0, 0);><span style=font-size: large;>Scientific value</span></span> <span style=color: rgb(255, 0, 0);><span style=font-size: large;>Steps</span></span>",0, 0, ,
"http://www.myexperiment.org/workflows/746/versions/5.html","Lymphoma type prediction based on microarray data","2010-05-1119:04:30","2010-05-1119:04:32","http://www.myexperiment.org/workflows/746/download/_Lymphoma_type_prediction_based_on_microarray_data_-v5.t2flow?version=5","/users/1019","Wei Tan","taverna 2","/users/1019, /users/298, /users/5,","Wei Tan, Ravi, Stian Soiland-Reyes,","Scientific value Using gene-expression patterns associated with DLBCL and FL to predict the lymphoma type of an unknown sample. Using SVM (Support Vector Machine) to classify data, and predicting the tumor types of unknown examples. Steps Querying training data from experiments stored in caArray. Preprocessing, or normalize the microarray data. Adding training and testing data into SVM service to get classification result.",0, 0, ,
"http://www.myexperiment.org/workflows/746/versions/6.html","Lymphoma type prediction based on microarray data","2010-05-1119:04:30","2010-05-1119:04:32","http://www.myexperiment.org/workflows/746/download/_Lymphoma_type_prediction_based_on_microarray_data_-v6.t2flow?version=6","/users/1019","Wei Tan","taverna 2","/users/1019, /users/298, /users/5,","Wei Tan, Ravi, Stian Soiland-Reyes,","Scientific value Using gene-expression patterns associated with DLBCL and FL to predict the lymphoma type of an unknown sample. Using SVM (Support Vector Machine) to classify data, and predicting the tumor types of unknown examples. Steps Querying training data from experiments stored in caArray. Preprocessing, or normalize the microarray data. Adding training and testing data into SVM service to get classification result.",0, 0, ,
"http://www.myexperiment.org/workflows/746/versions/7.html","Lymphoma type prediction based on microarray data","2010-05-1119:04:30","2010-05-1119:04:32","http://www.myexperiment.org/workflows/746/download/_Lymphoma_type_prediction_based_on_microarray_data_-v7.t2flow?version=7","/users/1019","Wei Tan","taverna 2","/users/1019, /users/298, /users/5,","Wei Tan, Ravi, Stian Soiland-Reyes,","Scientific value Using gene-expression patterns associated with DLBCL and FL to predict the lymphoma type of an unknown sample. Using SVM (Support Vector Machine) to classify data, and predicting the tumor types of unknown examples. Steps Querying training data from experiments stored in caArray. Preprocessing, or normalize the microarray data. Adding training and testing data into SVM service to get classification result.",0, 0, ,
"http://www.myexperiment.org/workflows/747/versions/1.html","Get the list of GeneID for all pathways of a specified taxon","2009-04-2807:48:40","","http://www.myexperiment.org/workflows/747/download/Get_the_list_of_GeneID_for_all_pathways_of_a_specified_taxon-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,",,1, 0, ,
"http://www.myexperiment.org/workflows/748/versions/1.html","Insert in local triplestore GeneID and KEGG pathway","2009-04-2807:55:10","","http://www.myexperiment.org/workflows/748/download/Insert_in_local_triplestore_GeneID_and_KEGG_pathway-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,",,0, 0, ,
"http://www.myexperiment.org/workflows/749/versions/1.html","DOI Record Generator","2009-04-2916:39:57","","http://www.myexperiment.org/workflows/749/download/DOI_Record_Generator-v1.xml?version=1","/users/384","Andrea Wiggins","taverna 1","/users/384,","Andrea Wiggins,","This workflow generates DOI record files for deposit, using data set metadata for the FLOSSmole project. It reads in an input file generated from a SQL query from an eprints database, and transforms the parts of the source file as necessary to create a comprehensive DOI deposit record. It also generates DOIs for the data sets. These metadata are inserted into an XML record template (based on the std-doi.xsd schema) and the individual resources are aggregated into a single file.",18, 0, file_location, split_rows, split_numbers_to_list, split_more, read_input, split_formatted_filesize, split_filesize_further, make_number_sequence, parse_url_for_source, aggregate_doi_records, build_URL_from_eprintid, split_fields, generate_doi, generate_description, format_filesize, generate_xml_record, construct_date, format_months, ,
"http://www.myexperiment.org/workflows/750/versions/1.html","Taverna rendering of the PAN-STARRS workflow for Provenance Challenge 3","2009-04-3016:32:17","","http://www.myexperiment.org/workflows/750/download/Taverna_rendering_of_the_PAN-STARRS_workflow_for_Provenance_Challenge_3-v1.t2flow?version=1","/users/500","Paolo","taverna 2","/users/500,","Paolo,","Example inputs: CSVRootPath = /Users/paolo/Documents/myGRID/OPM/PC3/SampleData/J062941 JobID:J062941 &nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/751/versions/1.html","Load GO terms in the triplestore","2009-05-0114:36:50","","http://www.myexperiment.org/workflows/751/download/Load_GO_terms_in_the_triplestore-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,",,1, 0, ,
"http://www.myexperiment.org/workflows/752/versions/1.html","Using CQL to query protein sequence data","2009-05-0714:28:59","","http://www.myexperiment.org/workflows/752/download/Using_CQL_to_query_protein_sequence_data-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","To query protein sequence infomation out of 3 caGrid data services: caBIO, CPAS and GridPIR <br /> <br /> Adapted from  <a href=http://www.myexperiment.org/workflows/600>http://www.myexperiment.org/workflows/600</a>",1, 0, ,
"http://www.myexperiment.org/workflows/754/versions/1.html","Updated Biomart and Emboss workflow","2009-05-1211:27:13","","http://www.myexperiment.org/workflows/754/download/Updated_Biomart_and_Emboss_workflow-v1.t2flow?version=1","/users/345","George","taverna 2","/users/345,","George,",,0, 0, ,
"http://www.myexperiment.org/workflows/754/versions/2.html","Updated Biomart and Emboss workflow","2009-05-1211:27:13","","http://www.myexperiment.org/workflows/754/download/Updated_Biomart_and_Emboss_workflow-v2.t2flow?version=2","/users/345","George","taverna 2","/users/345,","George,",,0, 0, ,
"http://www.myexperiment.org/workflows/755/versions/1.html","simpleBLAST workflow","2009-05-1315:57:01","","http://www.myexperiment.org/workflows/755/download/simpleBLAST_workflow-v1.t2flow?version=1","/users/1950","Shahid","taverna 2","/users/1950,","Shahid,","my first taverna workflow",-1, 0, ,
"http://www.myexperiment.org/workflows/755/versions/2.html","simpleBLAST workflow","2009-05-1315:57:01","","http://www.myexperiment.org/workflows/755/download/simpleBLAST_workflow-v2.t2flow?version=2","/users/1950","Shahid","taverna 2","/users/1950,","Shahid,","my first taverna workflow",-1, 0, ,
"http://www.myexperiment.org/workflows/757/versions/1.html","snpNeighbours","2009-05-1421:03:25","2009-05-1421:11:54","http://www.myexperiment.org/workflows/757/download/snpNeighbours-v1.xml?version=1","/users/12","Pierre Lindenbaum","taverna 1","/users/12,","Pierre Lindenbaum,","My first Taverna workflow:&nbsp; the input is the SNP &quot;rs25&quot;. The Web Services invoked finds its position on the human genome and find its neighbours at 100bp. The XML result is then saved to a local file. The web services used here are under developpement and might be turned off in a near future.",11, 2, getSNPByName, rs25, transformInput, extractRS, SnpDescriptorListXML, getSNPByPosition, input, ExtendRange, Extension, Write_Text_File, FileNameOut, ,
"http://www.myexperiment.org/workflows/760/versions/1.html","GetReactions","2009-05-1913:19:52","2009-05-1913:21:30","","/users/6","Duncan Hull","taverna 1","/users/6,","Duncan Hull,","This workflow takes an arbitrary SBML model from the BioModels database and returns a list of reactions contained in that model.",
"http://www.myexperiment.org/workflows/761/versions/1.html","DataBiNS with Kegg ID","2009-07-0921:39:54","2010-11-2223:16:42","http://www.myexperiment.org/workflows/761/download/DataBiNS_with_Kegg_ID-v1.t2flow?version=1","/users/358","Mark Wilkinson","taverna 2","/users/358, /users/275,","Mark Wilkinson, Fong Chun Chan,","DataBiNS was originally a custom-designed BioMoby Web Service workflow that gathered non-synonymous coding single nucleotide polymorphisms (nsSNPs) data with structure/function and pathway data for relevant proteins. While the usage of the automated workflow, rather than manual internet surfing, significantly reduced the effort required to retrieve the information, analyzing the data for co-relations between specific outputs was difficult. Further work on DataBiNS has produced a web-based tool that aims to solve the problems of visualizing the retrieved data. DataBiNS can now be accessed through a website which takes an unique identifier input, from numerous sources such as KEGG, Pubmed, and OMIM, and then initializes the DataBiNS workflow in the background. The workflow retrieves scientific data and knowledge from disparate web-based sources, relating to non-synonymous coding single nucleotide polymorphisms (nsSNPs) and then displays it in a format that makes studying the results easier than before.&nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/761/versions/2.html","DataBiNS with Kegg ID","2009-07-0921:39:54","2010-11-2223:16:42","http://www.myexperiment.org/workflows/761/download/DataBiNS_with_Kegg_ID-v2.t2flow?version=2","/users/358","Mark Wilkinson","taverna 2","/users/358, /users/275,","Mark Wilkinson, Fong Chun Chan,","DataBiNS was originally a custom-designed BioMoby Web Service workflow that gathered non-synonymous coding single nucleotide polymorphisms (nsSNPs) data with structure/function and pathway data for relevant proteins. While the usage of the automated workflow, rather than manual internet surfing, significantly reduced the effort required to retrieve the information, analyzing the data for co-relations between specific outputs was difficult. Further work on DataBiNS has produced a web-based tool that aims to solve the problems of visualizing the retrieved data. DataBiNS can now be accessed through a website which takes an unique identifier input, from numerous sources such as KEGG, Pubmed, and OMIM, and then initializes the DataBiNS workflow in the background. The workflow retrieves scientific data and knowledge from disparate web-based sources, relating to non-synonymous coding single nucleotide polymorphisms (nsSNPs) and then displays it in a format that makes studying the results easier than before.&nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/761/versions/3.html","DataBiNS with Kegg ID","2009-07-0921:39:54","2010-11-2223:16:42","http://www.myexperiment.org/workflows/761/download/DataBiNS_with_Kegg_ID-v3.t2flow?version=3","/users/358","Mark Wilkinson","taverna 2","/users/358, /users/275,","Mark Wilkinson, Fong Chun Chan,","Consumes a KEGG gene id and mines for pathway, GO, PubMed and SNP information about that gene <hr />",0, 0, ,
"http://www.myexperiment.org/workflows/763/versions/1.html","Validating_Workflow_BioMart_v5_5","2009-05-2206:45:42","","http://www.myexperiment.org/workflows/763/download/Validating_Workflow_BioMart_v5_5-v1.xml?version=1","/users/169","Kasikrit","taverna 1","/users/169,","Kasikrit,",,12, 0, XPath_Processor, Flattenlist_Filtered_Processor, FlattenList_DatasetName, Merge_Attribute_result_list, XPath_Extract_Processor, XPath_extract_DatasetName, Merge_Filter_result_list, XPath_Filter_Processor, DatasetName_XPath_Exp, XPath_Filter_Nested_Processor, Check_Filter, Check_Attribute, ,
"http://www.myexperiment.org/workflows/764/versions/1.html","inchi to Chebi","2009-05-2216:07:50","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow converts an inchi string to a chebi id.",
"http://www.myexperiment.org/workflows/765/versions/1.html","caviar cardiac application","2009-05-2317:49:08","2009-05-2317:52:04","http://www.myexperiment.org/workflows/765/download/caviar_cardiac_application-v1.scufl?version=1","/users/648","Glatard","taverna 1","/users/648,","Glatard,","Applications details in the following paper: <br /> Ketan Maheshwari, Tristan Glatard, Joel Schaerer, Bertrand Delhay, Sorina Camarasu, Patrick Clarysse, Johan Montagnat.   <i>&quot;Towards Production-level Cardiac Image Analysis with Grids&quot;</i>   in Proceedings of the HealthGrid'09,  Berlin, 28-30 june 2009 The 3 green boxes are run on the  <a href=http://www.eu-egee.org/>EGEE</a>  grid. Addional Beanshells have been added to transfer results from EGEE Storage Elements to a web server, to allow for better interactivity.",8, 3, config, mhd2qc_description, init_desc, mhd2qc, det3D4, cannyAndDistanceMapAndInitModel, putOnWebServer, putOnWebServer1, ,
"http://www.myexperiment.org/workflows/767/versions/1.html","Retrieve sequence in EMBL format","2009-05-2516:27:54","","http://www.myexperiment.org/workflows/767/download/Retrieve_sequence_in_EMBL_format-v1.xml?version=1","/users/1960","Tilsith","taverna 1","/users/1960,","Tilsith,","This workflow retrieves a sequence associated with its features in embl format",4, 1, sequence_id, sequence_feature, sequence_format, seqret, ,
"http://www.myexperiment.org/workflows/772/versions/1.html","Index MyExperiment Workflow","2009-05-2618:16:31","2009-05-2707:09:58","http://www.myexperiment.org/workflows/772/download/Index_MyExperiment_Workflow-v1.xml?version=1","/users/231","Edgar","taverna 1","/users/231,","Edgar,","This workflow will create an index of the descriptions of all the workflows stored in MyExperiment.",20, 1, extract_workflow_URIs, indexconfig, sandbox_myexperiment_org, Extract_Workflows, merge_title_description, append_extension, Write_Text_File, Get_all_workflows, Get_workflow, getTargetURL, create_all_worksflows_location, save_extract_workflow_XSLT, make_XSLTlocation, Select_temp_location, Split_string_into_string_list_by_regular_expression, save_workflow, add_prefix, extractDescription, extractTitle, addToIndexWithConfig, ,
"http://www.myexperiment.org/workflows/772/versions/2.html","Index MyExperiment Workflow","2009-05-2618:16:31","2009-05-2707:09:58","http://www.myexperiment.org/workflows/772/download/Index_MyExperiment_Workflow-v2.xml?version=2","/users/231","Edgar","taverna 1","/users/231,","Edgar,","This workflow uses AIDA components to index all of the workflows on MyExperiment. First, it lists and downloads each workflow's xml file. Then, the titles and descriptions are parsed and submitted to an Indexer webservice. After it's finished, your index will be searchable by visiting  <a href=http://aida.science.uva.nl:9999/search.&lt;/p>http://aida.science.uva.nl:9999/search.</a>",6, 0, Select_temp_location, pages, page_iterator, create_url, Ask_index_name, Nested_Workflow, ,
"http://www.myexperiment.org/workflows/773/versions/1.html","Test SoapLab Service Availability","2009-05-2910:13:45","2009-05-2910:14:47","http://www.myexperiment.org/workflows/773/download/Test_SoapLab_Service_Availability-v1.xml?version=1","/users/622","Wassinki","taverna 1","/users/622,","Wassinki,","This workflow tests for all Taverna workflows stored at myExperiment wether theS oapLab services used still exists. For each SOAP/WSDL service it checks wether the SoapLab service can still be accessed.  The output is among others a report of",20, 0, LastID, Merge_LogRecords, Flatten_NotExistingURL, Merge_ExistingURLs, Flatten_list, Merge_URLs, Flatten_ExsitingURL, Flatten_LogRecords, FirstID, Merge_NotExistingURLs, CreateRTable, Get_Analysed_URLs, generateIDs, generateURL, CountSoapLabServices, CreateWorkflowLog, FilterAndCount, CountUniqueSoapLabServices, Analyse_Single_Workflow, Analyse_Location, ,
"http://www.myexperiment.org/workflows/774/versions/1.html","Test SOAP/WSDL Service Availability","2009-05-2910:15:41","","http://www.myexperiment.org/workflows/774/download/Test_SOAP_WSDL_Service_Availability-v1.xml?version=1","/users/622","Wassinki","taverna 1","/users/622,","Wassinki,","This workflow tests for all Taverna workflows stored at myExperiment wether the SOAP/WSDL services used still exists. For each SOAP/WSDL service it checks wether the WSDL file is still accessible and whether the operation is still exists. The output is among others a report of <ul><li>accessible services and operation,</li><li>operations which WSDL file is not accessible,</li><li>operations which WSDL file still exists, but the operation is not defined anymore.</li></ul> The last set needs to be checked by hand, because this workflow currently does not check correctly WSDL files that use import statements, because these import statements are ignored. This means that many of the operations not found exists, but are defined in imported WSDL files.",20, 0, Flatten_NotExistingUrl, Flatten_ExistingUrlButOperationNot, MergeURLS, Merge_NotExistingUrl, generateIDs, Different_Count_Size, GetAnalysedWorkflows, Count_Size, createRTable, generateURL, FilterAndCount, Merge_ExistingUrlAndOperation, Merge_ExistingUrlBotOperationNot, Flatten_list, Flatten_ExistingUrlAndOperation, Flatten_Records, Merge_Records, Analyse_Location, CreateWorkflowLog, Analyse_Single_Workflow, ,
"http://www.myexperiment.org/workflows/778/versions/1.html","KEGG Gene IDs to KEGG Pathways","2009-06-0418:41:36","2010-01-0715:31:37","http://www.myexperiment.org/workflows/778/download/KEGG_Gene_IDs_to_KEGG_Pathways-v1.t2flow?version=1","/users/500","Paolo","taverna 2","/users/500,","Paolo,","this is a simplified version of Paul's workflow (linked?) that is designed to be provenance-friendly",1, 0, ,
"http://www.myexperiment.org/workflows/779/versions/1.html","DOI Files","2009-06-0513:51:57","","http://www.myexperiment.org/workflows/779/download/DOI_Files-v1.xml?version=1","/users/384","Andrea Wiggins","taverna 1","/users/384,","Andrea Wiggins,","This workflow generates additional files required for handling DOI creation: the DOI URL mapping required for the DOI deposit, and a set of sql update statements to insert the DOIs into an eprints database. Note that it is extremely important for this workflow to use the same CSV file as was used with the DOI record generator, as well as the same seed number.",13, 0, file_location, read_input, split_rows, split_numbers_to_list, split_more, make_number_sequence, format_months, aggregate_doi_urls, generate_doi, generate_doi_url_mapping, split_fields, make_sql_doi_updates, aggregate_sql_updates, ,
"http://www.myexperiment.org/workflows/780/versions/1.html","getCityCoordinates","2009-06-0811:02:31","","http://www.myexperiment.org/workflows/780/download/getCityCoordinates-v1.xml?version=1","/users/2026","Szypul","taverna 1","/users/2026,","Szypul,",,3, 0, composeURL, Get_web_page_from_URL, getLatAndLngfromXML, ,
"http://www.myexperiment.org/workflows/781/versions/1.html","getCountryCapital","2009-06-0811:03:55","","http://www.myexperiment.org/workflows/781/download/getCountryCapital-v1.xml?version=1","/users/2026","Szypul","taverna 1","/users/2026,","Szypul,",,3, 0, composeURL, Get_web_page_from_URL, getCapitalFromXML, ,
"http://www.myexperiment.org/workflows/782/versions/1.html","getCountryCode","2009-06-0811:04:24","","http://www.myexperiment.org/workflows/782/download/getCountryCode-v1.xml?version=1","/users/2026","Szypul","taverna 1","/users/2026,","Szypul,",,2, 0, Get_web_page_from_URL, composeURL, ,
"http://www.myexperiment.org/workflows/783/versions/1.html","getCountryInfo","2009-06-0811:05:08","","http://www.myexperiment.org/workflows/783/download/getCountryInfo-v1.xml?version=1","/users/2026","Szypul","taverna 1","/users/2026,","Szypul,",,2, 0, Get_web_page_from_URL, composeURL, ,
"http://www.myexperiment.org/workflows/784/versions/1.html","getMap","2009-06-0811:05:37","","http://www.myexperiment.org/workflows/784/download/getMap-v1.xml?version=1","/users/2026","Szypul","taverna 1","/users/2026,","Szypul,",,1, 0, composeURL, ,
"http://www.myexperiment.org/workflows/785/versions/1.html","projekt","2009-06-0811:15:03","","http://www.myexperiment.org/workflows/785/download/projekt-v1.xml?version=1","/users/2026","Szypul","taverna 1","/users/2026,","Szypul,",,5, 0, displayMap, getMapURL, getCapitalCords, getCountryCode, getCountryCapital, ,
"http://www.myexperiment.org/workflows/786/versions/1.html","NCBI Gi to Kegg Pathways","2009-06-0818:39:38","2009-12-1411:51:20","http://www.myexperiment.org/workflows/786/download/NCBI_Gi_to_Kegg_Pathways-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow converts a list of NCBI gi numbers and&nbsp; converts them to a list of KEGG genes. Those KEGG gene ids are subsequently turned into KEGG pathway identifiers and descriptions. It also removes any null values from a list of strings. <br /> <br /> Example input for this workflow is as follows (new line separated): <br /> gi:215422388 <br /> gi:120407068",14, 4, regex, merge_pathways, merge_pathways_2, merge_descriptions, Remove_duplicate_pathways, split_by_regex, btit1, get_pathways_by_genes, btit, remove_nulls_2, remove_Nulls, add_ncbi_to_string, extract_gene_ids, bconv, ,
"http://www.myexperiment.org/workflows/788/versions/1.html","myWorkflow","2009-06-0913:35:05","","http://www.myexperiment.org/workflows/788/download/myWorkflow-v1.t2flow?version=1","/users/2056","Rob","taverna 2","/users/2056,","Rob,","asdasdasd",0, 0, ,
"http://www.myexperiment.org/workflows/788/versions/2.html","myWorkflow","2009-06-0913:35:05","","http://www.myexperiment.org/workflows/788/download/myWorkflow-v2.t2flow?version=2","/users/2056","Rob","taverna 2","/users/2056,","Rob,","asdasdasd",0, 0, ,
"http://www.myexperiment.org/workflows/789/versions/1.html","getSynonymsFromSBML","2009-06-0920:02:05","2009-06-0920:08:02","http://www.myexperiment.org/workflows/789/download/getSynonymsFromSBML-v1.xml?version=1","/users/6","Duncan Hull","taverna 1","/users/6,","Duncan Hull,","This service takes an SBML file (for example from the Biomodels database) and extracts synonyms for each of the SBML species in the file, using ChEBI. Service is written and maintained by Neil Swainston at the MCISB.",1, 1, getSynonyms, ,
"http://www.myexperiment.org/workflows/790/versions/1.html","getOntologyTerm","2009-06-0920:18:21","2009-06-0920:19:29","http://www.myexperiment.org/workflows/790/download/getOntologyTerm-v1.xml?version=1","/users/6","Duncan Hull","taverna 1","/users/6,","Duncan Hull,","This service takes a MIRIAM compliant URI and looks up all the synonyms for that URI using ChEBI and other services. Service developed and maintained by Neil Swainston at the MCISB in Manchester.",1, 1, getOntologyTerm, ,
"http://www.myexperiment.org/workflows/795/versions/1.html","FirstExampleWorkflow","2009-06-2409:30:14","","","/users/2037","Jelena (Obradovic) Dreskai","taverna 1","/users/2037,","Jelena (Obradovic) Dreskai,","This is my first test example of Taverna Workflow.",
"http://www.myexperiment.org/workflows/799/versions/1.html","G-language Genome Analysis Environment - Bacteria Analysis System","2010-04-0506:08:25","2010-04-0506:08:26","http://www.myexperiment.org/workflows/799/download/G-language_Genome_Analysis_Environment_-_Bacteria_Analysis_System-v1.t2flow?version=1","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","&nbsp; <span class=Apple-style-span>Given an identifier for genome sequence (by default, genome of Mycoplasma genitalium: refseq:NC_000908) or raw sequence data in FASTA format, this workflow calculates and graphs the following properties using the G-language Genome Analysis Environment: GC skew (gcskew), cumulative GC skew (gcskew_cumulative), GC skew of coding/intergenic/GC3 (genomicskew), GC content with sliding windows (gcwin), replication origin and terminus (find_ori_ter), codon usage table (codon_usage), the Codon Adaptation Index (cai), nucleotide composition around the start/stop codons calculated with different information theory measures (view_cds,&nbsp;base_information_content, base_entropy, base_relative_entropy).&nbsp;<span class=Apple-style-span>See&nbsp;<a rel=nofollow href=http://www.g-language.org/>http://www.g-language.org/</a>&nbsp;for more information about the G-language Genome Analysis Environment.</span></span>",-1, 0, ,
"http://www.myexperiment.org/workflows/799/versions/2.html","G-language Genome Analysis Environment - Bacteria Analysis System","2010-04-0506:08:25","2010-04-0506:08:26","http://www.myexperiment.org/workflows/799/download/G-language_Genome_Analysis_Environment_-_Bacteria_Analysis_System-v2.t2flow?version=2","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","Given an identifier for genome sequence (by default, genome of Mycoplasma genitalium: refseq:NC_000908) or raw sequence data in FASTA format, this workflow calculates and graphs the following properties using the G-language Genome Analysis Environment: GC skew (gcskew), cumulative GC skew (gcskew_cumulative), GC skew of coding/intergenic/GC3 (genomicskew), GC content with sliding windows (gcwin), replication origin and terminus (find_ori_ter), codon usage table (codon_usage), the Codon Adaptation Index (cai), nucleotide composition around the start/stop codons calculated with different information theory measures (view_cds, base_information_content, base_entropy, base_relative_entropy). See  <a href=http://www.g-language.org/ rel=nofollow>http://www.g-language.org/</a>  for more information about the G-language Genome Analysis Environment. <hr /> This workflow calculates the Student's T-test and Pearson/Spearman correlations. See  <a href=http://www.g-language.org/ rel=nofollow>http://www.g-language.org/</a>  for more information about the G-language Genome Analysis Environment.",1, 0, ,
"http://www.myexperiment.org/workflows/800/versions/1.html","G-language Genome Analysis Environment - Basic statistics on a numerical vector","2010-04-0506:15:53","","http://www.myexperiment.org/workflows/800/download/G-language_Genome_Analysis_Environment_-_Basic_statistics_on_a_numerical_vector-v1.t2flow?version=1","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","<span>&nbsp;<span class=Apple-style-span>Given a numerical vector (array), this workflow calculates the maximum value (max) and its index (maxdex), minumum value (min) and its index (mindex), mean, sum, median, and standard deviation.&nbsp;<span class=Apple-style-span>See&nbsp;<a rel=nofollow href=http://www>http://www</a>.<strong class=highlight>g-language</strong>.org/&nbsp;for more information about the&nbsp;<strong class=highlight>G-language</strong>&nbsp;Genome Analysis Environment.</span></span></span>",-1, 0, ,
"http://www.myexperiment.org/workflows/800/versions/2.html","G-language Genome Analysis Environment - Basic statistics on a numerical vector","2010-04-0506:15:53","","http://www.myexperiment.org/workflows/800/download/G-language_Genome_Analysis_Environment_-_Basic_statistics_on_a_numerical_vector-v2.t2flow?version=2","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","Given a numerical vector (array), this workflow calculates the maximum value (max) and its index (maxdex), minumum value (min) and its index (mindex), mean, sum, median, and standard deviation. See  <a href=http://www.g-language.org/ rel=nofollow>http://www.g-language.org/</a>  for more information about the G-language Genome Analysis Environment.",0, 0, ,
"http://www.myexperiment.org/workflows/801/versions/1.html","G-language Genome Analysis Environment - GC skew analysis (basic)","2010-04-0506:20:58","","http://www.myexperiment.org/workflows/801/download/G-language_Genome_Analysis_Environment_-_GC_skew_analysis__basic_-v1.t2flow?version=1","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","&nbsp; <span class=Apple-style-span>This workflow calculates and graphs the GC skew of a given genome sequence. Use this as a template for using more than 100 analysis programs implemented in G-language Genome Analysis Environment, which can be used in a similar manner.&nbsp;<span class=Apple-style-span>See&nbsp;<a rel=nofollow href=http://www.g-language.org/>http://www.g-language.org/</a>&nbsp;for more information about the G-language Genome Analysis Environment.</span></span>",-1, 0, ,
"http://www.myexperiment.org/workflows/801/versions/2.html","G-language Genome Analysis Environment - GC skew analysis (basic)","2010-04-0506:20:58","","http://www.myexperiment.org/workflows/801/download/G-language_Genome_Analysis_Environment_-_GC_skew_analysis__basic_-v2.t2flow?version=2","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","This workflow calculates and graphs the GC skew of a given genome sequence. Use this as a template for using more than 100 analysis programs implemented in G-language Genome Analysis Environment, which can be used in a similar manner. See  <a href=http://www.g-language.org/ rel=nofollow>http://www.g-language.org/</a>  for more information about the G-language Genome Analysis Environment.",0, 0, ,
"http://www.myexperiment.org/workflows/802/versions/1.html","G-language Genome Analysis Environment - GC skew analysis (sequence retrieval via togoWS)","2010-04-0506:24:02","","http://www.myexperiment.org/workflows/802/download/G-language_Genome_Analysis_Environment_-_GC_skew_analysis__sequence_retrieval_via_togoWS_-v1.t2flow?version=1","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","&nbsp; <span class=Apple-style-span>This workflow calculates and graphs the GC skew (by default, for keto bases, with window size of 1000) of a given genome sequence identifier. Here the genome sequence in Fasta format is downloaded through the Togo Web Service with RefSeq identifier.&nbsp;<span class=Apple-style-span>See&nbsp;<a rel=nofollow href=http://www.g-language.org/>http://www.g-language.org/</a>&nbsp;for more information about the G-language Genome Analysis Environment.</span></span>",-1, 0, ,
"http://www.myexperiment.org/workflows/802/versions/2.html","G-language Genome Analysis Environment - GC skew analysis (sequence retrieval via togoWS)","2010-04-0506:24:02","","http://www.myexperiment.org/workflows/802/download/G-language_Genome_Analysis_Environment_-_GC_skew_analysis__sequence_retrieval_via_togoWS_-v2.t2flow?version=2","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","This workflow calculates and graphs the GC skew (by default, for keto bases, with window size of 1000) of a given genome sequence identifier. Here the genome sequence in Fasta format is downloaded through the Togo Web Service with RefSeq identifier. See  <a href=http://www.g-language.org/ rel=nofollow>http://www.g-language.org/</a>  for more information about the G-language Genome Analysis Environment.",0, 0, ,
"http://www.myexperiment.org/workflows/803/versions/1.html","G-language Genome Analysis Environment - Basic sequence manipulations","2010-04-0506:13:16","2010-04-0506:13:17","http://www.myexperiment.org/workflows/803/download/G-language_Genome_Analysis_Environment_-_Basic_sequence_manipulations-v1.t2flow?version=1","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","<span class=Apple-style-span>This workflow shows simple sequence manipulation functions of G-language GAE, such as random shuffling, obtaining a reverse complement, and translation of nucleotide sequences, and showing basic composition statistics for nucleotide and amino acid sequences.&nbsp;<span class=Apple-style-span>See&nbsp;<a rel=nofollow href=http://www.g-language.org/>http://www.g-language.org/</a>&nbsp;for more information about the G-language Genome Analysis Environment.</span></span>",-1, 0, ,
"http://www.myexperiment.org/workflows/803/versions/2.html","G-language Genome Analysis Environment - Basic sequence manipulations","2010-04-0506:13:16","2010-04-0506:13:17","http://www.myexperiment.org/workflows/803/download/G-language_Genome_Analysis_Environment_-_Basic_sequence_manipulations-v2.t2flow?version=2","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","This workflow shows simple sequence manipulation functions of G-language GAE, such as random shuffling, obtaining a reverse complement, and translation of nucleotide sequences, and showing basic composition statistics for nucleotide and amino acid sequences. See  <a href=http://www.g-language.org/ rel=nofollow>http://www.g-language.org/</a>  for more information about the G-language Genome Analysis Environment.",0, 0, ,
"http://www.myexperiment.org/workflows/804/versions/1.html","G-language Genome Analysis Environment - GC skew analysis (multiple)","2010-04-0506:22:28","","http://www.myexperiment.org/workflows/804/download/G-language_Genome_Analysis_Environment_-_GC_skew_analysis__multiple_-v1.t2flow?version=1","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","&nbsp; <span class=Apple-style-span>This workflow calculates and graphs the GC skew of a given genome sequence (for the entire genome, for only the coding sequences, for only the intergenic regions, and for only the third codon positions), as well as the GC content with sliding windows.&nbsp;<span class=Apple-style-span>See&nbsp;<a rel=nofollow href=http://www.g-language.org/>http://www.g-language.org/</a>&nbsp;for more information about the G-language Genome Analysis Environment.</span></span>",-1, 0, ,
"http://www.myexperiment.org/workflows/804/versions/2.html","G-language Genome Analysis Environment - GC skew analysis (multiple)","2010-04-0506:22:28","","http://www.myexperiment.org/workflows/804/download/G-language_Genome_Analysis_Environment_-_GC_skew_analysis__multiple_-v2.t2flow?version=2","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","This workflow calculates and graphs the GC skew of a given genome sequence (for the entire genome, for only the coding sequences, for only the intergenic regions, and for only the third codon positions), as well as the GC content with sliding windows. See  <a href=http://www.g-language.org/ rel=nofollow>http://www.g-language.org/</a>  for more information about the G-language Genome Analysis Environment.",0, 0, ,
"http://www.myexperiment.org/workflows/805/versions/1.html","G-language Genome Analysis Environment - GC skew analysis (AT skew)","2010-04-0506:17:25","2011-01-0906:08:19","http://www.myexperiment.org/workflows/805/download/G-language_Genome_Analysis_Environment_-_GC_skew_analysis__AT_skew_-v1.t2flow?version=1","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","&nbsp; <span class=Apple-style-span>This workflow calculates and graphs the AT skew of a given genome sequence, using options of gcskew program.&nbsp;<span class=Apple-style-span>See&nbsp;<a rel=nofollow href=http://www.g-language.org/>http://www.g-language.org/</a>&nbsp;for more information about the G-language Genome Analysis Environment.</span></span>",-1, 0, ,
"http://www.myexperiment.org/workflows/805/versions/2.html","G-language Genome Analysis Environment - GC skew analysis (AT skew)","2010-04-0506:17:25","2011-01-0906:08:19","http://www.myexperiment.org/workflows/805/download/G-language_Genome_Analysis_Environment_-_GC_skew_analysis__AT_skew_-v2.t2flow?version=2","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","This workflow calculates and graphs the AT skew of a given genome sequence, using options of gcskew program. See  <a href=http://www.g-language.org/ rel=nofollow>http://www.g-language.org/</a>  for more information about the G-language Genome Analysis Environment.",0, 0, ,
"http://www.myexperiment.org/workflows/805/versions/3.html","G-language Genome Analysis Environment - GC skew analysis (AT skew)","2010-04-0506:17:25","2011-01-0906:08:19","http://www.myexperiment.org/workflows/805/download/G-language_Genome_Analysis_Environment_-_GC_skew_analysis__AT_skew_-v3.t2flow?version=3","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","This workflow calculates and graphs the AT skew of a given genome sequence, using options of gcskew program. See  <a href=http://www.g-language.org/ rel=nofollow>http://www.g-language.org/</a>  for more information about the G-language Genome Analysis Environment.",-1, 0, ,
"http://www.myexperiment.org/workflows/806/versions/1.html","G-language Genome Analysis Environment - Student&#39;s T-test and Pearson/Spearman correlations","2010-04-0506:26:41","","http://www.myexperiment.org/workflows/806/download/G-language_Genome_Analysis_Environment_-_Student_s_T-test_and_Pearson_Spearman_correlations-v1.t2flow?version=1","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","&nbsp; <span class=Apple-style-span>This workflow calculates the&nbsp;Student's T-test and Pearson/Spearman correlations.&nbsp;<span class=Apple-style-span>See&nbsp;<a rel=nofollow href=http://www.g-language.org/>http://www.g-language.org/</a>&nbsp;for more information about the G-language Genome Analysis Environment.</span></span>",-1, 0, ,
"http://www.myexperiment.org/workflows/806/versions/2.html","G-language Genome Analysis Environment - Student&#39;s T-test and Pearson/Spearman correlations","2010-04-0506:26:41","","http://www.myexperiment.org/workflows/806/download/G-language_Genome_Analysis_Environment_-_Student_s_T-test_and_Pearson_Spearman_correlations-v2.t2flow?version=2","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","This workflow calculates the Student's T-test and Pearson/Spearman correlations. See  <a href=http://www.g-language.org/ rel=nofollow>http://www.g-language.org/</a>  for more information about the G-language Genome Analysis Environment.",0, 0, ,
"http://www.myexperiment.org/workflows/807/versions/1.html","G-language Genome Analysis Environment - Reading manuals","2010-03-3010:58:18","2010-03-3011:19:03","http://www.myexperiment.org/workflows/807/download/G-language_Genome_Analysis_Environment_-_Reading_manuals-v1.t2flow?version=1","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","&nbsp; <span class=Apple-style-span>This workflow displays a documentation of G-language GAE programs.&nbsp;If you input the &quot;option&quot;, this workflow searches for the keyword through the documentations.&nbsp;<span class=Apple-style-span>See&nbsp;<a href=http://www.g-language.org/ rel=nofollow>http://www.g-language.org/</a>&nbsp;for more information about the G-language Genome Analysis Environment.</span></span> &nbsp; &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/807/versions/2.html","G-language Genome Analysis Environment - Reading manuals","2010-03-3010:58:18","2010-03-3011:19:03","http://www.myexperiment.org/workflows/807/download/G-language_Genome_Analysis_Environment_-_Reading_manuals-v2.t2flow?version=2","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","This workflow displays a documentation of G-language GAE programs. If you input the &quot;keywords&quot;, this workflow searches for the keyword through the documentations. See  <a href=http://www.g-language.org/ rel=nofollow>http://www.g-language.org/</a>  for more information about the G-language Genome Analysis Environment.",-1, 0, ,
"http://www.myexperiment.org/workflows/808/versions/1.html","Tuiuiu synchronous workflow","2009-06-2909:42:08","2009-06-2909:59:57","http://www.myexperiment.org/workflows/808/download/Tuiuiu_synchronous_workflow-v1.xml?version=1","/users/1990","http://...","taverna 1","/users/1990,","http://osallou.myopenid.com/,","Tuiuiu removes from a sequence or from a set of sequences areas as large as possible that do not contain researched repeats. <br /> <br /> Tuiuiu is used as a preliminary step before applying a multiple local aligner tool. <br /> <br /> <br /> <br /> Modeling and algorithmic details are provided in the following paper. <br /> Please, cite this paper if you use Tuiuiu. <br /> <br /> P. Peterlongo, G. Sacomoto, A. Pereira do Lago, N. Pisanti, M.-F. Sagot <br /> Lossless filter for multiple repeats with bounded edit distance <br /> BMC Algorithms for Molecular Biology 2009, 4:3 doi:10.1186/1748-7188-4-3 <br /> <br /> Link:  <a href=http://www.almob.org/content/4/1/3>http://www.almob.org/content/4/1/3</a> &nbsp; This web service is made available on GenOuest bioinformatics platform (Rennes, France) using  <a href=http://www.nbcr.net/software/opal/>Opal toolkit</a> . A list of other web-services available on GenOuest platform can be viewed  <a href=http://webservices.genouest.org/typedservices/>here</a> . This workflow uses Tuiuiu in a synchronous way: the workflow will launch Tuiuiu and wait the end of the job before continuing.",7, 1, filterListOfStringsByRegex, launchJobBlockingOutputXML, outputFileXML, launchJobBlockingInputXML, jobOutXML, inputFastaFileXML, launchJobBlocking, ,
"http://www.myexperiment.org/workflows/809/versions/1.html","Tuiuiu asynchronous workflow","2009-06-2909:53:39","2009-06-2909:59:23","http://www.myexperiment.org/workflows/809/download/Tuiuiu_asynchronous_workflow-v1.xml?version=1","/users/1990","http://...","taverna 1","/users/1990,","http://osallou.myopenid.com/,","Tuiuiu removes from a sequence or from a set of sequences areas as large as possible that do not contain researched repeats. <br /> <br /> Tuiuiu is used as a preliminary step before applying a multiple local aligner tool. <br /> <br /> <br /> <br /> Modeling and algorithmic details are provided in the following paper. <br /> Please, cite this paper if you use Tuiuiu. <br /> <br /> P. Peterlongo, G. Sacomoto, A. Pereira do Lago, N. Pisanti, M.-F. Sagot <br /> Lossless filter for multiple repeats with bounded edit distance <br /> BMC Algorithms for Molecular Biology 2009, 4:3 doi:10.1186/1748-7188-4-3 <br /> <br /> Link:  <a href=http://www.almob.org/content/4/1/3>http://www.almob.org/content/4/1/3</a> <br /> <br /> <br /> This web service is made available on GenOuest bioinformatics platform (Rennes, France) using  <a href=http://www.nbcr.net/software/opal/>Opal toolkit</a> . A list of other web-services available on GenOuest platform can be viewed  <a href=http://webservices.genouest.org/typedservices/>here</a> . <br /> <br /> This workflow uses Tuiuiu in an asynchronous way: the workflow will launch Tuiuiu and then regularly poll the server for results.",9, 2, launchJobOutputXML, launchJobInputXML, launchJob, getOutputsOutputXML, outputFileXML, filterListOfStringsByRegex, inputFastaFileXML, getOutputs, PollStatus, ,
"http://www.myexperiment.org/workflows/811/versions/1.html","Execute GWorkflowDL workflow using Taverna 2","2009-06-3010:01:35","2009-06-3010:07:25","http://www.myexperiment.org/workflows/811/download/Execute_GWorkflowDL_workflow_using_Taverna_2-v1.t2flow?version=1","/users/1333","Andreas Hoheisel","taverna 2","/users/1333,","Andreas Hoheisel,","This workflow makes use of the &quot;Grid Workflow Execution Service&quot; (GWES) in order to exececute a GWorkflowDL workflow by means of the Taverna Workbench 2. As the GWES is deployed as a regular SOAP service, the WSDL can be imported as a normal service into the Taverna Workbench.",2, 0, ,
"http://www.myexperiment.org/workflows/812/versions/1.html","EBI InterproScan T2","2009-06-3011:24:07","2009-06-3011:25:38","http://www.myexperiment.org/workflows/812/download/EBI_InterproScan_T2-v1.t2flow?version=1","/users/500","Paolo","taverna 2","/users/5, /users/13,","Stian Soiland-Reyes, Katy Wolstencroft,","This T2 version of the Interpro scan workflow is an example of the while loop in action. This is used to poll the async EBI service for the result (busy waiting)",2, 0, ,
"http://www.myexperiment.org/workflows/813/versions/1.html","Execute GWorkflowDL workflow using Taverna 2 (with inputs)","2009-06-3014:02:36","","http://www.myexperiment.org/workflows/813/download/Execute_GWorkflowDL_workflow_using_Taverna_2__with_inputs_-v1.t2flow?version=1","/users/1333","Andreas Hoheisel","taverna 2","/users/1333,","Andreas Hoheisel,","This workflow makes use of the Grid Workflow Execution Service (GWES) in order to exececute a GWorkflowDL workflow by means of the Taverna Workbench 2. As the GWES is deployed as a regular SOAP service, the WSDL can be imported as a normal service into the Taverna Workbench. This workflow contains all the input parameters as string constants, so it can be started right away without user inputs.",2, 0, ,
"http://www.myexperiment.org/workflows/814/versions/1.html","EBI_InterProScan for Taverna 2","2010-01-2614:46:07","2010-01-2614:46:08","http://www.myexperiment.org/workflows/814/download/EBI_InterProScan_for_Taverna_2-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5, /users/500, /users/13, /users/925,","Stian Soiland-Reyes, Paolo, Katy Wolstencroft, Hamish McWilliam,","Perform an InterProScan analysis of a protein sequence using the EBI&rsquo;s WSInterProScan service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/interproscan>http://www.ebi.ac.uk/Tools/webservices/services/interproscan</a> ). The input sequence to use and the user e-mail address are inputs, the other parameters for the analysis (see Job_params) are allowed to default. <br /> <br /> InterProScan searches a protein sequence against the protein family and domain signature databases integrated into InterPro (see  <a href=http://www.ebi.ac.uk/interpro/>http://www.ebi.ac.uk/interpro/</a> ). A set of matches to the signatures are returned, which are annotated with the corresponding InterPro and GO term assignments for these signature matches. <br /> <br /> The checkStatus processor has looping enabled, it will continue as long as the status is RUNNING - but with a 250 ms sleep. (done as a customized Beanshell script to add the sleep, avoiding overload of the checkStatus service)",2, 0, ,
"http://www.myexperiment.org/workflows/814/versions/2.html","EBI_InterProScan for Taverna 2","2010-01-2614:46:07","2010-01-2614:46:08","http://www.myexperiment.org/workflows/814/download/EBI_InterProScan_for_Taverna_2-v2.t2flow?version=2","/users/5","Stian Soiland-Reyes","taverna 2","/users/5, /users/500, /users/13, /users/925,","Stian Soiland-Reyes, Paolo, Katy Wolstencroft, Hamish McWilliam,",,2, 0, ,
"http://www.myexperiment.org/workflows/820/versions/1.html","EBI_InterProScan for Taverna 2","2010-01-2614:45:46","2010-11-2410:04:09","http://www.myexperiment.org/workflows/820/download/EBI_InterProScan_for_Taverna_2-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5, /users/13, /users/500, /users/925,","Stian Soiland-Reyes, Katy Wolstencroft, Paolo, Hamish McWilliam,","Perform an InterProScan analysis of a protein sequence using the EBI&rsquo;s WSInterProScan service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/interproscan>http://www.ebi.ac.uk/Tools/webservices/services/interproscan</a> ). The input sequence to use and the user e-mail address are inputs, the other parameters for the analysis (see Job_params) are allowed to default. <br /> <br /> InterProScan searches a protein sequence against the protein family and domain signature databases integrated into InterPro (see  <a href=http://www.ebi.ac.uk/interpro/>http://www.ebi.ac.uk/interpro/</a> ). A set of matches to the signatures are returned, which are annotated with the corresponding InterPro and GO term assignments for these signature matches. <br /> <br /> The checkStatus processor has looping enabled, it will continue as long as the status is RUNNING - but with a 250 ms sleep. (done as a customized Beanshell script to add the sleep, avoiding overload of the checkStatus service)",2, 0, ,
"http://www.myexperiment.org/workflows/820/versions/2.html","EBI_InterProScan for Taverna 2","2010-01-2614:45:46","2010-11-2410:04:09","http://www.myexperiment.org/workflows/820/download/EBI_InterProScan_for_Taverna_2-v2.t2flow?version=2","/users/5","Stian Soiland-Reyes","taverna 2","/users/5, /users/13, /users/500, /users/925,","Stian Soiland-Reyes, Katy Wolstencroft, Paolo, Hamish McWilliam,","Perform an InterProScan analysis of a protein sequence using the EBI&rsquo;s WSInterProScan service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/interproscan rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/interproscan</a> ). The input sequence to use and the user e-mail address are inputs, the other parameters for the analysis (see Job_params) are allowed to default. InterProScan searches a protein sequence against the protein family and domain signature databases integrated into InterPro (see  <a href=http://www.ebi.ac.uk/interpro/ rel=nofollow>http://www.ebi.ac.uk/interpro/</a> ). A set of matches to the signatures are returned, which are annotated with the corresponding InterPro and GO term assignments for these signature matches. checkStatus is executed repeatedly as long as the status is equal to RUNNING - check Details -&gt; Advanced for loop condition.",2, 0, ,
"http://www.myexperiment.org/workflows/821/versions/1.html","Biomart and EMBOSS analysis","2009-07-0314:18:28","2009-07-0314:19:32","http://www.myexperiment.org/workflows/821/download/Biomart_and_EMBOSS_analysis-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","Using Biomart and EMBOSS soaplab services, This workflow retrieves a number of sequences from 3 species: mouse, human, rat; align them, and returns a plot of the alignment result. Corresponding sequence ids are also returned.",1, 0, ,
"http://www.myexperiment.org/workflows/822/versions/1.html","Demonstration of configurable iteration","2009-07-0314:32:26","2009-07-0314:33:01","http://www.myexperiment.org/workflows/822/download/Demonstration_of_configurable_iteration-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5, /users/297,","Stian Soiland-Reyes, Tomoinn,","This workflow shows the use of the iteration strategy editor to ensure that only relevant combinations of inputs are used during an implicit iteration.",0, 0, ,
"http://www.myexperiment.org/workflows/823/versions/1.html","Fetch PDB flatfile from RCSB server","2009-07-0314:37:14","2009-07-0314:53:40","http://www.myexperiment.org/workflows/823/download/Fetch_PDB_flatfile_from_RCSB_server-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","Given an identifier such as '1crn' fetches the PDB format flatfile and returns the corresponding 3D image of the protein.",0, 0, ,
"http://www.myexperiment.org/workflows/824/versions/1.html","Fetch today&#39;s xkcd comic","2009-07-0314:40:25","","http://www.myexperiment.org/workflows/824/download/Fetch_today_s_xkcd_comic-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","Use the local java plugins and some filtering operations to fetch the comic strip image from  <a href=http://xkcd.com/>http://xkcd.com/</a> <br /> <br /> Based on the FetchDailyDilbert workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/825/versions/1.html","GBSeq test","2009-07-0314:48:38","","http://www.myexperiment.org/workflows/825/download/GBSeq_test-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","This workflow retrieves nucleotide and protein sequences with the literature and references associated to them given a protein and a nucleotide id.",0, 0, ,
"http://www.myexperiment.org/workflows/826/versions/1.html","Retrieve sequence in EMBL format","2009-07-0314:49:48","","http://www.myexperiment.org/workflows/826/download/Retrieve_sequence_in_EMBL_format-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","This workflow retrieves a sequence associated with its features in embl format",0, 0, ,
"http://www.myexperiment.org/workflows/827/versions/1.html","A workflow version of the EMBOSS tutorial","2009-07-0314:50:54","2009-07-0314:51:15","http://www.myexperiment.org/workflows/827/download/A_workflow_version_of_the_EMBOSS_tutorial-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","Designed to show the use of EMBOSS based Soaplab services from Taverna, this workflow has no inputs as all initial values are specified as string constants. A sequence set is fetched using the seqret tool, then simultaneously scanned for predicted transmembrane regions and subjected to a multiple alignment using emma. This alignment is then plotted to a set of PNG images and also used to build a profile using the prophecy and prophet tools.",0, 0, ,
"http://www.myexperiment.org/workflows/828/versions/1.html","Pipelined list iteration","2009-07-0314:59:53","","http://www.myexperiment.org/workflows/828/download/Pipelined_list_iteration-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5, /users/474,","Stian Soiland-Reyes, Ian Dunlop,","Perform multiple iterations of services in order to show pipelining",1, 0, ,
"http://www.myexperiment.org/workflows/829/versions/1.html","BioQuali synchronous workflow","2009-07-0610:00:52","2009-07-0610:05:49","http://www.myexperiment.org/workflows/829/download/BioQuali_synchronous_workflow-v1.xml?version=1","/users/2167","abretaud","taverna 1","/users/2167,","abretaud,","BioQuali: Network Compatibility and products variation inference in a biological network. Help page:  <a href=http://genoweb2.irisa.fr/claroline/claroline/course/index.php?cid=BIOQUALI>http://genoweb2.irisa.fr/claroline/claroline/course/index.php?cid=BIOQUALI</a> <span>Reference: <a href=http://www.biomedcentral.com/1471-2164/10/244>Carito Guziolowski, Annabel Bourd&eacute;, Francois Moreews and Anne Siegel BioQuali Cytoscape plugin: analysing the global consistency of regulatory networks           <br />BMC Genomics 2009, 10:244 doi:10.1186/1471-2164-10-244</a> </span> This web service is made available on GenOuest bioinformatics platform (Rennes, France) using  <a href=http://www.nbcr.net/software/opal/>Opal toolkit</a> . A list of other web-services available on GenOuest platform can be viewed  <a href=http://webservices.genouest.org/typedservices/>here</a> . This workflow uses BioQuali in a synchronous way: the workflow will launch BioQuali and wait the end of the job before continuing.",5, 1, inputNetworkFileXML, launchJobBlockingInputXML, launchJobBlockingOutputXML, inputObservationsFileXML, launchJobBlocking, ,
"http://www.myexperiment.org/workflows/830/versions/1.html","BioQuali asynchronous workflow","2009-07-0610:08:10","2009-07-0610:09:02","http://www.myexperiment.org/workflows/830/download/BioQuali_asynchronous_workflow-v1.xml?version=1","/users/2167","abretaud","taverna 1","/users/2167,","abretaud,","BioQuali: Network Compatibility and products variation inference in a biological network. Help page:  <a href=http://genoweb2.irisa.fr/claroline/claroline/course/index.php?cid=BIOQUALI>http://genoweb2.irisa.fr/claroline/claroline/course/index.php?cid=BIOQUALI</a> <span>Reference: <a href=http://www.biomedcentral.com/1471-2164/10/244>Carito Guziolowski, Annabel Bourd&eacute;, Francois Moreews and Anne Siegel BioQuali Cytoscape plugin: analysing the global consistency of regulatory networks <br />BMC Genomics 2009, 10:244 doi:10.1186/1471-2164-10-244</a> </span> This web service is made available on GenOuest bioinformatics platform (Rennes, France) using  <a href=http://www.nbcr.net/software/opal/>Opal toolkit</a> . A list of other web-services available on GenOuest platform can be viewed  <a href=http://webservices.genouest.org/typedservices/>here</a> . This workflow uses BioQuali in an asynchronous way: the workflow will launch BioQuali and then regularly poll the server for results.",8, 2, PollStatus, inputObservationsFileXML, inputNetworkFileXML, launchJob, launchJobInputXML, launchJobOutputXML, getOutputs, getOutputsOutputXML, ,
"http://www.myexperiment.org/workflows/831/versions/1.html","Arabidopsis thaliana QTL Analysis","2009-07-0816:26:13","2009-12-1411:59:14","http://www.myexperiment.org/workflows/831/download/Arabidopsis_thaliana_QTL_Analysis-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in Arabidopsis thaliana. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database. &nbsp; Example input for this workflow are given below. Chromosome_name: 5 start_position: 23446557 end_position: 26046557 &nbsp;",30, 3, remove_pathway_duplicates, kegg_pathway_release, merge_pathway_list_2, merge_kegg_references, merge_gene_desc, split_for_duplicates, merge_uniprot_ids, remove_duplicate_kegg_genes, merge_genes_and_pathways, merge_genes_and_pathways_2, merge_genes_and_pathways_3, merge_pathway_list_1, merge_pathway_desc, regex_2, remove_uniprot_duplicates, remove_pathway_nulls, split_gene_ids, add_uniprot_to_string, remove_pathway_nulls_2, remove_nulls, remove_nulls_3, Kegg_gene_ids, gene_descriptions, binfo, Get_pathways, athaliana_qtl_region, athaliana_gene_ensembl, merge_pathway_descriptions, split_pathway_duplicates, remove_duplicate_pathway_ids, ,
"http://www.myexperiment.org/workflows/832/versions/1.html","Arabidopsis thaliana Microarray Analysis","2009-07-0816:28:34","","http://www.myexperiment.org/workflows/832/download/Arabidopsis_thaliana_Microarray_Analysis-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow searches for genes which are found to be differentially expressed in a microarray study using Arabidopsis thaliana. The workflow requires an input of a list of differentially expressed AffyMetrix Probeset identifiers. Data is then extracted from BioMart to annotate each of the genes. The UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",30, 3, remove_pathway_duplicates, kegg_pathway_release, merge_pathway_list_2, merge_kegg_references, merge_gene_desc, split_for_duplicates, merge_uniprot_ids, remove_duplicate_kegg_genes, merge_genes_and_pathways, merge_genes_and_pathways_2, merge_genes_and_pathways_3, merge_pathway_list_1, merge_pathway_desc, regex_2, remove_uniprot_duplicates, remove_pathway_nulls, split_gene_ids, add_uniprot_to_string, remove_pathway_nulls_2, remove_nulls, remove_nulls_3, Kegg_gene_ids, gene_descriptions, binfo, Get_pathways, athaliana_microarray, athaliana_gene_ensembl, merge_pathway_descriptions, split_pathway_duplicates, remove_duplicate_pathway_ids, ,
"http://www.myexperiment.org/workflows/833/versions/1.html","getGoTermsFromUniprotId","2009-07-0907:23:08","2009-07-0907:24:19","http://www.myexperiment.org/workflows/833/download/getGoTermsFromUniprotId-v1.t2flow?version=1","/users/2037","Jelena (Obradovic) Dreskai","taverna 2","/users/2037,","Jelena (Obradovic) Dreskai,","This service is invoking UniprotAPI to retrive GOTerms associated with the list of UniprotIds provided in the input. It is using Axis2 webservice created using UniprotAPI and published with wsdl. Example uniprotIds for input: &quot;A2ABK7&quot;, &quot;A2ABK8&quot;, &quot;A2ABK9&quot;",-1, 0, ,
"http://www.myexperiment.org/workflows/834/versions/1.html","getPubMedIdsFromUniprotIds","2009-07-0907:29:16","","http://www.myexperiment.org/workflows/834/download/getPubMedIdsFromUniprotIds-v1.t2flow?version=1","/users/2037","Jelena (Obradovic) Dreskai","taverna 2","/users/2037,","Jelena (Obradovic) Dreskai,","This service is invoking UniprotAPI to retrive PubMedIds for articles associated with the list of UniprotIds provided in the input. It is using Axis2 webservice created using UniprotAPI and published with wsdl. Example uniprotIds for input: &quot;Q5VWZ2&quot;",-1, 0, ,
"http://www.myexperiment.org/workflows/840/versions/1.html","DNA sequence analysis pilot","2009-07-1014:31:27","2009-11-3009:37:38","http://www.myexperiment.org/workflows/840/download/DNA_sequence_analysis_pilot-v1.scufl?version=1","/users/36","Angela Luijf","taverna 1","/users/36, /users/648,","Angela Luijf, Glatard,","&nbsp; <i><a href=http://amc-app1.amc.sara.nl/twiki/bin/view rel=nofollow>http://amc-app1.amc.sara.nl/twiki/bin/view/</a></i> &nbsp; &nbsp; &nbsp; &nbsp; <i>Workflow-based&nbsp; DNA sequence analysis on the Dutch Life Science Grid,<br />presented as Application Showcase at the NBIC Conference 2009, Lunteren, The Netherlands, 17 &amp; 18 March 2009.</i> <a href=http://www.biomedgrid.it/programme rel=nofollow><em>http://www.biomedgrid.it/programme</em></a> <br /> may 15th 2009. Hands on workflow: grid-enabled medical imaging&nbsp; (Johan Montagnat &ndash; Tristan Glatard) <br /> &nbsp;",10, 3, empty, BlastConfigFile, patternMatch_configfile, sff2fasta_configfile, patternMatch, sffToFasta, Blastall, sffExecutable, formatdbExe, blastallExe, ,
"http://www.myexperiment.org/workflows/841/versions/1.html","Tutorial Workflow","2009-07-1823:40:31","","http://www.myexperiment.org/workflows/841/download/Tutorial_Workflow-v1.t2flow?version=1","/users/2077","Nima","taverna 2","/users/2077,","Nima,",,-1, 0, ,
"http://www.myexperiment.org/workflows/841/versions/2.html","Tutorial Workflow","2009-07-1823:40:31","","http://www.myexperiment.org/workflows/841/download/Tutorial_Workflow-v2.t2flow?version=2","/users/2077","Nima","taverna 2","/users/2077,","Nima,",,-1, 0, ,
"http://www.myexperiment.org/workflows/843/versions/1.html","Term Extraction with NaCTeM&#39;s TerMine Tool","2009-07-2317:11:14","","http://www.myexperiment.org/workflows/843/download/Term_Extraction_with_NaCTeM_s_TerMine_Tool-v1.t2flow?version=1","/users/884","Brian Rea","taverna 2","/users/884,","Brian Rea,","Pass in text and retrieve a list of terms discovered ranked by their importance within the text.",0, 0, ,
"http://www.myexperiment.org/workflows/843/versions/2.html","Term Extraction with NaCTeM&#39;s TerMine Tool","2009-07-2317:11:14","","http://www.myexperiment.org/workflows/843/download/Term_Extraction_with_NaCTeM_s_TerMine_Tool-v2.t2flow?version=2","/users/884","Brian Rea","taverna 2","/users/884,","Brian Rea,","Pass in text and retrieve a list of terms discovered ranked by their importance within the text.",0, 0, ,
"http://www.myexperiment.org/workflows/845/versions/1.html","An example workflow with WSRF service","2009-07-2817:24:05","","http://www.myexperiment.org/workflows/845/download/An_example_workflow_with_WSRF_service-v1.t2flow?version=1","/users/1019","Wei Tan","taverna 2","/users/1019, /users/5,","Wei Tan, Stian Soiland-Reyes,","An example workflow with WSRF service The service used is  <a href=http://sidgrid.ci.uchicago.edu:8100/wsrf/services/CounterService>http://sidgrid.ci.uchicago.edu:8100/wsrf/services/CounterService</a> The service is included in Globus toolkit installation (ws-core). If the it is down you can host your own and modify the workflow definition file to point to your own. The workflow first creates a counter instance and adds the value 10 for two times to the same counter. Therefore the result should be 20.",-1, 0, ,
"http://www.myexperiment.org/workflows/850/versions/1.html","Cosine vector space","2009-08-1013:19:36","2009-08-1013:24:28","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow calculates the cosine vector space between two sets of corpora. The workflow then removes any null values from the output. The result is a cosine vector score between 0 and 1, showing the significance of any links between one concept (e.g. pathway) to another (e.g. phenotype). A score of 0 means there is no or an undetermined correlation between the two concepts. A score approaching 1 represents positive correlation.",
"http://www.myexperiment.org/workflows/851/versions/1.html","Extract Scientific Terms","2009-08-1013:31:07","2009-08-1013:32:21","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow takes in a document containg text and removes any non-ascii characters. The cleaned text is then sent to a service in Dresden, to extract all scientific terms. These terms represent a concept profile for the input concpet. Any null values are also removed.",
"http://www.myexperiment.org/workflows/854/versions/1.html","Rank Phenotype Terms","2009-08-1015:43:48","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow counts the number of articles in the pubmed database in which each term occurs, and identifies the total number of articles in the entire PubMed database. It also identified the total number of articles within pubmed so that a term enrichment score may be calculated. The workflow also takes in a document containing abstracts that are related to a particular phenotype. Scientiifc terms are then extracted from this text and given a weighting according to the number of terms that appear in the document.  The higher the value the better the score.This is given as: X = log((a / b) / (c / d)) where:	a = number of occurnaces of individual terms in phenotype corpusb = number of abstracts in entire phenotype corpusc = number of occurnaces of individual terms in entire pubmedd = number of articles in entire pubmed Once this has been created, the pathways obtained from the QTL and microarray pathway analysis workflows are analysed. The documents from a search of each pathway in pubmed are merged into a single document of pathway abstracts. The (unweighted) phenotype terms are then searched in the pathways corpus. This will determine if the phenotype term is listed with the given pathway.  The higher the value the better the score.Each term is then assigned a weight as: Y = log((e / f) / (c /d)) where:	a = number of occurnaces of individual terms in pathway corpusb = number of abstracts in pathway corpus (per pathway)c = number of occurnaces of individual terms in entire pubmedd = number of articles in entire pubmed The weighted terms are then given a link score. This is the total of: X + Y. This gives the link between the pathway and the phenotype a score / significance value. The higher the score the more appropriate/interesting the link between the pathway and the phenotype. The terms are also ranked according to the number of pathways which have been given a weight. This is calculated as: W = Sum( X + Y). The higher the value the better the score.",
"http://www.myexperiment.org/workflows/856/versions/1.html","Retrieve details on genetic marker by UniSTS numerical UID","2009-08-1917:27:42","","http://www.myexperiment.org/workflows/856/download/Retrieve_details_on_genetic_marker_by_UniSTS_numerical_UID-v1.t2flow?version=1","/users/1169","Steffen MÃ¶ller","taverna 2","/users/1169,","Steffen MÃ¶ller,","This upload shell help to locate a bug in Taverna, which may have crippled the contents of this file and only half displays it now.",0, 0, ,
"http://www.myexperiment.org/workflows/856/versions/2.html","Retrieve details on genetic marker by UniSTS numerical UID","2009-08-1917:27:42","","http://www.myexperiment.org/workflows/856/download/Retrieve_details_on_genetic_marker_by_UniSTS_numerical_UID-v2.t2flow?version=2","/users/1169","Steffen MÃ¶ller","taverna 2","/users/1169,","Steffen MÃ¶ller,","The workflow retrieves the marker's primers and the organism name - if available. The organism name may not be unique for a given marker. The primers should be. It would be nice if some good soul could investigate how to retrieve the various mappings from the site. The retrieval of the primers is thought to prepare for a manual mapping of the marker's chromosomal location.",0, 0, ,
"http://www.myexperiment.org/workflows/856/versions/3.html","Retrieve details on genetic marker by UniSTS numerical UID","2009-08-1917:27:42","","http://www.myexperiment.org/workflows/856/download/Retrieve_details_on_genetic_marker_by_UniSTS_numerical_UID-v3.t2flow?version=3","/users/1169","Steffen MÃ¶ller","taverna 2","/users/1169,","Steffen MÃ¶ller,","The workflow retrieves the marker's primers and the organism name - if available. The organism name may not be unique for a given marker. The primers should be. It would be nice if some good soul could investigate how to retrieve the various mappings from the site. The retrieval of the primers is thought to prepare for a manual mapping of the marker's chromosomal location.",0, 0, ,
"http://www.myexperiment.org/workflows/857/versions/1.html","Retrieve UniSTS numerical UID from name of genetic marker","2009-08-1913:48:47","","http://www.myexperiment.org/workflows/857/download/Retrieve_UniSTS_numerical_UID_from_name_of_genetic_marker-v1.t2flow?version=1","/users/1169","Steffen MÃ¶ller","taverna 2","/users/1169,","Steffen MÃ¶ller,",,0, 0, ,
"http://www.myexperiment.org/workflows/857/versions/2.html","Retrieve UniSTS numerical UID from name of genetic marker","2009-08-1913:48:47","","http://www.myexperiment.org/workflows/857/download/Retrieve_UniSTS_numerical_UID_from_name_of_genetic_marker-v2.t2flow?version=2","/users/1169","Steffen MÃ¶ller","taverna 2","/users/1169,","Steffen MÃ¶ller,",,0, 0, ,
"http://www.myexperiment.org/workflows/858/versions/1.html","KEGG Pasrer","2009-08-1916:03:07","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow parses a KEGG species database into an Ondex Graph graphId - the ID of the Graph.inputDir - the plugin input directorySpecies - Use this parameter to specify the species to be loaded from the kegg database. Default value is all.ParseSequences - KEGG species code. Default value is false (boolean)ImportOrthologFillers - Import Ortholog Pathway Fillers. Default value is false (boolean)",
"http://www.myexperiment.org/workflows/859/versions/1.html","Table Parser","2009-08-1916:04:12","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow parsers a table (specified by the user), into an Ondex Graph on the web server.",
"http://www.myexperiment.org/workflows/860/versions/1.html","Tab Parser","2009-08-1916:05:20","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow takes in a tab separated file, and then parses specific rows and columns from the file into an Ondex Graph. Additional prarameters are provided, though these are optional: graphId 	Long 	the ID of the Graph (REQUIRED)input 	String 	the plugin input (REQUIRED)skip 	Integer 	How many rows to skip at begin of document (Optional). Default value is 22.fromCol 	Integer 	Index of concept parser id for from concept. Default value is 0. (REQUIRED)toCol 	Integer 	Index of concept parser id for to concept. Default value is 1. (REQUIRED)fromNameCol - ConceptName index for use with from concept. (Optional)toNameCol - ConceptName index for use with to concept. (Optional)fromPhenoCol - GDS Pheno index for use with from concept. (Optional)toPhenoCol - GDS Pheno index for use with to concept. (Optional)confCol - Index of confidence score of relation. (Optional)TaxId - Which taxonomy id should be assigned to the sequences. (Optional)CC - The type of the concepts (e.g. target, gene, protein) (Optional). Default value is Thing.CV - The source of the concepts (e.g. TAIR, KEGG, unknown) (Optional).  Default value is unknown.RelationType - The relation type to create for every line in the tabular file (Optional)Threshold - Import threshold for confidence value (Optional)fromTaxId - TaxID index for use with from concept. (Optional)toTaxId - TaxID index for use with to concept (Optional)",
"http://www.myexperiment.org/workflows/861/versions/1.html","All Pairs Filter","2009-08-1916:06:29","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a given Ondex graph based on the occurrence of directed edges within the graph. Only those concepts that have directional edges are returned to the user, in the form of a new graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph. Optional parameter. If no output graph is specified filtered items will be removed from the input graph.GdsWeight - The name of the GDS type to be used as edge weights.OnlyDirectedEdges - Follow edges only according to their direction (Optional). Default value is false. (boolean)InverseWeight - Takes the inverse of the GDS value as the weight. This is for probabilities or scores (Optional). Default value is false. (boolean)",
"http://www.myexperiment.org/workflows/862/versions/1.html","Clean GO Filter","2009-08-1916:07:27","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters an Ondex graph, by cleaning up any GO terms within the Graph (?). The result is a new Ondex graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph (Optional).  If no output graph is specified filtered items will be removed from the input graph.",
"http://www.myexperiment.org/workflows/863/versions/1.html","Clean UniProt Filter","2009-08-1916:08:48","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a given Ondex graph, removing any erroneous UniProt data. The result is a new Ondex graph that conatains only connected UniProt data. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph. Optional parameter. If no output graph is specified filtered items will be removed from the input graph.",
"http://www.myexperiment.org/workflows/864/versions/1.html","Concept Class Filter","2009-08-1916:10:36","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a  Ondex graph based on a specific concept class. The result is a new Ondex graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph (Optional). If no output graph is specified filtered items will be removed from the input graph.TargetConceptClass - Target Concept Class to filter out.RefactorTrinaries - Where the qualifier of a trinary relation is out of scope create a binary relation, excluding the qualifier (Optional).  Default value is true.(boolean)cv_to_filter - Filter the concepts of specified CV (Optional)acc_file - A file of accessions of type cv_to_filter; one per line (Optional)Exclude - Exclude concepts and relations that meet the given crieria, else if false then exclusivly include (Optional) Default value is true.(boolean)AttributeName - In case of ternary relation removal, average over this AttributeName (Optional)",
"http://www.myexperiment.org/workflows/865/versions/1.html","Concept Class Neighbours Filter","2009-08-1916:11:56","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a given Ondex graph based on a user defined concept class. The neighbours of the concept class are returned as a new Ondex graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph (Optional). If no output graph is specified filtered items will be removed from the input graph.Depth - The Depth (distance from seed in relations) to apply the filter to.ConceptClass - The Concepts of ConceptClass seed the algorithm with (Optional)RelationTypeAtDepth - Restricts RelationType at a given depth define by an array of pairs (depth1,rtsa;depth2,rtsb...) when no concept class at a depth is specified the default is any allowed (Optional)",
"http://www.myexperiment.org/workflows/866/versions/1.html","Context Consensus Filter","2009-08-1916:13:11","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a given Ondex graph according to a consensus with regards to a specific context (concept list). The result is a new Ondex graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph. Optional parameter. If no output graph is specified filtered items will be removed from the input graph.Threshold - Double value representing the share of contexts that qualify a graph element for being returned. Example: 0.5 (Optional). Default value is 0.5. Valid value range is 0.0 to 1.0.ContextList - Comma separated List of concept ids that serve as contexts, defining the set to work on. Leave blank for all (Optional).",
"http://www.myexperiment.org/workflows/867/versions/1.html","Context Filter","2009-08-1916:14:13","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters an Ondex graph according to a given context. The result is a new Ondex graph with only selected contexts. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph (Optional). If no output graph is specified filtered items will be removed from the input graph.ContextID - The Concept ID of the Context that starts the path.ContextBoolean - Defines two ContextIDs and a boolean operation (AND, OR, NOT), e.g. 11 AND 23 (Optional).",
"http://www.myexperiment.org/workflows/868/versions/1.html","CV Filter","2009-08-1916:15:20","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a given Ondex graph according to a controlled vocabulary specified by the user. The result is a new Ondex graph with only those concepts that passed the filter. The parameters that can be used with this service graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph. Optional parameter. If no output graph is specified filtered items will be removed from the input graph.CV - A CV to include/exclude Concepts and Relations of (see Exclude param).RefactorTrinaries - Where the qualifier of a trinary relation is out of scope create a binary relation, excluding the qualifier. Default value is true. (boolean)Exclude - Exclude concepts and relations that meet the given crieria, else if false then exclusivly include. Default value is true. (boolean)",
"http://www.myexperiment.org/workflows/869/versions/1.html","Evidence Type Filter","2009-08-1916:16:15","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a given Ondex graph according to some user defined evidence values. The result is a new Ondex graph.The parameters that can be used with this web service are given below: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph. Optional parameter. If no output graph is specified filtered items will be removed from the input graph.EvidenceType - EvidenceType to be taken into consideration.RefactorTrinaries - Where the qualifier of a trinary relation is out of scope create a binary relation, excluding the qualifier?. (Optional) Default value is false. (boolean)Exclude - If true exclude concepts and/or relations from graph, else exclude all non-matching concepts and/or relations. (Optional)  Default value is false.(boolean)OnConcepts - If true filter on concepts, else on relations. Default value is true. (boolean)",
"http://www.myexperiment.org/workflows/870/versions/1.html","GDS Value Filter","2009-08-1916:17:27","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a given Ondex graph based on a given GDS value supplied by the user. The result is a new Ondex graph with filtered content. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph. Optional parameter. If no output graph is specified filtered items will be removed from the input graph.AttributeName - AttributeName to filter out.GDSValue - A value which will be matched against the GDSs.Including - If true keep only concepts/relations that have GDS value or dont have the GDS at all. If false remove concepts that have GDS value. Default value is true. Valid values are [true, false].ConceptClass - ConceptClass to filter within (only concepts within this class will be removed): default = all. (Optional)RelationType - RelationType to filter within (only relations connected with this type will be removed): default = all (Optional)IgnoreValue - Removes concepts/relations that dont have the AttributeName (Optional)  Default value is false. Valid values are [true, false].Operator - A operator that will be used in conjuction with the gds value to determine if the object should be kept or not e.g. (&gt;,&lt;,=,&lt;=,&gt;=) NB mathmatical operators that are not = are only evaluated on Number Objects, all else will be false. i.e. a &gt;= b is false but a &gt;= a is true. Optional parameter. Default value is =.Modulus - Treat values as modulus in comparison (Optional) - boolean",
"http://www.myexperiment.org/workflows/871/versions/1.html","Genomic Filter","2009-08-1916:19:01","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a given Ondex graph according to a chromosomal region, or QTL region. The result is a new Ondex graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph (Optional). If no output graph is specified filtered items will be removed from the input graph.ContextID - The Concept ID of the Context (Chromosome).From - The start position on the chromosome, e.g. 100.To - The stop position on the chromosome, e.g. 30000.Keyword - The keyword of interest, e.g. branching (Optional).Algorithm - A method to show the subnetwork of interest, e.g Neighbourhood (Optional). Default value is Neighbourhood.",
"http://www.myexperiment.org/workflows/872/versions/1.html","Graph Cloner","2009-08-1916:22:13","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow clones a given Ondex Graph, based on an Ondex Graph identifier.",
"http://www.myexperiment.org/workflows/873/versions/1.html","Isolate Clusters Filter","2009-08-1916:23:45","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a given Ondex graph, isolating clusters within the graph and returning only those clusters as a new graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph (Optional). If no output graph is specified filtered items will be removed from the input graph.TargetConceptClass - Target Concept Class to be contained in clusters.",
"http://www.myexperiment.org/workflows/874/versions/1.html","One Pair Shortest Path Filter","2009-08-1916:24:41","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a pre-existing Ondex graph using the shortest path algorithm on the graph. The result is a new Ondex graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph. Optional parameter. If no output graph is specified filtered items will be removed from the input graph.StartConceptID - The Concept ID that starts the pathEndConceptID - The Concept ID that ends the pathUseWeights - Use gds values as edge weights (Optional)  Default value is false.(Boolean)GdsWeight - The name of the GDS type to be used as edge weights. (Optional)OnlyDirectedEdges - Follow edges only according to their direction (Optional)  Default value is false. (Boolean)InverseWeight - Takes the inverse of the GDS value as the weight. This is for probabilities or scores (Optional) Default is false. (Boolean)",
"http://www.myexperiment.org/workflows/875/versions/1.html","Optimal Paths Filter","2009-08-1916:25:49","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a given Ondex graph based on the optimal path between one or more concepts. The result is a new Ondex graph. The parameters that can be used with service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph. Optional parameter. If no output graph is specified filtered items will be removed from the input graph.PathwayDefinition - pathway definition file.StatisticsOutputDir - The directory to output statistics (Optional).IncludeAllOfTargetConceptClass - Include All Target Concept Class in the filtered graph (Optional). Default value is false. (Boolean)ReturnQualifiers - Returns all qualifiers for all relations in the filtered graph (Optional).  Default value is true. (boolean)GDSConsistancy - The AttributeName for a gds; the value of which is forced to be consistant accross a pathway..e.g. TAXID. Optional parameter.",
"http://www.myexperiment.org/workflows/876/versions/1.html","Pfam Based Ortholog Filter","2009-08-1916:26:55","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters an Ondex graph based on the occurrence of Pfam orthologs within the graph. The result is a new Ondex graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph (Optional). If no output graph is specified filtered items will be removed from the input graph.ConfidenceThreshold - Threshold value for inparanoid confidence. Default value is 100.AnnotationScoreThreshold - Threshold value for GO annotation score. Default value is 0.75.PfamSetIntersectionThreshold - Minimal number of matching protein families for a valid orthology relation. Default value is 2.TermDepthCutoff - Maximal distance between GO terms to be considered similar. Default value is 4.GoDataDirectory - Data directory of go file.",
"http://www.myexperiment.org/workflows/877/versions/1.html","Relation Neighbours Filter","2009-08-1916:28:09","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a given Ondex graph based on some neighbour parameters supplied by the user. The result is a new Ondex graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph. Optional parameter. If no output graph is specified filtered items will be removed from the input graph.Depth - The Depth (distance from seed in relations) to apply the filter toConceptID - The Concept ID to seed the algorithm with (Optional).ConceptAccession - Concept accession to apply relation neighbours search to all matching concepts (Optional).ConceptClass - ConceptClass to look for Concepts within if accession or name has been specified (Optional).ConceptAccessionCV - CV to look for Concept accession within (Optional).ConceptName - Concept name to apply relation neighbours search to all matching concepts (Optional).RelationTypeAtDepth - Restricts RelationType at a given depth define by an array of pairs (depth1,rta;depth2,rtb...) when no relation type at a depth is specified the default is any allowed. A valid relation will contain the relation in its relation type set. Where possible define the RelationType, this will be faster (Optional).",
"http://www.myexperiment.org/workflows/878/versions/1.html","Relation Type Filter","2009-08-1916:29:10","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a pre-existing ONdex graph based on a some paramters provided by the user. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph (Optional) parameter. If no output graph is specified filtered items will be removed from the input graph.TargetRelationType - Target RelationType to filter out.ConceptClassRestriction - Concept Class Restriction as ordered pair representing from/to Concepts in an evaluated Relation (Optional)CVRestriction - A CV Restriction as an ordered pair representing from and to Concepts in an evaluated Relation (Optional)RemoveTernaryRelations - Set false if ternary relations should not be removed (Optional)",
"http://www.myexperiment.org/workflows/879/versions/1.html","Shortest Path","2009-08-1916:30:35","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a given Ondex graph according to the shortest path (graph) algorithm. The result is a new Ondex graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph (Optional). If no output graph is specified filtered items will be removed from the input graph.StartConceptID - The Concept ID that starts the path. Valid value range is 1 to 2147483647.UseWeights - Use gds values as edge weights (Optional). Default value is false. (boolean)GdsWeight - The name of the GDS type to be used as edge weights (Optional).OnlyDirectedEdges - Follow edges only according to their direction (Optional). Default value is false. (boolean)InverseWeight - Takes the inverse of the GDS value as the weight. This is for probabilities or scores (Optional). Default value is false. (boolean)",
"http://www.myexperiment.org/workflows/880/versions/1.html","Significance Filter","2009-08-1916:31:24","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a given Ondex graph according to a level of significance set by the user. The result is a new Ondex graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph (Optional). If no output graph is specified filtered items will be removed from the input graph.TargetAttributeName - Target AttributeName to filter for significance.Significance - A significance value to filter relations with. Default value is 15.0.Inverse - If set to true only relation smaller than Significance will be kept (Optional). Default value is false (boolean)AbsoluteValues - Absolute GDS values when testing for significance (Optional). Default value is false. (boolean)Remove_no_att - Remove elements without the attribute, if set to true (Optional). Default value is false. (boolean)ConceptMode - If true filters concepts, if false filters realtions (Optional). Default value is false. (boolean)",
"http://www.myexperiment.org/workflows/881/versions/1.html","SubGraph Filter","2009-08-1916:38:17","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a given Ondex graph to return a new ondex sub-graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph. Optional parameter. If no output graph is specified filtered items will be removed from the input graph.ConceptID - The root concept to start at. Valid value range is 1 to 2147483647.FirstRelationType - RelationType limitation for depth 1 (Optional).FirstConceptClass - ConceptClass limitation for depth 1 (Optional).FirstRelationDirection - Direction of relation for depth 1, one of [both, incoming, outgoing] (Optional). Default value is both. Valid values are [incoming, outgoing, both].SecondRelationType - RelationType limitation for depth 2 (Optional).SecondConceptClass - ConceptClass limitation for depth 2 (Optional).SecondRelationDirection - Direction of relation for depth 2, one of [both, incoming, outgoing] (Optional). Default value is both. Valid values are [incoming, outgoing, both].ThirdRelationType - RelationType limitation for depth 3 (Optional).ThirdConceptClass - ConceptClass limitation for depth 3 (Optional).ThirdRelationDirection - Direction of relation for depth 3, one of [both, incoming, outgoing] (Optional). Default value is both. Valid values are [incoming, outgoing, both].ForthRelationType - RelationType limitation for depth 4 (Optional).ForthConceptClass - ConceptClass limitation for depth 4 (Optional).ForthRelationDirection - Direction of relation for depth 4, one of [both, incoming, outgoing (Optional). Default value is both. Valid values are [incoming, outgoing, both].FifthRelationType - RelationType limitation for depth 5 (Optional).FifthConceptClass  - ConceptClass limitation for depth 5 (Optional).FifthRelationDirection - Direction of relation for depth 5, one of [both, incoming, outgoing] (Optional). Default value is both. Valid values are [incoming, outgoing, both].",
"http://www.myexperiment.org/workflows/881/versions/2.html","SubGraph Filter","2009-08-1916:38:17","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters a given Ondex graph to return a new ondex sub-graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph. Optional parameter. If no output graph is specified filtered items will be removed from the input graph.ConceptID - The root concept to start at. Valid value range is 1 to 2147483647.FirstRelationType - RelationType limitation for depth 1 (Optional).FirstConceptClass - ConceptClass limitation for depth 1 (Optional).FirstRelationDirection - Direction of relation for depth 1, one of [both, incoming, outgoing] (Optional). Default value is both. Valid values are [incoming, outgoing, both].SecondRelationType - RelationType limitation for depth 2 (Optional).SecondConceptClass - ConceptClass limitation for depth 2 (Optional).SecondRelationDirection - Direction of relation for depth 2, one of [both, incoming, outgoing] (Optional). Default value is both. Valid values are [incoming, outgoing, both].ThirdRelationType - RelationType limitation for depth 3 (Optional).ThirdConceptClass - ConceptClass limitation for depth 3 (Optional).ThirdRelationDirection - Direction of relation for depth 3, one of [both, incoming, outgoing] (Optional). Default value is both. Valid values are [incoming, outgoing, both].ForthRelationType - RelationType limitation for depth 4 (Optional).ForthConceptClass - ConceptClass limitation for depth 4 (Optional).ForthRelationDirection - Direction of relation for depth 4, one of [both, incoming, outgoing (Optional). Default value is both. Valid values are [incoming, outgoing, both].FifthRelationType - RelationType limitation for depth 5 (Optional).FifthConceptClass  - ConceptClass limitation for depth 5 (Optional).FifthRelationDirection - Direction of relation for depth 5, one of [both, incoming, outgoing] (Optional). Default value is both. Valid values are [incoming, outgoing, both].",
"http://www.myexperiment.org/workflows/882/versions/1.html","Tranitive Filter","2009-08-1916:34:16","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow filters an Ondex graph to extract a sub-graph. The result is a new Ondex graph containing only the transitive sub-graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph (Optional). If no output graph is specified filtered items will be removed from the input graph.CV - Seed cv that will be used to extract the subgraph (Optional).AttributeName - Seed attribute name that will be used to extract the subgraph (Optional).level - Cutoff level (Optional).",
"http://www.myexperiment.org/workflows/883/versions/1.html","Unconnected Filter","2009-08-1916:35:08","","","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow removes any unconnected nodes from a given Ondex graph through filtering, and returns a new Ondex Graph. The parameters that can be used with this service are as follows: graphId - the ID of the input Graph.outputGraphId - the ID of the output Graph. Optional parameter. If no output graph is specified filtered items will be removed from the input graph.RemoveContextDependencies - Set true to remove context dependencies, otherwise unconnected concepts will still remain in the graph (Optional). Default value is false. (boolean)ConceptClassRestriction - A Concept Class Restriction as an ordered pair representing from and to Concepts in an evaluated Relation. (add the reverse compliment if direction is not important) - (Optional)",
"http://www.myexperiment.org/workflows/884/versions/1.html","Split text/string into its lines and filter on those to return subset or values","2009-08-1917:23:13","","http://www.myexperiment.org/workflows/884/download/Split_text_string_into_its_lines_and_filter_on_those_to_return_subset_or_values-v1.t2flow?version=1","/users/1169","Steffen MÃ¶ller","taverna 2","/users/1169,","Steffen MÃ¶ller,","When retrieving a URL or soemthing alike, one can often identify the region of interest as a single line. Besides the expected output, also some interim values, like the lines split are forwarded, to allow some straight-forward cascading of filters with reduced redundancy.",1, 0, ,
"http://www.myexperiment.org/workflows/884/versions/2.html","Split text/string into its lines and filter on those to return subset or values","2009-08-1917:23:13","","http://www.myexperiment.org/workflows/884/download/Split_text_string_into_its_lines_and_filter_on_those_to_return_subset_or_values-v2.t2flow?version=2","/users/1169","Steffen MÃ¶ller","taverna 2","/users/1169,","Steffen MÃ¶ller,","When retrieving a URL or soemthing alike, one can often identify the region of interest as a single line. Besides the expected output, also some interim values, like the lines split are forwarded, to allow some straight-forward cascading of filters with reduced redundancy.",1, 0, ,
"http://www.myexperiment.org/workflows/892/versions/1.html","Spreadsheet Importer","2009-08-2414:11:52","","http://www.myexperiment.org/workflows/892/download/Spreadsheet_Importer-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow is designed to import a spreadhseet from a local computer. The imported spreadsheet is parsed to extract the first two columns, A and B, for all rows in the spreadsheet. These are returned as two separate outputs.",0, 0, ,
"http://www.myexperiment.org/workflows/900/versions/1.html","caDSR Data service query in caGrid","2010-05-2519:16:58","2010-06-1104:50:15","http://www.myexperiment.org/workflows/900/download/caDSR_Data_service_query_in_caGrid-v1.t2flow?version=1","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","This workflow is used as an example in this wiki article: <a href=https://wiki.cagrid.org/display/knowledgebase/How+to+Create+CaGrid+Workflow+Using+Taverna+2>https://wiki.cagrid.org/display/knowledgebase/How+to+Create+CaGrid+Workflow+Using+Taverna+2</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/900/versions/2.html","caDSR Data service query in caGrid","2010-05-2519:16:58","2010-06-1104:50:15","http://www.myexperiment.org/workflows/900/download/caDSR_Data_service_query_in_caGrid-v2.t2flow?version=2","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","This workflow is used as an example in this wiki article: <a href=https://wiki.cagrid.org/display/knowledgebase/How+to+Create+CaGrid+Workflow+Using+Taverna+2>https://wiki.cagrid.org/display/knowledgebase/How+to+Create+CaGrid+Workflow+Using+Taverna+2</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/900/versions/3.html","caDSR Data service query in caGrid","2010-05-2519:16:58","2010-06-1104:50:15","http://www.myexperiment.org/workflows/900/download/caDSR_Data_service_query_in_caGrid-v3.t2flow?version=3","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","This workflow is used as an example in this wiki article: <a href=https://wiki.cagrid.org/display/knowledgebase/How+to+Create+CaGrid+Workflow+Using+Taverna+2 rel=nofollow>https://wiki.cagrid.org/display/knowledgebase/How+to+Create+CaGrid+Workflow+Using+Taverna+2</a> &nbsp; Tested with Taverna 2.1.2 as of 6/10/2010",-1, 0, ,
"http://www.myexperiment.org/workflows/902/versions/1.html","chicken_ensembl_gene_id","2009-09-0715:00:01","2009-09-0914:21:48","http://www.myexperiment.org/workflows/902/download/chicken_ensembl_gene_id-v1.t2flow?version=1","/users/1355","Rory","taverna 2","/users/1355,","Rory,","Accepts a chromosome eg. 1 and returns the ensembl gene ids for that chromosome",0, 0, ,
"http://www.myexperiment.org/workflows/906/versions/1.html","Get Bioentity from Organism","2009-09-0815:12:57","2009-09-1414:16:40","http://www.myexperiment.org/workflows/906/download/Get_Bioentity_from_Organism-v1.t2flow?version=1","/users/1307","Pedro Lopes","taverna 2","/users/1307,","Pedro Lopes,","GeNS workflow that lists the identifiers corresponding to a given species and data type. For instance, list all OMIM associated with the human species. <span class=Apple-style-span style=font-family: 'Times New Roman'; font-size: medium; ><div style=background-color: rgb(255, 255, 255); padding-top: 5px; padding-right: 5px; padding-bottom: 5px; padding-left: 5px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; font-family: Arial, Verdana, sans-serif; font-size: 12px; ><b>Disclaimer:</b>&nbsp;This workflow is just a simple example designed for academic purposes.</div></span>",0, 0, ,
"http://www.myexperiment.org/workflows/907/versions/1.html","Sample Entity Converter","2009-09-0815:13:44","2009-09-1414:14:32","http://www.myexperiment.org/workflows/907/download/Sample_Entity_Converter-v1.t2flow?version=1","/users/1307","Pedro Lopes","taverna 2","/users/1307,","Pedro Lopes,","<b>&nbsp;Disclaimer:</b>  This workflow is just a simple example designed for academic purposes.",-1, 0, ,
"http://www.myexperiment.org/workflows/908/versions/1.html","Workflow for provenance testing -- example 1","2009-09-1012:15:02","","http://www.myexperiment.org/workflows/908/download/Workflow_for_provenance_testing_--_example_1-v1.t2flow?version=1","/users/500","Paolo","taverna 2","/users/500,","Paolo,","this simply includes a few beanshells and is used for testing our provenance capture and query algorithms",-1, 0, ,
"http://www.myexperiment.org/workflows/909/versions/1.html","example of a 2-deep nested workflow","2009-09-1100:44:53","","http://www.myexperiment.org/workflows/909/download/example_of_a_2-deep_nested_workflow-v1.t2flow?version=1","/users/500","Paolo","taverna 2","/users/500,","Paolo,","used for testing provenance as well as experimenting with Scufl2 specfications",-1, 0, ,
"http://www.myexperiment.org/workflows/911/versions/1.html","EBI_InterProScan_T2","2009-09-1111:49:11","","http://www.myexperiment.org/workflows/911/download/EBI_InterProScan_T2-v1.t2flow?version=1","/users/2791","Steve Crouch","taverna 2","/users/2791, /users/5,","Steve Crouch, Stian Soiland-Reyes,",,2, 0, ,
"http://www.myexperiment.org/workflows/912/versions/1.html","Search GeNS BioEntity","2009-09-1511:32:52","2009-09-1511:34:26","http://www.myexperiment.org/workflows/912/download/Search_GeNS_BioEntity-v1.t2flow?version=1","/users/1307","Pedro Lopes","taverna 2","/users/1307,","Pedro Lopes,","&nbsp;This workflow returns a list of know associations between an organism and a data type. All identifiers correspond to GeNS database identifiers. &nbsp; <span class=Apple-style-span style=font-family: arial, helvetica, clean, sans-serif; font-size: 11px; line-height: 14px; >&nbsp;Disclaimer: This workflow is just a simple example designed for academic purposes.</span>",-1, 0, ,
"http://www.myexperiment.org/workflows/913/versions/1.html","Search GeNS DataType","2009-09-1511:36:00","","http://www.myexperiment.org/workflows/913/download/Search_GeNS_DataType-v1.t2flow?version=1","/users/1307","Pedro Lopes","taverna 2","/users/1307,","Pedro Lopes,","&nbsp;This workflow returns a single GeNS identifier corresponding to the given data type. &nbsp; <span class=Apple-style-span style=font-family: arial, helvetica, clean, sans-serif; font-size: 11px; line-height: 14px; >&nbsp;Disclaimer: This workflow is just a simple example designed for academic purposes.</span>",0, 0, ,
"http://www.myexperiment.org/workflows/914/versions/1.html","Search GeNS Organism","2009-09-1511:36:54","","http://www.myexperiment.org/workflows/914/download/Search_GeNS_Organism-v1.t2flow?version=1","/users/1307","Pedro Lopes","taverna 2","/users/1307,","Pedro Lopes,","&nbsp;This workflow returns a GeNS identifier for a given organism. &nbsp; <span class=Apple-style-span style=font-family: arial, helvetica, clean, sans-serif; font-size: 11px; line-height: 14px; >&nbsp;Disclaimer: This workflow is just a simple example designed for academic purposes.</span>",0, 0, ,
"http://www.myexperiment.org/workflows/916/versions/1.html","BioMart and Emboss Analysis (T2)","2009-09-1515:05:11","","http://www.myexperiment.org/workflows/916/download/BioMart_and_Emboss_Analysis__T2_-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/30,","Katy Wolstencroft, Alan Williams,","This is the Taverna 2 version of the Biomart and Emboss Analysis workflow <a href=../../../workflows/158>http://www.myexperiment.org/workflows/158</a> &nbsp; Using Biomart and EMBOSS soaplab services, This workflow retrieves a number of sequences from 3 species: mouse, human, rat; align them, and returns a plot of the alignment result. Corresponding sequence ids are also returned. Previous versions of this workflow only returned sequences with an ID mapped to a MIM_morbid_accession. This was primarily to reduce the number of alignments returned becuase it is an example workflow. This option is no longer available through BioMart, so this version returns all sequences on your chosen chromosome. To reduce the number of sequences returned during testing, try changing the filter on the hsapiens_gene_ensembl to the Y chromosome, or change the base pair range. I have also added control links before the start of createFasta. This is necessary due to a bug we discovered in the latest version of Taverna. This will be looked into soon &nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/931/versions/1.html","Pathways and Gene annotations for QTL region","2009-11-2014:04:37","2009-11-2014:04:39","http://www.myexperiment.org/workflows/931/download/Pathways_and_Gene_annotations_for_QTL_region-v1.xml?version=1","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in the Pig, Sus scrofa. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",39, 7, regex_2, species, kegg_pathway_release, remove_pathway_duplicates, remove_nulls_3, remove_Nulls, remove_pathway_nulls, add_uniprot_to_string, split_gene_ids, REMOVE_NULLS_2, add_ncbi_to_string, merge_gene_desc, remove_pathway_nulls_2, remove_duplicate_kegg_genes, merge_reports, create_report, split_for_duplicates, merge_genes_and_pathways, merge_genes_and_pathways_2, merge_entrez_genes, merge_pathway_list_1, remove_uniprot_duplicates, merge_uniprot_ids, merge_pathway_list_2, concat_kegg_genes, merge_kegg_references, merge_pathway_desc, merge_genes_and_pathways_3, remove_entrez_duplicates, Kegg_gene_ids_2, gene_descriptions, get_pathway_descriptions, Kegg_gene_ids, Get_pathways, binfo, flatten_pathway_files, getcurrentdatabase, genes_in_qtl, sscrofa_gene_ensembl, ,
"http://www.myexperiment.org/workflows/931/versions/2.html","Pathways and Gene annotations for QTL region","2009-11-2014:04:37","2009-11-2014:04:39","http://www.myexperiment.org/workflows/931/download/Pathways_and_Gene_annotations_for_QTL_region-v2.xml?version=2","/users/43","Paul Fisher","taverna 1","/users/43,","Paul Fisher,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in the Pig, Sus scrofa. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",40, 6, regex_2, kegg_pathway_release, remove_uniprot_duplicates, merge_genes_and_pathways, remove_pathway_duplicates, remove_duplicate_ids, merge_reports, remove_duplicate_kegg_genes, remove_entrez_duplicates, merge_pathway_desc, merge_genes_and_pathways_2, merge_patwhay_ids, merge_genes_and_pathways_3, merge_kegg_references, merge_pathway_list_1, split_for_duplicate_pathways, merge_gene_desc, merge_uniprot_ids, merge_pathway_list_2, merge_entrez_genes, concat_kegg_genes, split_for_duplicates, remove_nulls_3, add_uniprot_to_string, remove_Nulls, split_gene_ids, remove_pathway_nulls_2, add_ncbi_to_string, remove_pathway_nulls, REMOVE_NULLS_2, flatten_pathway_files, create_report, pathway_descriptions, gene_descriptions, Kegg_gene_ids, binfo, Kegg_gene_ids_2, Get_pathways, genes_in_qtl, sscrofa_gene_ensembl, ,
"http://www.myexperiment.org/workflows/932/versions/1.html","Example 3","2009-10-2017:00:59","","http://www.myexperiment.org/workflows/932/download/Example_3-v1.t2flow?version=1","/users/3374","Ruben","taverna 2","/users/3374,","Ruben,","Search in the Datenbank SWISS the Sequence 1220173",0, 0, ,
"http://www.myexperiment.org/workflows/933/versions/1.html","sample workflow","2009-10-2120:52:44","2009-10-2120:53:07","http://www.myexperiment.org/workflows/933/download/sample_workflow-v1.t2flow?version=1","/users/3755","Vikramk...","taverna 2","/users/3755,","Vikramkumra,",,-1, 0, ,
"http://www.myexperiment.org/workflows/936/versions/1.html","What is [query] from NCBI, EBI, UniProt and KEGG ?","2009-11-0304:29:15","2009-11-0304:29:19","http://www.myexperiment.org/workflows/936/download/What_is__query__from_NCBI__EBI__UniProt_and_KEGG__-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","This rdfiser query those four federated search services EB-Eye, KEGG LinkDB, NCBI Entrez and UniProt knowledgebase.&nbsp; RDF triples are returned for the founded documents and for search statistics with Bio2RDF normalised URIs.&nbsp; This workflow should be used responsibly because it can generate high load at the provider resources. test values: query = pdb4 query = hk1 query = hexokinase query = paget disease",0, 0, ,
"http://www.myexperiment.org/workflows/936/versions/2.html","What is [query] from NCBI, EBI, UniProt and KEGG ?","2009-11-0304:29:15","2009-11-0304:29:19","http://www.myexperiment.org/workflows/936/download/What_is__query__from_NCBI__EBI__UniProt_and_KEGG__-v2.t2flow?version=2","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","test values: query = paget diseasequery = pdb4query = hk1query = h1n1 <hr /> This rdfiser query those four federated search services EB-Eye, KEGG LinkDB, NCBI Entrez and UniProt knowledgebase.  RDF triples are returned for search statistics with Bio2RDF normalised URIs. This workflow should be used responsibly because it can generate high load at the provider resources. test values: query = paget diseasequery = pdb4query = hk1query = h1n1 <hr /> query = paget diseasequery = pdb4query = hk1query = h1n1",0, 0, ,
"http://www.myexperiment.org/workflows/939/versions/1.html","MY_Multi_Alignment_Phylo","2009-11-0314:46:38","","http://www.myexperiment.org/workflows/939/download/MY_Multi_Alignment_Phylo-v1.xml?version=1","/users/1601","Achille Zappa","taverna 1","/users/1601,","Achille Zappa,","This workflow performs a 'multiple' multiple sequence alignment and  phylogenetic analysis.",18, 1, Extract_Seq_Description, Get_Proteins_FASTA, ClustalW2, Clustal_Tcoffee, Muscle, Nested_Workflow4, Nested_Workflow5, ClustalW, Nested_Workflow6, Nested_Workflow10, Nested_Workflow8, Nested_Workflow3, Nested_Workflow1, Nested_Workflow2, Nested_Workflow9, Nested_Workflow11, Nested_Workflow, Nested_Workflow7, ,
"http://www.myexperiment.org/workflows/940/versions/1.html","find events in xray and radio","2010-03-1615:07:39","2010-03-1615:19:30","http://www.myexperiment.org/workflows/940/download/find_events_in_xray_and_radio-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Search for events which have data from Rhessi and Phoenix2.",-1, 0, ,
"http://www.myexperiment.org/workflows/940/versions/2.html","find events in xray and radio","2010-03-1615:07:39","2010-03-1615:19:30","http://www.myexperiment.org/workflows/940/download/find_events_in_xray_and_radio-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Search for events which have data from Rhessi and Phoenix2.",-1, 0, ,
"http://www.myexperiment.org/workflows/940/versions/3.html","find events in xray and radio","2010-03-1615:07:39","2010-03-1615:19:30","http://www.myexperiment.org/workflows/940/download/find_events_in_xray_and_radio-v3.t2flow?version=3","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Search for events which have data from Rhessi and Phoenix2.",-1, 0, ,
"http://www.myexperiment.org/workflows/940/versions/4.html","find events in xray and radio","2010-03-1615:07:39","2010-03-1615:19:30","http://www.myexperiment.org/workflows/940/download/find_events_in_xray_and_radio-v4.t2flow?version=4","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Search for events which have data from Rhessi and Phoenix2. inputs: Events between start and stop and between GOES min and max are considered for overlaps; if you want to search without GOES filter enter an empty string for these variables.",-1, 0, ,
"http://www.myexperiment.org/workflows/940/versions/5.html","find events in xray and radio","2010-03-1615:07:39","2010-03-1615:19:30","http://www.myexperiment.org/workflows/940/download/find_events_in_xray_and_radio-v5.t2flow?version=5","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,",,-1, 0, ,
"http://www.myexperiment.org/workflows/940/versions/6.html","find events in xray and radio","2010-03-1615:07:39","2010-03-1615:19:30","http://www.myexperiment.org/workflows/940/download/find_events_in_xray_and_radio-v6.t2flow?version=6","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","instruments: hessi_ec, phoenix2",-1, 0, ,
"http://www.myexperiment.org/workflows/940/versions/7.html","find events in xray and radio","2010-03-1615:07:39","2010-03-1615:19:30","http://www.myexperiment.org/workflows/940/download/find_events_in_xray_and_radio-v7.t2flow?version=7","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","instruments: hessiEC, phoenix2 attention: hessi name has changed!",-1, 0, ,
"http://www.myexperiment.org/workflows/941/versions/1.html","getTimololFromMassBank","2009-11-1008:58:05","2009-11-1008:59:56","http://www.myexperiment.org/workflows/941/download/getTimololFromMassBank-v1.t2flow?version=1","/users/514","http://...","taverna 2","/users/514,","http://sneumann.pip.verisignlabs.com/,","This workflow will retrieve a peaklist from a fixed entry (Timolol) from the MassBank spectral library. Note, the API is still in alpha, as of 10.11.2009. &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/942/versions/1.html","blastp using the MRS system","2009-11-1014:20:40","","http://www.myexperiment.org/workflows/942/download/blastp_using_the_MRS_system-v1.t2flow?version=1","/users/586","Bas Vroling","taverna 2","/users/586,","Bas Vroling,","This blastp workflow uses the blast service of MRS ( <a href=http://mrs.cmbi.ru.nl rel=nofollow>http://mrs.cmbi.ru.nl</a> ). Inputs are a sequence (only amino acids, not a fasta sequence) and a database. Databases that can be used are sprot, uniprot, trembl, pdb, refseq, ipi and gpcrdb.",0, 0, ,
"http://www.myexperiment.org/workflows/943/versions/1.html","Beanshell Test","2009-11-1023:15:40","","http://www.myexperiment.org/workflows/943/download/Beanshell_Test-v1.t2flow?version=1","/users/2","David Withers","taverna 2","","","A test workflow that uses beanshell services",-1, 0, ,
"http://www.myexperiment.org/workflows/945/versions/1.html","retrieving solar monitor urls for votable events","2009-11-1214:02:59","2009-11-1214:34:33","http://www.myexperiment.org/workflows/945/download/retrieving_solar_monitor_urls_for_votable_events-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,",,-1, 0, ,
"http://www.myexperiment.org/workflows/950/versions/1.html","workflow1","2009-11-1612:08:24","","http://www.myexperiment.org/workflows/950/download/workflow1-v1.t2flow?version=1","/users/5187","Jorgep","taverna 2","/users/5187,","Jorgep,",,0, 0, ,
"http://www.myexperiment.org/workflows/951/versions/1.html","workflow1","2009-11-1612:12:53","","http://www.myexperiment.org/workflows/951/download/workflow1-v1.t2flow?version=1","/users/5194","Susaninha","taverna 2","/users/5194,","Susaninha,",,0, 0, ,
"http://www.myexperiment.org/workflows/952/versions/1.html","Ex","2009-11-1612:37:25","","","/users/5190","Mventosa","taverna 2","/users/5190,","Mventosa,","Ex of exercise",
"http://www.myexperiment.org/workflows/954/versions/1.html","workflow1","2009-11-1614:12:30","","http://www.myexperiment.org/workflows/954/download/workflow1-v1.t2flow?version=1","/users/5187","Jorgep","taverna 2","/users/5187,","Jorgep,",,0, 0, ,
"http://www.myexperiment.org/workflows/955/versions/1.html","Multiple Choice Quiz","2009-11-1618:10:54","","http://www.myexperiment.org/workflows/955/download/Multiple_Choice_Quiz_-v1.t2flow?version=1","/users/345","George","taverna 2","/users/345,","George,","A multiple choice quiz constructed using the select webservice, control links and looping strategy.",-1, 0, ,
"http://www.myexperiment.org/workflows/956/versions/1.html","Search for BMURI in PubMed [myexperiment:pubmed_step1_search]","2009-11-1706:59:06","","http://www.myexperiment.org/workflows/956/download/Search_for_BMURI_in_PubMed__myexperiment_pubmed_step1_search_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","test values: subkect <hr /> test values: query = bio2rdfgraph =  <a href=http://bio2rdf rel=nofollow>http://bio2rdf</a> query = nur77 AND Rouillard,Cgraph =  <a href=http://nur77 rel=nofollow>http://nur77</a> <hr /> test values: query = bio2rdfgraph =  <a href=http://bio2rdf rel=nofollow>http://bio2rdf</a> query = nur77 AND Rouillard,Cgraph =  <a href=http://nur77 rel=nofollow>http://nur77</a> query = labriegraph =  <a href=http://labrie rel=nofollow>http://labrie</a>",3, 0, ,
"http://www.myexperiment.org/workflows/957/versions/1.html","Search for citations and related article in PubMed [myexperiment:pubmed_step2_link]","2009-11-1707:02:11","","http://www.myexperiment.org/workflows/957/download/Search_for_citations_and_related_article_in_PubMed__myexperiment_pubmed_step2_link_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","graph =  <a href=http://nur77 rel=nofollow>http://nur77</a> bmuri = <a href=http://bio2rdf.org/pubmed:18843482 rel=nofollow>http://bio2rdf.org/pubmed:18843482</a> <a href=http://bio2rdf.org/pubmed:18466322 rel=nofollow>http://bio2rdf.org/pubmed:18466322</a> <a href=http://bio2rdf.org/pubmed:17201484 rel=nofollow>http://bio2rdf.org/pubmed:17201484</a> <a href=http://bio2rdf.org/pubmed:14603264 rel=nofollow>http://bio2rdf.org/pubmed:14603264</a> <a href=http://bio2rdf.org/pubmed:12629527 rel=nofollow>http://bio2rdf.org/pubmed:12629527</a>",1, 0, ,
"http://www.myexperiment.org/workflows/958/versions/1.html","Sponge into Virtuoso triplestore the needed ressource from PubMed [myexperiment:pubmed_step3_describe]","2009-11-1707:09:01","2009-11-2703:32:15","http://www.myexperiment.org/workflows/958/download/Sponge_into_Virtuoso_triplestore_the_needed_ressource_from_PubMed__myexperiment_pubmed_step3_describe_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","query = labrie,fquery = labrie <hr /> query = labrie,fquery = labriequery = h1n1 <hr /> query = morissette,jquery = labrie,fquery = labriequery = h1n1 <hr /> Get a list of paper from pubmed.",6, 0, ,
"http://www.myexperiment.org/workflows/958/versions/2.html","Sponge into Virtuoso triplestore the needed ressource from PubMed [myexperiment:pubmed_step3_describe]","2009-11-1707:09:01","2009-11-2703:32:15","http://www.myexperiment.org/workflows/958/download/Sponge_into_Virtuoso_triplestore_the_needed_ressource_from_PubMed__myexperiment_pubmed_step3_describe_-v2.t2flow?version=2","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","query = labrie,f query = labrie query = labrie,f query = labrie query = h1n1 query = morissette,j query = labrie,f query = labrie query = h1n1 Get a list of paper from pubmed.",6, 0, ,
"http://www.myexperiment.org/workflows/960/versions/1.html","DNA sequence analysis pilot  (Blat)","2009-11-2011:12:43","2009-11-3009:35:38","http://www.myexperiment.org/workflows/960/download/DNA_sequence_analysis_pilot___Blat_-v1.xml?version=1","/users/36","Angela Luijf","taverna 1","/users/36, /users/1195, /users/648,","Angela Luijf, Barbera van Schaik, Glatard,","<a href=http://amc-app1.amc.sara.nl/twiki4/bin/view/BioLab rel=nofollow><em>http://amc-app1.amc.sara.nl/twiki4/bin/view/BioLab</em></a> &nbsp; <i>Workflow-based&nbsp; DNA sequence analysis on the Dutch Life Science Grid.</i> <i>This workflow is&nbsp;&nbsp;based on <a href=http://www.myexperiment.org/workflows/840 rel=nofollow>http://www.myexperiment.org/workflows/840</a>&nbsp;, the last component (Blast analysis) is replaced by Blat analysis<br /></i> &nbsp; &nbsp;",9, 3, BlatConfigFile, sff2fasta_configfile, empty, patternMatch_configfile, patternMatch, sffToFasta, Blat, sffExecutable, blatExe, ,
"http://www.myexperiment.org/workflows/960/versions/2.html","DNA sequence analysis pilot  (Blat)","2009-11-2011:12:43","2009-11-3009:35:38","http://www.myexperiment.org/workflows/960/download/DNA_sequence_analysis_pilot___Blat_-v2.xml?version=2","/users/36","Angela Luijf","taverna 1","/users/36, /users/1195, /users/648,","Angela Luijf, Barbera van Schaik, Glatard,","<em><a href=http://amc-app1.amc.sara.nl/twiki/bin/view/ rel=nofollow>http://amc-app1.amc.sara.nl/twiki/bin/view/</a></em> &nbsp; <i>Workflow-based&nbsp; DNA sequence analysis on the Dutch Life Science Grid.</i> <i>This workflow is&nbsp;&nbsp;based on <a href=http://www.myexperiment.org/workflows/840 rel=nofollow>http://www.myexperiment.org/workflows/840</a>&nbsp;, the last component (Blast analysis) is replaced by Blat analysis<br /></i> &nbsp; &nbsp;",7, 3, empty, patternMatch_configfile, sff2fasta_configfile, BlatConfigFile, sffToFasta, Blat, patternMatch, ,
"http://www.myexperiment.org/workflows/963/versions/1.html","caArray data retrieving","2009-11-2318:09:47","","http://www.myexperiment.org/workflows/963/download/caArray_data_retrieving-v1.t2flow?version=1","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","Query all the gene expression data in a caArray experiment. Returns a evenly divided gene expression data set with corresponding class information. They ca be later used as training and test data set in many classification algorithms. <hr /> Query all the gene expression data in a caArray experiment. Returns a evenly divided gene expression data set with corresponding class information. They can be later used as training and test data set in many classification algorithms.",0, 0, ,
"http://www.myexperiment.org/workflows/964/versions/1.html","genePattern data preprocessing","2010-05-2422:42:38","2010-05-2422:42:39","http://www.myexperiment.org/workflows/964/download/genePattern_data_preprocessing-v1.t2flow?version=1","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","preprocess data set using genePattern preProces service, the input &lt;data /&gt; should be in genePattern STATML format. Configuration parameters can be adjusted by changing the default  <hr /> preprocess data set using genePattern preProces service, the input &lt;data /&gt; should be in genePattern STATML format. <hr /> preprocess data set using genePattern preProces service, the input &lt;data /&gt; should be in genePattern STATML format. Configuration parameters can be adjusted by changing the string constants.",0, 0, ,
"http://www.myexperiment.org/workflows/964/versions/2.html","genePattern data preprocessing","2010-05-2422:42:38","2010-05-2422:42:39","http://www.myexperiment.org/workflows/964/download/genePattern_data_preprocessing-v2.t2flow?version=2","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","preprocess data set using genePattern preProces service, the input &lt;data /&gt; should be in genePattern STATML format. Configuration parameters can be adjusted by changing the default  <hr /> preprocess data set using genePattern preProces service, the input &lt;data /&gt; should be in genePattern STATML format. <hr /> preprocess data set using genePattern preProces service, the input &lt;data /&gt; should be in genePattern STATML format. Configuration parameters can be adjusted by changing the string constants.",0, 0, ,
"http://www.myexperiment.org/workflows/965/versions/1.html","Support-Vector-Machine (SVM) based data classification","2010-05-2422:34:31","2010-05-2422:34:32","http://www.myexperiment.org/workflows/965/download/Support-Vector-Machine__SVM__based_data_classification-v1.t2flow?version=1","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","Support-Vector-Machine based data classification <hr /> Support-Vector-Machine based data classification using genePattern SVM service, the input &lt;data /&gt; should be in genePattern STATML format.",0, 0, ,
"http://www.myexperiment.org/workflows/965/versions/2.html","Support-Vector-Machine (SVM) based data classification","2010-05-2422:34:31","2010-05-2422:34:32","http://www.myexperiment.org/workflows/965/download/Support-Vector-Machine__SVM__based_data_classification-v2.t2flow?version=2","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","Support-Vector-Machine based data classification <hr /> Support-Vector-Machine based data classification using genePattern SVM service, the input &lt;data /&gt; should be in genePattern STATML format.",0, 0, ,
"http://www.myexperiment.org/workflows/966/versions/1.html","demo_dbpedia_search2graph","2009-11-2706:57:36","","http://www.myexperiment.org/workflows/966/download/demo_dbpedia_search2graph-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","Do a full text search in DBpedia and load triples from results into a local Virtuoso graph. <hr /> Do a full text search in DBpedia and load result resource triples into a local Virtuoso graph.",1, 0, ,
"http://www.myexperiment.org/workflows/967/versions/1.html","Triplify KEGG database list [myexperiments:kegg_namespace2rdf]","2009-11-2818:06:16","2009-11-3020:17:03","http://www.myexperiment.org/workflows/967/download/Triplify_KEGG_database_list__myexperiments_kegg_namespace2rdf_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","knowledgescope, kegg, bio2rdf, banff_manifesto <hr /> TAG: knowledgescope, kegg, bio2rdf, banff_manifesto, rdf",0, 0, ,
"http://www.myexperiment.org/workflows/967/versions/2.html","Triplify KEGG database list [myexperiments:kegg_namespace2rdf]","2009-11-2818:06:16","2009-11-3020:17:03","http://www.myexperiment.org/workflows/967/download/Triplify_KEGG_database_list__myexperiments_kegg_namespace2rdf_-v2.t2flow?version=2","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","TAG: knowledgescope, kegg, bio2rdf, banff_manifesto, rdf",0, 0, ,
"http://www.myexperiment.org/workflows/977/versions/1.html","Triplify search results from KEGG bfind SOAP service [myexperiments:kegg_search2rdf]","2009-11-3016:21:05","2009-11-3020:48:50","http://www.myexperiment.org/workflows/977/download/Triplify_search_results_from_KEGG_bfind_SOAP_service__myexperiments_kegg_search2rdf_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","This workflow use KEGG's SOAP service provided to do a BFIND serch within one of the KEGG's official database. The results are returned in RDF ntriples format. TAG: kegg, search, knowledgescope, bio2rdf, bfind <hr /> This workflow use KEGG's SOAP service provided to do a BFIND serch within one of the KEGG's official database. The results are returned in RDF ntriples format. TAG: kegg, search, knowledgescope, bio2rdf, bfind, soap <hr /> This workflow use KEGG's SOAP service provided to do a BFIND serch within one of the KEGG's official database. The results are returned in RDF ntriples format. <hr /> test values: search = hk1kegg_namespace = path <hr /> test values: search = hk1search = parkinson diseasekegg_namespace = pathkegg_namespace = genes <hr /> This workflow use KEGG's SOAP service provided to do a BFIND serch within one of the KEGG's database. The results are returned in RDF ntriples format. TAG: kegg, search, knowledgescope, bio2rdf, bfind, soap <hr /> <hr /> test values: search = hk1search = parkinsonkegg_namespace = pathkegg_namespace = genes",4, 0, ,
"http://www.myexperiment.org/workflows/977/versions/2.html","Triplify search results from KEGG bfind SOAP service [myexperiments:kegg_search2rdf]","2009-11-3016:21:05","2009-11-3020:48:50","http://www.myexperiment.org/workflows/977/download/Triplify_search_results_from_KEGG_bfind_SOAP_service__myexperiments_kegg_search2rdf_-v2.t2flow?version=2","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","This workflow use KEGG's SOAP service provided to do a BFIND serch within one of the KEGG's official database.  The results are returned in RDF ntriples format.  TAG: kegg, search, knowledgescope, bio2rdf, bfind This workflow use KEGG's SOAP service provided to do a BFIND serch within one of the KEGG's official database.  The results are returned in RDF ntriples format.  TAG: kegg, search, knowledgescope, bio2rdf, bfind, soap This workflow use KEGG's SOAP service provided to do a BFIND serch within one of the KEGG's official database.  The results are returned in RDF ntriples format. test values: search = hk1 kegg_namespace = path test values: search = hk1 search = parkinson disease kegg_namespace = path kegg_namespace = genes This workflow use KEGG's SOAP service provided to do a BFIND serch within one of the KEGG's database.  The results are returned in RDF ntriples format.  TAG: kegg, search, knowledgescope, bio2rdf, bfind, soap test values: search = hk1 search = parkinson kegg_namespace = path kegg_namespace = genes",4, 0, ,
"http://www.myexperiment.org/workflows/977/versions/3.html","Triplify search results from KEGG bfind SOAP service [myexperiments:kegg_search2rdf]","2009-11-3016:21:05","2009-11-3020:48:50","http://www.myexperiment.org/workflows/977/download/Triplify_search_results_from_KEGG_bfind_SOAP_service__myexperiments_kegg_search2rdf_-v3.t2flow?version=3","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","This workflow use KEGG's SOAP service provided to do a BFIND serch within one of the KEGG's official database.  The results are returned in RDF ntriples format.&nbsp;",4, 0, ,
"http://www.myexperiment.org/workflows/980/versions/1.html","Triplify search results from all KEGG databases [myexperiments:kegg_search_all2rdf]","2009-11-3020:44:13","2009-11-3020:44:55","http://www.myexperiment.org/workflows/980/download/Triplify_search_results_from_all_KEGG_databases__myexperiments_kegg_search_all2rdf_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","Search all KEGG databases using bfind SOAP service and merge results into a bmuri list and a ntriples string.",0, 0, ,
"http://www.myexperiment.org/workflows/980/versions/2.html","Triplify search results from all KEGG databases [myexperiments:kegg_search_all2rdf]","2009-11-3020:44:13","2009-11-3020:44:55","http://www.myexperiment.org/workflows/980/download/Triplify_search_results_from_all_KEGG_databases__myexperiments_kegg_search_all2rdf_-v2.t2flow?version=2","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","Search all KEGG databases using bfind SOAP service and merge results into a bmuri list and a ntriples string.&nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/980/versions/3.html","Triplify search results from all KEGG databases [myexperiments:kegg_search_all2rdf]","2009-11-3020:44:13","2009-11-3020:44:55","http://www.myexperiment.org/workflows/980/download/Triplify_search_results_from_all_KEGG_databases__myexperiments_kegg_search_all2rdf_-v3.t2flow?version=3","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","Search all KEGG databases using bfind SOAP service and merge results into a bmuri list and a ntriples string.&nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/982/versions/1.html","Triplify UniProt database list [myexperiments:uniprotkb_namespace2rdf]","2009-11-3019:35:17","2009-11-3019:43:03","http://www.myexperiment.org/workflows/982/download/Triplify_UniProt_database_list__myexperiments_uniprotkb_namespace2rdf_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","TAG: knowledgescope, uniprotkb, bio2rdf, banff_manifesto",2, 0, ,
"http://www.myexperiment.org/workflows/984/versions/1.html","Triplify UniProt text search results [myexperiments:uniprotkb_search2rdf]","2009-11-3019:55:35","2009-11-3019:56:33","http://www.myexperiment.org/workflows/984/download/Triplify_UniProt_text_search_results__myexperiments_uniprotkb_search2rdf_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","TAG: knowledgescope, uniprotkb, bio2rdf, search, rdf",0, 0, ,
"http://www.myexperiment.org/workflows/985/versions/1.html","Triplify UniProt text search results from all databases [myexperiments:uniprotkb_search_all2rdf]","2009-11-3020:44:32","2009-11-3020:45:08","http://www.myexperiment.org/workflows/985/download/Triplify_UniProt_text_search_results_from_all_databases__myexperiments_uniprotkb_search_all2rdf_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","TAG: knowledgescope, uniprotkb, bio2rdf, search_all, rdf",1, 0, ,
"http://www.myexperiment.org/workflows/985/versions/2.html","Triplify UniProt text search results from all databases [myexperiments:uniprotkb_search_all2rdf]","2009-11-3020:44:32","2009-11-3020:45:08","http://www.myexperiment.org/workflows/985/download/Triplify_UniProt_text_search_results_from_all_databases__myexperiments_uniprotkb_search_all2rdf_-v2.t2flow?version=2","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","Search all UniProt databases using search URL service and merge results into a bmuri list and a ntriples string.&nbsp;",1, 0, ,
"http://www.myexperiment.org/workflows/986/versions/1.html","Triplify EB-Eye databases list from EBI [myexperiments:eb-eye_namespace2rdf2rdf]","2009-11-3020:58:14","2009-11-3020:59:49","http://www.myexperiment.org/workflows/986/download/Triplify_EB-Eye_databases_list_from_EBI__myexperiments_eb-eye_namespace2rdf2rdf_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","TAG: knowledgescope, eb-eye, bio2rdf, banff_manifesto, rdf, ebi, soap",1, 0, ,
"http://www.myexperiment.org/workflows/987/versions/1.html","Triplify namespace list from global search services  from EBI, KEGG, NCBI and UniProt [myexperiment:search_services_namespace2rdf]","2009-11-3021:38:23","2009-11-3021:44:57","http://www.myexperiment.org/workflows/987/download/Triplify_namespace_list_from_global_search_services__from_EBI__KEGG__NCBI_and_UniProt__myexperiment_search_services_namespace2rdf_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,",,1, 0, ,
"http://www.myexperiment.org/workflows/988/versions/1.html","Triplify NCBI databases list [myexperiment:ncbi_namespace2rdf]","2009-11-3021:47:05","2009-12-0102:49:34","http://www.myexperiment.org/workflows/988/download/Triplify_NCBI_databases_list__myexperiment_ncbi_namespace2rdf_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","List NCBI's database name. Using this URL service:   <a href=http://www.ncbi.nlm.nih.gov/entrez/eutils/einfo.fcgi rel=nofollow>http://www.ncbi.nlm.nih.gov/entrez/eutils/einfo.fcgi</a> ? This is NCBI's namespace list supported by Bio2RDF : pubmed  <br /> protein <br /> nucleotide <br /> gene=geneid <br /> homologene <br /> mesh <br /> omim <br /> pccompound=cid <br /> pcsubstance=sid <br /> taxonomy <br /> unigene <br /> unists",4, 0, ,
"http://www.myexperiment.org/workflows/989/versions/1.html","Triplify NCBI databases external reference list [myexperiment:ncbi_xref_namespace2rdf]","2009-12-0103:01:28","2009-12-0103:03:24","http://www.myexperiment.org/workflows/989/download/Triplify_NCBI_databases_external_reference_list__myexperiment_ncbi_xref_namespace2rdf_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","Get NCBI external database list from  <a href=http://www.ncbi.nlm.nih.gov/projects/collab/db_xref.html rel=nofollow>http://www.ncbi.nlm.nih.gov/projects/collab/db_xref.html</a>",1, 0, ,
"http://www.myexperiment.org/workflows/990/versions/1.html","Triplify UniProt database external reference  [myexperiment:uniprot_xref_namespace2rdf]","2009-12-0104:08:08","2009-12-0104:09:39","http://www.myexperiment.org/workflows/990/download/Triplify_UniProt_database_external_reference___myexperiment_uniprot_xref_namespace2rdf_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","Get UniProt external database list from  <a href=http://www.ncbi.nlm.nih.gov/projects/collab/db_xref.html rel=nofollow>http://www.ncbi.nlm.nih.gov/projects/collab/db_xref.html</a> TAG: banff_manifesto, ncbi, xref, bio2rdf, rdf <a href=http://www.uniprot.org/docs/dbxref.txt rel=nofollow>http://www.uniprot.org/docs/dbxref.txt</a> <hr /> <a href=http://www.uniprot.org/docs/dbxref.txt rel=nofollow>http://www.uniprot.org/docs/dbxref.txt</a> <hr /> test values: bmuri =  <a href=http://bio2rdf.orf/geneid:15275 rel=nofollow>http://bio2rdf.orf/geneid:15275</a> <hr /> Get UniProt external database list from  <a href=http://www.uniprot.org/docs/dbxref.txt rel=nofollow>http://www.uniprot.org/docs/dbxref.txt</a> TAG: banff_manifesto, uniprot, xref, bio2rdf, rdf <hr /> <hr /> test values: bmuri =  <a href=http://bio2rdf.org/geneid:15275 rel=nofollow>http://bio2rdf.org/geneid:15275</a>",0, 0, ,
"http://www.myexperiment.org/workflows/990/versions/2.html","Triplify UniProt database external reference  [myexperiment:uniprot_xref_namespace2rdf]","2009-12-0104:08:08","2009-12-0104:09:39","http://www.myexperiment.org/workflows/990/download/Triplify_UniProt_database_external_reference___myexperiment_uniprot_xref_namespace2rdf_-v2.t2flow?version=2","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","Get UniProt external database list from  <a href=http://www.ncbi.nlm.nih.gov/projects/collab/db_xref.html rel=nofollow>http://www.ncbi.nlm.nih.gov/projects/collab/db_xref.html</a> &nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/991/versions/1.html","Triplify LSRN record name list  [myexperiment:lsrn_xref_namespace2rdf]","2009-12-0106:24:54","2009-12-0106:27:20","http://www.myexperiment.org/workflows/991/download/Triplify_LSRN_record_name_list___myexperiment_lsrn_xref_namespace2rdf_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","Get LSRN list from  <a href=http://www.lsrn.org/lsrn/registry-2009-04-26-32404.rdf rel=nofollow>http://www.lsrn.org/lsrn/registry-2009-04-26-32404.rdf</a> &nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/992/versions/1.html","Triplify GO database external reference  [myexperiment:go_xref_namespace2rdf]","2009-12-0106:28:26","2009-12-0106:29:35","http://www.myexperiment.org/workflows/992/download/Triplify_GO_database_external_reference___myexperiment_go_xref_namespace2rdf_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","Get GO external database list from   <a href=http://www.geneontology.org/doc/GO.xrf_abbs rel=nofollow>http://www.geneontology.org/doc/GO.xrf_abbs</a> &nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/993/versions/1.html","Triplify namespace XREF list from GO, LSRN, NCBI and UniProt  [myexperiment:xref_namespace2rdf]","2009-12-0106:56:54","","http://www.myexperiment.org/workflows/993/download/Triplify_namespace_XREF_list_from_GO__LSRN__NCBI_and_UniProt___myexperiment_xref_namespace2rdf__-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","TAG: banff_manifesto, xref, bio2rdf, rdf <hr /> TAG: banff_manifesto, xref, bio2rdf, rdf, mashup <hr /> Triplify namespace XREF list from GO, LSRN, NCBI and UniProt  [myexperiment:xref_namespace2rdf] TAG: banff_manifesto, xref, bio2rdf, rdf <hr /> TAG: banff_manifesto, xref, bio2rdf, rdf",0, 0, ,
"http://www.myexperiment.org/workflows/994/versions/1.html","workflowDiagramConcatenateString","2009-12-0410:47:04","","http://www.myexperiment.org/workflows/994/download/workflowDiagramConcatenateString-v1.xml?version=1","/users/4594","Giulia","taverna 1","/users/4594,","Giulia,",,1, 0, Concatenate_two_strings, ,
"http://www.myexperiment.org/workflows/996/versions/1.html","A workflow version of the EMBOSS tutorial","2009-12-1522:10:36","","http://www.myexperiment.org/workflows/996/download/A_workflow_version_of_the_EMBOSS_tutorial-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","Designed to show the use of EMBOSS based Soaplab services from Taverna, this workflow has no inputs as all initial values are specified as string constants. A sequence set is fetched using the seqret tool, then simultaneously scanned for predicted transmembrane regions and subjected to a multiple alignment using emma. This alignment is then plotted to a set of PNG images and also used to build a profile using the prophecy and prophet tools.",0, 0, ,
"http://www.myexperiment.org/workflows/997/versions/1.html","BiomartAndEMBOSSAnalysis","2009-12-1522:12:00","","http://www.myexperiment.org/workflows/997/download/BiomartAndEMBOSSAnalysis-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","Using Biomart and EMBOSS soaplab services, This workflow retrieves a number of sequences from 3 species: mouse, human, rat; align them, and returns a plot of the alignment result. Corresponding sequence ids are also returned.",0, 0, ,
"http://www.myexperiment.org/workflows/998/versions/1.html","Demonstration of configurable iteration","2009-12-1522:12:50","","http://www.myexperiment.org/workflows/998/download/Demonstration_of_configurable_iteration-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow shows the use of the iteration strategy editor to ensure that only relevant combinations of inputs are used during an implicit iteration.",0, 0, ,
"http://www.myexperiment.org/workflows/999/versions/1.html","EBI_InterProScan_T2","2009-12-1522:13:44","","http://www.myexperiment.org/workflows/999/download/EBI_InterProScan_T2-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,",,2, 0, ,
"http://www.myexperiment.org/workflows/1000/versions/1.html","Fetch PDB flatfile from RCSB server","2009-12-1522:14:39","","http://www.myexperiment.org/workflows/1000/download/Fetch_PDB_flatfile_from_RCSB_server-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","Given an identifier such as '1crn' fetches the PDB format flatfile from the RCSB",0, 0, ,
"http://www.myexperiment.org/workflows/1001/versions/1.html","Fetch today&#39;s xkcd comic","2009-12-1522:15:21","","http://www.myexperiment.org/workflows/1001/download/Fetch_today_s_xkcd_comic-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","Use the local java plugins and some filtering operations to fetch the comic strip image from  <a href=http://xkcd.com/ rel=nofollow>http://xkcd.com/</a> Based on the FetchDailyDilbert workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/1002/versions/1.html","GBSeq test","2009-12-1522:16:23","","http://www.myexperiment.org/workflows/1002/download/GBSeq_test-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow retrieves nucleotide and protein sequences with the literature and references associatedto them given a protein and a nucleotide id.",0, 0, ,
"http://www.myexperiment.org/workflows/1003/versions/1.html","Pipelined list iteration","2009-12-1522:17:11","","http://www.myexperiment.org/workflows/1003/download/Pipelined_list_iteration-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","Perform multiple iterations of services in order to show pipelining",0, 0, ,
"http://www.myexperiment.org/workflows/1004/versions/1.html","Retrieve sequence in EMBL format","2009-12-1522:17:56","","http://www.myexperiment.org/workflows/1004/download/Retrieve_sequence_in_EMBL_format-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow retrieves a sequence associated with its features in embl format",0, 0, ,
"http://www.myexperiment.org/workflows/1005/versions/1.html","Fetch Dragon images from BioMoby","2009-12-1522:33:09","2010-07-1416:41:23","http://www.myexperiment.org/workflows/1005/download/Fetch_Dragon_images_from_BioMoby-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/9981,","EdwardKawas,","Fetch images and annotations of snapdragons",0, 0, ,
"http://www.myexperiment.org/workflows/1005/versions/2.html","Fetch Dragon images from BioMoby","2009-12-1522:33:09","2010-07-1416:41:23","http://www.myexperiment.org/workflows/1005/download/Fetch_Dragon_images_from_BioMoby-v2.t2flow?version=2","/users/30","Alan Williams","taverna 2","/users/9981,","EdwardKawas,","Fetch images and annotations of snapdragons",0, 0, ,
"http://www.myexperiment.org/workflows/1009/versions/1.html","Pattern: Return errors instead of null","2010-01-0417:42:36","2010-01-0417:49:58","http://www.myexperiment.org/workflows/1009/download/Pattern__Return_errors_instead_of_null-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","&nbsp;As Taverna can't (currently) handle null (see&nbsp; <a href=http://www.mygrid.org.uk/dev/issues/browse/TAV-653 rel=nofollow>http://www.mygrid.org.uk/dev/issues/browse/TAV-653</a> ) - in Taverna 2 one can instead return exceptions on individual ports and inside lists. Exceptions are registered as error documents by Taverna, and are passed along. The ErrorBounce layer of processors downstream will prevent execution if they see this 'null'-exception - as showed in this example that the string concatination is just run for the two list elements that are not exceptions. Downstream processors that don't read the port with an error on it's output are not affected. This pattern could be used for instance for database lookups. A database NULL has semantically almost the same meaning as error documents in Taverna - placeholders for the expected value.&nbsp; TAV-653 suggests registering a special exception that is defined as null, so that future null-supporting services/beanshell scripts can dereference the error as null again - while services that can't handle it will behave like in this workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/1012/versions/1.html","Get TP53 Mutation Function Entries  And TP53 Cell Line Entries By MutAa And Codon Number","2010-01-1516:18:54","2010-01-1516:20:32","http://www.myexperiment.org/workflows/1012/download/Get_TP53_Mutation_Function_Entries__And_TP53_Cell_Line_Entries_By_MutAa_And_Codon_Number-v1.xml?version=1","/users/1601","Achille Zappa","taverna 1","/users/1601,","Achille Zappa,","This workflow retrieves from two different databases two distinct set of entries starting from the same inputs data (i.e. the Mutated Aminoacid encoded at the codon in which the mutation occurred, and the Codon Number where the mutation occurs).  Input data: Mutant Amino Acid encoded at the codon in which the mutation occurred and Codon Number where the mutation is located. Special requirements on input data are: - the MutAA (Mutated Amino Acid) in three letters code (Gly, Ala, Trp, Phe etc.) - the Codon Number range is 1-393, - other values may lead to errors, - when specifying more than one MutAA or Codon Number, they must be in a unique input string but on distinct text lines",22, 6, Tp53CellLineLib, StringListSeparator, Tp53MutantFunctionLib, SplitStringIntoStringListForTp53CellLinesMutAA, SplitStringIntoStringListForTp53CellLinesCodonNumber, SplitStringIntoStringListFromMutationFunctionCodonNumber, IdsSeparator, SplitStringIntoStringListFornMutationFunctionMutAA, Beanshell_scripting_host, IdsTokenPosition, Tp53CellLineFieldsIntersection, ExtractIdsFromCellLineMutAA, Tp53MutationFunctionFieldsIntersection, ExtractIdsFromCellLineCodonNumbers, ExtractIdsFromMutationFunctionMutAA, ExtractIdsFromMutationFunctionCodonNumbers, GetTp53CellLineIdsByMutAa, getP53MutationFunctionEntryById, getP53CellLinesStatusEntryById, GetMutantFunctionIdsByMutAA, GetTp53CellLineIdsByCodonNumber, GetMutantFunctionIdsByCodonNumber, ,
"http://www.myexperiment.org/workflows/1013/versions/1.html","Get TP53 Mutations By Exon","2010-01-1516:21:45","","http://www.myexperiment.org/workflows/1013/download/Get_TP53_Mutations_By_Exon-v1.xml?version=1","/users/1601","Achille Zappa","taverna 1","/users/1601,","Achille Zappa,","This workflow takes the exon and the TP53 somatic mutation database as input and retrieve the full TP53 somatic mutation description(s) by first retrieving the TP53 somatic mutation database unique IDs associated with the input (done via a call to the getP53MutationIdsByExon web service) and then using IDs for retrieving the full TP53 somatic mutations descriptions (done via a call to the getP53MutationsByIds web service).Special requirements on input data are: - The exon range of numbers is 2-11,- when specifying more than one exon, they must be in a unique input string but on distinct text lines",7, 2, Filter_list_of_strings_extracting_match_to_a_regex, Split_string_into_string_list_by_regular_expression, regex_entry_list_separator, id_position, regex_id_separator, getP53MutationsByIds, getP53MutationIdsByExon, ,
"http://www.myexperiment.org/workflows/1014/versions/1.html","Search TP53 Somatic Mutation catalogue by exon and by effect according to the boolean operators (and, or and butnot) and retrieve full somatic mutation descriptions","2010-01-1516:22:15","","http://www.myexperiment.org/workflows/1014/download/Search_TP53_Somatic_Mutation_catalogue_by_exon_and_by_effect_according_to_the_boolean_operators_____and________or____and____butnot_____and_retrieve_full_somatic_mutation_descriptions-v1.xml?version=1","/users/1601","Achille Zappa","taverna 1","/users/1601,","Achille Zappa,",,17, 5, tp53_somatic_mutations_database, id_position, regex_id_separator, regex_entry_list_separator, Filter_list_of_strings_extracting_match_to_a_regex_in_or, Split_string_into_string_list_by_regular_expression, Filter_list_of_strings_extracting_match_to_a_regex_in_butnot, String_list_intersection, Split_string_into_list_by_regular_expression_2, String_list_difference, Filter_list_of_strings_extracting_match_to_a_regex_in_and, String_list_union, getP53MutationsByIdsInAnd, getP53MutationIdsByEffect, getP53MutationsByIdsInOr, getP53MutationIdsByExon, getP53MutationsByIdsInButnot, ,
"http://www.myexperiment.org/workflows/1015/versions/1.html","Search TP53 Somatic Mutation catalogue by exon and effect and retrieve full somatic mutation descriptions","2010-01-1516:23:23","","http://www.myexperiment.org/workflows/1015/download/Search_TP53_Somatic_Mutation_catalogue_by_exon_and_effect_and_retrieve_full_somatic_mutation_descriptions-v1.xml?version=1","/users/1601","Achille Zappa","taverna 1","/users/1601,","Achille Zappa,","This workflow takes the exon, the effect and the TP53 somatic mutation database as input and retrieves the full TP53 somatic mutation description(s) by first retrieving two different outputs:- first output: a TP53 somatic mutation database unique IDs list associated with the input exon (done via a call to the getP53MutationIdsByExon web service)- second output: a TP53 somatic mutation database unique IDs list associated with the input effect (done via a call to the getP53MutationIdsByEffect web service)and then using IDs for retrieving the full TP53 somatic mutations descriptions (done via a call to the getP53MutationsByIds web service).All these web services are available at the soaplab system at  <a href=http://bioinformatics.istge.it:8080/axis/services rel=nofollow>http://bioinformatics.istge.it:8080/axis/services</a> <br /> A number or string list local elaborations (for both outputs) are required: - returned IDs are in a string and this must be transformed in a list (done by the 'Split_string_into_string_list_by_regular_expression' processor and by the 'Split_string_into_string_list_by_regular_expression_2' processor, that are implemented by using a Split_string_into_string_list_by_regular_expression local processor)- comparison of the two above outputs and identification of the common subset (done by the 'String_list_intersection' processor, that is implemented by using a String_list_intersection local processor)- returned IDs include catalogues' names and this must be removed before their utilization for further processing (done by the 'Filter_list_of_strings_extracting_match_to_a_regex' processor, that is implemented by using a Filter_list_of_strings_extracting_match_to_a_regex local processor) <br /> Special requirements on input data are: - the exon range of numbers is 2-11,- one or more of the following effects can be specified: 'fs' (frameshift), 'missense', 'na' (not available), 'nonsense', 'other', 'silent', 'splice'. Other values may lead to errors,- when specifying more than one exon or effect, they must be in a unique input string but on distinct text lines",11, 3, regex_entry_list_separator, id_position, regex_id_separator, tp53_somatic_mutations_database, Split_string_into_list_by_regular_expression_2, Filter_list_of_strings_extracting_match_to_a_regex, Split_string_into_string_list_by_regular_expression, String_list_intersection, getP53MutationIdsByExon, getP53MutationsByIds, getP53MutationIdsByEffect, ,
"http://www.myexperiment.org/workflows/1016/versions/1.html","Get TP53 Mutations By Intron","2010-01-1516:24:10","","http://www.myexperiment.org/workflows/1016/download/Get_TP53_Mutations_By_Intron-v1.xml?version=1","/users/1601","Achille Zappa","taverna 1","/users/1601,","Achille Zappa,","This workflow takes the intron and the TP53 somatic mutation database as input and retrieve the full TP53 somatic mutation description(s) by first retrieving the TP53 somatic mutation database unique IDs associated with the input (done via a call to the getP53MutationIdsByIntron web service) and then using IDs for retrieving the full TP53 somatic mutations descriptions (done via a call to the getP53MutationsByIds web service).Special requirements on input data are: - The intron range of numbers is 2-11,- when specifying more than one intron, they must be in a unique input string but on distinct text lines",7, 2, Filter_list_of_strings_extracting_match_to_a_regex, regex_entry_list_separator, regex_id_separator, Split_string_into_string_list_by_regular_expression, id_position, getP53MutationsByIds, getP53MutationIdsByIntron, ,
"http://www.myexperiment.org/workflows/1017/versions/1.html","Search TP53 Somatic Mutation catalogue by intron and by effect according to the boolean operators (and, or and butnot) and retrieve full somatic mutation descriptions","2010-01-1516:24:42","","http://www.myexperiment.org/workflows/1017/download/Search_TP53_Somatic_Mutation_catalogue_by_intron_and_by_effect_according_to_the_boolean_operators_____and________or____and____butnot_____and_retrieve_full_somatic_mutation_descriptions-v1.xml?version=1","/users/1601","Achille Zappa","taverna 1","/users/1601,","Achille Zappa,","This workflow takes the intron, the effect and the TP53 somatic mutation database as input and retrieves the full TP53 somatic mutation description(s) by first retrieving two different outputs and arranging them according to the boolean operators (and, or and butnot): - first output: a TP53 somatic mutation database unique IDs list associated with the input 'intron' (done via a call to the getP53MutationIdsByIntron web service)- second output: a TP53 somatic mutation database unique IDs list associated with the input 'effect' (done via a call to the getP53MutationIdsByEffect web service)and then using IDs for retrieving the full TP53 somatic mutations descriptions (done via a call to the getP53MutationsByIds web service).Special requirements on input data are: - the intron range of numbers is 2-11,- one or more of the following effects can be specified: 'fs' (frameshift), 'missense', 'na' (not available), 'nonsense', 'other', 'silent', 'splice'. Other values may lead to errors,- when specifying more than one intron or effect, they must be in a unique input string but on distinct text lines.",17, 5, Split_string_into_list_by_regular_expression_2, Filter_list_of_strings_extracting_match_to_a_regex_in_and, Split_string_into_string_list_by_regular_expression, String_list_intersection, regex_id_separator, Filter_list_of_strings_extracting_match_to_a_regex2_in_or, String_list_difference, Filter_list_of_strings_extracting_match_to_a_regex3_in_butnot, String_list_union, regex_entry_list_separator, id_position, String_Constant, getP53MutationIdsByEffect, getP53MutationsByIdsInOr, getP53MutationsByIdsInButnot, getP53MutationsByIdsInAnd, getP53MutationIdsByIntron, ,
"http://www.myexperiment.org/workflows/1018/versions/1.html","Search TP53 Somatic Mutation catalogue by intron and effect and retrieve full somatic mutation descriptions","2010-01-1516:25:32","","http://www.myexperiment.org/workflows/1018/download/Search_TP53_Somatic_Mutation_catalogue_by_intron_and_effect_and_retrieve_full_somatic_mutation_descriptions-v1.xml?version=1","/users/1601","Achille Zappa","taverna 1","/users/1601,","Achille Zappa,","This workflow takes the intron, the effect and the TP53 somatic mutation database as input and retrieves the full TP53 somatic mutation description(s) by first retrieving two different outputs:- first output: a TP53 somatic mutation database unique IDs list associated with the input intron (done via a call to the getP53MutationIdsByIntron web service)- second otput: a TP53 somatic mutation database unique IDs list associated with the input effect (done via a call to the getP53MutationIdsByEffect web service)and then using IDs for retrieving the full TP53 somatic mutations descriptions (done via a call to the getP53MutationsByIds web service).All these web services are available at the soaplab system at  <a href=http://bioinformatics.istge.it:8080/axis/services rel=nofollow>http://bioinformatics.istge.it:8080/axis/services</a> <br /> A number or string list local elaborations (for both outputs) are required: - returned IDs are in a string and this must be transformed in a list (done by the 'Split_string_into_string_list_by_regular_expression' processor and by the 'Split_string_into_string_list_by_regular_expression_2' processor, that are implemented by using a Split_string_into_string_list_by_regular_expression local processor)- comparison of the two above outputs and identification of the common subset (done by the 'String_list_intersection' processor, that is implemented by using a String_list_intersection local processor)- returned IDs include catalogues' names and this must be removed before their utilization for further processing (done by the 'Filter_list_of_strings_extracting_match_to_a_regex' processor, that is implemented by using a Filter_list_of_strings_extracting_match_to_a_regex local processor) <br /> Special requirements on input data are: - the intron range of numbers is 2-11,- one or more of the following effects can be specified: 'fs' (frameshift), 'missense', 'na' (not available), 'nonsense', 'other', 'silent', 'splice'. Other values may lead to errors,- when specifying more than one intron or effect, they must be in a unique input string but on distinct text lines",11, 3, regex_id_separator, regex_entry_list_separator, id_position, Split_string_into_list_by_regular_expression_2, Filter_list_of_strings_extracting_match_to_a_regex, Split_string_into_string_list_by_regular_expression, String_list_intersection, tp53_somatic_mutations_database, getP53MutationIdsByEffect, getP53MutationsByIds, getP53MutationIdsByIntron, ,
"http://www.myexperiment.org/workflows/1019/versions/1.html","Retrieve full descriptions of bacteria strains from CABRI catalogues (see www.cabri.org) by their scientific name (genus and species only)","2010-01-1516:26:06","","http://www.myexperiment.org/workflows/1019/download/Retrieve_full_descriptions_of_bacteria_strains_from_CABRI_catalogues__see_www.cabri.org__by_their_scientific_name__genus_and_species_only_-v1.xml?version=1","/users/1601","Achille Zappa","taverna 1","/users/1601,","Achille Zappa,","This workflow retrieves the full description of bacteria strains that are available in the CABRI network services (see  <a href=http://www.cabri.org rel=nofollow>www.cabri.org</a> ). Input are the name of the involved CABRI catalogues (text/plain string with one catalogue name per line) and the scientific name of the desired bacteria strain (a text/plain string including genus and species separated by a blank space). Data are retrieved from the CABRI Web Services in two steps. First, all bacteria strains IDs are retrieved by using the getBacteriaIdsByName method, and after descriptions are retrieved by using the getBacteriaById method. Some list/text elaboration is required to remove catalogue names from retirned IDs and to substitute blank spaces with the '_SP_' string in the search terms.",9, 2, line_terminator, Substitute_blanks_in_IDs, Extract_acc_no, Separate_bacteria_ids, acc_no_regex, acc_no_pos, Substitute_blanks_in_scientific_name, getBacteriaIdsByName, getBacteriaById, ,
"http://www.myexperiment.org/workflows/1020/versions/1.html","Search CABRI human and animal cell lines catalogues by cell line name and retrieve full cell line descriptions","2010-01-1516:26:41","2010-01-1516:26:59","http://www.myexperiment.org/workflows/1020/download/Search_CABRI_human_and_animal_cell_lines_catalogues_by_cell_line_name_and_retrieve_full_cell_line_descriptions-v1.xml?version=1","/users/1601","Achille Zappa","taverna 1","/users/1601,","Achille Zappa,","This workflow takes the cell line name and the catalogue(s) name(s) as input and retrieve the full cell line description(s) by first retrieving the cell lines' unique IDs associated with the input (done via a call to the getCellLineIdsByName web service) and then using IDs for retrieving the full cell lines descriptions (done via a call to the getCellLinesByIds web service).",8, 2, Text_lines_separator, Substitute_blanks_with_SP, Regex_for_catalogue_name_extraction, Group_for_catalogue_name_extraction, Separate_cell_line_ids, Extract_ids_by_removing_catalogues_names, getCellLinesById, getCellLineIdsByName, ,
"http://www.myexperiment.org/workflows/1028/versions/1.html","Dummy example of looping","2010-01-2715:52:50","2013-10-0811:24:47","http://www.myexperiment.org/workflows/1028/download/Dummy_example_of_looping-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","<span class=Apple-style-span><div class=contribution_description><div>Example of looping over asynchronous services. The dummy beanshell scripts represents the operations of an asynchronous submit-status-results style service, such as EBI's&nbsp;<a href=http://www.biocatalogue.org/services/5-wsinterproscanservice_85990#operations rel=nofollow>InterProScan&nbsp;</a>and&nbsp;<a href=http://www.biocatalogue.org/services/44-wsncbiblastservice_863693#operations rel=nofollow>NCBI Blast</a>.</div><div>&nbsp;</div><div><b>createJob&nbsp;</b>creates a temporary file with the content &quot;0&quot;. Filename retuirned as a &quot;<i>job ID</i>&quot;.</div><div>&nbsp;</div><div><b>checkStatus&nbsp;</b>reads the job, and return state &quot;<i>RUNNING</i>&quot; as long as the content is less than 10, increasing the number for each call. (As no actual job is being run)</div><div>&nbsp;</div><div><b>getResults</b><i>&nbsp;</i>reads the file content, with the condition 'Run after checkStatus'.</div><div>&nbsp;</div><div>In&nbsp;<i>Details-&gt;Advanced</i>&nbsp;for&nbsp;<i>checkStatus&nbsp;</i>you can check the loop condition, which says it will loop as long as the output '<i>state</i>' is equal to '<i>RUNNING</i>' - with a 0.5s delay.&nbsp;</div><div>&nbsp;</div><div>Thus when executing this workflow, checkStatus will be called repeatedly, and finally the 'result' should be '10' and '<i>state</i>' should be '<i>COMPLETE</i>'.</div><div>&nbsp;</div><div>See&nbsp;<a href=http://www.mygrid.org.uk/dev/wiki/display/scrap/Looping+in+Taverna+2.1 rel=nofollow>http://www.mygrid.org.uk/dev/wiki/display/scrap/Looping+in+Taverna+2.1</a>&nbsp;for details</div><div>&nbsp;</div></div></span>",0, 0, ,
"http://www.myexperiment.org/workflows/1028/versions/2.html","Dummy example of looping","2010-01-2715:52:50","2013-10-0811:24:47","http://www.myexperiment.org/workflows/1028/download/Dummy_example_of_looping-v2.t2flow?version=2","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","<span class=Apple-style-span><div>Example of looping over asynchronous services. The dummy beanshell scripts represents the operations of an asynchronous submit-status-results style service, such as EBI's&nbsp;<a href=http://www.biocatalogue.org/services/5-wsinterproscanservice_85990#operations rel=nofollow>InterProScan&nbsp;</a>and&nbsp;<a href=http://www.biocatalogue.org/services/44-wsncbiblastservice_863693#operations rel=nofollow>NCBI Blast</a>.</div><div>&nbsp;</div><div><b>createJob&nbsp;</b>creates a temporary file with the content &quot;0&quot;. Filename retuirned as a &quot;<i>job ID</i>&quot;.</div><div>&nbsp;</div><div><b>checkStatus&nbsp;</b>reads the job, and return state &quot;<i>RUNNING</i>&quot; as long as the content is less than 10, increasing the number for each call. (As no actual job is being run)</div><div>&nbsp;</div><div><b>getResults</b><i>&nbsp;</i>reads the file content, with the condition 'Run after checkStatus'.</div><div>&nbsp;</div><div>In&nbsp;<i>Details-&gt;Advanced</i>&nbsp;for&nbsp;<i>checkStatus&nbsp;</i>you can check the loop condition, which says it will loop as long as the output '<i>state</i>' is equal to '<i>RUNNING</i>' - with a 0.5s delay.&nbsp;</div><div>&nbsp;</div><div>Thus when executing this workflow, checkStatus will be called repeatedly, and finally the 'result' should be '10' and '<i>state</i>' should be '<i>COMPLETE</i>'.</div><div>&nbsp;</div><div>See&nbsp;<a href=http://www.mygrid.org.uk/dev/wiki/display/scrap/Looping+in+Taverna+2.1 rel=nofollow>http://www.mygrid.org.uk/dev/wiki/display/scrap/Looping+in+Taverna+2.1</a>&nbsp;for details</div></span>",0, 0, ,
"http://www.myexperiment.org/workflows/1028/versions/3.html","Dummy example of looping","2010-01-2715:52:50","2013-10-0811:24:47","http://www.myexperiment.org/workflows/1028/download/Dummy_example_of_looping-v3.t2flow?version=3","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","Example of looping over asynchronous services. The dummy beanshell scripts represents the operations of an asynchronous submit-status-results style service, such as EBI's InterProScan and NCBI Blast. createJob creates a temporary file with the content 0. Filename retuirned as a job ID. checkStatus reads the job, and return state RUNNING as long as the content is less than 10, increasing the number for each call. (As no actual job is being run) getResults reads the file content, with the condition 'Run after checkStatus'. In Details-&gt;Advanced for checkStatus you can check the loop condition for checkStatus, which says it will loop as long as the output 'state' is equal to 'RUNNING' - with a 0.5s delay. Thus when executing this workflow, checkStatus will be called repeatedly, and finally the 'result' should be '10' and 'state' should be 'COMPLETE'. See  <a href=http://www.mygrid.org.uk/dev/wiki/display/scrap/Looping+in+Taverna+2.1 rel=nofollow>http://www.mygrid.org.uk/dev/wiki/display/scrap/Looping+in+Taverna+2.1</a>  for details",0, 0, ,
"http://www.myexperiment.org/workflows/1031/versions/1.html","Rdfise Riken SciNes Database Repository [myexperiment:scines2rdf]","2010-02-0120:10:43","2010-02-0120:13:51","http://www.myexperiment.org/workflows/1031/download/Rdfise_Riken_SciNes_Database_Repository__myexperiment_scines2rdf_-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","This workflow rdfise Riken  SciNes Database Repository available at  <a href=https://database.riken.jp/sw/links/en/crib151s2i/.&lt;/p>https://database.riken.jp/sw/links/en/crib151s2i/.</a> There is a bug with main page listing databases: version 2p and 3p are similar to 1p.",2, 0, ,
"http://www.myexperiment.org/workflows/1032/versions/1.html","SBML to SBML shortand converter","2010-02-0319:18:28","2010-02-0319:21:13","http://www.myexperiment.org/workflows/1032/download/SBML_to_SBML_shortand_converter-v1.t2flow?version=1","/users/6890","Yuhuichen","taverna 2","","","converts SBML document to SBML shorthand via BASIS web servicesBASIS:  <a href=http://www.basis.ncl.ac.uk:81/Basis rel=nofollow>www.basis.ncl.ac.uk:81/Basis</a> SBML shorthand:  <a href=http://www.staff.ncl.ac.uk/d.j.wilkinson/software/sbml-sh/ rel=nofollow>http://www.staff.ncl.ac.uk/d.j.wilkinson/software/sbml-sh/</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/1033/versions/1.html","SBML shorthand to SBML converter","2010-02-0319:19:39","2010-02-0319:20:34","http://www.myexperiment.org/workflows/1033/download/SBML_shorthand_to_SBML_converter-v1.t2flow?version=1","/users/6890","Yuhuichen","taverna 2","","","converts SBML shorthand to SBML document via BASIS web servicesBASIS:  <a href=http://www.basis.ncl.ac.uk:81/Basis rel=nofollow>www.basis.ncl.ac.uk:81/Basis</a> SBML shorthand:  <a href=http://www.staff.ncl.ac.uk/d.j.wilkinson/software/sbml-sh/ rel=nofollow>http://www.staff.ncl.ac.uk/d.j.wilkinson/software/sbml-sh/</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/1036/versions/1.html","CaliBayes_Client","2010-02-0322:29:47","2010-02-0322:44:14","http://www.myexperiment.org/workflows/1036/download/CaliBayes_Client-v1.t2flow?version=1","/users/6890","Yuhuichen","taverna 2","","","A workflow for consuming CaliBayes web services. CaliBayes:  <a href=http://www.calibayes.ncl.ac.uk rel=nofollow>www.calibayes.ncl.ac.uk</a>",3, 0, ,
"http://www.myexperiment.org/workflows/1037/versions/1.html","Get Gene Ids for Human","2010-02-0412:47:16","2010-02-0412:48:11","http://www.myexperiment.org/workflows/1037/download/Get_Gene_Ids_for_Human-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow gets a list of gene ids (number depending on Ret_Max_value variable) for Homo sapiens. The species may be changed according to that desired, by altering the term_value string constant",1, 0, ,
"http://www.myexperiment.org/workflows/1049/versions/1.html","t_tp53_mutations_info_by_morpho - &quot;in progress&quot;","2010-02-0913:45:16","2010-06-0408:22:15","http://www.myexperiment.org/workflows/1049/download/t_tp53_mutations_info_by_morpho_-__in_progress_-v1.xml?version=1","/users/1601","Achille Zappa","taverna 1","/users/1601,","Achille Zappa,",,29, 8, String_Constant2, String_Constant3, dataset, query_field, Split_string_2, Remove_duplicate_strings, Filter_list_3, Filter_list_1, Filter_list_2, Split_string_, Split_string_1, Filter_list_, filter_list1, filter_list, count, count1, R_topo, R_type, R_effect, R_exon, R_codons, getP53_Mutations, getP53_Ids, getP53_Intron, getP53_Topography, getP53_Effect, getP53_Codons, getP53_Mut_Type, getP53_Exon, ,
"http://www.myexperiment.org/workflows/1051/versions/1.html","PDB2KEGG step 1done during BH2010","2010-02-1309:37:39","","http://www.myexperiment.org/workflows/1051/download/PDB2KEGG_step_1done_during_BH2010-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,",,0, 0, ,
"http://www.myexperiment.org/workflows/1052/versions/1.html","LipidMaps Query","2010-02-1614:47:56","","http://www.myexperiment.org/workflows/1052/download/LipidMaps_Query-v1.t2flow?version=1","/users/4584","Michael Eiden","taverna 2","","","This workflow retrieves database entries from LipidMaps for given exact mass and tolerance inputs.",0, 0, ,
"http://www.myexperiment.org/workflows/1054/versions/1.html","Clean plain text (ASCII)","2010-02-1818:39:01","2011-12-1315:53:46","http://www.myexperiment.org/workflows/1054/download/Clean_plain_text__ASCII_-v1.t2flow?version=1","/users/267","James Eales","taverna 2","/users/267,","James Eales,","This workflow will remove any XML-invalid and non-ASCII characters (e.g. for sending to the ASCII-only Termine service) from any text supplied to the input port. This is a workflow component, designed to be used as a nested workflow inside a larger text mining or text processing workflow.",-1, 0, ,
"http://www.myexperiment.org/workflows/1055/versions/1.html","Clean plain text","2010-02-1818:59:35","2011-12-1315:54:09","http://www.myexperiment.org/workflows/1055/download/Clean_plain_text-v1.t2flow?version=1","/users/267","James Eales","taverna 2","/users/267,","James Eales,","<span class=Apple-style-span> </span> This workflow will remove any XML-invalid characters (these characters often appear in the output of PDF to text software) from any text supplied to the input port. This is a workflow component, designed to be used as a nested workflow inside a larger text mining or text processing workflow. &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/1056/versions/1.html","Load plain text from directory","2010-02-1819:09:07","2011-12-1315:54:57","http://www.myexperiment.org/workflows/1056/download/Load_plain_text_from_directory-v1.t2flow?version=1","/users/267","James Eales","taverna 2","/users/267,","James Eales,","<span class=Apple-style-span><span class=Apple-style-span>This workflow will automate the reading of a set of text files stored in a single directory (the path to which should be supplied as a single input value). &nbsp;It will assume that the text files are saved using the default character encoding for the system that Taverna is running on.</span></span> &nbsp; <span class=Apple-style-span> </span> This is a workflow component, designed to be used as a nested workflow inside a larger text mining or text processing workflow. &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/1057/versions/1.html","Load PDF from directory","2010-02-1908:59:01","2011-12-1315:54:34","http://www.myexperiment.org/workflows/1057/download/Load_PDF_from_directory-v1.t2flow?version=1","/users/267","James Eales","taverna 2","/users/267,","James Eales,","<span class=Apple-style-span><span class=Apple-style-span>This workflow will automate the reading of a set of PDF files stored in a single directory (the path to which should be supplied as a single input value).</span></span> This is a workflow component, designed to be used as a nested workflow inside a larger text mining or text processing workflow. &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/1058/versions/1.html","PDF to plain text","2010-02-1909:07:41","2011-12-1315:53:29","http://www.myexperiment.org/workflows/1058/download/PDF_to_plain_text-v1.t2flow?version=1","/users/267","James Eales","taverna 2","/users/267,","James Eales,","<span><span>This workflow will extract the plain text content of PDF files supplied to the input port. &nbsp;You can connect the </span></span> <span><a href=http://www.myexperiment.org/workflows/1057 rel=nofollow><span>Load PDF from directory</span></a><span> workflow to this workflows input. We recommend you send the output from this workflow to the </span></span> <span><a href=http://www.myexperiment.org/workflows/1055 rel=nofollow><span>Clean plain text</span></a><span> workflow, because the PDF to text process can add characters into the text that are XML-invalid and therefore can not be sent to most services as plain text. &nbsp;Another way round this problem is to encode the text as Base64 using the handy local service (&quot;Encode Byte Array to Base 64&quot;) included with Taverna, although this requires a service that knows to decode the Base 64 back to text, which is not common. The PDF to text service makes use of the &quot;pdftotext&quot; executable from <a href=http://www.foolabs.com/xpdf/ rel=nofollow>Xpdf</a>.</span></span> <span><span><span class=Apple-style-span><span class=Apple-style-span>This is a workflow component, designed to be used as a nested workflow inside a larger text mining or text processing workflow.</span></span></span></span>",-1, 0, ,
"http://www.myexperiment.org/workflows/1059/versions/1.html","Sentence splitting","2010-02-1909:30:37","2011-12-1315:52:36","http://www.myexperiment.org/workflows/1059/download/Sentence_splitting-v1.t2flow?version=1","/users/267","James Eales","taverna 2","/users/267,","James Eales,","<span class=Apple-style-span>This workflow will attempt to split up text into sentences, returning a list of sentences to the output port. &nbsp;The sentence splitting service makes use of the <a href=http://opennlp.sourceforge.net/ rel=nofollow>OpenNLP</a> <a href=http://opennlp.sourceforge.net/api/opennlp/tools/lang/english/SentenceDetector.html rel=nofollow>sentence detector</a> and has been trained to work on english text. This workflow can be used to provide input to the <a href=http://www.myexperiment.org/workflows/1060 rel=nofollow>Termine with c-value threshold</a> workflow.</span> This is a workflow component, designed to be used as a nested workflow inside a larger text mining or text processing workflow.",-1, 0, ,
"http://www.myexperiment.org/workflows/1060/versions/1.html","Termine with c-value threshold","2010-02-1909:57:15","2011-12-1315:52:56","http://www.myexperiment.org/workflows/1060/download/Termine_with_c-value_threshold-v1.t2flow?version=1","/users/267","James Eales","taverna 2","/users/267,","James Eales,","<span>This workflow accepts a list of sentences from a single document and returns the terms found by the </span> <a href=http://www.nactem.ac.uk/software/termine/ rel=nofollow><span>TerMine</span></a> <span> web service. It also allows you to set a threshold c-value score so that only terms with a user-controlled probability (of being a real term) are returned as an <span>output. </span></span> &nbsp; <span><span>To get sentences to supply to this workflow you can use the <a href=http://www.myexperiment.org/workflows/1059 rel=nofollow>sentence splitting</a> workflow. &nbsp;The TerMine service (used in this workflow) only accepts text in ASCII encoding, so you should also use the <a href=http://www.myexperiment.org/workflows/1054 rel=nofollow>Clean plain text (ASCII)</a> workflow before splitting sentences.</span></span> <span><span><span class=Apple-style-span>This is a workflow component, designed to be used as a nested workflow inside a larger text mining or text processing workflow.</span></span></span> Unfortunately there are some restrictions on IP access to the TerMine web service at the NaCTeM. These can be viewed  <a href=http://www.nactem.ac.uk/requestaccess.php rel=nofollow>here</a> . If you are at a UK higher eductation institution then there should be no problems, others have to request access through  <a href=http://www.nactem.ac.uk/requestaccess.php rel=nofollow>this page</a> .",-1, 0, ,
"http://www.myexperiment.org/workflows/1061/versions/1.html","Terms from collection of PDF files","2010-02-1910:52:29","2011-12-1315:56:08","http://www.myexperiment.org/workflows/1061/download/Terms_from_collection_of_PDF_files_-v1.t2flow?version=1","/users/267","James Eales","taverna 2","/users/267,","James Eales,","This workflow will give you a set of candidate terms for each PDF document in a user-specified directory. You can also specify a c-value threshold that will restrict the terms to those with scores",1, 0, ,
"http://www.myexperiment.org/workflows/1061/versions/2.html","Terms from collection of PDF files","2010-02-1910:52:29","2011-12-1315:56:08","http://www.myexperiment.org/workflows/1061/download/Terms_from_collection_of_PDF_files_-v2.t2flow?version=2","/users/267","James Eales","taverna 2","/users/267,","James Eales,","This workflow will give you a set of candidate terms for each PDF document in a user-specified directory. You can also specify a c-value threshold that will restrict the terms to those with higher scores. This workflow was created using only nested workflows. &nbsp;These  <a href=http://www.myexperiment.org/tags/1790 rel=nofollow>workflow components</a>  work on their own and can be linked together to form more complex workflows such as this. You can view the text mining workflow components in  <a href=http://www.myexperiment.org/packs/106 rel=nofollow>this pack</a> . If you receive errors when running this workflow then check if you have access to the NaCTeM web services  <a href=http://www.nactem.ac.uk/requestaccess.php rel=nofollow>here</a> . If you do not have access then you can request access from the same page.",1, 0, ,
"http://www.myexperiment.org/workflows/1065/versions/1.html","Terms from collection of text files","2010-02-2218:05:24","2011-12-1315:55:39","http://www.myexperiment.org/workflows/1065/download/Terms_from_collection_of_text_files-v1.t2flow?version=1","/users/267","James Eales","taverna 2","/users/267,","James Eales,","<span><span>This workflow will give you a set of candidate terms for each text file in a user-specified directory. You can also specify a c-value threshold that will restrict the terms to those with higher scores.</span></span> This workflow was created using only nested workflows. &nbsp;These  <a href=http://www.myexperiment.org/tags/1790 rel=nofollow>workflow components</a>  work on their own and can be linked together to form more complex workflows such as this. You can view the text mining workflow components in  <a href=http://www.myexperiment.org/packs/106 rel=nofollow>this pack</a> . If you receive errors when running this workflow then check if you have access to the NaCTeM web services  <a href=http://www.nactem.ac.uk/requestaccess.php rel=nofollow>here</a> . If you do not have access then you can request access from the same page.",0, 0, ,
"http://www.myexperiment.org/workflows/1076/versions/1.html","Tutorial Taverna","2010-02-2610:38:56","2010-02-2610:39:52","http://www.myexperiment.org/workflows/1076/download/Tutorial_Taverna-v1.t2flow?version=1","/users/7161","Rodriguez","taverna 2","/users/7161,","Rodriguez,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1077/versions/1.html","Taverna Tutorial2","2010-02-2611:54:18","2010-02-2611:55:51","http://www.myexperiment.org/workflows/1077/download/Taverna_Tutorial2-v1.t2flow?version=1","/users/7161","Rodriguez","taverna 2","/users/7161,","Rodriguez,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1086/versions/1.html","Transciption (DNA into RNA)","2010-03-0509:55:43","2010-03-0509:57:04","http://www.myexperiment.org/workflows/1086/download/Transciption__DNA_into_RNA_-v1.t2flow?version=1","/users/7486","Fahad Alqahtani","taverna 2","","","This workflow allows a user to transcibe DNA into RNA.",-1, 0, ,
"http://www.myexperiment.org/workflows/1088/versions/1.html","Get locations from postcode","2010-03-0814:38:04","2010-03-0814:41:20","http://www.myexperiment.org/workflows/1088/download/Get_locations_from_postcode-v1.t2flow?version=1","/users/1355","Rory","taverna 2","/users/1355,","Rory,","&nbsp;This workflow will return all the areas that correspond to a postcode. Enter the first part of the postcode only, e.g. SW19",-1, 0, ,
"http://www.myexperiment.org/workflows/1097/versions/1.html","M_Fetch_e-T_phylo_boot - (BETA)","2010-03-1015:44:02","2010-03-1015:49:06","http://www.myexperiment.org/workflows/1097/download/M_Fetch_e-T_phylo_boot_-__BETA_-v1.xml?version=1","/users/1601","Achille Zappa","taverna 1","/users/1601, /users/925,","Achille Zappa, Hamish McWilliam,","This workflow performs a generic protein sequence analysis. In order to do that a novel protein sequence enters into the software along with a list of known protein identifiers chosen by the biologist to perform a homology search, followed by a multiple sequence alignment and finally a phylogenetic analysis.",16, 1, String_Constant, String_Constant1, seq_descriptions, Muscle, Fetch, T_coffee, ClustalW2, emma, emma_ML, Muscle_NJ, T_coffe_ML, ClustalW2_NJ, ClustalW2_ML, Muscle_ML, T_coffee_NJ, emma_NJ, ,
"http://www.myexperiment.org/workflows/1099/versions/1.html","Get Kegg Pathway information","2010-03-1017:15:47","2010-03-1017:18:47","http://www.myexperiment.org/workflows/1099/download/Get_Kegg_Pathway_information-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow gets a series of information relating to a list of KEGG pathways supplied to it. It also removes any null values from a list of strings.  Example input: path:mmu04010 path:mmu05014",1, 0, ,
"http://www.myexperiment.org/workflows/1103/versions/1.html","OpenTox Get Algorithms on TUM server","2010-05-1118:26:32","2011-05-1114:33:43","http://www.myexperiment.org/workflows/1103/download/OpenTox_Get_Algorithms_on_TUM_server-v1.t2flow?version=1","/users/6658","Wicker","taverna 2","","","Get URIs of all available algorithms",-1, 0, ,
"http://www.myexperiment.org/workflows/1103/versions/2.html","OpenTox Get Algorithms on TUM server","2010-05-1118:26:32","2011-05-1114:33:43","http://www.myexperiment.org/workflows/1103/download/OpenTox_Get_Algorithms_on_TUM_server-v2.t2flow?version=2","/users/6658","Wicker","taverna 2","","","Get URIs of all available algorithms",-1, 0, ,
"http://www.myexperiment.org/workflows/1103/versions/3.html","OpenTox Get Algorithms on TUM server","2010-05-1118:26:32","2011-05-1114:33:43","http://www.myexperiment.org/workflows/1103/download/OpenTox_Get_Algorithms_on_TUM_server-v3.t2flow?version=3","/users/6658","Wicker","taverna 2","","","Get URIs of all available algorithms",-1, 0, ,
"http://www.myexperiment.org/workflows/1103/versions/4.html","OpenTox Get Algorithms on TUM server","2010-05-1118:26:32","2011-05-1114:33:43","http://www.myexperiment.org/workflows/1103/download/OpenTox_Get_Algorithms_on_TUM_server-v4.t2flow?version=4","/users/6658","Wicker","taverna 2","","","Get URIs of all available algorithms",-1, 0, ,
"http://www.myexperiment.org/workflows/1103/versions/5.html","OpenTox Get Algorithms on TUM server","2010-05-1118:26:32","2011-05-1114:33:43","http://www.myexperiment.org/workflows/1103/download/OpenTox_Get_Algorithms_on_TUM_server-v5.t2flow?version=5","/users/6658","Wicker","taverna 2","","","Get URIs of all available algorithms on TUM server",-1, 0, ,
"http://www.myexperiment.org/workflows/1103/versions/6.html","OpenTox Get Algorithms on TUM server","2010-05-1118:26:32","2011-05-1114:33:43","http://www.myexperiment.org/workflows/1103/download/OpenTox_Get_Algorithms_on_TUM_server-v6.t2flow?version=6","/users/6658","Wicker","taverna 2","","","Get URIs of all available algorithms on TUM server",-1, 0, ,
"http://www.myexperiment.org/workflows/1104/versions/1.html","OpenTox Apply Algorithm","2010-05-1118:16:40","2011-05-1114:34:17","http://www.myexperiment.org/workflows/1104/download/OpenTox_Apply_Algorithm-v1.t2flow?version=1","/users/6658","Wicker","taverna 2","","","Apply an OpenTox algorithm",-1, 0, ,
"http://www.myexperiment.org/workflows/1104/versions/2.html","OpenTox Apply Algorithm","2010-05-1118:16:40","2011-05-1114:34:17","http://www.myexperiment.org/workflows/1104/download/OpenTox_Apply_Algorithm-v2.t2flow?version=2","/users/6658","Wicker","taverna 2","","","Apply an OpenTox algorithm",-1, 0, ,
"http://www.myexperiment.org/workflows/1104/versions/3.html","OpenTox Apply Algorithm","2010-05-1118:16:40","2011-05-1114:34:17","http://www.myexperiment.org/workflows/1104/download/OpenTox_Apply_Algorithm-v3.t2flow?version=3","/users/6658","Wicker","taverna 2","","","Apply an OpenTox algorithm",-1, 0, ,
"http://www.myexperiment.org/workflows/1104/versions/4.html","OpenTox Apply Algorithm","2010-05-1118:16:40","2011-05-1114:34:17","http://www.myexperiment.org/workflows/1104/download/OpenTox_Apply_Algorithm-v4.t2flow?version=4","/users/6658","Wicker","taverna 2","","","Apply an OpenTox algorithm",-1, 0, ,
"http://www.myexperiment.org/workflows/1104/versions/5.html","OpenTox Apply Algorithm","2010-05-1118:16:40","2011-05-1114:34:17","http://www.myexperiment.org/workflows/1104/download/OpenTox_Apply_Algorithm-v5.t2flow?version=5","/users/6658","Wicker","taverna 2","","","Apply an OpenTox algorithm",-1, 0, ,
"http://www.myexperiment.org/workflows/1104/versions/6.html","OpenTox Apply Algorithm","2010-05-1118:16:40","2011-05-1114:34:17","http://www.myexperiment.org/workflows/1104/download/OpenTox_Apply_Algorithm-v6.t2flow?version=6","/users/6658","Wicker","taverna 2","","","Apply an OpenTox algorithm",-1, 0, ,
"http://www.myexperiment.org/workflows/1104/versions/7.html","OpenTox Apply Algorithm","2010-05-1118:16:40","2011-05-1114:34:17","http://www.myexperiment.org/workflows/1104/download/OpenTox_Apply_Algorithm-v7.t2flow?version=7","/users/6658","Wicker","taverna 2","","","Apply an OpenTox algorithm",-1, 0, ,
"http://www.myexperiment.org/workflows/1105/versions/1.html","OpenTox Apply Model On Dataset","2010-05-1118:20:05","2010-05-1118:20:06","http://www.myexperiment.org/workflows/1105/download/OpenTox_Apply_Model_On_Dataset-v1.t2flow?version=1","/users/6658","Wicker","taverna 2","","","Apply a model to predict a dataset",-1, 0, ,
"http://www.myexperiment.org/workflows/1105/versions/2.html","OpenTox Apply Model On Dataset","2010-05-1118:20:05","2010-05-1118:20:06","http://www.myexperiment.org/workflows/1105/download/OpenTox_Apply_Model_On_Dataset-v2.t2flow?version=2","/users/6658","Wicker","taverna 2","","","Apply a model to predict a dataset",-1, 0, ,
"http://www.myexperiment.org/workflows/1105/versions/3.html","OpenTox Apply Model On Dataset","2010-05-1118:20:05","2010-05-1118:20:06","http://www.myexperiment.org/workflows/1105/download/OpenTox_Apply_Model_On_Dataset-v3.t2flow?version=3","/users/6658","Wicker","taverna 2","","","Apply a model to predict a dataset",-1, 0, ,
"http://www.myexperiment.org/workflows/1107/versions/1.html","OpenTox Handle Task","2010-05-1819:12:25","","http://www.myexperiment.org/workflows/1107/download/OpenTox_Handle_Task-v1.t2flow?version=1","/users/6658","Wicker","taverna 2","","","Waits for a task to be finished and returns resulting URI",-1, 0, ,
"http://www.myexperiment.org/workflows/1107/versions/2.html","OpenTox Handle Task","2010-05-1819:12:25","","http://www.myexperiment.org/workflows/1107/download/OpenTox_Handle_Task-v2.t2flow?version=2","/users/6658","Wicker","taverna 2","","","Waits for a task to be finished and returns resulting URI",-1, 0, ,
"http://www.myexperiment.org/workflows/1107/versions/3.html","OpenTox Handle Task","2010-05-1819:12:25","","http://www.myexperiment.org/workflows/1107/download/OpenTox_Handle_Task-v3.t2flow?version=3","/users/6658","Wicker","taverna 2","","","Waits for a task to be finished and returns resulting URI",-1, 0, ,
"http://www.myexperiment.org/workflows/1107/versions/4.html","OpenTox Handle Task","2010-05-1819:12:25","","http://www.myexperiment.org/workflows/1107/download/OpenTox_Handle_Task-v4.t2flow?version=4","/users/6658","Wicker","taverna 2","","","Waits for a task to be finished and returns resulting URI",-1, 0, ,
"http://www.myexperiment.org/workflows/1107/versions/5.html","OpenTox Handle Task","2010-05-1819:12:25","","http://www.myexperiment.org/workflows/1107/download/OpenTox_Handle_Task-v5.t2flow?version=5","/users/6658","Wicker","taverna 2","","","Waits for a task to be finished and returns resulting URI",-1, 0, ,
"http://www.myexperiment.org/workflows/1107/versions/6.html","OpenTox Handle Task","2010-05-1819:12:25","","http://www.myexperiment.org/workflows/1107/download/OpenTox_Handle_Task-v6.t2flow?version=6","/users/6658","Wicker","taverna 2","","","Waits for a task to be finished and returns resulting URI",-1, 0, ,
"http://www.myexperiment.org/workflows/1107/versions/7.html","OpenTox Handle Task","2010-05-1819:12:25","","http://www.myexperiment.org/workflows/1107/download/OpenTox_Handle_Task-v7.t2flow?version=7","/users/6658","Wicker","taverna 2","","","Waits for a task to be finished and returns resulting URI",-1, 0, ,
"http://www.myexperiment.org/workflows/1107/versions/8.html","OpenTox Handle Task","2010-05-1819:12:25","","http://www.myexperiment.org/workflows/1107/download/OpenTox_Handle_Task-v8.t2flow?version=8","/users/6658","Wicker","taverna 2","","","Waits for a task to be finished and returns resulting URI",-1, 0, ,
"http://www.myexperiment.org/workflows/1110/versions/1.html","OpenTox Get Datasets","2010-05-1118:30:37","","http://www.myexperiment.org/workflows/1110/download/OpenTox_Get_Datasets-v1.t2flow?version=1","/users/6658","Wicker","taverna 2","","","Gets a list of available data set URIs",-1, 0, ,
"http://www.myexperiment.org/workflows/1110/versions/2.html","OpenTox Get Datasets","2010-05-1118:30:37","","http://www.myexperiment.org/workflows/1110/download/OpenTox_Get_Datasets-v2.t2flow?version=2","/users/6658","Wicker","taverna 2","","","Gets a list of available data set URIs",-1, 0, ,
"http://www.myexperiment.org/workflows/1110/versions/3.html","OpenTox Get Datasets","2010-05-1118:30:37","","http://www.myexperiment.org/workflows/1110/download/OpenTox_Get_Datasets-v3.t2flow?version=3","/users/6658","Wicker","taverna 2","","","Gets a list of available data set URIs",-1, 0, ,
"http://www.myexperiment.org/workflows/1118/versions/1.html","Kegg pathway diagrams","2010-03-1308:17:39","","http://www.myexperiment.org/workflows/1118/download/Kegg_pathway_diagrams-v1.t2flow?version=1","/users/7551","Jannetta","taverna 2","/users/7551,","Jannetta,","Find pathways in which all the genes in the list are involved. For each pathway draw the pathway diagram. <hr /> for each protein draw a diagram of the Kegg pathway that its protein is involved in and where available visualise the structures",0, 0, ,
"http://www.myexperiment.org/workflows/1120/versions/1.html","Kegg pathway diagrams","2010-03-1912:41:27","2010-03-1912:41:28","http://www.myexperiment.org/workflows/1120/download/Kegg_pathway_diagrams-v1.t2flow?version=1","/users/7551","Jannetta","taverna 2","","","Find pathways in which all the genes in the list are involved. Find all enzymes from the list of genes. For each pathway draw the diagram and colour the enzymes boxes in the colours specified.",1, 0, ,
"http://www.myexperiment.org/workflows/1120/versions/2.html","Kegg pathway diagrams","2010-03-1912:41:27","2010-03-1912:41:28","http://www.myexperiment.org/workflows/1120/download/Kegg_pathway_diagrams-v2.t2flow?version=2","/users/7551","Jannetta","taverna 2","","","Find pathways in which all the genes in the list are involved. For each pathway draw the pathway diagram. Colour all enzyme boxes with colours specified. This workflow still has one problem. The list of colours have to be specified. I would like ideally to only except one background and one foreground colour and expand that to a list with length equivalent to the number of enzymes found - just duplicating the specified colours. However with almost no Taverna documentation to speak of, none of my efforts wanted to work so far. <hr /> Find pathways in which all the genes in the list are involved. For each pathway draw the pathway diagram. <hr /> for each protein draw a diagram of the Kegg pathway that its protein is involved in and where available visualise the structures",1, 0, ,
"http://www.myexperiment.org/workflows/1120/versions/3.html","Kegg pathway diagrams","2010-03-1912:41:27","2010-03-1912:41:28","http://www.myexperiment.org/workflows/1120/download/Kegg_pathway_diagrams-v3.t2flow?version=3","/users/7551","Jannetta","taverna 2","","","Find pathways in which all the genes in the list are involved. For each pathway draw the pathway diagram. <hr /> Find pathways in which all the genes in the list are involved. For each pathway draw the pathway diagram. Colour all enzyme boxes with colours specified. This workflow still has one problem. The list of colours have to be specified. I would like ideally to only except one background and one foreground colour and expand that to a list with length equivalent to the number of enzymes found - just duplicating the specified colours. However with almost no Taverna documentation to speak of, none of my efforts wanted to work so far. <hr /> for each protein draw a diagram of the Kegg pathway that its protein is involved in and where available visualise the structures",1, 0, ,
"http://www.myexperiment.org/workflows/1123/versions/1.html","Compare two genomes for similarity","2010-03-1711:01:09","2010-03-1711:05:00","http://www.myexperiment.org/workflows/1123/download/Compare_two_genomes_for_similarity-v1.t2flow?version=1","/users/7600","Gregg Iceton","taverna 2","/users/7600,","Gregg Iceton,","The workflow takes as input two nucleotide/protein sequences in FastA format, requests a minimum percentage similarity threshold and then checks this against the similarity of the two sequences as determined by the Needleman-Wunsch global alignment.",1, 0, ,
"http://www.myexperiment.org/workflows/1123/versions/2.html","Compare two genomes for similarity","2010-03-1711:01:09","2010-03-1711:05:00","http://www.myexperiment.org/workflows/1123/download/Compare_two_genomes_for_similarity-v2.t2flow?version=2","/users/7600","Gregg Iceton","taverna 2","/users/7600,","Gregg Iceton,","The workflow takes as input two nucleotide/protein sequences in FastA format, requests a minimum percentage similarity threshold and then checks this against the similarity of the two sequences as determined by the Needleman-Wunsch global alignment.",1, 0, ,
"http://www.myexperiment.org/workflows/1123/versions/3.html","Compare two genomes for similarity","2010-03-1711:01:09","2010-03-1711:05:00","http://www.myexperiment.org/workflows/1123/download/Compare_two_genomes_for_similarity-v3.t2flow?version=3","/users/7600","Gregg Iceton","taverna 2","/users/7600,","Gregg Iceton,","The workflow takes as input two nucleotide/protein sequences in FastA format, requests a minimum percentage similarity threshold and then checks this against the similarity of the two sequences as determined by the Needleman-Wunsch global alignment.",-1, 0, ,
"http://www.myexperiment.org/workflows/1123/versions/4.html","Compare two genomes for similarity","2010-03-1711:01:09","2010-03-1711:05:00","http://www.myexperiment.org/workflows/1123/download/Compare_two_genomes_for_similarity-v4.t2flow?version=4","/users/7600","Gregg Iceton","taverna 2","/users/7600,","Gregg Iceton,","This workflow takes the file path to two genome nucleotide files in fasta format and requests a minimum similarity required from the user.&nbsp; The genomes are aligned according to the M-GCAT algorithm ( <a href=http://alggen.lsi.upc.es/recerca/align/mgcat/intro-mgcat.html rel=nofollow>http://alggen.lsi.upc.es/recerca/align/mgcat/intro-mgcat.html</a> ) and the genome similarity parsed out of the resultant log file.&nbsp; Output is either 0 (genome similarity less than required similarity) or 1 (genome similarity equal to or greater than the required similarity). NB - The file paths to the sequence files MUST be provided, not the sequences themselves!",-1, 0, ,
"http://www.myexperiment.org/workflows/1125/versions/1.html","Calculating frequencies of gene expression levels using microarray data in MaxD","2010-03-1508:43:31","","","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","This workflow retrieves data from the MaxD microarray database and calculates the frequencies of gene expression levels using an R script",
"http://www.myexperiment.org/workflows/1129/versions/1.html","Cross-references search, duplicated genes search, cross-reference fetch","2010-03-1608:13:50","2010-03-1608:18:06","http://www.myexperiment.org/workflows/1129/download/Cross-references_search__duplicated_genes_search__cross-reference_fetch-v1.t2flow?version=1","/users/2167","abretaud","taverna 2","/users/2167,","abretaud,","This workflow is composed of 3 steps: -First, it search for Ensembl gene Ids matching a list of identifier, using the GenOuest Xref webservice. -Then it uses the  <a href=http://dgd.genouest.org rel=nofollow>Duplicated Genes Database</a>  webservice to search for duplication information about each found gene. -Finally, it uses the GenOuest Xref webservice to fetch external identifier for each found gene (GO term in this example).",-1, 0, ,
"http://www.myexperiment.org/workflows/1132/versions/1.html","[untitled]","2010-03-1616:33:35","","http://www.myexperiment.org/workflows/1132/download/_untitled_-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1133/versions/1.html","Split multi-sequence FASTA file into list","2010-03-1617:46:06","","http://www.myexperiment.org/workflows/1133/download/Split_multi-sequence_FASTA_file_into_list-v1.t2flow?version=1","/users/7599","White duncan100","taverna 2","","","Splits a flat file containing multiple fasta sequences into a list of fasta sequences.",-1, 0, ,
"http://www.myexperiment.org/workflows/1138/versions/1.html","microRNA to KEGG Pathways and Abstracts","2010-03-1710:53:02","","","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","Workflow takes in a text file of microRNAs from microCOSM (at the EBI) and outputs a list of KEGG pathway information, including genes in pathways and pathway abstracts from PubMed. The results can then be used in various text mining applications/workflows to rank the results against a given disease. <hr /> Workflow takes in a file of microRNAs",
"http://www.myexperiment.org/workflows/1139/versions/1.html","Log into Alitora system","2010-03-1711:57:58","","","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","A nested workflow to be used for logging into Alitora",
"http://www.myexperiment.org/workflows/1140/versions/1.html","Log out from Alitora system","2010-03-1712:00:22","2010-03-1712:09:46","","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","A nested workflow to be used for logging out of Alitora",
"http://www.myexperiment.org/workflows/1142/versions/1.html","Test workflow for logging into Alitora and getting information about a specific meme","2010-03-1712:04:26","","","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,",,
"http://www.myexperiment.org/workflows/1146/versions/1.html","Convert to KEGG ID","2010-03-1717:43:24","2010-03-1717:44:58","http://www.myexperiment.org/workflows/1146/download/Convert_to_KEGG_ID-v1.t2flow?version=1","/users/7599","White duncan100","taverna 2","/users/7599,","White duncan100,","Convert another database ID to a KEGG ID. Valid namespaces are NCBI_gi, GebBank, UniProt, UniGene, PMID or OMIM.",-1, 0, ,
"http://www.myexperiment.org/workflows/1147/versions/1.html","Visualise KDA output data with Cytoscape","2010-03-1809:53:47","2010-03-1809:53:48","","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","This workflow retrieves a data file on a web server directory and launches Cytoscape to visualise it.",
"http://www.myexperiment.org/workflows/1147/versions/2.html","Visualise KDA output data with Cytoscape","2010-03-1809:53:47","2010-03-1809:53:48","","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","This workflow retrieves a data file on a web server directory and launches Cytoscape to visualise it.",
"http://www.myexperiment.org/workflows/1151/versions/1.html","Part 2","2010-03-1812:38:50","","http://www.myexperiment.org/workflows/1151/download/Part_2-v1.t2flow?version=1","/users/7599","White duncan100","taverna 2","/users/7599,","White duncan100,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1152/versions/1.html","Parts 4-6","2010-03-1812:39:55","2010-03-1812:40:43","http://www.myexperiment.org/workflows/1152/download/Parts_4-6-v1.t2flow?version=1","/users/7599","White duncan100","taverna 2","/users/7599,","White duncan100,",,0, 0, ,
"http://www.myexperiment.org/workflows/1157/versions/1.html","Square A List Of Numbers","2010-03-1903:45:10","2010-03-1904:16:44","http://www.myexperiment.org/workflows/1157/download/Square_A_List_Of_Numbers-v1.t2flow?version=1","/users/3143","Paul Miller","taverna 2","/users/3143,","Paul Miller,","Simple workflow which squares a list of numbers.",-1, 0, ,
"http://www.myexperiment.org/workflows/1165/versions/1.html","Requirement 1","2010-03-1908:50:12","2010-03-1908:54:23","http://www.myexperiment.org/workflows/1165/download/Requirement_1-v1.t2flow?version=1","/users/7551","Jannetta","taverna 2","/users/7551,","Jannetta,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1166/versions/1.html","Requirement 1 and 3","2010-03-1908:50:48","2010-03-1908:55:11","http://www.myexperiment.org/workflows/1166/download/Requirement_1_and_3-v1.t2flow?version=1","/users/7551","Jannetta","taverna 2","/users/7551,","Jannetta,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1167/versions/1.html","Requirement 3","2010-03-1908:51:54","2010-03-1908:52:30","http://www.myexperiment.org/workflows/1167/download/Requirement_3-v1.t2flow?version=1","/users/7551","Jannetta","taverna 2","/users/7551,","Jannetta,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1168/versions/1.html","Invocation of Gene Pattern modules using R","2010-03-1910:26:34","2010-03-1910:29:08","","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","&nbsp;A workflow to invoke a Gene Pattern module using an R script. Note that a FTP URL for the data to be analysed is required, not the data itself!",
"http://www.myexperiment.org/workflows/1169/versions/1.html","BlastandParse1","2010-03-1912:09:15","","http://www.myexperiment.org/workflows/1169/download/BlastandParse1-v1.t2flow?version=1","/users/7581","Andrew David King","taverna 2","","","This workflow allows you to configure a BioMart query to fetch sequences you want from Ensembl. These sequences are retrieved and a blast database of them is created (by default, in the directory you ran taverna from). Warning: This workflow assumes that you have blastall and formatdb installed on the machine, and that by default, these are both found or linked in /usr/local/bin. It also assumes that you have write permission to the directory you have run taverna from. The beanshells create_blastall_cmdArgs and create_formatdb_cmdArgs are what you need to edit if the default locations are not appropriate for you. Shortcomings: The names of all the files created and used is hard coded in this workflow. This means that if you run this workflow more than once without editing anything, you will overwrite files you have previously created. The results are parsed using threshold values for percent identity similarity and e-value as input by the user and outputs those values above these thresholds. Credit: Bela",1, 0, ,
"http://www.myexperiment.org/workflows/1170/versions/1.html","BlastandParse2","2010-03-1912:20:29","","http://www.myexperiment.org/workflows/1170/download/BlastandParse2-v1.t2flow?version=1","/users/7581","Andrew David King","taverna 2","","","This workflow allows you to configure a BioMart query to fetch sequences you want from Ensembl. These sequences are retrieved and a blast database of them is created (by default, in the directory you ran taverna from). Warning: This workflow assumes that you have blastall and formatdb installed on the machine, and that by default, these are both found or linked in /usr/local/bin. It also assumes that you have write permission to the directory you have run taverna from. The beanshells create_blastall_cmdArgs and create_formatdb_cmdArgs are what you need to edit if the default locations are not appropriate for you. Shortcomings: The names of all the files created and used is hard coded in this workflow. This means that if you run this workflow more than once without editing anything, you will overwrite files you have previously created. The results of the blastall are parsed to give those that are above the max e-value and minimum percent identity as indicated by the user and an output of uniprot accession numbers is created that can be searched against KEGG.",1, 0, ,
"http://www.myexperiment.org/workflows/1172/versions/1.html","Compare genome, extract proteins which are drug targets, apply to KEGG pathway","2010-03-1913:16:24","2010-03-1913:33:53","http://www.myexperiment.org/workflows/1172/download/Compare_genome__extract_proteins_which_are_drug_targets__apply_to_KEGG_pathway-v1.t2flow?version=1","/users/7582","Ian Laycock","taverna 2","/users/7582,","Ian Laycock,","&nbsp; Takes GI number for source (non-pathogenic) and target (pathogneic) genomes, extracts list of all proteins from each genome using GenBank database. Outputs prtoeins in FastA format. Creates database from source proteins using formatdb (locally installed) and blasts (local installed) proteins from target against this database. Extracts protens which are unique (no blast hits) to the target (pathogenic) genome based on eValue set by user. Takes unique proteins from target and blasts against another formatdb database created from existing drug targets (provided by user). Finds proteins that are similar between pathogenic proteins and existing drug targets. Feeds the GI numbers of these proteins into KEGG. Workflow produces image of KEGG pathways which protein is involved in. Also outputs final list of interesting proteins, pathway and KEGG descriptions, url of image (from KEGG database).",1, 0, ,
"http://www.myexperiment.org/workflows/1173/versions/1.html","Fetch EMBL File","2010-03-1913:23:40","","http://www.myexperiment.org/workflows/1173/download/Fetch_EMBL_File-v1.t2flow?version=1","/users/7581","Andrew David King","taverna 2","","","Fetches an EMBL file using the EMBL id. Creates file to a specified location.",2, 0, ,
"http://www.myexperiment.org/workflows/1177/versions/1.html","Fetch Fasta and Genbank files","2010-03-1913:32:07","","http://www.myexperiment.org/workflows/1177/download/Fetch_Fasta_and_Genbank_files-v1.t2flow?version=1","/users/7581","Andrew David King","taverna 2","","","Fetches fasta and genbank files for a given identifier.,e.g., CP000256",0, 0, ,
"http://www.myexperiment.org/workflows/1178/versions/1.html","Run MGCAT for Global Sequence Comparison","2010-03-1913:42:38","","http://www.myexperiment.org/workflows/1178/download/Run_MGCAT_for_Global_Sequence_Comparison-v1.t2flow?version=1","/users/7581","Andrew David King","taverna 2","","","Runs the M-GCAT  tool for  Global Sequence Comparison. M-GCAT:  <a href=http://alggen.lsi.upc.es/recerca/align/mgcat/ rel=nofollow>http://alggen.lsi.upc.es/recerca/align/mgcat/</a> intro-mgcat.html",0, 0, ,
"http://www.myexperiment.org/workflows/1179/versions/1.html","KEGG Pathway Analysis","2010-03-1913:46:37","","http://www.myexperiment.org/workflows/1179/download/KEGG_Pathway_Analysis-v1.t2flow?version=1","/users/7581","Andrew David King","taverna 2","","","The KEGG pathway analysis of the workflow takes a list of UniProt accession numbers in any of the following formats with the following prefixes: External database  Database prefix-----------------            ---------------NCBI GI                     ncbi-gi: NCBI GeneID           ncbi-geneid: GenBank                  genbank: UniGene                   unigene: UniProt                      uniprot: It performs this using the web service bconv, provided by the KEGG database (Kanehisa et al., 2010), described in the KEGG API available at:  <a href=http://www.genome.jp/kegg/docs/keggapi_manual.html#label rel=nofollow>http://www.genome.jp/kegg/docs/keggapi_manual.html#label</a> :42.A list of KEGG Ids in a tabular format is produced, the first element contains the input ID, the second element is the KEGG ID and the third element is a string confirming the corresponding existence of the proteins in both databases used. This tabular format is then split into three segments using white-space as a regular expression. Each element from each line is then entered into a new separate list. The next step in the workflow is to remove the confirmation string and the NCBI-GI ID, leaving the KEGG ID of the proteins.  This is done by using the regular expression:.{3}:.*The get_pathways_by_genes web service from the KEGG database then queries the KEGG database and retrieves the pathways the protein participates in. The mark_pathway_by_objects method is used to mark the input proteins from the filtered list in their respective KEGG pathways found by get_pathways_by_genes. This method then generates a list of URLs as an output. The URLs retrieved corresponds to the images of the KEGG pathways. In these images the target proteins are marked in orange. For this procedure the Get_Image_From_URL method is used. The final output is a list of images with the target proteins in their respective KEGG pathways highlighted in orange.",0, 0, ,
"http://www.myexperiment.org/workflows/1180/versions/1.html","NCBI Gi to Kegg Pathways","2010-03-1913:47:39","2010-03-1913:52:45","http://www.myexperiment.org/workflows/1180/download/NCBI_Gi_to_Kegg_Pathways-v1.t2flow?version=1","/users/7582","Ian Laycock","taverna 2","/users/7582,","Ian Laycock,","User inputs background and foreground colour to be used to highlight proteins in KEGG pathway image. User provides NCBI GI numbers. Worflow calculates KEGG ID and pathway ID and sends value to colour service, which adds colour to that KEGG id on pathway image. Also outputs kegg description, pathway description and url of image.",0, 0, ,
"http://www.myexperiment.org/workflows/1181/versions/1.html","Test for Orthologues","2010-03-1913:53:54","","http://www.myexperiment.org/workflows/1181/download/Test_for_Orthologues-v1.t2flow?version=1","/users/7581","Andrew David King","taverna 2","","","Warning: The files are hardcoded in to the beanshell of this workflow. Given an orthlog file for an organism from <a href=http://www.ebi.ac.uk/integr8/FtpSearch.do rel=nofollow>http://www.ebi.ac.uk/integr8/FtpSearch.do</a> ?orgProteomeId=22602,find proteins that are orthologous to proteinsin another oragnsims, e.g., B.subtils.  Outputspercent.",1, 0, ,
"http://www.myexperiment.org/workflows/1182/versions/1.html","Extract proteins using a gi - output as fasta file","2010-03-1913:54:54","","http://www.myexperiment.org/workflows/1182/download/Extract_proteins_using_a_gi_-_output_as_fasta_file_-v1.t2flow?version=1","/users/7582","Ian Laycock","taverna 2","/users/7582,","Ian Laycock,","The workflow uses the gi id to retrieve a xml format of the genbank entry. Using a beanscript, the workflow then parses the required data for the creation of the protein fasta file.",0, 0, ,
"http://www.myexperiment.org/workflows/1183/versions/1.html","blastp of target vs source database","2010-03-1913:57:32","2010-03-1914:05:40","http://www.myexperiment.org/workflows/1183/download/blastp_of_target_vs_source_database-v1.t2flow?version=1","/users/7582","Ian Laycock","taverna 2","/users/7582,","Ian Laycock,","This worlflow allows the user to input two sets of proteins in fasta format. One file is converted to a database using formatdb, the set is blasted against this database to test for Blast hits. Users is able to set eValue and destination of files for database and blast file. Arguments can be added to either formatdb or blast in beanshell supplied. Blast and formatdb must be installed locally and the correct filepaths for these applications must entered into the workflow accordingly.",1, 0, ,
"http://www.myexperiment.org/workflows/1184/versions/1.html","Parse unique proteins from Blast file","2010-03-1914:07:24","2010-03-1914:09:22","http://www.myexperiment.org/workflows/1184/download/Parse_unique_proteins_from_Blast_file-v1.t2flow?version=1","/users/7582","Ian Laycock","taverna 2","/users/7582,","Ian Laycock,","The workflow parses uses the blast results to determine the unique proteins found in the target genome that have no similairty to the source genome. Using these unique protein ids, and the original target protein fasta file, a fasta file of unique proteins is created.",1, 0, ,
"http://www.myexperiment.org/workflows/1185/versions/1.html","Extract proteins from xml blast results","2010-03-1914:14:44","","http://www.myexperiment.org/workflows/1185/download/Extract_proteins_from_xml_blast_results-v1.t2flow?version=1","/users/7582","Ian Laycock","taverna 2","/users/7582,","Ian Laycock,","The workflow extracts a list of proteins from the target genome that may be known drugs using the blast similarity results.",2, 0, ,
"http://www.myexperiment.org/workflows/1186/versions/1.html","Kegg pathway diagrams (missing part 3)","2010-03-1915:40:02","2010-03-1915:40:26","http://www.myexperiment.org/workflows/1186/download/Kegg_pathway_diagrams__missing_part_3_-v1.t2flow?version=1","/users/7600","Gregg Iceton","taverna 2","/users/7600,","Gregg Iceton,","Find pathways in which all the genes in the list are involved. For each pathway draw the pathway diagram. Find pathways in which all the genes in the list are involved. For each pathway draw the pathway diagram. Colour all enzyme boxes with colours specified. This workflow still has one problem. The list of colours have to be specified. I would like ideally to only except one background and one foreground colour and expand that to a list with length equivalent to the number of enzymes found - just duplicating the specified colours. However with almost no Taverna documentation to speak of, none of my efforts wanted to work so far. for each protein draw a diagram of the Kegg pathway that its protein is involved in and where available visualise the structures",1, 0, ,
"http://www.myexperiment.org/workflows/1186/versions/2.html","Kegg pathway diagrams (missing part 3)","2010-03-1915:40:02","2010-03-1915:40:26","http://www.myexperiment.org/workflows/1186/download/Kegg_pathway_diagrams__missing_part_3_-v2.t2flow?version=2","/users/7600","Gregg Iceton","taverna 2","/users/7600,","Gregg Iceton,","Find pathways in which all the genes in the list are involved. For each pathway draw the pathway diagram. Colour all enzyme boxes with colours specified. This workflow still has one problem. The list of colours have to be specified. I would like ideally to only except one background and one foreground colour and expand that to a list with length equivalent to the number of enzymes found - just duplicating the specified colours. However with almost no Taverna documentation to speak of, none of my efforts wanted to work so far. Find pathways in which all the genes in the list are involved. For each pathway draw the pathway diagram. for each protein draw a diagram of the Kegg pathway that its protein is involved in and where available visualise the structures",1, 0, ,
"http://www.myexperiment.org/workflows/1188/versions/1.html","Retrieve Genome Seqn using gi nos","2010-03-1915:17:53","","http://www.myexperiment.org/workflows/1188/download/Retrieve_Genome_Seqn_using_gi_nos-v1.t2flow?version=1","/users/7582","Ian Laycock","taverna 2","/users/7582,","Ian Laycock,","Retrieves the genome seqn for both the target and source strains using gi nos",1, 0, ,
"http://www.myexperiment.org/workflows/1189/versions/1.html","KEGG pathway analysis","2010-03-1915:53:18","","http://www.myexperiment.org/workflows/1189/download/KEGG_pathway_analysis-v1.t2flow?version=1","/users/7597","Fergus","taverna 2","","","The KEGG pathway analysis of the workflow takes a list of UniProt accession numbers in any of the following formats with the following prefixes: External database Database prefix ----------------- --------------- NCBI GI ncbi-gi: NCBI GeneID ncbi-geneid: GenBank genbank: UniGene unigene: UniProt uniprot: It performs this using the web service bconv, provided by the KEGG database (Kanehisa et al., 2010), described in the KEGG API available at:  <a href=http://www.genome.jp/kegg/docs/keggapi_manual.html#label rel=nofollow>http://www.genome.jp/kegg/docs/keggapi_manual.html#label</a> :42. A list of KEGG Ids in a tabular format is produced, the first element contains the input ID, the second element is the KEGG ID and the third element is a string confirming the corresponding existence of the proteins in both databases used. This tabular format is then split into three segments using white-space as a regular expression. Each element from each line is then entered into a new separate list. The next step in the workflow is to remove the confirmation string and the NCBI-GI ID, leaving the KEGG ID of the proteins. This is done by using the regular expression: .{3}:.* The get_pathways_by_genes web service from the KEGG database then queries the KEGG database and retrieves the pathways the protein participates in. The mark_pathway_by_objects method is used to mark the input proteins from the filtered list in their respective KEGG pathways found by get_pathways_by_genes. This method then generates a list of URLs as an output. The URLs retrieved corresponds to the images of the KEGG pathways. In these images the target proteins are marked in orange. For this procedure the Get_Image_From_URL method is used. The final output is a list of images with the target proteins in their respective KEGG pathways highlighted in orange.",0, 0, ,
"http://www.myexperiment.org/workflows/1191/versions/1.html","Sage bionetwork demo workflow","2010-03-2209:56:03","","","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","This workflow performs key driver analysis and displays the results in Cytoscape.",
"http://www.myexperiment.org/workflows/1193/versions/1.html","Angiogenesis Feature Extraction workflow","2010-03-2313:19:35","2012-01-1008:47:41","http://www.myexperiment.org/workflows/1193/download/Angiogenesis_Feature_Extraction_workflow-v1.t2flow?version=1","/users/7800","Charala...","taverna 2","/users/7800,","Charalampos,","This is a sample Workflow based on an Image Mining Web Service developed in the context of e-LICO project ( <a href=http://www.e-lico.eu rel=nofollow>www.e-lico.eu</a> ). It demonstrates the main functionality of the Web Service, involving the application of several basic image operators on angiogenic images and then performing useful feature (e.g., image texture, vessel length, branch count, etc.) extraction. Current version is for demonstration purposes. Only Angiogenic images that already exist on server's repository might by used. You can use &quot;testImage&quot; as input Image Reference for a demonstration.",-1, 0, ,
"http://www.myexperiment.org/workflows/1193/versions/2.html","Angiogenesis Feature Extraction workflow","2010-03-2313:19:35","2012-01-1008:47:41","http://www.myexperiment.org/workflows/1193/download/Angiogenesis_Feature_Extraction_workflow-v2.t2flow?version=2","/users/7800","Charala...","taverna 2","/users/7800,","Charalampos,","This is a sample Workflow based on an Image Mining Web Service developed in the context of e-LICO project ( <a href=http://www.e-lico.eu rel=nofollow>www.e-lico.eu</a> ). It demonstrates the main functionality of the Web Service, involving the application of several basic image operators on angiogenic images and then performing useful feature (e.g., image texture, vessel length, branch count, etc.) extraction. &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/1193/versions/3.html","Angiogenesis Feature Extraction workflow","2010-03-2313:19:35","2012-01-1008:47:41","http://www.myexperiment.org/workflows/1193/download/Angiogenesis_Feature_Extraction_workflow-v3.t2flow?version=3","/users/7800","Charala...","taverna 2","/users/7800,","Charalampos,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1197/versions/1.html","Construction of skeleton SBML model using a list of yeast ORF numbers","2010-03-2617:08:13","2010-03-2617:13:15","http://www.myexperiment.org/workflows/1197/download/Construction_of_skeleton_SBML_model_using_a_list_of_yeast_ORF_numbers-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","This workflow generates a skeleton SBML model consisting of the metabolic reactions for a given list of yeast enzymes ORF numbers",0, 0, ,
"http://www.myexperiment.org/workflows/1198/versions/1.html","Construction of skeleton SBML model using subsystem term","2010-03-2617:11:26","2010-03-2617:12:06","http://www.myexperiment.org/workflows/1198/download/Construction_of_skeleton_SBML_model_using_subsystem_term-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","This workflow generates a skeleton SBML model consisting of the metabolic reactions for a given subsystem term.",1, 0, ,
"http://www.myexperiment.org/workflows/1200/versions/1.html","SBML model parameterisation","2010-03-2617:20:14","","http://www.myexperiment.org/workflows/1200/download/SBML_model_parameterisation-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","This workflow parameterises an SBML model generated by the qualitative SBML model construction workflow",0, 0, ,
"http://www.myexperiment.org/workflows/1201/versions/1.html","SBML model optimisation","2010-03-2617:21:53","","http://www.myexperiment.org/workflows/1201/download/SBML_model_optimisation-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","This workflow modifies reaction kinetic parameters against experimental data stored in the MCISB key results database",0, 0, ,
"http://www.myexperiment.org/workflows/1202/versions/1.html","Copasi time simulation of SBML model","2010-03-2617:23:25","","http://www.myexperiment.org/workflows/1202/download/Copasi_time_simulation_of_SBML_model-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Uses the synchronous Copasi time simulation web service to predict the concentrations of species over a time period. The results from Copasi are provided in SBRML format which is visualised as a graph using an R script.",2, 0, ,
"http://www.myexperiment.org/workflows/1203/versions/1.html","Select items from list","2010-03-3014:04:45","","http://www.myexperiment.org/workflows/1203/download/Select_items_from_list-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","This workflow pops up a window containing an input list of strings. The user is invited to select one or more strings for downstream processing.",0, 0, ,
"http://www.myexperiment.org/workflows/1206/versions/1.html","XSTAR","2010-04-0219:52:35","2011-02-2717:34:42","http://www.myexperiment.org/workflows/1206/download/XSTAR-v1.t2flow?version=1","/users/8014","Juan Gonzalez","taverna 2","","","This is a simple workflow designed to run XSTAR with an user selected input.  XSTAR is a computer program for calculating the physical conditions and emission spectra of photoionized gases. More information can be found here: - XSTAR home page:  <a href=http://heasarc.nasa.gov/lheasoft/xstar/xstar.html rel=nofollow>http://heasarc.nasa.gov/lheasoft/xstar/xstar.html</a> - XSTAR on the Spinet client (Soaplab2):  <a href=http://caoba.ivic.ve:8180/soaplab2-axis/ rel=nofollow>http://caoba.ivic.ve:8180/soaplab2-axis/</a>",0, 0, ,
"http://www.myexperiment.org/workflows/1206/versions/2.html","XSTAR","2010-04-0219:52:35","2011-02-2717:34:42","http://www.myexperiment.org/workflows/1206/download/XSTAR-v2.t2flow?version=2","/users/8014","Juan Gonzalez","taverna 2","","","This is a simple workflow designed to run XSTAR with an user selected input.  XSTAR is a computer program for calculating the physical conditions and emission spectra of photoionized gases. More information can be found here: - XSTAR home page:  <a href=http://heasarc.nasa.gov/lheasoft/xstar/xstar.html rel=nofollow>http://heasarc.nasa.gov/lheasoft/xstar/xstar.html</a> - XSTAR on the Spinet client (Soaplab2):  <a href=http://caoba.ivic.ve:8180/soaplab2-axis/ rel=nofollow>http://caoba.ivic.ve:8180/soaplab2-axis/</a>",0, 0, ,
"http://www.myexperiment.org/workflows/1206/versions/3.html","XSTAR","2010-04-0219:52:35","2011-02-2717:34:42","http://www.myexperiment.org/workflows/1206/download/XSTAR-v3.t2flow?version=3","/users/8014","Juan Gonzalez","taverna 2","","","This is a simple workflow designed to run XSTAR with an user selected input.  XSTAR is a computer program for calculating the physical conditions and emission spectra of photoionized gases. More information can be found here: - XSTAR home page:  <a href=http://heasarc.nasa.gov/lheasoft/xstar/xstar.html rel=nofollow>http://heasarc.nasa.gov/lheasoft/xstar/xstar.html</a> - XSTAR on the Spinet client (Soaplab2):  <a href=http://caoba.ivic.ve:8180/soaplab2-axis/ rel=nofollow>http://caoba.ivic.ve:8180/soaplab2-axis/</a>",0, 0, ,
"http://www.myexperiment.org/workflows/1209/versions/1.html","myFirstLinearDataflow","2010-04-1209:32:13","","http://www.myexperiment.org/workflows/1209/download/myFirstLinearDataflow-v1.t2flow?version=1","/users/500","Paolo","taverna 2","/users/500,","Paolo,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1210/versions/1.html","Find/show Taverna&#39;s home directory","2010-04-1215:11:47","2010-04-1215:17:57","http://www.myexperiment.org/workflows/1210/download/Find_show_Taverna_s_home_directory-v1.xml?version=1","/users/5","Stian Soiland-Reyes","taverna 1","/users/5,","Stian Soiland-Reyes,","Find Taverna's home directory and open that folder using Explorer/Finder/Gnome. This is the folder that is typically something like  <code>C:\Users\stain\AppData\Roaming\taverna-2.1.2</code> ,  <code>C:\Documents and settings\stain\taverna-2.1.2</code> ,  <code>/home/stain/.taverna-2.1.2</code>  or  <code>/Users/stain/Library/Application support/taverna-2.1.2</code> This workflow should work on both Taverna 1 and Taverna 2. For Taverna 2 the beanshell script uses reflection to try to call  <code>ApplicationRuntime.getInstance().getApplicationHome()</code> On Taverna 1 the reflection will fail, and the beanshell will simply fall back to getting the variable  <code>taverna.home</code> . The last three local workers will attempt to open the folder using the commands  <code>explorer</code>  (for Windows),  <code>open</code>  (for OS X) and  <code>gnome-open</code>  (for Linux). Two of these will always fail.",4, 0, open_folder_osx, open_folder_windows, open_folder_linux_gnome, find_taverna_home, ,
"http://www.myexperiment.org/workflows/1212/versions/1.html","Entrez Gene to KEGG Pathway","2010-04-1512:22:12","2010-04-1512:22:13","","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow reads in a file from the GenePattern web site and extracts a list of Entrez gene ids. It then adds the string &quot;ncbi-geneid:&quot; to the start of each gene id. These gene ids are then cross-referenced to KEGG gene ids. Each KEGG gene id is then sent to the KEGG pathway database and its relevant pathways returned.",
"http://www.myexperiment.org/workflows/1212/versions/2.html","Entrez Gene to KEGG Pathway","2010-04-1512:22:12","2010-04-1512:22:13","","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in Entrez gene ids then adds the string ncbi-geneid: to the start of each gene id. These gene ids are then cross-referenced to KEGG gene ids. Each KEGG gene id is then sent to the KEGG pathway database and its relevant pathways returned.",
"http://www.myexperiment.org/workflows/1213/versions/1.html","Available instruments through DPAS","2010-04-1513:51:09","2012-03-1615:11:00","http://www.myexperiment.org/workflows/1213/download/Available_instruments_through_DPAS-v1.t2flow?version=1","/users/1184","AndrÃ© Csillaghy","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/1213/versions/2.html","Available instruments through DPAS","2010-04-1513:51:09","2012-03-1615:11:00","http://www.myexperiment.org/workflows/1213/download/Available_instruments_through_DPAS-v2.t2flow?version=2","/users/1184","AndrÃ© Csillaghy","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/1213/versions/3.html","Available instruments through DPAS","2010-04-1513:51:09","2012-03-1615:11:00","http://www.myexperiment.org/workflows/1213/download/Available_instruments_through_DPAS-v3.t2flow?version=3","/users/1184","AndrÃ© Csillaghy","taverna 2","","","This workflow returns a comma separeted list of instruments for the DPAS.&nbsp; It does not require any inputs.",-1, 0, ,
"http://www.myexperiment.org/workflows/1213/versions/4.html","Available instruments through DPAS","2010-04-1513:51:09","2012-03-1615:11:00","http://www.myexperiment.org/workflows/1213/download/Available_instruments_through_DPAS-v4.t2flow?version=4","/users/1184","AndrÃ© Csillaghy","taverna 2","","","no inputs required; returns a list of instrument names as  known by the DPAS",1, 0, ,
"http://www.myexperiment.org/workflows/1213/versions/5.html","Available instruments through DPAS","2010-04-1513:51:09","2012-03-1615:11:00","http://www.myexperiment.org/workflows/1213/download/Available_instruments_through_DPAS-v5.t2flow?version=5","/users/1184","AndrÃ© Csillaghy","taverna 2","","","This workflow uses a DPAS servlet to obtain all available intrument keys in the DPAS (Data Provider Access Service) and formats the return as VOTable.",0, 0, ,
"http://www.myexperiment.org/workflows/1214/versions/1.html","Retrieve all data for all instruments for a given periode of time","2010-04-1514:06:32","2010-08-0915:01:12","http://www.myexperiment.org/workflows/1214/download/Retrieve_all_data_for_all_instruments_for_a_given_periode_of_time-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow gets all available instruments from the DPAS and requests a sample set of data for each of this instruments. Input date range fixed in this version. Returns a list&nbsp; of output data in XML format.",-1, 0, ,
"http://www.myexperiment.org/workflows/1214/versions/2.html","Retrieve all data for all instruments for a given periode of time","2010-04-1514:06:32","2010-08-0915:01:12","http://www.myexperiment.org/workflows/1214/download/Retrieve_all_data_for_all_instruments_for_a_given_periode_of_time-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow gets all available instruments from the DPAS and  requests a data for a given time intervall for each of this instruments. Input date  range fixed in this version. Returns a list&nbsp; of output data in XML format.",-1, 0, ,
"http://www.myexperiment.org/workflows/1214/versions/3.html","Retrieve all data for all instruments for a given periode of time","2010-04-1514:06:32","2010-08-0915:01:12","http://www.myexperiment.org/workflows/1214/download/Retrieve_all_data_for_all_instruments_for_a_given_periode_of_time-v3.t2flow?version=3","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow looks up all instruments known to have worked during the requested periode of time (ICS), restructures results to make them fit instruments.xsd and requests data for this periode from DPAS.Result: VOTable with list of URLs to data.",0, 0, ,
"http://www.myexperiment.org/workflows/1215/versions/1.html","DPAS simpel query workflow","2010-04-1610:35:31","","http://www.myexperiment.org/workflows/1215/download/DPAS_simpel_query_workflow-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","","","call of the simpleQuery web service; all inputs are requested from the user; xml list as output file format",-1, 0, ,
"http://www.myexperiment.org/workflows/1216/versions/1.html","HEC standard query","2010-04-1615:00:50","","http://www.myexperiment.org/workflows/1216/download/HEC_standard_query-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","","","calls the HEC web service;inputs are start and stop time, which table should be queried and an optional where clause, as in an SQL statementoutput is of VOTable format",-1, 0, ,
"http://www.myexperiment.org/workflows/1217/versions/1.html","DPAS general query","2010-04-1915:04:01","2010-04-1915:11:36","http://www.myexperiment.org/workflows/1217/download/DPAS_general_query-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","general query to DPAS; it gets a list of instruments and lists for start and stop times; for a query hessiEC, phoenix2; start times 2001-01-01 00:00:00, 2005-04-01 00:00:00; stop times 2001-01-05 00:00:00, 2005-05-1 00:00:00 it would perform to queries: <br /> hessiEC from 2001-01-01 00:00:00 to 2001-01-05 00:00:00 and phoenix2 from 2005-04-01 00:00:00 to 2005-05-1 00:00:00 There is only one output file with the results from both queries.",-1, 0, ,
"http://www.myexperiment.org/workflows/1218/versions/1.html","DPAS general query with sorted field","2010-04-1915:37:50","2010-04-1915:43:06","http://www.myexperiment.org/workflows/1218/download/DPAS_general_query_with_sorted_field-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","same as DPAS general query. Calling the DPAS sortedQuery web service. additional input: partialSorting input boolean true or false false all result entries are sorted by start measurementTime <br /> true each request is sorted by measurement time; no overall time order, but queries stay in the order they there asked.",-1, 0, ,
"http://www.myexperiment.org/workflows/1222/versions/1.html","retrieve data for all instruments for events during a time span","2010-04-2115:13:00","","http://www.myexperiment.org/workflows/1222/download/retrieve_data_for_all_instruments_for_events_during_a_time_span-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow uses the HEC to retrieve events for a time spane given by the user from a HEC table given by the user as well.It uses all instruments available in the DPAS to retrieve data for the events Output: XML as returned by the DPAS <hr /> This workflow uses the HEC to retrieve events for a time spane given by the user from a HEC table given by the user as well.It uses all instruments available in the DPAS to retrieve data for the events; empty results are filtered out, the data is combind with the instrument name from which it was measured. Output a list of events with lists of instrument and data values.",1, 0, ,
"http://www.myexperiment.org/workflows/1223/versions/1.html","Census data and PRM services integration","2010-04-2117:37:48","2010-04-2118:19:05","http://www.myexperiment.org/workflows/1223/download/Census_data_and_PRM_services_integration-v1.t2flow?version=1","/users/666","Alex Nenadic","taverna 2","/users/666,","Alex Nenadic,","This workflow combines services that provide census data with PRM (Population Reconstruction Model) services.",-1, 0, ,
"http://www.myexperiment.org/workflows/1224/versions/1.html","Census data service","2010-04-2117:40:10","2010-04-2118:09:10","http://www.myexperiment.org/workflows/1224/download/Census_data_service-v1.t2flow?version=1","/users/666","Alex Nenadic","taverna 2","/users/666,","Alex Nenadic,","Census data services, invoked with a fixed SQL query",-1, 0, ,
"http://www.myexperiment.org/workflows/1225/versions/1.html","PRM (People Reconstruction Model) service","2010-04-2118:10:58","2010-09-1518:43:08","http://www.myexperiment.org/workflows/1225/download/PRM__People_Reconstruction_Model__service-v1.t2flow?version=1","/users/666","Alex Nenadic","taverna 2","/users/666,","Alex Nenadic,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1225/versions/2.html","PRM (People Reconstruction Model) service","2010-04-2118:10:58","2010-09-1518:43:08","http://www.myexperiment.org/workflows/1225/download/PRM__People_Reconstruction_Model__service-v2.t2flow?version=2","/users/666","Alex Nenadic","taverna 2","/users/666,","Alex Nenadic,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1226/versions/1.html","Get survey data from SurveyMapper","2010-04-2118:13:04","2010-06-1811:51:29","http://www.myexperiment.org/workflows/1226/download/Get_survey_data_from_SurveyMapper-v1.t2flow?version=1","/users/666","Alex Nenadic","taverna 2","/users/666,","Alex Nenadic,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1226/versions/2.html","Get survey data from SurveyMapper","2010-04-2118:13:04","2010-06-1811:51:29","http://www.myexperiment.org/workflows/1226/download/Get_survey_data_from_SurveyMapper-v2.t2flow?version=2","/users/666","Alex Nenadic","taverna 2","/users/666,","Alex Nenadic,","Extracting public data (such as public surveys and their questions) from SurveyMapper. SurveyMapper ( <a href=http://www.surveymapper.com/ rel=nofollow>http://www.surveymapper.com/</a> ) a free real-time                         geographic survey and polling tool from the nice people at the  <a href=http://www.casa.ucl.ac.uk/ rel=nofollow>Centre                         for Advanced Spatial Analysis</a> ,  <a href=http://www.ucl.ac.uk/ rel=nofollow>University College London</a> .",-1, 0, ,
"http://www.myexperiment.org/workflows/1231/versions/1.html","ChEBI mashup from searched string","2010-04-2914:09:37","","http://www.myexperiment.org/workflows/1231/download/ChEBI_mashup_from_searched_string-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","A demo showing hoe to use SOAP services from Bio2RDF ChEBI SPARQL endpoint. <hr /> A demo showing hoe to use SOAP services from Bio2RDF ChEBI SPARQL endpoint. First a full text search query is done, then we do a reverse link query to get all the related topic.  Finally with a describe queries we obtain the complete graph of each topic. The ntriples result is a mashup of what is known about this searched topic form ChEBI.  This graph can then be loaded in a triplestore for further exploration.",0, 0, ,
"http://www.myexperiment.org/workflows/1237/versions/1.html","Get KEGG gene descriptions and pathways","2010-04-3016:09:29","2010-04-3016:12:02","http://www.myexperiment.org/workflows/1237/download/Get_KEGG_gene_descriptions_and_pathways-v1.t2flow?version=1","/users/6902","Nadia Cerezo","taverna 2","/users/6902, /users/43,","Nadia Cerezo, Paul Fisher,","This workflow takes a list of KEGG gene identifiers and supplies descriptions associated to said genes + pathways including all genes and the descriptions associated to said pathways. The list_to_string local beanshell scripts merely transform a given list into a string of unique not-null elements separated by new lines (for batch btit use). Note that the input is a real taverna list : multiple values must be declared as multiple values instead of a single string value with distinct identifiers separated by new lines. This workflow is a slight modification of one made by Paul Fisher called &quot;Get Kegg Gene information&quot;.",1, 0, ,
"http://www.myexperiment.org/workflows/1238/versions/1.html","Genes encoded by KEGG pathway","2010-04-3020:56:06","2010-05-0120:42:27","http://www.myexperiment.org/workflows/1238/download/Genes_encoded_by_KEGG_pathway-v1.t2flow?version=1","/users/2","David Withers","taverna 2","","","Takes a KEGG pathway (e.g. hsa00232), finds the  proteins that those genes code for and returns the sequences of those proteins.",0, 0, ,
"http://www.myexperiment.org/workflows/1239/versions/1.html","Uniprot Protein Visualization","2010-05-0120:29:37","2010-05-0120:40:10","http://www.myexperiment.org/workflows/1239/download/Uniprot_Protein_Visualization-v1.t2flow?version=1","/users/2","David Withers","taverna 2","","","Jmol 3D visualization of a protein structure.",1, 0, ,
"http://www.myexperiment.org/workflows/1246/versions/1.html","iceLogo","2010-05-0713:22:20","2010-05-0713:23:45","http://www.myexperiment.org/workflows/1246/download/iceLogo-v1.t2flow?version=1","/users/150","N. Colaert","taverna 2","/users/150,","N. Colaert,","This example workflow creates an iceLogo",1, 0, ,
"http://www.myexperiment.org/workflows/1254/versions/1.html","Query caArray data service and retrieving files","2010-05-2422:55:57","2010-05-2422:55:58","http://www.myexperiment.org/workflows/1254/download/Query_caArray_data_service_and_retrieving_files_-v1.t2flow?version=1","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","<i><span>CQL_Builder</span></i> <span> provides a GUI to build a complex CQL clause querying caArray   files. <i>CaGrid_Transfer_Activity</i> downloads files to a   local directory using caGrid transfer utility.&lt;o:p&gt;&lt;/o:p&gt;</span> Need to install Taverna 2 caGrid integration suite from    <a href=http://www.mcs.anl.gov/~wtan/t2/ rel=nofollow>http://www.mcs.anl.gov/~wtan/t2/</a>  and get a cagrid Dorian account (see    <a href=http://wiki.cagrid.org/display/caGrid13/Home rel=nofollow>http://wiki.cagrid.org/display/caGrid13/Home</a> )",0, 0, ,
"http://www.myexperiment.org/workflows/1254/versions/2.html","Query caArray data service and retrieving files","2010-05-2422:55:57","2010-05-2422:55:58","http://www.myexperiment.org/workflows/1254/download/Query_caArray_data_service_and_retrieving_files_-v2.t2flow?version=2","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","need to install Taverna 2 caGrid integration suite from  <a href=http://www.mcs.anl.gov/~wtan/t2/ rel=nofollow>http://www.mcs.anl.gov/~wtan/t2/</a>  and get a cagrid Dorian account (see  <a href=http://wiki.cagrid.org/display/caGrid13/Home rel=nofollow>http://wiki.cagrid.org/display/caGrid13/Home</a> )",0, 0, ,
"http://www.myexperiment.org/workflows/1255/versions/1.html","Federated query using DCQL and credential delegation","2010-05-1120:21:58","2010-11-0521:06:29","http://www.myexperiment.org/workflows/1255/download/Federated_query_using_DCQL_and_credential_delegation-v1.t2flow?version=1","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","CDS_Activity issues an EPR of the delegated credential. FQP uses this EPR to fetch the actual delegated credential from CDS and uses it to invoke multiple data services (the query activity) on behalf of the invoker. CDS_Activity issues an EPR of the delegated credential. FQP uses this EPR to fetch the actual delegated credential from CDS and uses it to invoke multiple data services (the query activity) on behalf of the invoker. Need to install Taverna 2 caGrid integration suite from  <a href=http://www.mcs.anl.gov/~wtan/t2/ rel=nofollow>http://www.mcs.anl.gov/~wtan/t2/</a>  and get a cagrid Dorian account (see  <a href=http://wiki.cagrid.org/display/caGrid13/Home rel=nofollow>http://wiki.cagrid.org/display/caGrid13/Home</a> )",0, 0, ,
"http://www.myexperiment.org/workflows/1255/versions/2.html","Federated query using DCQL and credential delegation","2010-05-1120:21:58","2010-11-0521:06:29","http://www.myexperiment.org/workflows/1255/download/Federated_query_using_DCQL_and_credential_delegation-v2.t2flow?version=2","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","CDS_Activity issues an EPR of the delegated credential. FQP uses this EPR to fetch the actual delegated credential from CDS and uses it to invoke multiple data services (the query activity) on behalf of the invoker. <hr /> CDS_Activity issues an EPR of the delegated credential. FQP uses this EPR to fetch the actual delegated credential from CDS and uses it to invoke multiple data services (the query activity) on behalf of the invoker.Need to install Taverna 2 caGrid integration suite from  <a href=http://www.mcs.anl.gov/~wtan/t2/ rel=nofollow>http://www.mcs.anl.gov/~wtan/t2/</a>  and get a cagrid Dorian account (see  <a href=http://wiki.cagrid.org/display/caGrid13/Home rel=nofollow>http://wiki.cagrid.org/display/caGrid13/Home</a> )",0, 0, ,
"http://www.myexperiment.org/workflows/1256/versions/1.html","Homology workflow","2010-05-1207:31:32","2010-05-1207:33:11","http://www.myexperiment.org/workflows/1256/download/Homology_workflow-v1.t2flow?version=1","/users/8705","wabi","taverna 2","/users/8705,","wabi,","There are many kinds of DNA data derived from many species in DDBJ. It makes possible to carry out the comparative study of genes of multiple species. The workflow provides a list of species and their genes that are similar to a human gene in response to a name of the human gene.",0, 0, ,
"http://www.myexperiment.org/workflows/1258/versions/1.html","Nucleotide frequency workflow","2010-05-1301:51:22","2010-11-1210:30:15","http://www.myexperiment.org/workflows/1258/download/Nucleotide_frequency_workflow-v1.t2flow?version=1","/users/8705","wabi","taverna 2","/users/8705,","wabi,","ALDH2 gene encodes enzyme which transform from acetaldehyde to acetic acid. It is known that variation of one DNA weakens the function. It is said that there are a lot of people who have the gene of such a type in Asia including Japan. However there are few people of such type of the gene in Europe or America. Therefore this workflow verifies that how type of the gene is distributed among Asian and Europe or America by using DDBJ and dbSNP data.",0, 0, ,
"http://www.myexperiment.org/workflows/1258/versions/2.html","Nucleotide frequency workflow","2010-05-1301:51:22","2010-11-1210:30:15","http://www.myexperiment.org/workflows/1258/download/Nucleotide_frequency_workflow-v2.t2flow?version=2","/users/8705","wabi","taverna 2","/users/8705,","wabi,",,0, 0, ,
"http://www.myexperiment.org/workflows/1260/versions/1.html","Virus genome extraction workflow","2010-05-1301:59:19","2010-05-1301:59:48","http://www.myexperiment.org/workflows/1260/download/Virus_genome_extraction_workflow-v1.t2flow?version=1","/users/8705","wabi","taverna 2","/users/8705,","wabi,","Retrieve genome entries which agree with the following conditions regarding the Definition item of entries from both VRL and PHG division in DDBJ.",1, 0, ,
"http://www.myexperiment.org/workflows/1262/versions/1.html","BLAST-ClustalW workflow","2010-05-1302:11:12","2010-05-1302:12:28","http://www.myexperiment.org/workflows/1262/download/BLAST-ClustalW_workflow-v1.t2flow?version=1","/users/8705","wabi","taverna 2","/users/8705,","wabi,","Execute blastn against DDBJ database with a given DNA sequence and compare the alignment regions of high similar sequences by using ClustalW.",1, 0, ,
"http://www.myexperiment.org/workflows/1263/versions/1.html","BLAST workflow","2010-05-1302:15:45","2010-05-1302:17:34","http://www.myexperiment.org/workflows/1263/download/BLAST_workflow-v1.t2flow?version=1","/users/8705","wabi","taverna 2","/users/8705,","wabi,","You can get three BLAST results&nbsp;against DDBJ, swiss-prot and PDB by using accession number of DDBJ.",0, 0, ,
"http://www.myexperiment.org/workflows/1264/versions/1.html","EntrezGeneId_to_GOFunction","2010-05-1312:07:48","2010-05-1312:09:51","http://www.myexperiment.org/workflows/1264/download/EntrezGeneId_to_GOFunction-v1.t2flow?version=1","/users/62","Franck Tanoh","taverna 2","/users/62,","Franck Tanoh,","The workflow takes a list of Entrez gene ids and returns the corresponding GO function definitions. Example value: 1306 <br /> 486 <br /> 4712 <br /> 108 <br /> 9912 <br /> 7639 <br /> 23786",0, 0, ,
"http://www.myexperiment.org/workflows/1283/versions/1.html","Warp2D - 2D Time Alignment Workflow","2010-05-2018:46:07","2010-11-2210:32:03","http://www.myexperiment.org/workflows/1283/download/Warp2D_-_2D_Time_Alignment_Workflow-v1.t2flow?version=1","/users/3920","Ishtiaq AHMAD","taverna 2","/users/3920,","Ishtiaq AHMAD,","<span><b><span class=capslock>2D Time Alignment</span></b></span> We describe a new time alignment method that takes advantage of both  dimensions of LC-MS data to resolve ambiguities in peak matching while  remaining computationally efficient. This approach,  <a href=http://www.nbpp.nl/warp2d.html rel=nofollow>Warp2D</a> , combines peak extraction  with a two-dimensional correlation function to provide a reliable  alignment scoring function that is insensitive to spurious peaks and  background noise. One-dimensional alignment methods are often based on  the total-ion-current elution profile of the spectrum and are unable to  distinguish peaks of different masses. <a href=http://www.nbpp.nl/warp2d.html rel=nofollow><span>Click Here to try out  yourself!</span></a> We have an online version of this approach as SaaS(Software as a Service)  i.e Web Services to facilitate large number of audience. This service enable you to upload Generic Peak lists and get back your  Results. And of course don't worry about processing power, we are Grid  enabled. &nbsp; <span><span><b><span class=capslock>2D Time Alignment i.e warping web service is powered by Data Analysis Framework (DAF)</span></b></span> </span> Data Analysis Framework (DAF) services are available  <a href=http://ws.nbpp.nl/axis2/services/listServices rel=nofollow>here</a>  and source code  <a href=http://gbic.target.rug.nl/trac/daf rel=nofollow>here</a> Discuss with us  <a href=https://wiki.nbic.nl/index.php/NBPP rel=nofollow>here</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/1283/versions/2.html","Warp2D - 2D Time Alignment Workflow","2010-05-2018:46:07","2010-11-2210:32:03","http://www.myexperiment.org/workflows/1283/download/Warp2D_-_2D_Time_Alignment_Workflow-v2.t2flow?version=2","/users/3920","Ishtiaq AHMAD","taverna 2","/users/3920,","Ishtiaq AHMAD,","&nbsp; <span><b><span class=capslock>2D Time Alignment</span></b></span> We describe a new time alignment method that takes advantage of both   dimensions of LC-MS data to resolve ambiguities in peak matching while   remaining computationally efficient. This approach,  <a href=http://www.nbpp.nl/warp2d.html rel=nofollow>Warp2D</a> ,  combines peak extraction  with a two-dimensional correlation function  to provide a reliable  alignment scoring function that is insensitive to  spurious peaks and  background noise. One-dimensional alignment methods  are often based on  the total-ion-current elution profile of the  spectrum and are unable to  distinguish peaks of different masses. <b>Warp2D - 2D Time Alignment</b> Warp2D is an efficient, fundamentally new approach to correct for non  linear retention time shifts between complex proteomics and  metabolomics LC-MS data sets. Warp2D operates on peak lists and use the  integral of overlapping peak volume of the reference and sample  chromatograms in benefit function with Correlation Optimized Warping  algorithm. We have an online version of this approach as SaaS(Software as a  Service)  i.e Web Services to facilitate large number of audience. This  service enable you to upload Generic Peak lists and get back your   Results. &nbsp; <a href=http://www.nbpp.nl/warp2d.html rel=nofollow><span>Click Here to try out  yourself!</span></a> And of course don't worry about processing power, we are Grid   enabled. &nbsp; <span><span><b><span class=capslock>2D Time Alignment i.e warping web service is powered by Data Analysis Framework (DAF)</span></b></span> </span> Data Analysis Framework (DAF) services are available  <a href=http://ws.nbpp.nl/axis2/services/listServices rel=nofollow>here</a>  and source code  <a href=http://gbic.target.rug.nl/trac/daf rel=nofollow>here</a> Discuss with us  <a href=https://wiki.nbic.nl/index.php/NBPP rel=nofollow>here</a>",1, 0, ,
"http://www.myexperiment.org/workflows/1283/versions/3.html","Warp2D - 2D Time Alignment Workflow","2010-05-2018:46:07","2010-11-2210:32:03","http://www.myexperiment.org/workflows/1283/download/Warp2D_-_2D_Time_Alignment_Workflow-v3.t2flow?version=3","/users/3920","Ishtiaq AHMAD","taverna 2","/users/3920,","Ishtiaq AHMAD,","<span><b><span class=capslock>2D Time Alignment</span></b></span> We describe a new time alignment method that takes advantage of both    dimensions of LC-MS data to resolve ambiguities in peak matching while    remaining computationally efficient. This approach,  <a href=http://www.nbpp.nl/warp2d.html rel=nofollow>Warp2D</a> ,   combines peak extraction  with a two-dimensional correlation function   to provide a reliable  alignment scoring function that is insensitive  to  spurious peaks and  background noise. One-dimensional alignment  methods  are often based on  the total-ion-current elution profile of  the  spectrum and are unable to  distinguish peaks of different masses. <b>Warp2D - 2D Time Alignment</b> Warp2D is an efficient, fundamentally new approach to correct for non   linear retention time shifts between complex proteomics and   metabolomics LC-MS data sets. Warp2D operates on peak lists and use the   integral of overlapping peak volume of the reference and sample   chromatograms in benefit function with Correlation Optimized Warping   algorithm. We have an online version of this approach as SaaS(Software as a   Service)  i.e Web Services to facilitate large number of audience. This   service enable you to upload Generic Peak lists and get back your    Results. &nbsp; <a href=http://www.nbpp.nl/warp2d.html rel=nofollow><span>Click Here to try out  yourself!</span></a> And of course don't worry about processing power, we are Grid   enabled. &nbsp; <span><span><b><span class=capslock>2D Time Alignment i.e warping web service is powered by Data Analysis Framework (DAF)</span></b></span> </span> Data Analysis Framework (DAF) services are available  <a href=http://ws.nbpp.nl/axis2/services/listServices rel=nofollow>here</a>  and source code  <a href=http://gbic.target.rug.nl/trac/daf rel=nofollow>here</a> Discuss with us  <a href=https://wiki.nbic.nl/index.php/NBPP rel=nofollow>here</a> <span><b>Example data set:</b></span>  The peak list can be downloaded  <a href=http://www.nbpp.nl/example_data_warp2D.zip rel=nofollow>here</a> <br /> <b><span>Note:</span></b>  This Workflow has been tested with  <b>Taverna 2.1.0</b>",2, 0, ,
"http://www.myexperiment.org/workflows/1285/versions/1.html","simple HEC query","2010-05-2109:50:10","2010-08-0415:02:05","http://www.myexperiment.org/workflows/1285/download/simple_HEC_query-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","HEC query for table 'goes_xray_flare'",0, 0, ,
"http://www.myexperiment.org/workflows/1285/versions/2.html","simple HEC query","2010-05-2109:50:10","2010-08-0415:02:05","http://www.myexperiment.org/workflows/1285/download/simple_HEC_query-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","HEC query for table 'goes_xray_flare'",0, 0, ,
"http://www.myexperiment.org/workflows/1286/versions/1.html","Retrieve Instruments for event dates","2010-05-2610:45:52","","http://www.myexperiment.org/workflows/1286/download/Retrieve_Instruments_for_event_dates_-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Queries the HELIO ICS web service and returns a list of instruments available for the time periodes in VOTable format",1, 0, ,
"http://www.myexperiment.org/workflows/1286/versions/2.html","Retrieve Instruments for event dates","2010-05-2610:45:52","","http://www.myexperiment.org/workflows/1286/download/Retrieve_Instruments_for_event_dates_-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Queries the HELIO ICS web service and returns a list of instruments available for the time periodes in VOTable format",1, 0, ,
"http://www.myexperiment.org/workflows/1287/versions/1.html","Invoke a secured caGrid service: caTissue","2010-05-2423:41:56","2010-11-0521:04:04","http://www.myexperiment.org/workflows/1287/download/Invoke_a_secured_caGrid_service__caTissue-v1.t2flow?version=1","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","Invoke a secure caGrid service, i.e., caTissueCore, to query all the cell specimen. 1. This workflow is tested with Taverna 2.1.2 and the caGrid Workflow Suite plugin downloadable from  <a href=http://www.mcs.anl.gov/~wtan/t2/.&lt;/p>http://www.mcs.anl.gov/~wtan/t2/.</a> 2. Sample input is embedded in the workflow file. 3. You need a caGrid username/password to invoke it. Find more regarding caGrid security from  <a href=http://wiki.cagrid.org/display/gaards/.&lt;/p>http://wiki.cagrid.org/display/gaards/.</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/1287/versions/2.html","Invoke a secured caGrid service: caTissue","2010-05-2423:41:56","2010-11-0521:04:04","http://www.myexperiment.org/workflows/1287/download/Invoke_a_secured_caGrid_service__caTissue-v2.t2flow?version=2","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1288/versions/1.html","A simple CQL query workflow in caGrid","2010-05-2423:52:05","2010-05-2519:20:30","http://www.myexperiment.org/workflows/1288/download/A_simple_CQL_query_workflow_in_caGrid-v1.t2flow?version=1","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","1. CQL is a language to query data from caGrid/caBIG services. This workflow is tested with Taverna 2.1.2 and the caGrid Workflow Suite downloadable from  <a href=http://www.mcs.anl.gov/~wtan/t2/.&lt;/p>http://www.mcs.anl.gov/~wtan/t2/.</a> 2.More information regarding CQL can be found from  <a href=http://wiki.cagrid.org/display/dataservices.&lt;/p>http://wiki.cagrid.org/display/dataservices.</a> 3. Sample input (95) is provided in the workflow. It is to query all the hybridization data within a microarray experiment whose id is 95.",-1, 0, ,
"http://www.myexperiment.org/workflows/1289/versions/1.html","Simple DPAS query","2010-05-2611:11:32","2011-12-1509:59:41","http://www.myexperiment.org/workflows/1289/download/Simple_DPAS_query-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","queries dpas for each time priode and instrument",0, 0, ,
"http://www.myexperiment.org/workflows/1289/versions/2.html","Simple DPAS query","2010-05-2611:11:32","2011-12-1509:59:41","http://www.myexperiment.org/workflows/1289/download/Simple_DPAS_query-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","queries dpas for each time priode and instrument",0, 0, ,
"http://www.myexperiment.org/workflows/1289/versions/3.html","Simple DPAS query","2010-05-2611:11:32","2011-12-1509:59:41","http://www.myexperiment.org/workflows/1289/download/Simple_DPAS_query-v3.t2flow?version=3","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","queries dpas for each time priode and instrument",0, 0, ,
"http://www.myexperiment.org/workflows/1289/versions/4.html","Simple DPAS query","2010-05-2611:11:32","2011-12-1509:59:41","http://www.myexperiment.org/workflows/1289/download/Simple_DPAS_query-v4.t2flow?version=4","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","queries dpas for each time priode and instrument",0, 0, ,
"http://www.myexperiment.org/workflows/1294/versions/1.html","Provenance Challenge 1 workflow -- mockup version","2010-05-2807:14:35","","http://www.myexperiment.org/workflows/1294/download/Provenance_Challenge_1_workflow_--_mockup_version-v1.t2flow?version=1","/users/500","Paolo","taverna 2","/users/500,","Paolo,","simulates the image processing for the PC1 workflow using beanshell that simply track test strings an image is a pair (header, image) specified as a list of depth 1: [header,image]so each processor with image input takes an input list.Note that the processors are designed to operate on single images (except softmean that operates on a list of images), but because the initial input is a list of images, all are processed by implicit iteration.",0, 0, ,
"http://www.myexperiment.org/workflows/1318/versions/1.html","Using HEK information to get DPAS data","2010-06-1016:35:17","2010-06-1016:35:18","http://www.myexperiment.org/workflows/1318/download/Using_HEK_information_to_get_DPAS_data_-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Query HEK for all kinds of events and query DPAS for given instrument for data from event times.",0, 0, ,
"http://www.myexperiment.org/workflows/1320/versions/1.html","Nucleotide FASTA to PDB file.","2010-06-1106:40:25","2010-06-1106:44:25","http://www.myexperiment.org/workflows/1320/download/Nucleotide_FASTA_to_PDB_file.-v1.t2flow?version=1","/users/7572","Prateek","taverna 2","/users/7572,","Prateek,","<span><span>This workflow is designed to convert nucleotide fasta sequence to corresponding pdb file,which could be used for modelling. In this workflow nucleotide fasta sequence is given as input, eg. &gt;gi|119889797|ref|XM_864887.2| PREDICTED: Bos taurus amylase, alpha 2A (pancreatic), transcript variant 2 (AMY2A), mRNA </span></span> <span></span> <span>ATGAAGTTTTTTCTGTTGCTTTCAGCAATTGGGTTCTGCTGGGCTCAGTATGACCCACACGTCAAATCTG GACGGACCTCCATTGTCCATCTGTTTGAGTGGCGCTGGGTAGATATTGCTCTTGAATGTGAGCGATACTT AGCCCCCAAAGGATTTGGAGGGGTTCAGGTCTCCCCACCCAGTGAAAATGCTGTGATTACTGACCCTTCA CGACCTTGGTGGGAAAGATACCAACCAGTTAGTTACAAGT</span> &nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/1346/versions/1.html","Provenance Challenge 1 workflow part A -- mockup version","2010-06-2109:43:55","2010-06-2109:47:28","http://www.myexperiment.org/workflows/1346/download/Provenance_Challenge_1_workflow_part_A_--_mockup_version-v1.t2flow?version=1","/users/500","Paolo","taverna 2","/users/500,","Paolo,",,0, 0, ,
"http://www.myexperiment.org/workflows/1347/versions/1.html","Provenance Challenge 1 workflow part B -- mockup version","2010-06-2109:48:42","2010-06-2109:49:25","http://www.myexperiment.org/workflows/1347/download/Provenance_Challenge_1_workflow_part_B_--_mockup_version-v1.t2flow?version=1","/users/500","Paolo","taverna 2","/users/500,","Paolo,",,0, 0, ,
"http://www.myexperiment.org/workflows/1353/versions/1.html","Syntetic population mapper","2010-06-2313:12:41","2010-12-0910:43:38","http://www.myexperiment.org/workflows/1353/download/Syntetic_population_mapper-v1.t2flow?version=1","/users/666","Alex Nenadic","taverna 2","/users/666,","Alex Nenadic,","This workflow takes a csv file with census data, runs the PRM over it and the resulting csv is visualsed using the MapTube software.",-1, 0, ,
"http://www.myexperiment.org/workflows/1353/versions/2.html","Syntetic population mapper","2010-06-2313:12:41","2010-12-0910:43:38","http://www.myexperiment.org/workflows/1353/download/Syntetic_population_mapper-v2.t2flow?version=2","/users/666","Alex Nenadic","taverna 2","/users/666,","Alex Nenadic,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1353/versions/3.html","Syntetic population mapper","2010-06-2313:12:41","2010-12-0910:43:38","http://www.myexperiment.org/workflows/1353/download/Syntetic_population_mapper-v3.t2flow?version=3","/users/666","Alex Nenadic","taverna 2","/users/666,","Alex Nenadic,","This workflow creates individual-level population from census data and then joins with the BHPS (British Household Panel Survey) and reaggregates. In the last stage it maps the chosen BHPS field.",-1, 0, ,
"http://www.myexperiment.org/workflows/1360/versions/1.html","Workflow for Automated Comparative Protein Sequences Analysis","2010-06-2912:59:57","2010-08-3109:43:41","http://www.myexperiment.org/workflows/1360/download/Workflow_for_Automated_Comparative_Protein_Sequences_Analysis-v1.t2flow?version=1","/users/1601","Achille Zappa","taverna 2","/users/1601,","Achille Zappa,","This workflow performs &quot;parallel&quot; generic protein sequence analysis. In order to do that a list of known protein identifiers chosen by the biologist&nbsp;enters into the software&nbsp;to perform different multiple sequence alignments and finally &nbsp;phylogenetic analysis.",0, 0, ,
"http://www.myexperiment.org/workflows/1360/versions/2.html","Workflow for Automated Comparative Protein Sequences Analysis","2010-06-2912:59:57","2010-08-3109:43:41","http://www.myexperiment.org/workflows/1360/download/Workflow_for_Automated_Comparative_Protein_Sequences_Analysis-v2.t2flow?version=2","/users/1601","Achille Zappa","taverna 2","/users/1601,","Achille Zappa,","This workflow performs &quot;parallel&quot; generic protein sequence analysis. In order to do that a list of known protein identifiers chosen by the biologist enters into the software to perform different multiple sequence alignments and finally  phylogenetic analysis.",1, 0, ,
"http://www.myexperiment.org/workflows/1363/versions/1.html","Extracting data from VOTable format by using XPath query","2010-07-0114:01:03","2010-07-0114:01:04","http://www.myexperiment.org/workflows/1363/download/Extracting_data_from_VOTable_format_by_using_XPath_query-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706, /users/9056,","Anja Le Blanc, Donal Fellows,","Input VOTable and 'name' of a &lt;field&gt;Output corrosponding data  <td> of that field in an array<hr />Input VOTable and 'name' of a Field</td>",0, 0, ,
"http://www.myexperiment.org/workflows/1364/versions/1.html","A workflow version of the EMBOSS tutorial","2010-07-0418:29:33","2010-07-0418:29:34","http://www.myexperiment.org/workflows/1364/download/A_workflow_version_of_the_EMBOSS_tutorial-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/297,","Tomoinn,","Designed to show the use of EMBOSS based Soaplab services from Taverna, this workflow has no inputs as all initial values are specified as string constants. A sequence set is fetched using the seqret tool, then simultaneously scanned for predicted transmembrane regions and subjected to a multiple alignment using emma. This alignment is then plotted to a set of PNG images and also used to build a profile using the prophecy and prophet tools.",0, 0, ,
"http://www.myexperiment.org/workflows/1365/versions/1.html","BiomartAndEMBOSSAnalysis","2010-07-0418:30:58","2010-07-0418:31:00","http://www.myexperiment.org/workflows/1365/download/BiomartAndEMBOSSAnalysis-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","Using Biomart and EMBOSS soaplab services, This workflow retrieves a number of sequences from 3 species: mouse, human, rat; align them, and returns a plot of the alignment result. Corresponding sequence ids are also returned.",0, 0, ,
"http://www.myexperiment.org/workflows/1366/versions/1.html","BioMoby tutorial workflow","2010-07-0418:31:57","2010-07-0418:31:59","http://www.myexperiment.org/workflows/1366/download/BioMoby_tutorial_workflow-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/9981,","EdwardKawas,","A workflow from part of the BioMoby tutorial",0, 0, ,
"http://www.myexperiment.org/workflows/1367/versions/1.html","Demonstration of configurable iteration","2010-07-0418:32:58","2010-07-0418:33:00","http://www.myexperiment.org/workflows/1367/download/Demonstration_of_configurable_iteration-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/297,","Tomoinn,","This workflow shows the use of the iteration strategy editor to ensure that only relevant combinations of inputs are used during an implicit iteration.",0, 0, ,
"http://www.myexperiment.org/workflows/1368/versions/1.html","EBI_InterProScan for Taverna 2","2010-07-0418:33:54","2010-07-0418:33:55","http://www.myexperiment.org/workflows/1368/download/EBI_InterProScan_for_Taverna_2-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,",,2, 0, ,
"http://www.myexperiment.org/workflows/1369/versions/1.html","Fetch PDB flatfile from RCSB server","2010-07-0418:34:57","2010-07-0418:34:59","http://www.myexperiment.org/workflows/1369/download/Fetch_PDB_flatfile_from_RCSB_server-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/297,","Tomoinn,","Given an identifier such as '1crn' fetches the PDB format flatfile from the RCSB",0, 0, ,
"http://www.myexperiment.org/workflows/1370/versions/1.html","Fetch today&#39;s xkcd comic","2010-07-0418:35:59","2010-07-0418:36:00","http://www.myexperiment.org/workflows/1370/download/Fetch_today_s_xkcd_comic-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/297, /users/5,","Tomoinn, Stian Soiland-Reyes,","Use the local java plugins and some filtering operations to fetch the comic strip image from  <a href=http://xkcd.com/ rel=nofollow>http://xkcd.com/</a> Based on the FetchDailyDilbert workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/1371/versions/1.html","GBSeq test","2010-07-0418:36:58","2010-07-0418:37:00","http://www.myexperiment.org/workflows/1371/download/GBSeq_test-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/62,","Franck Tanoh,","This workflow retrieves nucleotide and protein sequences with the literature and references associatedto them given a protein and a nucleotide id.",0, 0, ,
"http://www.myexperiment.org/workflows/1372/versions/1.html","Pipelined list iteration","2010-07-0418:37:58","2010-07-0418:38:00","http://www.myexperiment.org/workflows/1372/download/Pipelined_list_iteration-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/474, /users/5,","Ian Dunlop, Stian Soiland-Reyes,","Perform multiple iterations of services in order to show pipelining",0, 0, ,
"http://www.myexperiment.org/workflows/1373/versions/1.html","Retrieve sequence in EMBL format","2010-07-0418:39:07","2010-07-0418:39:09","http://www.myexperiment.org/workflows/1373/download/Retrieve_sequence_in_EMBL_format-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/62,","Franck Tanoh,","This workflow retrieves a sequence associated with its features in embl format",0, 0, ,
"http://www.myexperiment.org/workflows/1374/versions/1.html","Perfrom a text based search through PubMed","2010-07-0513:03:35","2010-07-0513:03:37","http://www.myexperiment.org/workflows/1374/download/Perfrom_a_text_based_search_through_PubMed-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a number of search terms in which to perform a search over the PubMed literature database. These search terms may be input as if entered in the web based version of PubMed. The output from this workflow is a list of PubMed identifiers in xml based format",0, 0, ,
"http://www.myexperiment.org/workflows/1375/versions/1.html","Gene to Pubmed","2010-07-0513:14:36","2011-01-2616:57:39","http://www.myexperiment.org/workflows/1375/download/Gene_to_Pubmed-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a list of gene names and searches the PubMed database for corresponding articles. Any matches to the genes are then retrieved (abstracts only). These abstracts are then returned to the user.",0, 0, ,
"http://www.myexperiment.org/workflows/1375/versions/2.html","Gene to Pubmed","2010-07-0513:14:36","2011-01-2616:57:39","http://www.myexperiment.org/workflows/1375/download/Gene_to_Pubmed-v2.t2flow?version=2","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a list of gene names and searches the PubMed database for corresponding articles. Any matches to the genes are then retrieved (abstracts only). These abstracts are then returned to the user.",0, 0, ,
"http://www.myexperiment.org/workflows/1375/versions/3.html","Gene to Pubmed","2010-07-0513:14:36","2011-01-2616:57:39","http://www.myexperiment.org/workflows/1375/download/Gene_to_Pubmed-v3.t2flow?version=3","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a list of gene names and searches the PubMed database for corresponding articles. Any matches to the genes are then retrieved (abstracts only). These abstracts are then returned to the user.",0, 0, ,
"http://www.myexperiment.org/workflows/1376/versions/1.html","Phenotype to pubmed","2010-07-0514:07:33","2011-01-1112:07:22","http://www.myexperiment.org/workflows/1376/download/Phenotype_to_pubmed-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a list of terms to search across the MEDLINE database (through PubMed).&nbsp; Terms are passed to the eSearch function and searched for in PubMed. Those abstracts found are returned to the user via the eFetch service.",1, 0, ,
"http://www.myexperiment.org/workflows/1376/versions/2.html","Phenotype to pubmed","2010-07-0514:07:33","2011-01-1112:07:22","http://www.myexperiment.org/workflows/1376/download/Phenotype_to_pubmed-v2.t2flow?version=2","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a phenotype search term, and searches for abstracts in the PubMed database. These are passed to the eSearch function and searched for in PubMed. Those abstracts found are returned to the user",0, 0, ,
"http://www.myexperiment.org/workflows/1376/versions/3.html","Phenotype to pubmed","2010-07-0514:07:33","2011-01-1112:07:22","http://www.myexperiment.org/workflows/1376/download/Phenotype_to_pubmed-v3.t2flow?version=3","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a phenotype search term, and searches for abstracts in the PubMed database. These are passed to the eSearch function and searched for in PubMed. Those abstracts found are returned to the user",0, 0, ,
"http://www.myexperiment.org/workflows/1377/versions/1.html","A template example workflow using U-Compare text mining system inside","2010-07-0515:32:19","2010-09-0204:43:04","http://www.myexperiment.org/workflows/1377/download/A_template_example_workflow_using_U-Compare_text_mining_system_inside-v1.t2flow?version=1","/users/9694","Yoshinobu Kano","taverna 2","/users/9694,","Yoshinobu Kano,","An example workflow using the U-Compare text mining system inside embedded.Users can easily make their own workflow with U-Compare reusing this workflow.This workflow retrieves abstract texts from Pubmed with user specified query, inputs the texts to U-Compare, interprets the output of U-Compare.You have to download and store the XML descriptor file from XXX to run the default setting, which runs a event extraction text mining workflow by U-Compare.See our publication XXX for details.",1, 0, ,
"http://www.myexperiment.org/workflows/1377/versions/2.html","A template example workflow using U-Compare text mining system inside","2010-07-0515:32:19","2010-09-0204:43:04","http://www.myexperiment.org/workflows/1377/download/A_template_example_workflow_using_U-Compare_text_mining_system_inside-v2.t2flow?version=2","/users/9694","Yoshinobu Kano","taverna 2","/users/9694,","Yoshinobu Kano,","An example workflow using the U-Compare text mining system inside embedded. Users can easily make their own workflow with U-Compare reusing this workflow. This workflow retrieves abstract texts from Pubmed with user specified query, inputs the texts to U-Compare, interprets the output of U-Compare. You have to download and store the UIMA CPE XML descriptor file (StdinPPIExtraction-CPE-EventMine.xml) to run the default setting, which runs a event extraction text mining workflow by U-Compare. See our publication, Kano, et al., 2010,&nbsp; &quot; <strong>Text Mining Meets Workflow: Linking U-Compare with Taverna</strong>  		  &quot;  <a href=http://bioinformatics.oxfordjournals.org/cgi/content/abstract/btq464 rel=nofollow>http://bioinformatics.oxfordjournals.org/cgi/content/abstract/btq464</a>  for details.",1, 0, ,
"http://www.myexperiment.org/workflows/1378/versions/1.html","CTF - MEG Event Averager","2010-07-0611:48:21","2010-07-0612:00:58","http://www.myexperiment.org/workflows/1378/download/CTF_-_MEG_Event_Averager-v1.t2flow?version=1","/users/9777","Lakelander","taverna 2","/users/9777,","Lakelander,","<span>This workflow applies parametrs in a user-specified processing.cfg file</span>  to a set of MEG data files. The datasets must be in CTF-format, such as those produced by Omega275 systems. The  <span>processing.cfg file</span>  and datasets are selected at the initialization of the workflow.&nbsp;  <span>processing.cfg can be created by the data inspection tool DataEditor, and contains desired filter settings etc. This file can also be edited easily with a text editor to tweak settings. The workflow identifies all the trigger events in each of the datasets, and for each it applies the processing parameters in </span> <span>processing.cfg and generates a new average dataset for each trigger event.</span> <span><br /></span>",-1, 0, ,
"http://www.myexperiment.org/workflows/1380/versions/1.html","AlitoraKDAInputModule test workflow","2010-07-0711:14:19","2010-07-0711:16:04","","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","&nbsp;This workflow calls the AlitoraKDAInputModule service from the test GenePattern server.",
"http://www.myexperiment.org/workflows/1382/versions/1.html","Who is Dr Labrie according to Pubmed publication queried with a cognoscope ?","2010-07-0807:18:09","2010-07-0807:32:26","http://www.myexperiment.org/workflows/1382/download/Who_is_Dr_Labrie_according_to_Pubmed_publication_queried_with_a_cognoscope__-v1.t2flow?version=1","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,",,0, 0, ,
"http://www.myexperiment.org/workflows/1382/versions/2.html","Who is Dr Labrie according to Pubmed publication queried with a cognoscope ?","2010-07-0807:18:09","2010-07-0807:32:26","http://www.myexperiment.org/workflows/1382/download/Who_is_Dr_Labrie_according_to_Pubmed_publication_queried_with_a_cognoscope__-v2.t2flow?version=2","/users/1620","Francois Belleau","taverna 2","/users/1620,","Francois Belleau,","To use this wokflow you need to import services from  <hr /> To use this wokflow you need to import services from <a href=http://proxy.bio2rdf.org/bio2rdf/services.txt rel=nofollow>http://proxy.bio2rdf.org/bio2rdf/services.txt</a> you can explore the loaded data at <a href=http://proxy.bio2rdf.org/fct rel=nofollow>http://proxy.bio2rdf.org/fct</a>",0, 0, ,
"http://www.myexperiment.org/workflows/1383/versions/1.html","EBI_InterProScan for Taverna 2","2010-07-0809:27:34","2010-07-0809:27:35","http://www.myexperiment.org/workflows/1383/download/EBI_InterProScan_for_Taverna_2-v1.t2flow?version=1","/users/9775","Benb","taverna 2","/users/9775,","Benb,",,2, 0, ,
"http://www.myexperiment.org/workflows/1384/versions/1.html","EBI_InterProScan for Taverna 2","2010-07-0809:58:33","2010-07-0809:58:34","http://www.myexperiment.org/workflows/1384/download/EBI_InterProScan_for_Taverna_2-v1.t2flow?version=1","/users/9775","Benb","taverna 2","/users/9775,","Benb,",,2, 0, ,
"http://www.myexperiment.org/workflows/1387/versions/1.html","Generate inChi","2010-07-0910:06:35","2010-07-0910:08:37","http://www.myexperiment.org/workflows/1387/download/Generate_inChi-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Generates an inChi string for a given chemical represented by its SMILES string, SDF  or MOL file using the inchi web service provided by ChemSpider",0, 0, ,
"http://www.myexperiment.org/workflows/1388/versions/1.html","Generate inChi information","2010-07-0910:22:29","2010-07-0910:23:47","http://www.myexperiment.org/workflows/1388/download/Generate_inChi_information-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Uses the GenerateInchiInfo web service operation from ChemSpider to generate information relating to the InChi string for a given chemical compound",0, 0, ,
"http://www.myexperiment.org/workflows/1389/versions/1.html","Generate InChi key","2010-07-0910:45:09","2010-07-0910:45:11","http://www.myexperiment.org/workflows/1389/download/Generate_InChi_key-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Generates an inchi key for a given compound using the inchi web service provided by ChemSpider",0, 0, ,
"http://www.myexperiment.org/workflows/1390/versions/1.html","InChi key to ChemSpider identifier","2010-07-0910:54:07","2010-07-0910:54:08","http://www.myexperiment.org/workflows/1390/download/InChi_key_to_ChemSpider_identifier-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Returns  <hr /> Converts an InChIKey to a ChemSpider ID",0, 0, ,
"http://www.myexperiment.org/workflows/1391/versions/1.html","InChi key to Inchi string","2010-07-0910:58:54","2010-07-0911:00:16","http://www.myexperiment.org/workflows/1391/download/InChi_key_to_Inchi_string-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Converts an InChI key to an InChI string using the ChemSpider Inchi web service.",-1, 0, ,
"http://www.myexperiment.org/workflows/1392/versions/1.html","InChi key to MOL file","2010-07-0911:05:11","2010-07-0911:05:13","http://www.myexperiment.org/workflows/1392/download/InChi_key_to_MOL_file_-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Returns a MOL file for a given InChi key",1, 0, ,
"http://www.myexperiment.org/workflows/1393/versions/1.html","InChIToCSID","2010-07-0911:09:29","2010-07-0911:09:31","http://www.myexperiment.org/workflows/1393/download/InChIToCSID-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Convert InChI to ChemSpider ID",0, 0, ,
"http://www.myexperiment.org/workflows/1394/versions/1.html","InChIStringToInChiKey","2010-07-0911:12:58","2010-07-0911:23:55","http://www.myexperiment.org/workflows/1394/download/InChIStringToInChiKey-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Converts an InChI string to an InChi key",2, 0, ,
"http://www.myexperiment.org/workflows/1395/versions/1.html","InChIStringToMolFile","2010-07-0911:21:23","2010-07-0911:23:05","http://www.myexperiment.org/workflows/1395/download/InChIStringToMolFile-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Converts an InChI string into a MOL file using the Inchi ChemSpider web service",3, 0, ,
"http://www.myexperiment.org/workflows/1396/versions/1.html","InchiStringToSmiles","2010-07-0911:38:59","2010-07-0911:39:01","http://www.myexperiment.org/workflows/1396/download/InchiStringToSmiles-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Converts an inchi string into SMILES format",0, 0, ,
"http://www.myexperiment.org/workflows/1397/versions/1.html","isValidInChiKey","2010-07-0911:55:56","2010-07-0911:55:58","http://www.myexperiment.org/workflows/1397/download/isValidInChiKey-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Checks that specified argument is valid InChIKey. Works for v1.02b InChIKey only.",0, 0, ,
"http://www.myexperiment.org/workflows/1398/versions/1.html","MolToInchiString","2010-07-0912:01:45","2010-07-0912:01:47","http://www.myexperiment.org/workflows/1398/download/MolToInchiString-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Converts a MOL file to InChI. Result is v1.02s InChI.",0, 0, ,
"http://www.myexperiment.org/workflows/1399/versions/1.html","MolToInchiKey","2010-07-0912:10:00","2010-07-0912:10:02","http://www.myexperiment.org/workflows/1399/download/MolToInchiKey-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Converts a MOL file to an InChIKey. Result is v1.02s InChIKey.",0, 0, ,
"http://www.myexperiment.org/workflows/1400/versions/1.html","SmilesToInchi","2010-07-0915:37:08","2010-07-0915:37:10","http://www.myexperiment.org/workflows/1400/download/SmilesToInchi-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Convert SMILES to InChI. Result is v1.02s InChI.",0, 0, ,
"http://www.myexperiment.org/workflows/1401/versions/1.html","Convert chemical identifier","2010-07-0915:45:53","2010-07-0915:46:31","http://www.myexperiment.org/workflows/1401/download/Convert_chemical_identifier-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Converts a chemical compound identifier from one format to another using the open babel web service provided by ChemSpider",0, 0, ,
"http://www.myexperiment.org/workflows/1404/versions/1.html","Get list of chemspider databases","2010-07-1209:53:38","2010-07-1209:53:40","http://www.myexperiment.org/workflows/1404/download/Get_list_of_chemspider_databases-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Returns a list of databases cataloged <hr /> Returns a list of databases cataloged by ChemSpider",0, 0, ,
"http://www.myexperiment.org/workflows/1405/versions/1.html","Get extended compound information","2010-07-1210:06:37","2010-07-1210:06:39","http://www.myexperiment.org/workflows/1405/download/Get_extended_compound_information-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Returns information from chemspider for a given chemical represented by its chemspider identifier",0, 0, ,
"http://www.myexperiment.org/workflows/1406/versions/1.html","Get extended compound information for a list of chemspider identifiers","2010-07-1210:33:31","2010-07-1210:34:11","http://www.myexperiment.org/workflows/1406/download/Get_extended_compound_information_for_a_list_of_chemspider_identifiers_-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","&nbsp;Returns information for a given list of chemspider compound identifiers.",0, 0, ,
"http://www.myexperiment.org/workflows/1407/versions/1.html","Get ChemSpider record in MOL format","2010-07-1210:47:44","2010-07-1210:47:46","http://www.myexperiment.org/workflows/1407/download/Get_ChemSpider_record_in_MOL_format-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Returns ChemSpider record in MOL format or empty string in case of failure.",0, 0, ,
"http://www.myexperiment.org/workflows/1408/versions/1.html","Get spectra information","2010-07-1309:32:27","2010-07-1309:32:28","http://www.myexperiment.org/workflows/1408/download/Get_spectra_information-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Returns information about the spectra stored in ChemSpider",0, 0, ,
"http://www.myexperiment.org/workflows/1409/versions/1.html","Get compound spectra information","2010-07-1309:42:03","2010-07-1309:42:04","http://www.myexperiment.org/workflows/1409/download/Get_compound_spectra_information-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Returns information about spectra stored in ChemSpider for a given compound represented by its chemspider identifier",0, 0, ,
"http://www.myexperiment.org/workflows/1410/versions/1.html","Get spectrum information","2010-07-1309:48:50","2010-07-1309:48:51","http://www.myexperiment.org/workflows/1410/download/Get_spectrum_information-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Returns information about a spectrum identified by its chemspider spectrum identifier",0, 0, ,
"http://www.myexperiment.org/workflows/1411/versions/1.html","Asynchronous chemspider simple search","2010-07-1311:08:34","2010-07-1311:08:35","http://www.myexperiment.org/workflows/1411/download/Asynchronous_chemspider_simple_search-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Performs an asynchronous simple search on ChemSpider",0, 0, ,
"http://www.myexperiment.org/workflows/1412/versions/1.html","Get compound information","2010-07-1311:17:08","2010-07-1311:17:09","http://www.myexperiment.org/workflows/1412/download/Get_compound_information-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Returns information about a given compound represented by its chemspider id",0, 0, ,
"http://www.myexperiment.org/workflows/1413/versions/1.html","Spreadsheet Import Example","2010-07-1311:23:31","2010-07-1311:23:30","http://www.myexperiment.org/workflows/1413/download/Spreadsheet_Import_Example-v1.t2flow?version=1","/users/2","David Withers","taverna 2","","","Example using the SpreadsheetImport service to import data from an Excel spreadsheet.The workflow imports the file spreadsheet file WaterUse.xlsx and generates a graph from the date.The source data is from  <a href=http://data.gov.uk/ rel=nofollow>http://data.gov.uk/</a>",3, 0, ,
"http://www.myexperiment.org/workflows/1414/versions/1.html","Get compound thumbnail","2010-07-1311:29:03","2010-07-1311:29:04","http://www.myexperiment.org/workflows/1414/download/Get_compound_thumbnail-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Returns a small image of the 2D structure of given chemical compound represented by its chemspider identifier",0, 0, ,
"http://www.myexperiment.org/workflows/1415/versions/1.html","Get structure synonyms","2010-07-1311:38:56","2010-07-1311:38:57","http://www.myexperiment.org/workflows/1415/download/Get_structure_synonyms-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Returns synonyms for a given compound represented by a MOL file <hr /> Returns synonyms for a given compound",0, 0, ,
"http://www.myexperiment.org/workflows/1417/versions/1.html","Spreadsheed Data Import Example","2010-07-1312:50:54","2010-07-1312:50:55","http://www.myexperiment.org/workflows/1417/download/Spreadsheed_Data_Import_Example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/2,","David Withers,","Example using the SpreadsheetImport service to import data from an Excel spreadsheet.The workflow imports the file spreadsheet file WaterUse.xlsx and generates a graph from the date.The source data is from  <a href=http://data.gov.uk/ rel=nofollow>http://data.gov.uk/</a>",3, 0, ,
"http://www.myexperiment.org/workflows/1418/versions/1.html","chemspider identifier to MOL format","2010-07-1313:52:02","","http://www.myexperiment.org/workflows/1418/download/chemspider_identifier_to_MOL_format-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Returns the MOL file for a given compound represented by its chemspider identifier",0, 0, ,
"http://www.myexperiment.org/workflows/1419/versions/1.html","getLiteEntity","2010-07-1314:14:52","2010-07-1314:14:53","http://www.myexperiment.org/workflows/1419/download/getLiteEntity-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Retrieves a list of lite entities containing only the ChEBI ASCII name and ChEBI identifier. The input parameters are a search string and a search category. If the search category is null then it will search under all fields. The search string accepts the wildcard character * and also unicode characters. You can get maximum results upto 5000 entries at a time.",0, 0, ,
"http://www.myexperiment.org/workflows/1420/versions/1.html","Asynchronous chemspider search by formula","2010-07-1314:15:41","2010-07-1314:16:17","http://www.myexperiment.org/workflows/1420/download/Asynchronous_chemspider_search_by_formula-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Performs an asynchronous search on ChemSpider by molecular formula",1, 0, ,
"http://www.myexperiment.org/workflows/1421/versions/1.html","Get complete chebi entity","2010-07-1314:38:12","2010-07-1314:38:13","http://www.myexperiment.org/workflows/1421/download/Get_complete_chebi_entity-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Returns informations for a given compound represented by its chebi identifier",0, 0, ,
"http://www.myexperiment.org/workflows/1422/versions/1.html","Get complete entity by list","2010-07-1314:44:02","2010-07-1314:47:57","http://www.myexperiment.org/workflows/1422/download/Get_complete_entity_by_list-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Returns information from the chebi database for a list of chebi identifiers",0, 0, ,
"http://www.myexperiment.org/workflows/1423/versions/1.html","Get ontology parents","2010-07-1314:48:37","2010-07-1314:48:38","http://www.myexperiment.org/workflows/1423/download/Get_ontology_parents-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Retrieves the ontology parents of an entity including the relationship type, using the ChEBI identifier.",0, 0, ,
"http://www.myexperiment.org/workflows/1424/versions/1.html","Get ontology children","2010-07-1314:51:32","2010-07-1314:51:33","http://www.myexperiment.org/workflows/1424/download/Get_ontology_children-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Retrieves the ontology children of an entity including the relationship type, using the ChEBI identifier.",0, 0, ,
"http://www.myexperiment.org/workflows/1426/versions/1.html","Search structures in ChEBI database","2010-07-1315:08:20","2010-07-1315:10:10","http://www.myexperiment.org/workflows/1426/download/Search_structures_in_ChEBI_database-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","&nbsp; <span class=Apple-style-span>Does a substructure, similarity or identity search using a structure in the Chebi database</span>",-1, 0, ,
"http://www.myexperiment.org/workflows/1427/versions/1.html","Simple search","2010-07-1315:18:44","2010-07-1315:18:45","http://www.myexperiment.org/workflows/1427/download/Simple_search-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Performs a lite search on ChemSpider",0, 0, ,
"http://www.myexperiment.org/workflows/1428/versions/1.html","Fetch Dragon images from BioMoby","2010-07-1416:20:46","2010-07-1416:20:48","http://www.myexperiment.org/workflows/1428/download/Fetch_Dragon_images_from_BioMoby-v1.xml?version=1","/users/9981","EdwardK...","taverna 1","/users/9981, /users/297,","EdwardKawas, Tomoinn,","Fetch images and annotations of snapdragons",8, 2, id, namespace, Decode_base64_to_byte, getJpegFromAnnotatedImage, getDragonSimpleAnnotatedImages, Object, Parse_Moby_Data_JPEGImage, Parse_Moby_Data_SimpleAnnotatedJPEGImage, ,
"http://www.myexperiment.org/workflows/1430/versions/1.html","CTF - MEG SAM Analysis","2010-07-1516:36:52","2010-07-1516:36:53","http://www.myexperiment.org/workflows/1430/download/CTF_-_MEG_SAM_Analysis-v1.t2flow?version=1","/users/9777","Lakelander","taverna 2","/users/9777,","Lakelander,","Uses a user-defined text protocol file containing SAM analysis parameters and applies them to a set of MEG datasets. The dataset must be in CTF MEG system format.",-1, 0, ,
"http://www.myexperiment.org/workflows/1431/versions/1.html","file-similarity-entrez-url","2010-07-1609:34:45","2010-07-1609:43:39","http://www.myexperiment.org/workflows/1431/download/file-similarity-entrez-url-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Performs a 2D structure similarity search on the PubChem database. This workflow was written by the PubChem team @ NCBI ( <a href=http://pubchem.ncbi.nlm.nih.gov/ rel=nofollow>http://pubchem.ncbi.nlm.nih.gov/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/1431/versions/2.html","file-similarity-entrez-url","2010-07-1609:34:45","2010-07-1609:43:39","http://www.myexperiment.org/workflows/1431/download/file-similarity-entrez-url-v2.t2flow?version=2","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Performs a 2D structure similarity search on PubChem. The input structure has to be in the form of a SDF file. The original SDF-based similarity search workflow was written by the PubChem team @ NCBI ( <a href=http://pubchem.ncbi.nlm.nih.gov/ rel=nofollow>http://pubchem.ncbi.nlm.nih.gov/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/1432/versions/1.html","smiles-identity-idlist","2010-07-1609:50:50","2010-07-1609:53:16","http://www.myexperiment.org/workflows/1432/download/smiles-identity-idlist-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Searches for similar structures in PubChem to an input SMILES string. This workflow was written by the PubChem team @ NCBI ( <a href=http://pubchem.ncbi.nlm.nih.gov/ rel=nofollow>http://pubchem.ncbi.nlm.nih.gov/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/1433/versions/1.html","smiles-identity-idlist","2010-07-1610:20:48","2010-07-1610:25:06","http://www.myexperiment.org/workflows/1433/download/smiles-identity-idlist-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","","","Performs a search in PubChem for compounds similar to a given input compound in SMILES notation. This workflow was written by the PubChem team @ the NCBI ( <a href=http://pubchem.ncbi.nlm.nih.gov/ rel=nofollow>http://pubchem.ncbi.nlm.nih.gov/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/1433/versions/2.html","smiles-identity-idlist","2010-07-1610:20:48","2010-07-1610:25:06","http://www.myexperiment.org/workflows/1433/download/smiles-identity-idlist-v2.t2flow?version=2","/users/221","Peter Li","taverna 2","","","Performs a search in Pubchem for compounds similar to an input compound represented in SMILES notation. This workflow is based on the original&nbsp;smiles-identity-idlist workflow written by the PubChem team @ NCBI ( <a href=http://pubchem.ncbi.nlm.nih.gov/ rel=nofollow>http://pubchem.ncbi.nlm.nih.gov/</a> ).",1, 0, ,
"http://www.myexperiment.org/workflows/1434/versions/1.html","PubChem substructure search","2010-07-1610:31:51","2010-07-1610:52:28","http://www.myexperiment.org/workflows/1434/download/PubChem_substructure_search-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","","","Performs a substucture search in PubChem. This workflow was written by the PubChem team @ NCBI ( <a href=http://pubchem.ncbi.nlm.nih.gov/ rel=nofollow>http://pubchem.ncbi.nlm.nih.gov/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/1434/versions/2.html","PubChem substructure search","2010-07-1610:31:51","2010-07-1610:52:28","http://www.myexperiment.org/workflows/1434/download/PubChem_substructure_search-v2.t2flow?version=2","/users/221","Peter Li","taverna 2","","","Search PubChem Compound for structures containing the one given by the structure key input, based on a user-selected level of chemical identity: connectivity only, match isotopes and/or stereo, etc.&nbsp; <span class=Apple-style-span>The original workflow was written by the PubChem team @ NCBI (<a href=http://pubchem.ncbi.nlm.nih.gov/ rel=nofollow>http://pubchem.ncbi.nlm.nih.gov/</a>).</span>",1, 0, ,
"http://www.myexperiment.org/workflows/1435/versions/1.html","download","2010-07-1610:41:38","2010-07-1610:53:32","http://www.myexperiment.org/workflows/1435/download/download-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","&nbsp;Downloads records from PubChem given a list of identifiers. This workflow was written by the PubChem team @ NCBI ( <a href=http://pubchem.ncbi.nlm.nih.gov/ rel=nofollow>http://pubchem.ncbi.nlm.nih.gov/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/1435/versions/2.html","download","2010-07-1610:41:38","2010-07-1610:53:32","http://www.myexperiment.org/workflows/1435/download/download-v2.t2flow?version=2","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Given a list key, prepare for download a file containing those records in the selected format.&nbsp; <span class=Apple-style-span>The original workflow was written by the PubChem team @ NCBI (<a href=http://pubchem.ncbi.nlm.nih.gov/ rel=nofollow>http://pubchem.ncbi.nlm.nih.gov/</a>).</span>",1, 0, ,
"http://www.myexperiment.org/workflows/1450/versions/1.html","retrieve protein sequence and do a BLAST and extract position from DDBJ Web services","2010-07-2113:10:40","2010-07-2113:10:41","http://www.myexperiment.org/workflows/1450/download/retrieve_protein_sequence_and_do_a_BLAST_and_extract_position_from_DDBJ_Web_services-v1.xml?version=1","/users/10110","Lebreton","taverna 1","/users/10110,","Lebreton,","retrieve protein sequence and do a BLAST and extract position from DDBJ Web services &nbsp; informations on Web services available at  <a href=http://xml.nig.ac.jp/index.html rel=nofollow>http://xml.nig.ac.jp/index.html</a> <br /> <br /> example <br /> <br /> accession : Q9NRA8 <br /> database : UNIPROT <br /> program : blastp &nbsp;",3, 3, getFASTA_UNIPROTEntry, searchSimple, extractPosition, ,
"http://www.myexperiment.org/workflows/1451/versions/1.html","retrieve protein sequence and do a high speed BLAST and extract position from DDBJ Web services","2010-07-2113:16:00","2010-07-2113:23:12","http://www.myexperiment.org/workflows/1451/download/retrieve_protein_sequence_and_do_a_high_speed_BLAST_and_extract_position_from_DDBJ_Web_services-v1.xml?version=1","/users/10110","Lebreton","taverna 1","/users/10110,","Lebreton,","retrieve protein sequence and do a high speed BLAST and extract position from DDBJ Web services <br /> <br /> informations on Web services available at  <a href=http://xml.nig.ac.jp/index.html rel=nofollow>http://xml.nig.ac.jp/index.html</a> <br /> <br /> example <br /> accession : Q9NRA8 <br /> database : ddbjbct <br /> program : tblastn <br /> param : -b 100 -v 100",3, 3, getFASTA_UNIPROTEntry, searchParallel, extractPosition, ,
"http://www.myexperiment.org/workflows/1452/versions/1.html","retrieve protein sequence and do a BLAST with options from DDBJ Web services","2010-07-2113:24:56","2010-09-0117:37:48","http://www.myexperiment.org/workflows/1452/download/retrieve_protein_sequence_and_do_a_BLAST_with_options_from_DDBJ_Web_services-v1.xml?version=1","/users/10110","Lebreton","taverna 1","/users/10110,","Lebreton,","retrieve protein sequence and do a BLAST with options from DDBJ Web services <br /> informations on Web services available at  <a href=http://xml.nig.ac.jp/index.html rel=nofollow>http://xml.nig.ac.jp/index.html</a> exxample accession : Q9NRA8 <br /> database : UNIPROT <br /> program : blastp <br /> param : -b 5 -m 7 &nbsp; &nbsp;",2, 2, getFASTA_UNIPROTEntry, searchParam, ,
"http://www.myexperiment.org/workflows/1454/versions/1.html","retrieve nucleotide sequence and do a BLAST and extract position from DDBJ Web services","2010-07-2113:56:08","2010-07-2113:58:41","http://www.myexperiment.org/workflows/1454/download/retrieve_nucleotide_sequence_and_do_a_BLAST_and_extract_position_from_DDBJ_Web_services-v1.xml?version=1","/users/10110","Lebreton","taverna 1","/users/10110,","Lebreton,","retrieve nucleotide sequence and do a BLAST and extract position from DDBJ Web services informations on Web services available at  <a href=http://xml.nig.ac.jp/index.html rel=nofollow>http://xml.nig.ac.jp/index.html</a> example : accession : AB000100 <br /> database : DDBJ <br /> program : blastn &nbsp; &nbsp;",3, 3, getFASTA_DDBJEntry, searchSimple, extractPosition, ,
"http://www.myexperiment.org/workflows/1455/versions/1.html","retrieve nucleotide sequence and do a high speed BLAST and extract position from DDBJ Web services","2010-07-2114:08:32","2010-09-0710:04:55","http://www.myexperiment.org/workflows/1455/download/retrieve_nucleotide_sequence_and_do_a_high_speed_BLAST_and_extract_position_from_DDBJ_Web_services-v1.xml?version=1","/users/10110","Lebreton","taverna 1","/users/10110,","Lebreton,","retrieve nucleotide sequence and do a high speed BLAST and extract position from DDBJ Web services informations on Web services available at  <a href=http://xml.nig.ac.jp/index.html rel=nofollow>http://xml.nig.ac.jp/index.html</a> accession : AB000100 <br /> database : DDBJ <br /> program : blastn <br /> param : -b 5 -m 7",3, 3, getFASTA_UNIPROTEntry, searchParallel, extractPosition, ,
"http://www.myexperiment.org/workflows/1455/versions/2.html","retrieve nucleotide sequence and do a high speed BLAST and extract position from DDBJ Web services","2010-07-2114:08:32","2010-09-0710:04:55","http://www.myexperiment.org/workflows/1455/download/retrieve_nucleotide_sequence_and_do_a_high_speed_BLAST_and_extract_position_from_DDBJ_Web_services-v2.xml?version=2","/users/10110","Lebreton","taverna 1","/users/10110,","Lebreton,",,3, 3, getFASTA_DDBJEntry, searchParallel, extractPosition, ,
"http://www.myexperiment.org/workflows/1455/versions/3.html","retrieve nucleotide sequence and do a high speed BLAST and extract position from DDBJ Web services","2010-07-2114:08:32","2010-09-0710:04:55","http://www.myexperiment.org/workflows/1455/download/retrieve_nucleotide_sequence_and_do_a_high_speed_BLAST_and_extract_position_from_DDBJ_Web_services-v3.xml?version=3","/users/10110","Lebreton","taverna 1","/users/10110,","Lebreton,","retrieve nucleotide sequence and do a high speed BLAST and extract position from DDBJ Web services <br /> <br /> informations on Web services available at  <a href=http://xml.nig.ac.jp/index.html rel=nofollow>http://xml.nig.ac.jp/index.html</a> <br /> <br /> example <br /> accession : AB000100 <br /> database : DDBJ <br /> program : blastn <br /> param : -b 5 -m 7",3, 3, getFASTA_DDBJEntry, searchParallel, extractPosition, ,
"http://www.myexperiment.org/workflows/1455/versions/4.html","retrieve nucleotide sequence and do a high speed BLAST and extract position from DDBJ Web services","2010-07-2114:08:32","2010-09-0710:04:55","http://www.myexperiment.org/workflows/1455/download/retrieve_nucleotide_sequence_and_do_a_high_speed_BLAST_and_extract_position_from_DDBJ_Web_services-v4.xml?version=4","/users/10110","Lebreton","taverna 1","/users/10110,","Lebreton,","retrieve nucleotide sequence and do a high speed BLAST and extract position from DDBJ Web services <br /> <br /> informations on Web services available at  <a href=http://xml.nig.ac.jp/index.html rel=nofollow>http://xml.nig.ac.jp/index.html</a> <br /> <br /> example <br /> accession : AB000100 <br /> database : DDBJ <br /> program : blastn <br /> param : -b 5 -m 7",3, 3, getFASTA_DDBJEntry, searchParallel, extractPosition, ,
"http://www.myexperiment.org/workflows/1456/versions/1.html","retrieve nucleotide sequence and do a BLAST with options from DDBJ Web services","2010-07-2114:21:50","2010-07-2114:21:52","http://www.myexperiment.org/workflows/1456/download/retrieve_nucleotide_sequence_and_do_a_BLAST_with_options_from_DDBJ_Web_services-v1.xml?version=1","/users/10110","Lebreton","taverna 1","/users/10110,","Lebreton,","retrieve nucleotide sequence and do a BLAST with options from DDBJ Web services informations on Web services available at  <a href=http://xml.nig.ac.jp/index.html rel=nofollow>http://xml.nig.ac.jp/index.html</a> example accession : AB000100 <br /> database : DDBJ <br /> program : blastn <br /> param : -b 5 -m 7",2, 2, getFASTA_DDBJEntry, searchParam, ,
"http://www.myexperiment.org/workflows/1457/versions/1.html","retrieve nucleotide sequence and do a VecScreen from DDBJ Web services","2010-07-2114:36:36","2010-09-0117:35:20","http://www.myexperiment.org/workflows/1457/download/retrieve_nucleotide_sequence_and_do_a_VecScreen_from_DDBJ_Web_services-v1.xml?version=1","/users/10110","Lebreton","taverna 1","/users/10110,","Lebreton,","retrieve nucleotide sequence and do a VecScreen from DDBJ Web services : A system for quickly identifying segments of a nucleic acid sequence  that may be of vector origin &nbsp; informations on Web services available at  <a href=http://xml.nig.ac.jp/index.html rel=nofollow>http://xml.nig.ac.jp/index.html</a> accession : AB000100",2, 2, getFASTA_DDBJEntry, searchSimple, ,
"http://www.myexperiment.org/workflows/1466/versions/1.html","Call VSO web service with HELIO input data","2010-08-0411:21:15","2010-08-0411:22:26","http://www.myexperiment.org/workflows/1466/download/Call_VSO_web_service_with_HELIO_input_data-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","&nbsp; date transformation from 2000-10-02T23:00:00 to 20001002230000 HELIO instrument names as in  <a href=http://helio-dev.i4ds.ch/xsd/instruments.xsd rel=nofollow>http://helio-dev.i4ds.ch/xsd/instruments.xsd</a>  spitt into source and instrument names; if these pair don't exist only first part (source) is tried.",0, 0, ,
"http://www.myexperiment.org/workflows/1467/versions/1.html","Predict chemical solubility in solvents","2010-08-0411:42:55","2010-08-0411:43:30","http://www.myexperiment.org/workflows/1467/download/Predict_chemical_solubility_in_solvents-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Predicts solubility in molar units for a given chemical compound represented as a SMILES string in a given solvent",0, 0, ,
"http://www.myexperiment.org/workflows/1467/versions/2.html","Predict chemical solubility in solvents","2010-08-0411:42:55","2010-08-0411:43:30","http://www.myexperiment.org/workflows/1467/download/Predict_chemical_solubility_in_solvents-v2.t2flow?version=2","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Predicts solubility in molar units for a given chemical compound represented as a SMILES string in a given solvent. Uses a beanshell script to enable the user to select the solvent from a list.",0, 0, ,
"http://www.myexperiment.org/workflows/1470/versions/1.html","AUTOSTRUCTURE","2010-08-0417:50:21","2011-02-2717:26:17","http://www.myexperiment.org/workflows/1470/download/AUTOSTRUCTURE-v1.t2flow?version=1","/users/8014","Juan Gonzalez","taverna 2","","","This is a simple workflow designed to run AUTOSTRUCTURE with an user selected input. The code is a full implementation of the program AUTOSTRUCTURE developed by N. R. Badnell. The entire capability of the original program for arbitrary structure, Auger rate and Radiative rate calculation has been retained. However input driver file selection, driver templates, output selection and output routing have been enabled within the ADAS framework to simplify the production of two types of data, namely dielectronic recombination rates and data for doubly excited state (satellite line) models. More information can be found here: - Reference Manual:  <a href=http://www.adas.ac.uk/man/chap7-01.pdf rel=nofollow>http://www.adas.ac.uk/man/chap7-01.pdf</a> - AUTOSTRUCTURE on the Spinet client (Soaplab2):  <a href=http://caoba.ivic.ve:8180/soaplab2-axis/ rel=nofollow>http://caoba.ivic.ve:8180/soaplab2-axis/</a>",2, 0, ,
"http://www.myexperiment.org/workflows/1470/versions/2.html","AUTOSTRUCTURE","2010-08-0417:50:21","2011-02-2717:26:17","http://www.myexperiment.org/workflows/1470/download/AUTOSTRUCTURE-v2.t2flow?version=2","/users/8014","Juan Gonzalez","taverna 2","","","This is a simple workflow designed to run AUTOSTRUCTURE with an user selected input. The code is a full implementation of the program AUTOSTRUCTURE developed by N. R. Badnell. The entire capability of the original program for arbitrary structure, Auger rate and Radiative rate calculation has been retained. However input driver file selection, driver templates, output selection and output routing have been enabled within the ADAS framework to simplify the production of two types of data, namely dielectronic recombination rates and data for doubly excited state (satellite line) models. More information can be found here: - Reference Manual:  <a href=http://www.adas.ac.uk/man/chap7-01.pdf rel=nofollow>http://www.adas.ac.uk/man/chap7-01.pdf</a> - AUTOSTRUCTURE on the Spinet client (Soaplab2):  <a href=http://caoba.ivic.ve:8180/soaplab2-axis/ rel=nofollow>http://caoba.ivic.ve:8180/soaplab2-axis/</a>",2, 0, ,
"http://www.myexperiment.org/workflows/1470/versions/3.html","AUTOSTRUCTURE","2010-08-0417:50:21","2011-02-2717:26:17","http://www.myexperiment.org/workflows/1470/download/AUTOSTRUCTURE-v3.t2flow?version=3","/users/8014","Juan Gonzalez","taverna 2","","","This is a simple workflow designed to run AUTOSTRUCTURE with an user selected input. The code is a full implementation of the program AUTOSTRUCTURE developed by N. R. Badnell. The entire capability of the original program for arbitrary structure, Auger rate and Radiative rate calculation has been retained. However input driver file selection, driver templates, output selection and output routing have been enabled within the ADAS framework to simplify the production of two types of data, namely dielectronic recombination rates and data for doubly excited state (satellite line) models. More information can be found here: - Reference Manual:  <a href=http://www.adas.ac.uk/man/chap7-01.pdf rel=nofollow>http://www.adas.ac.uk/man/chap7-01.pdf</a> - AUTOSTRUCTURE on the Spinet client (Soaplab2):  <a href=http://caoba.ivic.ve:8180/soaplab2-axis/ rel=nofollow>http://caoba.ivic.ve:8180/soaplab2-axis/</a>",2, 0, ,
"http://www.myexperiment.org/workflows/1470/versions/4.html","AUTOSTRUCTURE","2010-08-0417:50:21","2011-02-2717:26:17","http://www.myexperiment.org/workflows/1470/download/AUTOSTRUCTURE-v4.t2flow?version=4","/users/8014","Juan Gonzalez","taverna 2","","","This is a simple workflow designed to run AUTOSTRUCTURE with an user selected input. The code is a full implementation of the program AUTOSTRUCTURE developed by N. R. Badnell. The entire capability of the original program for arbitrary structure, Auger rate and Radiative rate calculation has been retained. However input driver file selection, driver templates, output selection and output routing have been enabled within the ADAS framework to simplify the production of two types of data, namely dielectronic recombination rates and data for doubly excited state (satellite line) models. More information can be found here: - Reference Manual:  <a href=http://www.adas.ac.uk/man/chap7-01.pdf rel=nofollow>http://www.adas.ac.uk/man/chap7-01.pdf</a> - AUTOSTRUCTURE on the Spinet client (Soaplab2):  <a href=http://caoba.ivic.ve:8180/soaplab2-axis/ rel=nofollow>http://caoba.ivic.ve:8180/soaplab2-axis/</a>",2, 0, ,
"http://www.myexperiment.org/workflows/1471/versions/1.html","Predict Abraham descriptors","2010-08-0516:26:19","2010-08-0516:26:20","http://www.myexperiment.org/workflows/1471/download/Predict_Abraham_descriptors-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","Predicts descriptor values using a model derived from a linear regression analysis of the Open Notebook Science solubility data and literature values. The workflow returns all the Abraham descriptors E, S, A, B and V in a HTML file. <hr /> Predicts descriptor values using a model derived from a linear regression analysis of the Open Notebook Science solubility data and literature values",0, 0, ,
"http://www.myexperiment.org/workflows/1474/versions/1.html","Generate CombiUgi library","2010-08-1012:15:37","2010-08-1012:16:00","http://www.myexperiment.org/workflows/1474/download/Generate_CombiUgi_library-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221, /users/10473,","Peter Li, Romney,","Generates a CombiUgi library using data from a Goolgle spreadsheet containing smiles strings of compounds to undergo virtual Ugi reactions",1, 0, ,
"http://www.myexperiment.org/workflows/1477/versions/1.html","KEIO Bioinformatics Web Service - a generating sequence logo image for a set of sequence retrieval via homology search","2010-08-1314:02:59","2010-11-1905:32:37","http://www.myexperiment.org/workflows/1477/download/KEIO_Bioinformatics_Web_Service_-_a_generating_sequence_logo_image_for_a_set_of_sequence_retrieval_via_homology_search_-v1.t2flow?version=1","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","This workflow generates a sequence logo image for a set of amino acid sequences of FOXP2, downloading the amino acid sequence in Fasta format through Togo Web Service with UniProt identifier, using BLAST web service (runBLAST), retrieving a set of sequence from ID list (togoWS), aligning the sequence with MUSCLE (runMUSCLE), extracting a certain region from the alignment (extractalign), and generating its sequence logo image (runWebLogo). See  <a href=http://www.g-language.org/kbws/ rel=nofollow>http://www.g-language.org/kbws/</a>  for more information about KEIO Bioinformatics Web Service.",2, 0, ,
"http://www.myexperiment.org/workflows/1477/versions/2.html","KEIO Bioinformatics Web Service - a generating sequence logo image for a set of sequence retrieval via homology search","2010-08-1314:02:59","2010-11-1905:32:37","http://www.myexperiment.org/workflows/1477/download/KEIO_Bioinformatics_Web_Service_-_a_generating_sequence_logo_image_for_a_set_of_sequence_retrieval_via_homology_search_-v2.t2flow?version=2","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","This workflow generates a sequence logo image for a set of amino acid sequences of FOXP2 gene, by downloading the amino acid sequences in Fasta format through Togo Web Service with UniProt identifiers (togoWS, provided by the G-language Genome Analysis Environment SOAP Service), running BLAST web service (runBLAST), retrieving a set of sequences from ID list (togoWS), aligning the sequence with MUSCLE (runMUSCLE), extracting a certain region from the alignment (extractalign, provided by Soaplab), and generating its sequence logo image (runWebLogo). See  <a href=http://www.g-language.org/kbws/ rel=nofollow>http://www.g-language.org/kbws/</a>  for more information about Keio Bioinformatics Web Services. <hr /> This workflow generates a sequence logo image for a set of amino acid sequences of FOXP2, downloading the amino acid sequence in Fasta format through Togo Web Service with UniProt identifier, using BLAST web service (runBLAST), retrieving a set of sequence from ID list (togoWS), aligning the sequence with MUSCLE (runMUSCLE), extracting a certain region from the alignment (extractalign), and generating its sequence logo image (runWebLogo). See  <a href=http://www.g-language.org/kbws/ rel=nofollow>http://www.g-language.org/kbws/</a>  for more information about KEIO Bioinformatics Web Service.",2, 0, ,
"http://www.myexperiment.org/workflows/1478/versions/1.html","caArray","2010-08-1406:02:00","2010-08-1406:03:20","http://www.myexperiment.org/workflows/1478/download/caArray-v1.t2flow?version=1","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","preprocess data before it is sent to any GenePattern services.",-1, 0, ,
"http://www.myexperiment.org/workflows/1480/versions/1.html","Testing caBIG workflow","2010-08-1718:24:05","2010-08-1719:45:34","http://www.myexperiment.org/workflows/1480/download/Testing_caBIG_workflow-v1.t2flow?version=1","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","An example workflow to test the installation of caGrid Workflow Suite and the submission of a workflow to a caGrid workflow service.",-1, 0, ,
"http://www.myexperiment.org/workflows/1483/versions/1.html","instruments in sxr and euv spectrum","2010-08-2015:39:20","2010-08-2015:39:22","http://www.myexperiment.org/workflows/1483/download/instruments_in_sxr_and_euv_spectrum-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","ICS use case 5",0, 0, ,
"http://www.myexperiment.org/workflows/1484/versions/1.html","Retrieve a protein from the GPCRDB","2010-08-2413:37:05","2010-08-2413:42:54","http://www.myexperiment.org/workflows/1484/download/Retrieve_a_protein_from_the_GPCRDB-v1.t2flow?version=1","/users/586","Bas Vroling","taverna 2","/users/586,","Bas Vroling,","This small workflow illustrates how to use the web service access provided by the GPCRDB in Taverna. The proteinId input field is case sensitive and by default the identifiers in the GPCRDB are lowercase. You can try this mini-workflow with e.a. 'adrb2_human'.",-1, 0, ,
"http://www.myexperiment.org/workflows/1485/versions/1.html","BLAST against the GPCRDB","2010-08-2413:45:14","2010-08-2413:45:16","http://www.myexperiment.org/workflows/1485/download/BLAST_against_the_GPCRDB-v1.t2flow?version=1","/users/586","Bas Vroling","taverna 2","/users/586,","Bas Vroling,","With this workflow you can submit a BLAST query to the GPCRDB. Input requires a sequence with amino acids only.",-1, 0, ,
"http://www.myexperiment.org/workflows/1486/versions/1.html","Create custom-made GPCR alignments","2010-08-2413:58:32","2010-08-2413:58:35","http://www.myexperiment.org/workflows/1486/download/Create_custom-made_GPCR_alignments-v1.t2flow?version=1","/users/586","Bas Vroling","taverna 2","/users/586,","Bas Vroling,","<span><span>This workflow allows you to create your own GPCR alignments. <span>The alignments are built from the residues that are annotated with the general residue numbers. Alignments are therefore not built using standard alignment algorithms but are created by selecting residues that are likely to share the same position in the three-dimensional structure. Users can select the proteins and residue positions that should be aligned, allowing for the creation of e.g. an alignment of all binding pocket residues of all human adrenoceptors. </span></span></span> &nbsp; <span><span><span>Input is a list of proteins and a list of residue numbers in the GPCRDB residue numbering scheme. If you are using Ballesteros-Weinstein numbers you can convert these to GPCRDB number by using our conversion service.</span>&lt;!--EndFragment--&gt; </span></span>",-1, 0, ,
"http://www.myexperiment.org/workflows/1491/versions/1.html","retrieve protein sequence and do a high speed BLAST from DDBJ Web services","2010-09-0117:16:24","2010-09-0117:18:45","http://www.myexperiment.org/workflows/1491/download/retrieve_protein_sequence_and_do_a_high_speed_BLAST_from_DDBJ_Web_services-v1.xml?version=1","/users/10110","Lebreton","taverna 1","/users/10110,","Lebreton,","retrieve protein sequence and do a high speed BLAST from DDBJ Web services <br /> <br /> informations on Web services available at  <a href=http://xml.nig.ac.jp/index.html rel=nofollow>http://xml.nig.ac.jp/index.html</a> <br /> <br /> example <br /> accession : Q9NRA8 <br /> database : ddbjbct <br /> program : tblastn <br /> param : -b 100 -v 100",2, 2, getFASTA_UNIPROTEntry, searchParallel, ,
"http://www.myexperiment.org/workflows/1492/versions/1.html","retrieve protein sequence and do a BLAST from DDBJ Web services","2010-09-0117:22:14","2010-09-0117:22:37","http://www.myexperiment.org/workflows/1492/download/retrieve_protein_sequence_and_do_a_BLAST_from_DDBJ_Web_services-v1.xml?version=1","/users/10110","Lebreton","taverna 1","/users/10110,","Lebreton,","retrieve protein sequence and do a BLAST from DDBJ Web services &nbsp; informations on Web services available at  <a href=http://xml.nig.ac.jp/index.html rel=nofollow>http://xml.nig.ac.jp/index.html</a> <br /> <br /> example <br /> <br /> accession : Q9NRA8 <br /> database : UNIPROT <br /> program : blastp &nbsp;",2, 2, getFASTA_UNIPROTEntry, searchSimple, ,
"http://www.myexperiment.org/workflows/1493/versions/1.html","retrieve nucleotide sequence and do a high speed BLAST from DDBJ Web services","2010-09-0117:26:07","2010-09-0117:26:39","http://www.myexperiment.org/workflows/1493/download/retrieve_nucleotide_sequence_and_do_a_high_speed_BLAST_from_DDBJ_Web_services-v1.xml?version=1","/users/10110","Lebreton","taverna 1","/users/10110,","Lebreton,","retrieve nucleotide sequence and do a high speed BLAST from DDBJ Web services informations on Web services available at  <a href=http://xml.nig.ac.jp/index.html rel=nofollow>http://xml.nig.ac.jp/index.html</a> accession : AB000100 <br /> database : DDBJ <br /> program : blastn <br /> param : -b 5 -m 7",2, 2, getFASTA_DDBJEntry, searchParallel, ,
"http://www.myexperiment.org/workflows/1494/versions/1.html","retrieve nucleotide sequence and do a BLAST from DDBJ Web services","2010-09-0117:31:29","2010-09-0117:33:51","http://www.myexperiment.org/workflows/1494/download/retrieve_nucleotide_sequence_and_do_a_BLAST_from_DDBJ_Web_services_-v1.xml?version=1","/users/10110","Lebreton","taverna 1","/users/10110,","Lebreton,","retrieve nucleotide sequence and do a BLAST from DDBJ Web services informations on Web services available at  <a href=http://xml.nig.ac.jp/index.html rel=nofollow>http://xml.nig.ac.jp/index.html</a> example : accession : AB000100 <br /> database : DDBJ <br /> program : blastn&nbsp;",2, 2, getFASTA_DDBJEntry, searchSimple, ,
"http://www.myexperiment.org/workflows/1498/versions/1.html","Cow SNP annotation","2010-09-0309:39:49","2010-09-0309:42:57","http://www.myexperiment.org/workflows/1498/download/Cow_SNP_annotation_-v1.t2flow?version=1","/users/6695","Mkh","taverna 2","/users/6695,","Mkh,","SNP annotation",-1, 0, ,
"http://www.myexperiment.org/workflows/1505/versions/1.html","Multiple choice quiz","2010-09-0617:12:15","","http://www.myexperiment.org/workflows/1505/download/Multiple_choice_quiz-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/345,","George,","A fun example workflow showing user-interaction and service looping",0, 0, ,
"http://www.myexperiment.org/workflows/1508/versions/1.html","Principle Component Analysis (PCA) over microarray data","2010-09-1023:45:05","2010-09-1023:51:03","http://www.myexperiment.org/workflows/1508/download/Principle_Component_Analysis__PCA__over_microarray_data-v1.t2flow?version=1","/users/1019","Wei Tan","taverna 2","/users/1019,","Wei Tan,","Principle Component Analysis (PCA) over microarray data. Data is uploaded through caGrid transfer ultility.",-1, 0, ,
"http://www.myexperiment.org/workflows/1510/versions/1.html","Example workflow for REST and XPath activities","2010-09-1314:27:25","2010-09-1314:31:33","http://www.myexperiment.org/workflows/1510/download/Example_workflow_for_REST_and_XPath_activities-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/979,","Sergejs Aleksejevs,","<b>Note that this workflow depends upon the REST and XPath plugins.</b> This workflow fetches weather forecast for the user-specified location.  First of all it uses the provided location name to obtain a WOEID (&quot;Where On Earth ID&quot;) of that location, then uses that unique identifier to fetch the weather forecast from Yahoo server.  Multiple results may be obtained in case there is no unique translation of the location to a WOEID.  REST activity is used to perform HTTP requests and fetch data from remote servers; XPath activity is then used to parse the XML data and extract only selected elements.",0, 0, ,
"http://www.myexperiment.org/workflows/1512/versions/1.html","retrive dpas data for all ics instruments for HEC event data","2010-09-1413:55:06","2010-09-1413:59:12","http://www.myexperiment.org/workflows/1512/download/retrive_dpas_data_for_all_ics_instruments_for_HEC_event_data-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow demonstrates the standard query there events for a period of time are requested from the HEC service, available instruments for this time come from the ICS and data only for the times of the events are requested from the DPAS.",0, 0, ,
"http://www.myexperiment.org/workflows/1513/versions/1.html","retrive dpas data for all ics instruments for only a limited number (3 random) HEC event data","2010-09-1414:24:20","2010-09-1414:24:24","http://www.myexperiment.org/workflows/1513/download/retrive_dpas_data_for_all_ics_instruments_for_only_a_limited_number__3_random__HEC_event_data-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow demonstrates the standard query where events for a period of time are requested from the HEC service, available instruments for this time come from the ICS and data only for the times of the events are requested from the DPAS.In this version data from only 3 random events (out of the HEC list) will be requested from the DPAS.",1, 0, ,
"http://www.myexperiment.org/workflows/1516/versions/1.html","From PDF to lemmatized text","2010-09-1610:09:58","2012-01-1810:27:27","http://www.myexperiment.org/workflows/1516/download/From_PDF_to_lemmatized_text-v1.t2flow?version=1","/users/11207","Netr","taverna 2","/users/11207, /users/1125,","Netr, James Eales,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1517/versions/1.html","BowtieToPileup","2010-09-1611:07:53","","http://www.myexperiment.org/workflows/1517/download/BowtieToPileup-v1.t2flow?version=1","/users/4585","Wbkoets","taverna 2","","","This example workflow aligns short sequencing reads to a reference genome using Bowtie and generates a SAMtools pileup file. By analysing an actual data set (SNP detection in N. vitripennis) and translating this analysis pipeline into a Taverna workflow, I was able to come up with an easy way of using Taverna for such analysis. I created a Java API (with my limited Java experience) that wraps the command line programs used in the analysis pipeline: Bowtie and some of the SAMtools. Instead of passing Taverna or the API data, only references to files are used. The API does not have a main entry point, instead, each step in the analysis pipeline is represented by a short Beanshell script that calls the appropriate method of the API. These scripts are used as services. This workflow is part of my bachelors thesis (bioinformatics at the Hanze University Groningen, the Netherlands). Please note that Bowtie and the SAMtools need to be installed and in the path. The API needs to be present in the .taverna/lib directory, please check dependencies of the Beanshell services. Assumes Linux.",0, 0, ,
"http://www.myexperiment.org/workflows/1525/versions/1.html","Sff2Fasta_Blast_ParseBlast","2010-09-2212:40:55","2010-09-2213:35:26","http://www.myexperiment.org/workflows/1525/download/Sff2Fasta_Blast_ParseBlast-v1.xml?version=1","/users/1195","Barbera van Schaik","taverna 1","/users/1195, /users/29, /users/36, /users/1612,","Barbera van Schaik, Antoine van Kampen, Angela Luijf, Silvia Olabarriaga,","Blast Roche 454 sequences against a reference database on the Dutch Life Science Grid <a href=http://www.bioinformaticslaboratory.nl/ rel=nofollow>http://www.bioinformaticslaboratory.nl/</a> &nbsp; &nbsp; &nbsp;",6, 3, config_Blast, config_Sff2Fasta, Blast, config_ParseBlast, ParseBlast, Sff2Fasta, ,
"http://www.myexperiment.org/workflows/1526/versions/1.html","Population projection transport simulation","2010-09-2212:55:37","2010-09-2214:08:08","http://www.myexperiment.org/workflows/1526/download/Population_projection_transport_simulation-v1.t2flow?version=1","/users/8344","Nick Malleson","taverna 2","/users/8344,","Nick Malleson,","<u><b>Neiss Transport Sim Demo.</b></u> Runs a population reconstruction model (PRM) from census data, then projects the simulation through time. Also runs a transport simulation before and after the projection.",-1, 0, ,
"http://www.myexperiment.org/workflows/1527/versions/1.html","Sff2Fasta_Blat","2010-09-2213:18:55","2010-09-2213:35:49","http://www.myexperiment.org/workflows/1527/download/Sff2Fasta_Blat-v1.xml?version=1","/users/1195","Barbera van Schaik","taverna 1","/users/1195, /users/29, /users/36, /users/1612,","Barbera van Schaik, Antoine van Kampen, Angela Luijf, Silvia Olabarriaga,","<span class=Apple-style-span>Blat Roche 454 sequences against a reference database<span class=Apple-style-span>&nbsp;on the Dutch Life Science Grid</span></span> <a href=http://www.bioinformaticslaboratory.nl/ rel=nofollow>http://www.bioinformaticslaboratory.nl/</a> &nbsp;",4, 2, config_Sff2Fasta, config_Blat, Sff2Fasta, Blat, ,
"http://www.myexperiment.org/workflows/1528/versions/1.html","Sff2Fasta_Blast_Blat_ParseBlast","2010-09-2213:22:57","2010-09-2213:36:12","http://www.myexperiment.org/workflows/1528/download/Sff2Fasta_Blast_Blat_ParseBlast-v1.xml?version=1","/users/1195","Barbera van Schaik","taverna 1","/users/1195, /users/29, /users/36, /users/1612,","Barbera van Schaik, Antoine van Kampen, Angela Luijf, Silvia Olabarriaga,","<span class=Apple-style-span>Blast and Blat Roche 454 sequences against a reference database&nbsp;</span> <span class=Apple-style-span>on the Dutch Life Science Grid</span> <a href=http://www.bioinformaticslaboratory.nl/ rel=nofollow>http://www.bioinformaticslaboratory.nl/</a> &nbsp;",8, 4, config_Blast, config_Sff2Fasta, config_Blat, Sff2Fasta, Blast, Blat, ParseBlast, config_ParseBlast, ,
"http://www.myexperiment.org/workflows/1530/versions/1.html","Maptube mapper","2010-09-2215:56:19","2011-01-1014:10:07","http://www.myexperiment.org/workflows/1530/download/Maptube_mapper-v1.t2flow?version=1","/users/8344","Nick Malleson","taverna 2","/users/8344,","Nick Malleson,","Takes the URL of a csv file and a column in the file that contains numeric data and produces a URL to MapTube to display the data on a map. <br /> (Only works for OutputArea and Ward data at present).",0, 0, ,
"http://www.myexperiment.org/workflows/1530/versions/2.html","Maptube mapper","2010-09-2215:56:19","2011-01-1014:10:07","http://www.myexperiment.org/workflows/1530/download/Maptube_mapper-v2.t2flow?version=2","/users/8344","Nick Malleson","taverna 2","/users/8344,","Nick Malleson,","Takes a URL of some spatially-aggregated data and a field/column name to map and generates a MapTube url to an online map of the data.",-1, 0, ,
"http://www.myexperiment.org/workflows/1556/versions/1.html","BioXSD example workflow","2010-10-1209:19:17","2010-10-1209:21:55","http://www.myexperiment.org/workflows/1556/download/BioXSD_example_workflow-v1.t2flow?version=1","/users/221","Peter Li","taverna 2","/users/221,","Peter Li,","An attempt to implement in the BioXSD workflow described by Kalas et al., (2010) Bioinformatics 26:i540-6. The workflow only calls one BioXSD web service (BLAST) since the second service (ClustalW) in the example workflow is currently down :(",0, 0, ,
"http://www.myexperiment.org/workflows/1571/versions/1.html","Polygon buffer - Using pyWPS","2010-10-2616:10:14","2010-10-2616:10:15","http://www.myexperiment.org/workflows/1571/download/Polygon_buffer_-_Using_pyWPS-v1.t2flow?version=1","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","Basic example on how to integrate a Web Processing Service (WPS) using&nbsp; PyWPS's WSDL/SOAP The workflow will accept a GML file with featureCollection where polyon is described using gml:coordinate element structure. This GMl is easely generated with GDAL. The coodinate structure will be converted to WKT and used to create a polygon using shapely, the output will be a buffer polygon with a defined width. Output polygon will replace the orginal polygon and the existing XML will be returned as output THIS IS AN EXPERIMENTAL WORKFLOW TO SHOW TAVERNA WORKING WITH OGC SERVICES",-1, 0, ,
"http://www.myexperiment.org/workflows/1578/versions/1.html","Decode base64 to byte[]","2010-10-2814:16:22","","http://www.myexperiment.org/workflows/1578/download/Decode_base64_to_byte___-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The decode base64 to byte[] service decodes the base64 string.  The byte array is then converted into the string 'Hello world'.",2, 0, ,
"http://www.myexperiment.org/workflows/1579/versions/1.html","Encode byte[] to base64","2010-10-2814:18:06","","http://www.myexperiment.org/workflows/1579/download/Encode_byte___to_base64_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The encode byte[] to base 64 service encodes the bytes representing (in the local character set) 'hello'.",2, 0, ,
"http://www.myexperiment.org/workflows/1580/versions/1.html","Read GenBank file","2010-10-2814:20:12","2010-10-2814:20:51","http://www.myexperiment.org/workflows/1580/download/Read_GenBank_file_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The Read_GenBank_file service reads the file at the genbank_file_url and converts the GenBank data into Agave format.  The result is then sent to the workflow's gen_bank_data port.",2, 0, ,
"http://www.myexperiment.org/workflows/1581/versions/1.html","Read SwissProt file","2010-10-2814:24:51","2010-10-2814:25:36","http://www.myexperiment.org/workflows/1581/download/Read_SwissProt_file-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The Read_SwissProt_file service reads the file at the swiss_prot_file_url and converts the SwissProt data into Agave format.  The result is then sent to the workflow's swiss_prot_data port.",2, 0, ,
"http://www.myexperiment.org/workflows/1582/versions/1.html","Reverse complement DNA","2010-10-2814:26:57","","http://www.myexperiment.org/workflows/1582/download/Reverse_complement_DNA_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The Reverse Complement DNA service takes the DNA sequence, here defaulted to 'gatcctccat' and outputs the corresponding reverse complement sequence, in this example, 'atggaggatc'.",1, 0, ,
"http://www.myexperiment.org/workflows/1583/versions/1.html","Transcribe DNA","2010-10-2814:28:29","","http://www.myexperiment.org/workflows/1583/download/Transcribe_DNA_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The Transcribe DNA service takes the DNA sequence, here defaulted to 'gatcctccat' and outputs the corresponding transcribed RNA  sequence, in this example, 'gauccuccau'.",2, 0, ,
"http://www.myexperiment.org/workflows/1584/versions/1.html","Concatenate files - echo results and multiple files","2010-10-2814:39:24","","http://www.myexperiment.org/workflows/1584/download/Concatenate_files_-_echo_results_and_multiple_files-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The workflow splits the string 'a,b,c,d,e' into its five elements and saves the individual strings to five temporary files.  The file paths to those files are then output by the create_and_populate_temporary_file beanshell. The create_temporary_file beanshell creates a file to which the concatentation can be written. The concatenate_files service concatenates the five files and writes the result to the temporary output file.  Because the displayresults port has been given a default value of 'true', the results are also copied to the results port of concatenate_files. The temporary file to which the results were written is read by the read_text_file service and its contents output. Both of the workflow outputs contain 'abcde' i.e. the contents of the concatenated files separated by a newline.",2, 0, ,
"http://www.myexperiment.org/workflows/1585/versions/1.html","Concatenate files - echo results but no files","2010-10-2814:42:17","","http://www.myexperiment.org/workflows/1585/download/Concatenate_files_-_echo_results_but_no_files-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The split_string_into_string_list_by_regular_expresson outputs an empty list since the string to be split is defaulted to ''.  As there are no input values, the create_and_populate_temporary_file generates an empty list. The create_temporary_file beanshell creates a file to which the concatentation can be written. The concatenate_files service does not write anything to the temporary output file.  Because the displayresults port has been given a default value of 'true', the empty string is also copied to the results port of concatenate_files. The temporary file to which the results were written is read by the read_text_file service and its contents output. Both of the workflow outputs contain '' i.e. the empty string.",2, 0, ,
"http://www.myexperiment.org/workflows/1586/versions/1.html","Concatenate files - multiple files","2010-10-2814:44:17","","http://www.myexperiment.org/workflows/1586/download/Concatenate_files_-_multiple_files_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The workflow splits the string 'a,b,c,d,e' into its five elements and saves the individual strings to five temporary files.  The file paths to those files are then output by the create_and_populate_temporary_file beanshell. The create_temporary_file beanshell creates a file to which the concatentation can be written. The concatenate_files service concatenates the five files and writes the result to the temporary output file.  Because the displayresults port has no value, the results are not output by the service. The temporary file to which the results were written is read by the read_text_file service and its contents output. The workflow output contains 'abcde' i.e. the contents of the concatenated files separated by a newline.",2, 0, ,
"http://www.myexperiment.org/workflows/1587/versions/1.html","Execute cmd line app - unix - /bin/ls -R of temporary directory","2010-10-2814:50:13","2010-10-2814:50:58","http://www.myexperiment.org/workflows/1587/download/Execute_cmd_line_app_-_unix_-__bin_ls_-R_of_temporary_directory-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","Note that this workflow only works on Unix systems.  The get_temporary_directory beanshell returns the path to the directory in which temporary files are held.  This value is passed to the create_and_populate_list beanshell which creates a list of '-R' and the path.  The resultant list is passed to the args port of the Execute_cmd_line_app service.  The command port of that service has been defaulted to '/bin/ls'.  The execute_cmd_line_app service runs the /bin/ls -R command on the temporary directory.  The result is passed to its result port and then to the output port of the workflow.",2, 0, ,
"http://www.myexperiment.org/workflows/1588/versions/1.html","Execute cmd line app - unix - /bin/ls of temporary directory","2010-10-2814:53:06","2010-10-2814:54:03","http://www.myexperiment.org/workflows/1588/download/Execute_cmd_line_app_-_unix_-__bin_ls_of_temporary_directory_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","Note that this workflow only works on Unix systems.  The get_temporary_directory beanshell returns the path to the directory in which temporary files are held.  This value is passed to the args port of the execute_cmd_line_app service.  The command port of that service has been defaulted to '/bin/ls'.  The execute_cmd_line_app service runs the /bin/ls command on the temporary directory.  The result is passed to its result port and then to the output port of the workflow.",2, 0, ,
"http://www.myexperiment.org/workflows/1589/versions/1.html","Get Environment Variables as XML","2010-10-2815:15:24","","http://www.myexperiment.org/workflows/1589/download/Get_Environment_Variables_as_XML-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The Get_Environment_Variables_as_XML service returns an XML file containing a set of property elements each of which contains the name and value of an environment variable. <hr /> The Get_Environment_Variables_as_XML service returns an XML file containing",0, 0, ,
"http://www.myexperiment.org/workflows/1590/versions/1.html","List files by extension - empty directory","2010-10-2815:17:35","","http://www.myexperiment.org/workflows/1590/download/List_files_by_extension_-_empty_directory-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory. The empty directory is examined by the List_files_by_extension service.  Since no files end in .png, an empty list is output.",2, 0, ,
"http://www.myexperiment.org/workflows/1591/versions/1.html","List files by extension - no matches","2010-10-2815:18:53","2010-10-2815:18:54","http://www.myexperiment.org/workflows/1591/download/List_files_by_extension_-_no_matches-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory. The populate_directory beanshell creates several files within the temporary directory. Once the directory has been populated, it is examined by the List_files_by_extension service.  Since no files end in .fred, an empty list is output.",1, 0, ,
"http://www.myexperiment.org/workflows/1593/versions/1.html","List files by extension - several matches","2010-10-2815:21:24","2010-10-2815:22:55","http://www.myexperiment.org/workflows/1593/download/List_files_by_extension_-_several_matches-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory.  The populate_directory beanshell creates several files within the temporary directory.  Once the directory has been populated, it is examined by the List_files_by_extension service and the file paths to the three files ending in &quot;.png&quot; are output.",1, 0, ,
"http://www.myexperiment.org/workflows/1594/versions/1.html","List files by extension - single match","2010-10-2815:24:19","2010-10-2815:24:20","http://www.myexperiment.org/workflows/1594/download/List_files_by_extension_-_single_match-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory. The populate_directory beanshell creates several files within the temporary directory. Once the directory has been populated, it is examined by the List_files_by_extension service and the file path to the one file ending in .bin is output.",1, 0, ,
"http://www.myexperiment.org/workflows/1595/versions/1.html","List files by regex - empty directory","2010-10-2815:29:22","2010-10-2815:29:23","http://www.myexperiment.org/workflows/1595/download/List_files_by_regex_-_empty_directory-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory. The empty directory is examined by the List_files_by_regex service.  Since there are no files, an empty list is output.",2, 0, ,
"http://www.myexperiment.org/workflows/1596/versions/1.html","List files by regex - no matches","2010-10-2815:30:54","","http://www.myexperiment.org/workflows/1596/download/List_files_by_regex_-_no_matches-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory. The populate_directory beanshell creates several files within the temporary directory. Once the directory has been populated, it is examined by the List_files_by_regex service.  Since no files match the regular expression 'x.*' i.e. no files have a name that starts with 'x', an empty list is output.",1, 0, ,
"http://www.myexperiment.org/workflows/1597/versions/1.html","List files by regex - several answers","2010-10-2815:32:39","","http://www.myexperiment.org/workflows/1597/download/List_files_by_regex_-_several_answers-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory. The populate_directory beanshell creates several files within the temporary directory. Once the directory has been populated, it is examined by the List_files_by_regex service and the file paths matching the regular expression '.*i.*', i.e. those containing an 'i', are output.",1, 0, ,
"http://www.myexperiment.org/workflows/1598/versions/1.html","List files by regex - single match","2010-10-2816:29:51","","http://www.myexperiment.org/workflows/1598/download/List_files_by_regex_-_single_match_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The create_temporary_directory beanshell creates a temporary directory and outputs the path to that directory. The populate_directory beanshell creates several files within the temporary directory. Once the directory has been populated, it is examined by the List_files_by_regex service and the file path to the one file matching 'c.*' i.e. starting with 'c' is output.",2, 0, ,
"http://www.myexperiment.org/workflows/1599/versions/1.html","Read text file - empty file","2010-10-2816:32:28","2010-10-2816:32:29","http://www.myexperiment.org/workflows/1599/download/Read_text_file_-_empty_file-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The beanshell creates an empty temporary file.  The filepath to the temporary file is then passed to the Read_text_file service which reads the file and outputs the empty string ''.",2, 0, ,
"http://www.myexperiment.org/workflows/1600/versions/1.html","Read text file","2010-10-2816:33:35","","http://www.myexperiment.org/workflows/1600/download/Read_text_file_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The beanshell write the string 'hello' to a temporary file.  The filepath to the temporary file is then passed to the Read_text_file service which reads the file and outputs the string 'hello'.",2, 0, ,
"http://www.myexperiment.org/workflows/1601/versions/1.html","Read text file - several lines","2010-10-2816:34:56","","http://www.myexperiment.org/workflows/1601/download/Read_text_file_-_several_lines-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The beanshell write the string 'hello' four times separated by a new lineto a temporary file.  The filepath to the temporary file is then passed to the Read_text_file service which reads the file and outputs the string 'hellohellohellohello'.",2, 0, ,
"http://www.myexperiment.org/workflows/1602/versions/1.html","Write text file - empty string value","2010-10-2816:40:28","","http://www.myexperiment.org/workflows/1602/download/Write_text_file_-_empty_string_value_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The beanshell creates an empty temporary file.  The filepath to the temporary file is then passed to the Write_text_file service which writes the empty string '' into the file.  '' is also output by the service.",2, 0, ,
"http://www.myexperiment.org/workflows/1603/versions/1.html","Write text file - overwriting content","2010-10-2816:45:04","","http://www.myexperiment.org/workflows/1603/download/Write_text_file_-_overwriting_content_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The beanshell creates an empty temporary file.  The filepath to the temporary file is then passed to the Write_text_file A service which writes the string 'hello' into the file.  After service A has run, service B writes 'goodbye' into the file.  The file is then read by the Read_Text_File service and its content, 'goodbye', output by the workflow.",2, 0, ,
"http://www.myexperiment.org/workflows/1604/versions/1.html","Write text file - specified value","2010-10-2816:46:31","","http://www.myexperiment.org/workflows/1604/download/Write_text_file_-_specified_value-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The beanshell creates an empty temporary file.  The filepath to the temporary file is then passed to the Write_text_file service which writes 'hello' into the file.  'hello' is also output by the service.",2, 0, ,
"http://www.myexperiment.org/workflows/1605/versions/1.html","Flatten list","2010-10-2816:51:27","2010-10-2816:56:42","http://www.myexperiment.org/workflows/1605/download/Flatten_list-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The flatten_list service takes the list [['a'], ['b'], ['c'], ['d']] and outputs the list ['a', 'b', 'c', 'd', 'e'].",1, 0, ,
"http://www.myexperiment.org/workflows/1606/versions/1.html","Merge string list to string - colon separator","2010-10-2817:12:43","","http://www.myexperiment.org/workflows/1606/download/Merge_string_list_to_string_-_colon_separator-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The merge string list to string service takes the list ['a','b','c'] and using the separator ':' outputs the string 'a:b:c'.",3, 0, ,
"http://www.myexperiment.org/workflows/1607/versions/1.html","Merge string list to a string - default separator","2010-10-2817:14:12","","http://www.myexperiment.org/workflows/1607/download/Merge_string_list_to_a_string_-_default_separator-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The merge string list to string service takes the list ['a','b','c'] and outputs the string 'abc'.",1, 0, ,
"http://www.myexperiment.org/workflows/1608/versions/1.html","Merge string list to string - empty list","2010-10-2817:15:43","","http://www.myexperiment.org/workflows/1608/download/Merge_string_list_to_string_-_empty_list-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The merge string list to string service takes an empty list [] and outputs an empty string ''.",2, 0, ,
"http://www.myexperiment.org/workflows/1610/versions/1.html","Remove duplicate strings - empty list","2010-10-2910:09:24","2010-10-2910:09:25","http://www.myexperiment.org/workflows/1610/download/Remove_duplicate_strings_-_empty_list-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The remove duplicate strings service takes the empty list [] and outputs the result [].",2, 0, ,
"http://www.myexperiment.org/workflows/1611/versions/1.html","Remove duplicate strings","2010-10-2910:10:37","","http://www.myexperiment.org/workflows/1611/download/Remove_duplicate_strings-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The remove duplicate strings service takes the list ['a','b','c','b','a','d'], strips out duplicate strings and outputs the result ['a','b','c','d'].",2, 0, ,
"http://www.myexperiment.org/workflows/1612/versions/1.html","Get image from URL - only url specified","2010-10-2910:13:23","","http://www.myexperiment.org/workflows/1612/download/Get_image_from_URL_-_only_url_specified-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","Retrieve the image at  <a href=http://www.mygrid.org.uk/files/2008/09/dragon-workflow.png rel=nofollow>http://www.mygrid.org.uk/files/2008/09/dragon-workflow.png</a>  using just the url parameter",2, 0, ,
"http://www.myexperiment.org/workflows/1613/versions/1.html","Get image from URL - url and base specified","2010-10-2910:15:17","2010-10-2910:15:18","http://www.myexperiment.org/workflows/1613/download/Get_image_from_URL_-_url_and_base_specified-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","Retrieve the image at  <a href=http://www.mygrid.org.uk/files/2008/09/dragon-workflow.png rel=nofollow>http://www.mygrid.org.uk/files/2008/09/dragon-workflow.png</a>  using both the url and base parameters",2, 0, ,
"http://www.myexperiment.org/workflows/1614/versions/1.html","Get image URLs from HTTP document - no images","2010-10-2910:18:37","2010-10-2910:19:21","http://www.myexperiment.org/workflows/1614/download/Get_image_URLs_from_HTTP_document_-_no_images-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","Retrieve the web page at  <a href=http://www.mygrid.org.uk/usermanual1.7/user_gettings_started.html rel=nofollow>http://www.mygrid.org.uk/usermanual1.7/user_gettings_started.html</a>  and examine it for images.  The workflow should return an empty list.",1, 0, ,
"http://www.myexperiment.org/workflows/1615/versions/1.html","Get image URLs from HTTP document and output the results","2010-10-2911:39:00","2014-02-1211:41:59","http://www.myexperiment.org/workflows/1615/download/Get_image_URLs_from_HTTP_document_and_output_the_results-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","Retrieve the web page at  <a href=http://www.mygrid.org.uk rel=nofollow>http://www.mygrid.org.uk</a> , examine it for images and output the images.",3, 0, ,
"http://www.myexperiment.org/workflows/1615/versions/2.html","Get image URLs from HTTP document and output the results","2010-10-2911:39:00","2014-02-1211:41:59","http://www.myexperiment.org/workflows/1615/download/Get_image_URLs_from_HTTP_document_and_output_the_results-v2.t2flow?version=2","/users/30","Alan Williams","taverna 2","","","Retrieve the web page at  <a href=http://www.mygrid.org.uk rel=nofollow>http://www.mygrid.org.uk</a> , examine it for images and output the images.",0, 0, ,
"http://www.myexperiment.org/workflows/1616/versions/1.html","Get web page from URL - just url","2010-10-2911:41:21","","http://www.myexperiment.org/workflows/1616/download/Get_web_page_from_URL_-_just_url_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","Fetches a web page from  <a href=http://www.mygrid.org.uk/tools rel=nofollow>http://www.mygrid.org.uk/tools</a>  using just the url parameter of the service.  Note that when viewed, the HTML may not be rendered correctly.  However, the HTML may be viewed by rendering the result as plain text.",2, 0, ,
"http://www.myexperiment.org/workflows/1617/versions/1.html","Get web page from URL - url and base","2010-10-2911:42:15","2010-10-2911:42:16","http://www.myexperiment.org/workflows/1617/download/Get_web_page_from_URL_-_url_and_base-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","Fetches a web page from  <a href=http://www.mygrid.org.uk/tools rel=nofollow>http://www.mygrid.org.uk/tools</a>  with the base parameter as http://www.mygrid.org.uk and the url as /tools.  Note that when viewed, the HTML may not be rendered correctly.  However, the HTML may be viewed by rendering the result as plain text.",2, 0, ,
"http://www.myexperiment.org/workflows/1618/versions/1.html","Always fails - no parameters","2010-10-2912:04:47","2010-10-2912:06:27","http://www.myexperiment.org/workflows/1618/download/Always_fails_-_no_parameters-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The always fails service generates a service failure when no parameter values are supplied.",1, 0, ,
"http://www.myexperiment.org/workflows/1619/versions/1.html","Always fails - one parameter","2010-10-2912:05:15","2010-10-2912:07:52","http://www.myexperiment.org/workflows/1619/download/Always_fails_-_one_parameter-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The always fails service generates a service failure when one parameter value is supplied.",1, 0, ,
"http://www.myexperiment.org/workflows/1620/versions/1.html","Always fails - two parameters","2010-10-2912:05:36","2010-10-2912:08:47","http://www.myexperiment.org/workflows/1620/download/Always_fails_-_two_parameters-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The always fails service generates a service failure when two parameter values are supplied.",1, 0, ,
"http://www.myexperiment.org/workflows/1621/versions/1.html","Echo_with_occasional_failure","2010-10-2912:32:38","2010-10-2912:33:42","http://www.myexperiment.org/workflows/1621/download/Echo_with_occasional_failure-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The Sometimes_Fails service mostly echoes the string 'hello' to the out port.  Sometimes, it throws a service failure.",1, 0, ,
"http://www.myexperiment.org/workflows/1622/versions/1.html","Byte Array to string - empty value","2010-10-2913:25:51","2010-10-2913:27:38","http://www.myexperiment.org/workflows/1622/download/Byte_Array_to_string_-_empty_value-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The beanshell converts the empty string '' to a byte array which is then converted back to the empty string '' by the Byte_Array_To_string service.",1, 0, ,
"http://www.myexperiment.org/workflows/1623/versions/1.html","Byte Array to string - non empty value","2010-10-2913:26:10","2010-10-2913:31:19","http://www.myexperiment.org/workflows/1623/download/Byte_Array_to_string_-_non_empty_value-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The beanshell converts the string 'hello' to a byte array which is then converted back to the string 'hello' by the Byte_Array_to_string service.",1, 0, ,
"http://www.myexperiment.org/workflows/1624/versions/1.html","Concatenate two strings - empty strings","2010-10-2913:36:45","2010-10-2913:36:46","http://www.myexperiment.org/workflows/1624/download/Concatenate_two_strings_-_empty_strings-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The concatenate two strings service takes two empty strings and returns an empty string.",2, 0, ,
"http://www.myexperiment.org/workflows/1625/versions/1.html","Concatenate two strings","2010-10-2913:37:41","","http://www.myexperiment.org/workflows/1625/download/Concatenate_two_strings-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The concatenate two strings service takes the strings 'good' and 'bye' and returns the result 'goodbye'.",2, 0, ,
"http://www.myexperiment.org/workflows/1626/versions/1.html","FIlter list of strings by regex with a suitable regular expression","2010-10-2913:44:14","","http://www.myexperiment.org/workflows/1626/download/FIlter_list_of_strings_by_regex_with_a_suitable_regular_expression-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The workflow filters the five element list split from the first service and returns the three elements that match the regular expression.",2, 0, ,
"http://www.myexperiment.org/workflows/1627/versions/1.html","FIlter list of strings by regex with an unsuitable regular expression","2010-10-2913:44:28","","http://www.myexperiment.org/workflows/1627/download/FIlter_list_of_strings_by_regex_with_an_unsuitable_regular_expression_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The workflow filters the five element list split from the first service and returns an empty list as no elements match.",2, 0, ,
"http://www.myexperiment.org/workflows/1628/versions/1.html","FIlter list of strings by regex extracting the specified subgroup in the matches","2010-10-2914:02:28","","http://www.myexperiment.org/workflows/1628/download/FIlter_list_of_strings_by_regex_extracting_the_specified_subgroup_in_the_matches-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The workflow examines the five element list split from the first service.  For each element, if it contains an 'a' followed by two characters, then the two characters after the 'a' are included in the output.  Thus, for the input  ['a','b','abcde','cdef','axy'], only 'abcde' and 'axy' contain a match and so ['bc', 'xy'] is output.",1, 0, ,
"http://www.myexperiment.org/workflows/1629/versions/1.html","FIlter list of strings by regex extracting the matches","2010-10-2914:02:47","","http://www.myexperiment.org/workflows/1629/download/FIlter_list_of_strings_by_regex_extracting_the_matches-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The workflow examines the five element list split from the first service.  For each element, if it contains an 'a' followed by two characters, then that triple is included in the output.  Thus, for the input  ['a','b','abcde','cdef','axy'], only 'abcde' and 'axy' contain a match and so ['abc', 'axy'] is output.",3, 0, ,
"http://www.myexperiment.org/workflows/1630/versions/1.html","Pad numeral with leading 0s - default targetlength","2010-10-2915:13:52","2010-10-2915:13:53","http://www.myexperiment.org/workflows/1630/download/Pad_numeral_with_leading_0s_-_default_targetlength_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The pad numeral with leading 0s takes the input '12' and pads it to the default target length of 7, yielding the output '0000012'.",2, 0, ,
"http://www.myexperiment.org/workflows/1631/versions/1.html","Pad numeral with leading 0s - specified targetlength","2010-10-2915:14:02","2010-10-2915:14:03","http://www.myexperiment.org/workflows/1631/download/Pad_numeral_with_leading_0s_-_specified_targetlength-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The pad numeral with leading 0s takes the input '12' and pads it to the specified target length of 4, yielding the output '0012'.",2, 0, ,
"http://www.myexperiment.org/workflows/1632/versions/1.html","Pad numeral with leading 0s - too short targetlength","2010-10-2915:14:17","","http://www.myexperiment.org/workflows/1632/download/Pad_numeral_with_leading_0s_-_too_short_targetlength_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The pad numeral with leading 0s takes the input '12' and because the specified target length of 1 is too short, yields the output '12'.",2, 0, ,
"http://www.myexperiment.org/workflows/1633/versions/1.html","Split string into string list by regular expression - default regex","2010-10-2915:24:51","","http://www.myexperiment.org/workflows/1633/download/Split_string_into_string_list_by_regular_expression_-_default_regex_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The split string into string list by regular expression takes the string 'a,b,c' and using the default regular expression ',' splits it into the list ['a','b','c']",2, 0, ,
"http://www.myexperiment.org/workflows/1634/versions/1.html","Split string into string list by regular expression - colon regex","2010-10-2915:25:04","","http://www.myexperiment.org/workflows/1634/download/Split_string_into_string_list_by_regular_expression_-_colon_regex_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The split string into string list by regular expression takes the string 'boo:and:foo' and using the specified regular expression ':' splits it into the list ['boo','and','foo']",2, 0, ,
"http://www.myexperiment.org/workflows/1635/versions/1.html","Split string into string list by regular expression - complicated regex","2010-10-2915:25:14","2010-10-2915:32:11","http://www.myexperiment.org/workflows/1635/download/Split_string_into_string_list_by_regular_expression_-_complicated_regex_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The split string into string list by regular expression takes the string 'boo:and:foo' and using the specified regular expression 'o' splits it into the list ['b','',':and:f']",3, 0, ,
"http://www.myexperiment.org/workflows/1635/versions/2.html","Split string into string list by regular expression - complicated regex","2010-10-2915:25:14","2010-10-2915:32:11","http://www.myexperiment.org/workflows/1635/download/Split_string_into_string_list_by_regular_expression_-_complicated_regex_-v2.t2flow?version=2","/users/30","Alan Williams","taverna 2","","","The split string into string list by regular expression takes the string 'boo:and:foo' and using the specified regular expression 'o.*n' splits it into the list ['b','d:foo']",3, 0, ,
"http://www.myexperiment.org/workflows/1636/versions/1.html","String list difference - yielding non-empty list","2010-10-2916:16:50","","http://www.myexperiment.org/workflows/1636/download/String_list_difference_-_yielding_non-empty_list_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The string list difference service takes in ['a','b','c'] and ['a','e','c'] and returns the  list ['b','e'].",2, 0, ,
"http://www.myexperiment.org/workflows/1637/versions/1.html","String list difference - yielding empty list","2010-10-2916:17:15","","http://www.myexperiment.org/workflows/1637/download/String_list_difference_-_yielding_empty_list-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The string list difference service takes in ['a','b','c'] and ['a','c','b'] and returns the  empty list [].",2, 0, ,
"http://www.myexperiment.org/workflows/1638/versions/1.html","String list intersection - yielding non empty list","2010-10-2916:21:03","","http://www.myexperiment.org/workflows/1638/download/String_list_intersection_-_yielding_non_empty_list-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The string list intersection service takes in ['a','b','c'] and ['a','e','c] and returns the list ['a','c'].",2, 0, ,
"http://www.myexperiment.org/workflows/1639/versions/1.html","String list intersection - yielding empty list","2010-10-2916:21:18","","http://www.myexperiment.org/workflows/1639/download/String_list_intersection_-_yielding_empty_list_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The string list intersection service takes in ['a','b','c'] and ['x','y','z'] and returns the empty list [].",2, 0, ,
"http://www.myexperiment.org/workflows/1640/versions/1.html","String list union - yielding non-empty list","2010-10-2916:28:07","","http://www.myexperiment.org/workflows/1640/download/String_list_union_-_yielding_non-empty_list-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The string list union service takes in ['a','b','c'] and ['a','e','c'] and returns a list equivalent to ['a','b','c','e'].",2, 0, ,
"http://www.myexperiment.org/workflows/1641/versions/1.html","String list union - yielding empty list","2010-10-2916:28:18","2010-10-2916:28:19","http://www.myexperiment.org/workflows/1641/download/String_list_union_-_yielding_empty_list_-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The string list union service takes in two empty lists [] and [] and returns an empty list [].",2, 0, ,
"http://www.myexperiment.org/workflows/1642/versions/1.html","Ask - no parameters","2010-10-2916:40:12","","http://www.myexperiment.org/workflows/1642/download/Ask_-_no_parameters-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The ask service displays a prompt with no title and no prompt message.  If the user presses cancel, then a service failure is generated.  If the user presses OK then their input, even if it is empty, is passed to the answer port of the ask service and so to the output of the workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/1643/versions/1.html","Ask - just message parameter","2010-10-2916:40:24","","http://www.myexperiment.org/workflows/1643/download/Ask_-_just_message_parameter-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The ask service displays a prompt with no title but with the prompt message 'Some message'.  If the user presses cancel, then a service failure is generated.  If the user presses OK then their input, even if it is empty, is passed to the answer port of the ask service and so to the output of the workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/1644/versions/1.html","Ask - just title parameter","2010-10-2916:40:35","2010-10-2916:40:36","http://www.myexperiment.org/workflows/1644/download/Ask_-_just_title_parameter-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The ask service displays a prompt with the title 'Some title' but no prompt message.  If the user presses cancel, then a service failure is generated.  If the user presses OK then their input, even if it is empty, is passed to the answer port of the ask service and so to the output of the workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/1645/versions/1.html","Ask - title and message parameters","2010-10-2916:40:48","","http://www.myexperiment.org/workflows/1645/download/Ask_-_title_and_message_parameters-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The ask service displays a prompt with 'Some title' and the prompt message 'Some message'.  If the user presses cancel, then a service failure is generated.  If the user presses OK then their input, even if it is empty, is passed to the answer port of the ask service and so to the output of the workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/1648/versions/1.html","Async WPS example","2010-11-0416:03:38","2011-04-2717:24:42","http://www.myexperiment.org/workflows/1648/download/Async_WPS_example-v1.t2flow?version=1","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","PyWPS supports async calls where normal WPS processes are split in to sync and ascyn. Async processes will return a statusURL where WPS will update the document while the process runs, When finished the statusURL will contain the result. <br /> <br /> A beanshell service is used to check the service until it has a result. Please check  <a href=http://pywps.wikispaces.com/Async+request rel=nofollow>http://pywps.wikispaces.com/Async+request</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/1648/versions/2.html","Async WPS example","2010-11-0416:03:38","2011-04-2717:24:42","http://www.myexperiment.org/workflows/1648/download/Async_WPS_example-v2.t2flow?version=2","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","Example on how to work with an async service, where the statusURL is used to check for  <hr /> Example on how to work with an async service, where the statusURL is used to check for if the process has finished or not",0, 0, ,
"http://www.myexperiment.org/workflows/1649/versions/1.html","retry-example","2010-11-0813:37:33","2010-11-0813:44:33","http://www.myexperiment.org/workflows/1649/download/retry-example-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/30,","Alan Williams,","This workflow executes a local beanshell script that has been programmed to fail on some iterations. It demonstrates the advantages of setting retries in your workflows to make them more robust",-1, 0, ,
"http://www.myexperiment.org/workflows/1651/versions/1.html","[untitled]","2010-11-1211:50:38","2010-11-1211:51:03","http://www.myexperiment.org/workflows/1651/download/_untitled_-v1.t2flow?version=1","/users/12558","Sukhdeep Singh","taverna 2","/users/12558,","Sukhdeep Singh,","A tutorial workflow of Taverna.",-1, 0, ,
"http://www.myexperiment.org/workflows/1652/versions/1.html","BiomartAndEMBOSSAnalysis","2010-11-1217:23:09","2010-11-1217:23:10","http://www.myexperiment.org/workflows/1652/download/BiomartAndEMBOSSAnalysis-v1.t2flow?version=1","/users/12553","Krisztina","taverna 2","/users/12553,","Krisztina,","Using Biomart and EMBOSS soaplab services, This workflow retrieves a number of sequences from 3 species: mouse, human, rat; align them, and returns a plot of the alignment result. Corresponding sequence ids are also returned.",0, 0, ,
"http://www.myexperiment.org/workflows/1653/versions/1.html","BiomartAndEMBOSSAnalysis","2010-11-1217:23:38","","http://www.myexperiment.org/workflows/1653/download/BiomartAndEMBOSSAnalysis-v1.t2flow?version=1","/users/12553","Krisztina","taverna 2","/users/12553,","Krisztina,","Using Biomart and EMBOSS soaplab services, This workflow retrieves a number of sequences from 3 species: mouse, human, rat; align them, and returns a plot of the alignment result. Corresponding sequence ids are also returned.",0, 0, ,
"http://www.myexperiment.org/workflows/1661/versions/1.html","Pathways and Gene annotations for QTL region","2010-11-1512:08:18","2010-11-1616:07:49","http://www.myexperiment.org/workflows/1661/download/Pathways_and_Gene_annotations_for_QTL_region-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in the mouse, Mus musculus. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",0, 0, ,
"http://www.myexperiment.org/workflows/1662/versions/1.html","Pathways and Gene annotations for RefSeq ids","2010-11-1512:25:01","2010-11-1512:28:12","http://www.myexperiment.org/workflows/1662/download/Pathways_and_Gene_annotations_for_RefSeq_ids-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow searches for genes which were found to be differentially expressed from a microarray study in the mouse, Mus musculus. The workflow requires an input of gene ref_seq identifiers. Data is then extracted from BioMart to annotate each of the genes found for each ref_seq id. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to search for pathways in the KEGG pathway database.",0, 0, ,
"http://www.myexperiment.org/workflows/1663/versions/1.html","KEGG pathways common to both QTL and microarray based investigations","2010-11-1512:30:21","2010-11-1512:30:59","http://www.myexperiment.org/workflows/1663/download/KEGG_pathways_common_to_both_QTL_and_microarray_based_investigations-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in two lists of KEGG pathway ids. These are designed to come from pathways found from genes in a QTL (Quantitative Trait Loci) region, and from pathways found from genes differentially expressed in a microarray study. By identifying the intersecting pathways from both studies, a more informative picture is obtained of the candidate processes involved in the expression of a phenotype",0, 0, ,
"http://www.myexperiment.org/workflows/1670/versions/1.html","A Basic example R workflow","2010-11-2615:13:46","2014-08-2014:57:51","http://www.myexperiment.org/workflows/1670/download/A_Basic_example_R_workflow-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow uses an R service running on localhost to calculate sin(0.45)",0, 0, ,
"http://www.myexperiment.org/workflows/1670/versions/2.html","A Basic example R workflow","2010-11-2615:13:46","2014-08-2014:57:51","http://www.myexperiment.org/workflows/1670/download/A_Basic_example_R_workflow-v2.t2flow?version=2","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow uses an R service running on localhost to calculate sin(0.45)",0, 0, ,
"http://www.myexperiment.org/workflows/1670/versions/3.html","A Basic example R workflow","2010-11-2615:13:46","2014-08-2014:57:51","http://www.myexperiment.org/workflows/1670/download/A_Basic_example_R_workflow-v3.t2flow?version=3","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow uses an R service running on localhost to calculate sin(0.45)",0, 0, ,
"http://www.myexperiment.org/workflows/1671/versions/1.html","R logical workflow","2010-11-2615:44:15","2010-11-2615:44:18","http://www.myexperiment.org/workflows/1671/download/R_logical_workflow-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","Checks what the logical_input is in R.  For an logical_input ofTRUE - is_false should be FALSE and is_true TRUEFALSE - is_false should be TRUE and is_true FALSE For any other input values, is_false and is_true should both be NA",1, 0, ,
"http://www.myexperiment.org/workflows/1672/versions/1.html","R numeric workflow","2010-11-2616:17:23","","http://www.myexperiment.org/workflows/1672/download/R_numeric_workflow-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow uses an Rshell service to calculate the square of a numeric input <hr /> This workflow uses an",0, 0, ,
"http://www.myexperiment.org/workflows/1675/versions/1.html","R string workflow","2010-11-2616:47:02","2010-11-2616:47:04","http://www.myexperiment.org/workflows/1675/download/R_string_workflow-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow determines the lower case version of the input string.",0, 0, ,
"http://www.myexperiment.org/workflows/1676/versions/1.html","R logical vector workflow","2010-11-2617:06:00","2010-11-2617:06:03","http://www.myexperiment.org/workflows/1676/download/R_logical_vector_workflow-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","The workflow returns a list containing the logical inversion of the logical vector input",0, 0, ,
"http://www.myexperiment.org/workflows/1679/versions/1.html","R integer vector example","2010-11-2617:34:05","2010-11-2617:34:08","http://www.myexperiment.org/workflows/1679/download/R_integer_vector_example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow takes a list of integer values and returns a list containing the square of the input list's elements, and the sum of the input list's elements.",0, 0, ,
"http://www.myexperiment.org/workflows/1680/versions/1.html","R string vector example","2010-11-2618:06:35","2010-11-2618:06:37","http://www.myexperiment.org/workflows/1680/download/R_string_vector_example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","The workflow takes a list of strings and outputs a list contains the lower-cased versions of the input elements, and also a concatenation of the input elements",0, 0, ,
"http://www.myexperiment.org/workflows/1682/versions/1.html","R integer workflow","2010-11-2910:03:22","","http://www.myexperiment.org/workflows/1682/download/R_integer_workflow-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow uses an Rshell service to calculate 100 modulus the integer input",0, 0, ,
"http://www.myexperiment.org/workflows/1683/versions/1.html","R integer vector example","2010-11-2910:15:37","2010-11-2910:15:40","http://www.myexperiment.org/workflows/1683/download/R_integer_vector_example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow takes a list of integer values and returns a list containing 100 modulus the list's elements, and the sum of the input list's elements.",0, 0, ,
"http://www.myexperiment.org/workflows/1684/versions/1.html","Transform XML with parameters","2010-11-2911:45:52","2010-11-2911:53:46","http://www.myexperiment.org/workflows/1684/download/Transform_XML_with_parameters-v1.xml?version=1","/users/6843","trybik","taverna 1","/users/6843,","trybik,","Similar to Transform_XML local widget but accepts transformation parameters and skips the part with writing to the output file. The essence, i.e. Transform_XML beanshell works with Strings representing file contents, not with file URLs. The XML transfomation parameters are given as a list of strings in the &quot;param_name = param_value&quot; format.",3, 0, Transform_XML, Read_xslFile, Read_inFile, ,
"http://www.myexperiment.org/workflows/1685/versions/1.html","R PNG-value example","2010-11-2912:40:12","2010-11-2913:13:11","http://www.myexperiment.org/workflows/1685/download/R_PNG-value_example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow produces a PNG plot on the  <hr /> This workflow produces a PNG plot on the figure port.",0, 0, ,
"http://www.myexperiment.org/workflows/1685/versions/2.html","R PNG-value example","2010-11-2912:40:12","2010-11-2913:13:11","http://www.myexperiment.org/workflows/1685/download/R_PNG-value_example-v2.t2flow?version=2","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow produces a PNG plot on the figure port.",0, 0, ,
"http://www.myexperiment.org/workflows/1686/versions/1.html","R Text-file example","2010-11-2913:18:04","2010-11-2913:18:05","http://www.myexperiment.org/workflows/1686/download/R_Text-file_example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow contains two services.  The file_writer uses a File in R to output a string.  The file_reader uses a File in R to input a string, the contents of which are output.",0, 0, ,
"http://www.myexperiment.org/workflows/1687/versions/1.html","R generic example","2010-11-2913:43:11","","http://www.myexperiment.org/workflows/1687/download/R_generic_example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow shows how string vectors can be used to transfer a complex R object (in this case a matrix) between Rshell services",0, 0, ,
"http://www.myexperiment.org/workflows/1688/versions/1.html","NCBI BLAST (SOAP)","2010-11-2920:03:13","2013-03-2812:44:56","http://www.myexperiment.org/workflows/1688/download/NCBI_BLAST__SOAP_-v1.t2flow?version=1","/users/925","Hamish McWilliam","taverna 2","","",,0, 0, ,
"http://www.myexperiment.org/workflows/1689/versions/1.html","NCBI BLAST (SOAP)","2010-11-2920:46:58","2013-03-2812:45:26","http://www.myexperiment.org/workflows/1689/download/NCBI_BLAST__SOAP_-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,",,9, 2, run, parametersXML, parametersXML1, parametersXML2, getResult, parametersXML3, parametersXML4, Job_status_poll, Byte___to_String, ,
"http://www.myexperiment.org/workflows/1694/versions/1.html","Phylogenetic Tree","2010-11-3019:46:01","2010-11-3019:47:48","http://www.myexperiment.org/workflows/1694/download/Phylogenetic_Tree-v1.t2flow?version=1","/users/7035","Caiocb","taverna 2","/users/7035,","Caiocb,","Workflow compose by 2 services that goal buid a Phylogenetic Tree using ClusltalW and Phylip services.",-1, 0, ,
"http://www.myexperiment.org/workflows/1696/versions/1.html","InterProScan (SOAP)","2010-12-0307:41:47","2013-03-2812:45:59","http://www.myexperiment.org/workflows/1696/download/InterProScan__SOAP_-v1.t2flow?version=1","/users/925","Hamish McWilliam","taverna 2","","",,0, 0, ,
"http://www.myexperiment.org/workflows/1697/versions/1.html","InterProScan (SOAP)","2010-12-0308:20:21","2013-03-2812:46:15","http://www.myexperiment.org/workflows/1697/download/InterProScan__SOAP_-v1.xml?version=1","/users/925","Hamish McWilliam","taverna 1","/users/925,","Hamish McWilliam,",,13, 3, run, parametersXML, parametersXML1, parametersXML2, getResult, parametersXML3, parametersXML4, Byte___to_String, Byte___to_String1, getResult1, parametersXML5, parametersXML6, Job_status, ,
"http://www.myexperiment.org/workflows/1698/versions/1.html","HTTP Basic authentication example workflow","2010-12-0314:24:10","2010-12-0314:53:44","http://www.myexperiment.org/workflows/1698/download/HTTP_Basic_authentication_example_workflow-v1.t2flow?version=1","/users/666","Alex Nenadic","taverna 2","/users/666,","Alex Nenadic,","This workflow shows an example access to a resource protected by HTTP Basic authentication. Use testuser/testpasswd whenever prompted  for username and password. Check  <a href=http://www.mygrid.org.uk/dev/wiki/display/story/Taverna+2.x+test+secure+services+and+workflows rel=nofollow>http://www.mygrid.org.uk/dev/wiki/display/story/Taverna+2.x+test+secure+services+and+workflows</a>  for more details about the secure services used in the workflow.",-1, 0, ,
"http://www.myexperiment.org/workflows/1699/versions/1.html","HTTP Basic authentication + HTTPS example workflow","2010-12-0314:31:20","2010-12-0314:53:19","http://www.myexperiment.org/workflows/1699/download/HTTP_Basic_authentication___HTTPS_example_workflow-v1.t2flow?version=1","/users/666","Alex Nenadic","taverna 2","/users/666,","Alex Nenadic,","This workflow shows an example access to a resource protected by HTTP  Basic authentication and HTTPS. Use testuser/testpasswd whenever prompted  for username and password. Check  <a href=http://www.mygrid.org.uk/dev/wiki/display/story/Taverna+2.x+test+secure+services+and+workflows rel=nofollow>http://www.mygrid.org.uk/dev/wiki/display/story/Taverna+2.x+test+secure+services+and+workflows</a>  for more details about the secure services used in the workflow.",-1, 0, ,
"http://www.myexperiment.org/workflows/1700/versions/1.html","HTTP Digest authentication example workflow","2010-12-0314:34:07","2010-12-0314:52:49","http://www.myexperiment.org/workflows/1700/download/HTTP_Digest_authentication_example_workflow-v1.t2flow?version=1","/users/666","Alex Nenadic","taverna 2","/users/666,","Alex Nenadic,","This workflow shows an example access to a resource protected by HTTP Digest&nbsp; authentication. Use testuser/testpasswd whenever prompted  for username and password. Check  <a href=http://www.mygrid.org.uk/dev/wiki/display/story/Taverna+2.x+test+secure+services+and+workflows rel=nofollow>http://www.mygrid.org.uk/dev/wiki/display/story/Taverna+2.x+test+secure+services+and+workflows</a>  for more details about the secure services used in the workflow. &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/1701/versions/1.html","HTTP Digest authentication + HTTPS example workflow","2010-12-0314:35:38","2010-12-0314:52:25","http://www.myexperiment.org/workflows/1701/download/HTTP_Digest_authentication___HTTPS_example_workflow-v1.t2flow?version=1","/users/666","Alex Nenadic","taverna 2","/users/666,","Alex Nenadic,","This workflow shows an example access to a resource protected by HTTP  Digest&nbsp; authentication and HTTPS. Use testuser/testpasswd whenever prompted  for username and password. Check  <a href=http://www.mygrid.org.uk/dev/wiki/display/story/Taverna+2.x+test+secure+services+and+workflows rel=nofollow>http://www.mygrid.org.uk/dev/wiki/display/story/Taverna+2.x+test+secure+services+and+workflows</a>  for more details about the secure services used in the workflow.",-1, 0, ,
"http://www.myexperiment.org/workflows/1702/versions/1.html","WS-Security example workflow","2010-12-0314:40:28","2010-12-0314:50:41","http://www.myexperiment.org/workflows/1702/download/WS-Security_example_workflow_-v1.t2flow?version=1","/users/666","Alex Nenadic","taverna 2","/users/666,","Alex Nenadic,","This workflow shows an example access to various secure Web services protected by WS-Security authentication. Use testuser/testpasswd whenever prompted  for username and password. Check  <a href=http://www.mygrid.org.uk/dev/wiki/display/story/Taverna+2.x+test+secure+services+and+workflows rel=nofollow>http://www.mygrid.org.uk/dev/wiki/display/story/Taverna+2.x+test+secure+services+and+workflows</a>  for more details about the secure services used in the workflow.",-1, 0, ,
"http://www.myexperiment.org/workflows/1703/versions/1.html","WS-Security + HTTPS example workflow","2010-12-0314:47:47","2010-12-0314:50:24","http://www.myexperiment.org/workflows/1703/download/WS-Security___HTTPS_example_workflow_-v1.t2flow?version=1","/users/666","Alex Nenadic","taverna 2","/users/666,","Alex Nenadic,","This workflow shows an example access to various secure Web services  protected by WS-Security authentication. Use testuser/testpasswd  whenever prompted  for username and password. Check  <a href=http://www.mygrid.org.uk/dev/wiki/display/story/Taverna+2.x+test+secure+services+and+workflows rel=nofollow>http://www.mygrid.org.uk/dev/wiki/display/story/Taverna+2.x+test+secure+services+and+workflows</a>  for more details about the secure services used in the workflow.",-1, 0, ,
"http://www.myexperiment.org/workflows/1705/versions/1.html","EMBL-EBI ClustalW2 (SOAP)","2010-12-0613:16:52","2013-03-2812:46:34","http://www.myexperiment.org/workflows/1705/download/EMBL-EBI_ClustalW2__SOAP_-v1.t2flow?version=1","/users/925","Hamish McWilliam","taverna 2","","",,0, 0, ,
"http://www.myexperiment.org/workflows/1709/versions/1.html","Cosine vector space","2010-12-0811:35:18","2011-01-1112:05:41","http://www.myexperiment.org/workflows/1709/download/Cosine_vector_space-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow calculates the cosine vector space between two sets of  corpora. The workflow then removes any null values from the output. The result is a cosine vector score between 0 and 1, showing the  significance of any links between one concept (e.g. pathway) to another  (e.g. phenotype). A score of 0 means there is no or an undetermined correlation between  the two concepts. A score approaching 1 represents positive correlation.",0, 0, ,
"http://www.myexperiment.org/workflows/1709/versions/2.html","Cosine vector space","2010-12-0811:35:18","2011-01-1112:05:41","http://www.myexperiment.org/workflows/1709/download/Cosine_vector_space-v2.t2flow?version=2","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow calculates the cosine vector space between two sets of corpora. The workflow then removes any null values from the output. this is some extra text vbeing added",0, 0, ,
"http://www.myexperiment.org/workflows/1710/versions/1.html","Rank Phenotype Terms","2010-12-0811:38:37","2011-01-1112:02:30","http://www.myexperiment.org/workflows/1710/download/Rank_Phenotype_Terms-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow counts the number of articles in the pubmed database in  which each term occurs, and identifies the total number of articles in  the entire PubMed database. It also identified the total number of  articles within pubmed so that a term enrichment score may be  calculated. The workflow also takes in a document containing abstracts that are  related to a particular phenotype. Scientiifc terms are then extracted  from this text and given a weighting according to the number of terms  that appear in the document.  The higher the value the better the score.   This is given as: X = log((a / b) / (c / d)) where:	a = number of occurnaces of individual terms in phenotype corpus  	b = number of abstracts in entire phenotype corpus 	c = number of occurnaces of individual terms in entire pubmed 	d = number of articles in entire pubmed Once this has been created, the pathways obtained from the QTL and  microarray pathway analysis workflows are analysed. The documents from a  search of each pathway in pubmed are merged into a single document of  pathway abstracts. The (unweighted) phenotype terms are then searched in  the pathways corpus. This will determine if the phenotype term is  listed with the given pathway.  The higher the value the better the  score. Each term is then assigned a weight as: Y = log((e / f) / (c /d)) where:	a = number of occurnaces of individual terms in pathway corpus  	b = number of abstracts in pathway corpus (per pathway) 	c = number of occurnaces of individual terms in entire pubmed 	d = number of articles in entire pubmed The weighted terms are then given a link score. This is the total of: X +  Y. This gives the link between the pathway and the phenotype a score /  significance value. The higher the score the more  &quot;appropriate/interesting&quot; the link between the pathway and the  phenotype. The terms are also ranked according to the number of pathways which have  been given a weight. This is calculated as: W = Sum( X + Y). The higher  the value the better the score.",0, 0, ,
"http://www.myexperiment.org/workflows/1710/versions/2.html","Rank Phenotype Terms","2010-12-0811:38:37","2011-01-1112:02:30","http://www.myexperiment.org/workflows/1710/download/Rank_Phenotype_Terms-v2.t2flow?version=2","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow counts the number of articles in the pubmed database in which each term occurs, and identifies the total number of articles in the entire PubMed database. It also identified the total number of articles within pubmed so that a term enrichment score may be calculated.  The workflow also takes in a document containing abstracts that are related to a particular phenotype. Scientiifc terms are then extracted from this text and given a weighting according to the number of terms that appear in the document.  The higher the value the better the score.  This is given as: X = log((a / b) / (c / d))  where:	a = number of occurnaces of individual terms in phenotype corpus  	b = number of abstracts in entire phenotype corpus 	c = number of occurnaces of individual terms in entire pubmed 	d = number of articles in entire pubmed  Once this has been created, the pathways obtained from the QTL and microarray pathway analysis workflows are analysed. The documents from a search of each pathway in pubmed are merged into a single document of pathway abstracts. The (unweighted) phenotype terms are then searched in the pathways corpus. This will determine if the phenotype term is listed with the given pathway.  The higher the value the better the score. Each term is then assigned a weight as: Y = log((e / f) / (c /d))  where:	a = number of occurnaces of individual terms in pathway corpus  	b = number of abstracts in pathway corpus (per pathway) 	c = number of occurnaces of individual terms in entire pubmed 	d = number of articles in entire pubmed  The weighted terms are then given a link score. This is the total of: X + Y. This gives the link between the pathway and the phenotype a score / significance value. The higher the score the more &quot;appropriate/interesting&quot; the link between the pathway and the phenotype.  The terms are also ranked according to the number of pathways which have been given a weight. This is calculated as: W = Sum( X + Y). The higher the value the better the score.",0, 0, ,
"http://www.myexperiment.org/workflows/1711/versions/1.html","Pathway to Pubmed","2010-12-0811:47:10","2011-01-1112:00:16","http://www.myexperiment.org/workflows/1711/download/Pathway_to_Pubmed-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a list of KEGG pathway descriptions and searches the PubMed database for corresponding articles. Any matches to the pathways are then retrieved (abstracts only). These abstracts are then returned to the user.",0, 0, ,
"http://www.myexperiment.org/workflows/1711/versions/2.html","Pathway to Pubmed","2010-12-0811:47:10","2011-01-1112:00:16","http://www.myexperiment.org/workflows/1711/download/Pathway_to_Pubmed-v2.t2flow?version=2","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a list of KEGG pathway descriptions and searches the PubMed database for corresponding articles. Any matches to the pathways are then retrieved (abstracts only). These abstracts are then returned to the user.",0, 0, ,
"http://www.myexperiment.org/workflows/1712/versions/1.html","Extract Scientific Terms","2010-12-0811:50:01","2011-01-1111:58:09","http://www.myexperiment.org/workflows/1712/download/Extract_Scientific_Terms-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a document containg text and removes any  non-ascii characters. The cleaned text is then sent to a service in  Dresden, to extract all scientific terms. These terms represent a  concept profile for the input concpet. Any null values are also removed.",0, 0, ,
"http://www.myexperiment.org/workflows/1712/versions/2.html","Extract Scientific Terms","2010-12-0811:50:01","2011-01-1111:58:09","http://www.myexperiment.org/workflows/1712/download/Extract_Scientific_Terms-v2.t2flow?version=2","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a document containg text and removes and non-ascii characters. The cleaned text is then sent to a service in dresden to extract all scientific terms. These terms represent a profile for the input document. Any null values are also removed.",0, 0, ,
"http://www.myexperiment.org/workflows/1719/versions/1.html","Merge QSAR descriptor CSV files","2010-12-0909:06:39","2011-07-2118:23:06","http://www.myexperiment.org/workflows/1719/download/Merge_QSAR_descriptor_CSV_files-v1.t2flow?version=1","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow merges QSAR descriptor CSV files into a single CSV file. Therefor it loads the CSV files from hard disk and builds a single QSAR descriptor vector. Afterwards the vector is converted in a one single CSV file and saved to hard disk.",-1, 0, ,
"http://www.myexperiment.org/workflows/1719/versions/2.html","Merge QSAR descriptor CSV files","2010-12-0909:06:39","2011-07-2118:23:06","http://www.myexperiment.org/workflows/1719/download/Merge_QSAR_descriptor_CSV_files-v2.t2flow?version=2","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow merges QSAR descriptor CSV files into a single CSV file. Therefor it loads the CSV files from hard disk and builds a single QSAR descriptor vector. Afterwards the vector is converted in a one single CSV file and saved to hard disk.",-1, 0, ,
"http://www.myexperiment.org/workflows/1719/versions/3.html","Merge QSAR descriptor CSV files","2010-12-0909:06:39","2011-07-2118:23:06","http://www.myexperiment.org/workflows/1719/download/Merge_QSAR_descriptor_CSV_files-v3.t2flow?version=3","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow merges QSAR descriptor CSV files into a single CSV file. The workflow loads the CSV files from hard disk and builds a single QSAR descriptor vector. Afterwards the vector is converted in one single CSV file and saved to hard disk.",-1, 0, ,
"http://www.myexperiment.org/workflows/1720/versions/1.html","Curate QSAR descriptor CSV file","2010-12-0910:17:53","2011-07-2118:25:11","http://www.myexperiment.org/workflows/1720/download/Curate_QSAR_descriptor_CSV_file-v1.t2flow?version=1","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow erases descriptor entries which were not calculated. Therefor the CSF files are loaded and afterwards processed. At the end the curated CSV file is written to hard disk. The curation method can be chosen in the curation activity.",-1, 0, ,
"http://www.myexperiment.org/workflows/1720/versions/2.html","Curate QSAR descriptor CSV file","2010-12-0910:17:53","2011-07-2118:25:11","http://www.myexperiment.org/workflows/1720/download/Curate_QSAR_descriptor_CSV_file-v2.t2flow?version=2","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow erases descriptor entries which were not calculated. The QSAR data is loaded from a CSV file and afterwards processed by the Curate_QSAR_Vector worker. At the end the curated CSV file is written to hard disk.",-1, 0, ,
"http://www.myexperiment.org/workflows/1721/versions/1.html","ART-2a Classification Result As PDF","2010-12-0913:48:19","2011-07-2118:26:26","http://www.myexperiment.org/workflows/1721/download/ART-2a_Classification_Result_As_PDF-v1.t2flow?version=1","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow classifies a given CSV file with the ART-2a algorithm. The results are visualized in a PDF file. Therefor the CSV is loaded from hard disk and converted into a fingerprint items list which is the suitable data type for the ART-2a algorithm.",-1, 0, ,
"http://www.myexperiment.org/workflows/1721/versions/2.html","ART-2a Classification Result As PDF","2010-12-0913:48:19","2011-07-2118:26:26","http://www.myexperiment.org/workflows/1721/download/ART-2a_Classification_Result_As_PDF-v2.t2flow?version=2","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow classifies a given CSV file with the ART-2a algorithm. The results are visualized in a PDF file. The QSAR data is loaded from a CSV file and converted into a fingerprint items list which is the suitable data type for the ART-2a algorithm.",-1, 0, ,
"http://www.myexperiment.org/workflows/1725/versions/1.html","ART-2a Classification Considering Different Origins Result As PDF","2010-12-1313:52:45","2011-07-2118:27:33","http://www.myexperiment.org/workflows/1725/download/ART-2a_Classification_Considering_Different_Origins_Result_As_PDF-v1.t2flow?version=1","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow classifies the given CSV files with the ART-2a algorithm. The results are visualized in a PDF file. Therefor the CSV files are loaded from hard disk and merged together. Afterwards they are converted into a fingerprint items list which is the suitable data type for the ART-2a algorithm.",-1, 0, ,
"http://www.myexperiment.org/workflows/1725/versions/2.html","ART-2a Classification Considering Different Origins Result As PDF","2010-12-1313:52:45","2011-07-2118:27:33","http://www.myexperiment.org/workflows/1725/download/ART-2a_Classification_Considering_Different_Origins_Result_As_PDF-v2.t2flow?version=2","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow classifies the given CSV files with the ART-2a algorithm. The results are visualized in a PDF file. The QSAR dara is loaded from CSV files and merged together by the Merge_QSAR_Vectors worker. Afterwards they are converted into a fingerprint items list which is the suitable data type for the ART-2a algorithm.",-1, 0, ,
"http://www.myexperiment.org/workflows/1726/versions/1.html","Biomart and Blast","2010-12-1314:41:12","2010-12-1315:15:45","http://www.myexperiment.org/workflows/1726/download/Biomart_and_Blast-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","","","Perform Rodent BLAST sequence alignments (using  <a href=http://www.biocatalogue.org/soap_operations/34 rel=nofollow>DDBJ Blast</a> ) on the gene sequences for a (semi-random) selection of genes from Human sapiens chromosome 22. (Using Biomart) Referenced in the  <a href=http://taverna.knowledgeblog.org/2010/12/13/iteration-in-taverna-workflows/ rel=nofollow>Taverna knowledge blog</a> .",3, 0, ,
"http://www.myexperiment.org/workflows/1727/versions/1.html","Biomart and Blast with concatinated gene id","2010-12-1314:41:39","2010-12-1314:47:55","http://www.myexperiment.org/workflows/1727/download/Biomart_and_Blast_with_concatinated_gene_id-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","","","Perform Rodent BLAST sequence alignments (using  <a href=http://www.biocatalogue.org/soap_operations/34 rel=nofollow>DDBJ Blast</a> ) on the gene sequences for a (semi-random) selection of genes from Human sapiens chromosome 22. (Using Biomart).  Finally (to showcase  <a href=http://www.mygrid.org.uk/dev/wiki/display/taverna/Implicit+iteration#Implicititeration-Pipelining rel=nofollow>Taverna pipelining</a> ) - the Ensembl gene ID is added as a prefix on the BLAST report. Referenced in the  <a href=http://taverna.knowledgeblog.org/2010/12/13/iteration-in-taverna-workflows/ rel=nofollow>Taverna knowledge blog</a> .",3, 0, ,
"http://www.myexperiment.org/workflows/1730/versions/1.html","Biomart and 2x BLAST","2010-12-1317:11:54","2010-12-1317:11:55","http://www.myexperiment.org/workflows/1730/download/Biomart_and_2x_BLAST-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","","","Perform Roden and Invertebrates BLAST sequence alignments (using DDBJ Blast) on the gene sequences for a (semi-random) selection of genes from Human sapiens chromosome 22. (Using Biomart). blast_ddbj_invertebrates and blast_ddbj_rodents should execute in parallel as they don't depend on each other.",4, 0, ,
"http://www.myexperiment.org/workflows/1733/versions/1.html","Compound Library Screen For Reaction Enumeration","2010-12-1408:52:39","2011-07-2118:29:18","http://www.myexperiment.org/workflows/1733/download/Compound_Library_Screen_For_Reaction_Enumeration-v1.t2flow?version=1","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow performs a compound library screen for molecules which match the given template reaction. Therefor it loads a RXN file and splits it into its reactants. The compound library is loaded iteratively from a SD file. Afterwards a substructure search is performed and the results are saved as SD files.",-1, 0, ,
"http://www.myexperiment.org/workflows/1733/versions/2.html","Compound Library Screen For Reaction Enumeration","2010-12-1408:52:39","2011-07-2118:29:18","http://www.myexperiment.org/workflows/1733/download/Compound_Library_Screen_For_Reaction_Enumeration-v2.t2flow?version=2","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow performs a compound library screen for molecules which match the given template reaction. The reaction is loaded from a RXN file and the Reaction_Reactant_Splitter splits the reaction into its reactants. The compound library is loaded iteratively from a SD file. Afterwards a substructure search is performed for each reactant and the results are saved as SD files.",-1, 0, ,
"http://www.myexperiment.org/workflows/1735/versions/1.html","Get Molecular Weight Distribution From QSAR Vector","2010-12-1516:07:59","2011-07-2118:32:16","http://www.myexperiment.org/workflows/1735/download/Get_Molecular_Weight_Distribution_From_QSAR_Vector-v1.t2flow?version=1","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow calculates a molecular weight distribution from given QSAR vector. Therefor it reads a CSV from hard disk and converts it into a QSAR vector. Finally the molecular weight distribution is written to hard disk as a CSV file.",-1, 0, ,
"http://www.myexperiment.org/workflows/1735/versions/2.html","Get Molecular Weight Distribution From QSAR Vector","2010-12-1516:07:59","2011-07-2118:32:16","http://www.myexperiment.org/workflows/1735/download/Get_Molecular_Weight_Distribution_From_QSAR_Vector-v2.t2flow?version=2","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow calculates a molecular weight distribution from given QSAR vector. The QSAR data containing the molecular weight values is read from a CSV file and converted into a QSAR vector. Finally, the Get_molecular_Weight_Distribution_From_QSAR_vector extracts the weight data and saves it as CSV files.",-1, 0, ,
"http://www.myexperiment.org/workflows/1738/versions/1.html","Lemmatization","2010-12-1711:34:27","2010-12-2314:28:56","http://www.myexperiment.org/workflows/1738/download/Lemmatization-v1.t2flow?version=1","/users/13255","Petra Kralj Novak","taverna 2","/users/13255,","Petra Kralj Novak,","&nbsp;The workflow lemmatizes the text in the input port. The service asks for the language of lemmatization. Currently 12 languages are supported: en,sl,ge,bg,cs,et,fr,hu,ro,sr,it,sp.",-1, 0, ,
"http://www.myexperiment.org/workflows/1738/versions/2.html","Lemmatization","2010-12-1711:34:27","2010-12-2314:28:56","http://www.myexperiment.org/workflows/1738/download/Lemmatization-v2.t2flow?version=2","/users/13255","Petra Kralj Novak","taverna 2","/users/13255,","Petra Kralj Novak,","The workflow lemmatizes the text in the input port. <br /> <br /> Takes text as input and returns (language dependent) lemmatized text as output. All the words in the resulting text are in the same order as in the original text, but they are transformed to their dictionary form. <br /> <br /> The workflow asks for the language of lemmatization. Currently, 12 languages are supported: en,sl,ge,bg,cs,et,fr,hu,ro,sr,it,sp.",-1, 0, ,
"http://www.myexperiment.org/workflows/1738/versions/3.html","Lemmatization","2010-12-1711:34:27","2010-12-2314:28:56","http://www.myexperiment.org/workflows/1738/download/Lemmatization-v3.t2flow?version=3","/users/13255","Petra Kralj Novak","taverna 2","/users/13255,","Petra Kralj Novak,","The workflow lemmatizes the text in the input port. <br /> <br /> Takes text as input and returns (language dependent) lemmatized text as output. All the words in the resulting text are in the same order as in the original text, but they are transformed to their dictionary form. <br /> <br /> The workflow asks for the language of lemmatization. Currently, 12 languages are supported: en,sl,ge,bg,cs,et,fr,hu,ro,sr,it,sp.",-1, 0, ,
"http://www.myexperiment.org/workflows/1743/versions/1.html","Select from a list of possible web service parameter values","2010-12-2312:54:48","2010-12-2312:57:45","http://www.myexperiment.org/workflows/1743/download/Select_from_a_list_of_possible_web_service_parameter_values-v1.t2flow?version=1","/users/13255","Petra Kralj Novak","taverna 2","/users/13255, /users/13368,","Petra Kralj Novak, Janez Kranjc,","The workflow for selecting from a list of possible web service parameter values has two input ports: the wsdl address of the web service and the variable name. It parses the web service wsdl description (the web service  <a href=http://ropot.ijs.si/webservices/janez/getvalues.php?wsdl rel=nofollow>http://ropot.ijs.si/webservices/janez/getvalues.php?wsdl</a>  does that) and then it asks the user to select one value from a drop-down menu. This workflow is very useful when web services have inputs which expect as a parameter one value from a list of possible values.",-1, 0, ,
"http://www.myexperiment.org/workflows/1750/versions/1.html","Text preprocessing","2011-01-0716:13:58","2011-01-0716:17:13","http://www.myexperiment.org/workflows/1750/download/Text_preprocessing-v1.t2flow?version=1","/users/13255","Petra Kralj Novak","taverna 2","/users/13255,","Petra Kralj Novak,","The input to this workflow is plain text. The text is preprocessed so that non- alfanumeric symbols are removed, the text is transformed to to lower case and stop words are removed. The workflow first removes the charachters from this set: `~!@#$%^&amp;*()_+=-{}|\][&quot;:;'?&gt;&lt;,./. Then it transforms the text to lower case. The user will be prompted to select a dictionary for stop words from a list. The workflow will, based on the selected list, remove the stop words.  <br /> Stop words are words that do not carry meaning, like, the, an,... The web service for stop words removal integrates six English stop words dictionaries and one for the Slovenian language. The output of the workflow is text in lower case without non-alfanumeric charachters and without stop words.",0, 0, ,
"http://www.myexperiment.org/workflows/1753/versions/1.html","Text stemming with Porter Stemmer","2011-01-1118:12:30","2011-01-1118:16:01","http://www.myexperiment.org/workflows/1753/download/Text_stemming_with_Porter_Stemmer-v1.t2flow?version=1","/users/13255","Petra Kralj Novak","taverna 2","/users/13255,","Petra Kralj Novak,","This workflow does text stemming. Stemming removes the inflicted endings of words. It is often used as text preprocessing for text mining, since stemmed words can be easily matched and counted. The input to the workflow is the text to be stemmed, the output is the stemmed text. &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/1754/versions/1.html","Population reconstruction and dynamic population projection","2011-01-1211:21:05","2011-01-1916:30:25","http://www.myexperiment.org/workflows/1754/download/Population_reconstruction_and_dynamic_population_projection-v1.t2flow?version=1","/users/8344","Nick Malleson","taverna 2","/users/8344,","Nick Malleson,","Runs the population reconstruction model (PRM) to create a synthetic individual-level population and then projects the population through a number of years. This is still in progress, results cannot be made public yet.",-1, 0, ,
"http://www.myexperiment.org/workflows/1754/versions/2.html","Population reconstruction and dynamic population projection","2011-01-1211:21:05","2011-01-1916:30:25","http://www.myexperiment.org/workflows/1754/download/Population_reconstruction_and_dynamic_population_projection-v2.t2flow?version=2","/users/8344","Nick Malleson","taverna 2","/users/8344,","Nick Malleson,","Runs the population reconstruction model (PRM) to create a synthetic individual-level population and then projects the population through a number of years. This is still in progress, results cannot be made public yet.",0, 0, ,
"http://www.myexperiment.org/workflows/1756/versions/1.html","Weka Clustering With Silhouette Analysis As PDF","2011-01-1309:28:28","2011-07-2118:39:03","http://www.myexperiment.org/workflows/1756/download/Weka_Clustering_With_Silhouette_Analysis_As_PDF-v1.t2flow?version=1","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow clusters given QSAR CSV file and performs a silhouette analysis which is visualised in a PDF file. Therefor it loads the QSAR data from a file and converts it into the Weke dataformat. After that the data is clustered and the results are safed to a PDF file.",-1, 0, ,
"http://www.myexperiment.org/workflows/1756/versions/2.html","Weka Clustering With Silhouette Analysis As PDF","2011-01-1309:28:28","2011-07-2118:39:03","http://www.myexperiment.org/workflows/1756/download/Weka_Clustering_With_Silhouette_Analysis_As_PDF-v2.t2flow?version=2","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow clusters given QSAR CSV file and performs a silhouette analysis which is visualised in a PDF file. The QSAR data is loaded from a CSV file and converted into a Weka dataset. After that the data is clustered and the results are visualised in a PDF file.",-1, 0, ,
"http://www.myexperiment.org/workflows/1757/versions/1.html","Weka Clustering Considering Different Origins Result As PDF","2011-01-1311:12:17","2011-07-2119:04:57","http://www.myexperiment.org/workflows/1757/download/Weka_Clustering_Considering_Different_Origins_Result_As_PDF-v1.t2flow?version=1","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow clusters the given CSV files with the chosen Weka algorithm. The results are visualized in a PDF file. Therefor the CSV files are loaded from hard disk and merged together. Afterwards they are converted into a Weka dataset which is the suitable data type for the Weka clustering activity.",-1, 0, ,
"http://www.myexperiment.org/workflows/1757/versions/2.html","Weka Clustering Considering Different Origins Result As PDF","2011-01-1311:12:17","2011-07-2119:04:57","http://www.myexperiment.org/workflows/1757/download/Weka_Clustering_Considering_Different_Origins_Result_As_PDF-v2.t2flow?version=2","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow clusters the given CSV files with the chosen Weka algorithm. The results are visualized in a PDF file. The CSV files are loaded from hard disk and merged together. Afterwards they are converted into a Weka dataset which is the suitable data type for the Weka clustering activity. The results are visualized as a PDF file showing the cluster membership of each input CSV file.",-1, 0, ,
"http://www.myexperiment.org/workflows/1764/versions/1.html","Split Molecules Into Clusters","2011-01-1711:12:25","2011-07-2118:43:31","http://www.myexperiment.org/workflows/1764/download/Split_Molecules_Into_Clusters-v1.t2flow?version=1","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow splits given molecules into their cluster memberships. The molecules are loaded from a SD file and the relationship data from a CSV file. The results are saved into N different SD files, where N is the number of clusters.",-1, 0, ,
"http://www.myexperiment.org/workflows/1765/versions/1.html","EBI_NCBI_BLAST","2011-01-1712:51:58","2013-05-3011:51:59","http://www.myexperiment.org/workflows/1765/download/EBI_NCBI_BLAST-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/925,","Katy Wolstencroft, Hamish McWilliam,","This workflow performs an NCBI blast at the EBI. It uses the new EBI services, which are asynchronous and require looping over the nested workflow (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration.",0, 0, ,
"http://www.myexperiment.org/workflows/1765/versions/2.html","EBI_NCBI_BLAST","2011-01-1712:51:58","2013-05-3011:51:59","http://www.myexperiment.org/workflows/1765/download/EBI_NCBI_BLAST-v2.t2flow?version=2","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/925,","Katy Wolstencroft, Hamish McWilliam,","This workflow performs an NCBI blast at the EBI. It accepts a protein sequence as input. Default values have been set for the search database (Uniprot), the number of hite to return (10), and all scoring and matrix options. These can be changed in the workflow by altering the string constant values if required.This workflow uses the new EBI services. They are asynchronous and so require looping over the nested workflow (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration.",0, 0, ,
"http://www.myexperiment.org/workflows/1765/versions/3.html","EBI_NCBI_BLAST","2011-01-1712:51:58","2013-05-3011:51:59","http://www.myexperiment.org/workflows/1765/download/EBI_NCBI_BLAST-v3.t2flow?version=3","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/925,","Katy Wolstencroft, Hamish McWilliam,","This workflow performs an NCBI blast at the EBI. It accepts a protein sequence as input. Default values have been set for the search database (Uniprot), the number of hits to return (10), and all scoring and matrix options. These can be changed in the workflow by altering the string constant values if required.This workflow uses the new EBI services. They are asynchronous and so require looping over the nested workflow (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration.",0, 0, ,
"http://www.myexperiment.org/workflows/1765/versions/4.html","EBI_NCBI_BLAST","2011-01-1712:51:58","2013-05-3011:51:59","http://www.myexperiment.org/workflows/1765/download/EBI_NCBI_BLAST-v4.t2flow?version=4","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/925,","Katy Wolstencroft, Hamish McWilliam,","This workflow performs an NCBI blast at the EBI. It accepts a protein sequence as input. Default values have been set for the search database (Uniprot), the number of hits to return (10), and all scoring and matrix options. These can be changed in the workflow by altering the string constant values if required.This workflow uses the new EBI services. They are asynchronous and so require looping over the nested workflow (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration.",0, 0, ,
"http://www.myexperiment.org/workflows/1767/versions/1.html","EBI_InterproScan_NewServices","2011-01-1716:08:48","2011-01-1716:12:40","http://www.myexperiment.org/workflows/1767/download/EBI_InterproScan_NewServices-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/925, /users/5,","Katy Wolstencroft, Hamish McWilliam, Stian Soiland-Reyes,","This workflow performs an interproscan on provided sequences <hr /> This workflow performs an interproscan at the EBI on sequences provided as input. The output is provided as text, xml or png.This workflow uses the new EBI services, which are asynchronous and require looping over the nested workflow (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration.",0, 0, ,
"http://www.myexperiment.org/workflows/1767/versions/2.html","EBI_InterproScan_NewServices","2011-01-1716:08:48","2011-01-1716:12:40","http://www.myexperiment.org/workflows/1767/download/EBI_InterproScan_NewServices-v2.t2flow?version=2","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/925, /users/5,","Katy Wolstencroft, Hamish McWilliam, Stian Soiland-Reyes,","This workflow performs an interproscan on provided sequences <hr /> This workflow performs an interproscan at the EBI on sequences provided as input. The output is provided as text, xml or png.This workflow uses the new EBI services, which are asynchronous and require looping over the nested workflow (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration.",0, 0, ,
"http://www.myexperiment.org/workflows/1768/versions/1.html","EMBL-EBI ClustalW2_SOAP","2011-01-1716:48:40","2013-01-3012:57:29","http://www.myexperiment.org/workflows/1768/download/EMBL-EBI_ClustalW2_SOAP-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/925,","Katy Wolstencroft, Hamish McWilliam,",,1, 0, ,
"http://www.myexperiment.org/workflows/1768/versions/2.html","EMBL-EBI ClustalW2_SOAP","2011-01-1716:48:40","2013-01-3012:57:29","http://www.myexperiment.org/workflows/1768/download/EMBL-EBI_ClustalW2_SOAP-v2.t2flow?version=2","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/925,","Katy Wolstencroft, Hamish McWilliam,",,0, 0, ,
"http://www.myexperiment.org/workflows/1772/versions/1.html","QSPR Model Discovery -- workflow structure only","2011-01-1818:13:17","2011-01-1818:24:36","http://www.myexperiment.org/workflows/1772/download/QSPR_Model_Discovery_--_workflow_structure_only-v1.t2flow?version=1","/users/500","Paolo","taverna 2","","","see metadata in workflow spec.graph structure only (no semantics).Shows how the model discovery workflow fits the Taverna model",0, 0, ,
"http://www.myexperiment.org/workflows/1772/versions/2.html","QSPR Model Discovery -- workflow structure only","2011-01-1818:13:17","2011-01-1818:24:36","http://www.myexperiment.org/workflows/1772/download/QSPR_Model_Discovery_--_workflow_structure_only-v2.t2flow?version=2","/users/500","Paolo","taverna 2","","","replicates the structure of the QSPR model discovery workflow. Ref.: <hr /> replicates the structure of the QSPR model discovery workflow. Ref.:   <a href=http://www.openqsar.com/ rel=nofollow>http://www.openqsar.com/</a>",0, 0, ,
"http://www.myexperiment.org/workflows/1773/versions/1.html","PRM With External Data","2011-01-1916:32:43","2011-01-1916:33:30","http://www.myexperiment.org/workflows/1773/download/PRM_With_External_Data-v1.t2flow?version=1","/users/8344","Nick Malleson","taverna 2","/users/8344,","Nick Malleson,","IN PROGRESS! Runs the PRM using data from an external on-line source.",-1, 0, ,
"http://www.myexperiment.org/workflows/1776/versions/1.html","Pathways and Gene annotations forQTL region","2011-01-2116:56:47","2011-01-2116:58:50","http://www.myexperiment.org/workflows/1776/download/Pathways_and_Gene_annotations_forQTL_region-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in Cow, Bos taurus. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",0, 0, ,
"http://www.myexperiment.org/workflows/1778/versions/1.html","SELECT3","2011-01-2221:58:13","2011-02-2717:35:25","http://www.myexperiment.org/workflows/1778/download/SELECT3-v1.t2flow?version=1","/users/8014","Juan Gonzalez","taverna 2","","","Select3 decides if a particular transition matches the selection criteria based on the line strength and line opacity in a given medium. To do that select3 requires a model of the medium (temperature, pressure, node spacing), chemicalcomposition and boundary conditions. Only 1D models are supported at the moment. Select3 processes one transition at a time working in two modes: opacity and synthesis. In the first mode it computes line opacity, compares it to the reference (e.g. bf and ff opacities Of the medium at the central wavelength of the line). In second mode, the line depth relative To the continuum level is used for decision. Select3 works as a pipeline filter: it reads line information from standard input and if selected sends to standard output complementing it with the estimated line depth (synthesis mode). Before processing transitions select3 performs initialization consisting of reading the execution parameters, chemical composition and the model of the medium. After this select3 solves the equation of state (molecular and ionization equilibrium) of each model point getting partial number densities of all absorbers present in VALD3.",0, 0, ,
"http://www.myexperiment.org/workflows/1778/versions/2.html","SELECT3","2011-01-2221:58:13","2011-02-2717:35:25","http://www.myexperiment.org/workflows/1778/download/SELECT3-v2.t2flow?version=2","/users/8014","Juan Gonzalez","taverna 2","","","Select3 decides if a particular transition matches the selection criteria based on the line strength and line opacity in a given medium. To do that select3 requires a model of the medium (temperature, pressure, node spacing), chemicalcomposition and boundary conditions. Only 1D models are supported at the moment. Select3 processes one transition at a time working in two modes: opacity and synthesis. In the first mode it computes line opacity, compares it to the reference (e.g. bf and ff opacities Of the medium at the central wavelength of the line). In second mode, the line depth relative To the continuum level is used for decision. Select3 works as a pipeline filter: it reads line information from standard input and if selected sends to standard output complementing it with the estimated line depth (synthesis mode). Before processing transitions select3 performs initialization consisting of reading the execution parameters, chemical composition and the model of the medium. After this select3 solves the equation of state (molecular and ionization equilibrium) of each model point getting partial number densities of all absorbers present in VALD3.",0, 0, ,
"http://www.myexperiment.org/workflows/1781/versions/1.html","miRNA GFF to entrez gene","2011-01-2611:10:40","2012-01-1114:32:54","http://www.myexperiment.org/workflows/1781/download/miRNA_GFF_to_entrez_gene-v1.t2flow?version=1","/users/20","Simon Jupp","taverna 2","","","This workflow reads a GFF file of miRNA cooridinates and uses BioMart to search human ensemble genes for the gene that codes for the miRNA. The workflow returns a list of miRNAid, chromosome, start, stop, strand, entrez gene id, gene name, gene strand. Example input file here:  <a href=ftp://mirbase.org/pub/mirbase/CURRENT/genomes/hsa.gff rel=nofollow>ftp://mirbase.org/pub/mirbase/CURRENT/genomes/hsa.gff</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/1782/versions/1.html","prism Web service","2011-01-2621:53:24","2011-01-2621:53:25","http://www.myexperiment.org/workflows/1782/download/prism_Web_service-v1.xml?version=1","/users/6843","trybik","taverna 1","/users/6843,","trybik,","PRISM model checking ( <a href=http://www.prismmodelchecker.org/manual/RunningPRISM/ModelChecking rel=nofollow>http://www.prismmodelchecker.org/manual/RunningPRISM/ModelChecking</a> ). The '-fixdl' switch is used, which means that all deadlock states in model are fixed by addition of self-loops.",6, 1, setConstantCompactXmlList, prismParamsCompactXML, prism, prismResultXML, Merge_string_list_to_string, wrapWithResultsTag, ,
"http://www.myexperiment.org/workflows/1783/versions/1.html","asynchronous prism Web service","2011-01-2621:57:02","2011-01-2621:57:04","http://www.myexperiment.org/workflows/1783/download/asynchronous_prism_Web_service-v1.xml?version=1","/users/6843","trybik","taverna 1","/users/6843,","trybik,","Asynchronous version of the Prism Web service. Results XML list is sent via email.",4, 1, asyncResultXML, asyncPrismParamsCompactXML, setConstantCompactXmlList, asyncPrism, ,
"http://www.myexperiment.org/workflows/1784/versions/1.html","sbml2Prism Web service","2011-01-2621:59:36","2011-01-2621:59:39","http://www.myexperiment.org/workflows/1784/download/sbml2Prism_Web_service-v1.xml?version=1","/users/6843","trybik","taverna 1","/users/6843,","trybik,","For example of the SBML to PRISM translation and the description of its details see  <a href=http://www.prismmodelchecker.org/manual/RunningPRISM/SupportForSBML rel=nofollow>http://www.prismmodelchecker.org/manual/RunningPRISM/SupportForSBML</a>  .",3, 1, sbml2Prism, sbml2PrismResultXML, sbml2PrismParamsXML, ,
"http://www.myexperiment.org/workflows/1786/versions/1.html","odeSolver Web service","2011-01-2622:01:53","2011-01-2622:01:56","http://www.myexperiment.org/workflows/1786/download/odeSolver_Web_service-v1.xml?version=1","/users/6843","trybik","taverna 1","/users/6843,","trybik,","SBML ODE Solver Library ( <a href=http://www.tbi.univie.ac.at/~raim/odeSolver/ rel=nofollow>http://www.tbi.univie.ac.at/~raim/odeSolver/</a> ) Web service.",6, 1, odeSolver, odeSolverResultXML, odeSolverParamsXML, trajectoriesXML, getVariablesNames, variablesNamesXPath, ,
"http://www.myexperiment.org/workflows/1788/versions/1.html","mathPlot Web service","2011-01-2622:03:56","2011-01-2622:04:31","http://www.myexperiment.org/workflows/1788/download/mathPlot_Web_service-v1.xml?version=1","/users/6843","trybik","taverna 1","/users/6843,","trybik,","Plotting operation which uses Mathematica ( <a href=http://www.wolfram.com/mathematica/ rel=nofollow>http://www.wolfram.com/mathematica/</a> ) software.",5, 1, setOptionXmlList, mathPlotParamsXML, mathPlotResultXML, Decode_base64_to_byte, mathPlot, ,
"http://www.myexperiment.org/workflows/1789/versions/1.html","[deprecated] Simulate SBML-derived ODEs","2011-01-2622:10:31","2011-07-2014:05:59","http://www.myexperiment.org/workflows/1789/download/_deprecated__Simulate_SBML-derived_ODEs-v1.xml?version=1","/users/6843","trybik","taverna 1","/users/6843,","trybik,","This is a Taverna 1 version; if you're using latest Taverna 2 workbench please use:  <a href=http://www.myexperiment.org/workflows/2264.html rel=nofollow>www.myexperiment.org/workflows/2264.html</a>  . Exemplary experiment using Tav4SB ( <a href=http://bioputer.mimuw.edu.pl/tav4sb/ rel=nofollow>http://bioputer.mimuw.edu.pl/tav4sb/</a> ) ODEs simulation and plotting Web service operations.",13, 0, modelUrl, getModel, simTime, simTimepointsNr, string2List, timeStrListApend, concentrationStr, renameCoordinate, OdeSolver, MathPlot, timepointsXml2dataXmlList, filterVariables, plotMarkersOpt, ,
"http://www.myexperiment.org/workflows/1790/versions/1.html","[deprecated] Probabilistic Model Checking (PMC): compute results","2011-01-2622:14:41","2011-07-2014:14:30","http://www.myexperiment.org/workflows/1790/download/_deprecated__Probabilistic_Model_Checking__PMC___compute_results-v1.xml?version=1","/users/6843","trybik","taverna 1","/users/6843,","trybik,","This is a Taverna 1 version; if you're using latest Taverna 2 workbench please use:  <a href=../../../workflows/2266.html rel=nofollow>www.myexperiment.org/workflows/2266.html</a>  . Exemplary experiment using Tav4SB ( <a href=http://bioputer.mimuw.edu.pl/tav4sb/ rel=nofollow>http://bioputer.mimuw.edu.pl/tav4sb/</a> ) PRISM model translation and model checking Web service operations.",16, 0, varName, propertiesUrl, rewardsUrl, appendRewards, getRewards, setConstantsStr, getProperties, initValues, getModel, modelUrl, Prism, Sbml2Prism, parametrizePrismModel, constName, initvalues2List, initValuesSep, ,
"http://www.myexperiment.org/workflows/1791/versions/1.html","[deprecated] Probabilistic Model Checking (PMC): plot results","2011-01-2622:17:00","2011-07-2014:23:03","http://www.myexperiment.org/workflows/1791/download/_deprecated__Probabilistic_Model_Checking__PMC___plot_results-v1.xml?version=1","/users/6843","trybik","taverna 1","/users/6843,","trybik,","This is a Taverna 1 version; if you're using latest Taverna 2 workbench please use:  <a href=../../../workflows/2267.html rel=nofollow>www.myexperiment.org/workflows/2267</a>  . Exemplary experiment using Tav4SB ( <a href=http://bioputer.mimuw.edu.pl/tav4sb/ rel=nofollow>http://bioputer.mimuw.edu.pl/tav4sb/</a> ) Mathematica plotting Web service operation. This is a second-part for the computationaly exhaustive PMC: compute results workflow ( <a href=http://www.myexperiment.org/workflows/1790 rel=nofollow>http://www.myexperiment.org/workflows/1790</a> ).",5, 0, string2List, extendList, getPropertiesNames, MathPlot, resultsXml2dataXmlList, ,
"http://www.myexperiment.org/workflows/1792/versions/1.html","A workflow version of the EMBOSS tutorial","2011-01-2704:14:45","2011-01-2704:14:46","http://www.myexperiment.org/workflows/1792/download/A_workflow_version_of_the_EMBOSS_tutorial-v1.t2flow?version=1","/users/14068","Maninder","taverna 2","/users/14068,","Maninder,","Designed to show the use of EMBOSS based Soaplab services from Taverna, this workflow has no inputs as all initial values are specified as string constants. A sequence set is fetched using the seqret tool, then simultaneously scanned for predicted transmembrane regions and subjected to a multiple alignment using emma. This alignment is then plotted to a set of PNG images and also used to build a profile using the prophecy and prophet tools.",0, 0, ,
"http://www.myexperiment.org/workflows/1794/versions/1.html","BiomartAndEMBOSSDisease","2011-01-2717:03:03","2012-09-0409:32:08","http://www.myexperiment.org/workflows/1794/download/BiomartAndEMBOSSDisease-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/30,","Katy Wolstencroft, Alan Williams,","This workflow retrieves all genes on human chromosome 22 that are associated with a disease and aligns the upstream regions with mouse and rat homologues. The alignments are plotted and corresponding sequence ids are also returned.",1, 0, ,
"http://www.myexperiment.org/workflows/1794/versions/2.html","BiomartAndEMBOSSDisease","2011-01-2717:03:03","2012-09-0409:32:08","http://www.myexperiment.org/workflows/1794/download/BiomartAndEMBOSSDisease-v2.t2flow?version=2","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/30,","Katy Wolstencroft, Alan Williams,","Using Biomart and EMBOSS soaplab services, This workflow retrieves a number of sequences from 3 species: mouse, human, rat; align them, and returns a plot of the alignment result. Corresponding sequence ids are also returned. <hr /> This workflow retrieves all genes on human chromosome 22 that are associated with a disease and aligns the upstream regions with mouse and rat homologues. The alignments are plotted and corresponding sequence ids are also returned.",1, 0, ,
"http://www.myexperiment.org/workflows/1794/versions/3.html","BiomartAndEMBOSSDisease","2011-01-2717:03:03","2012-09-0409:32:08","http://www.myexperiment.org/workflows/1794/download/BiomartAndEMBOSSDisease-v3.t2flow?version=3","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/30,","Katy Wolstencroft, Alan Williams,","Using Biomart and EMBOSS soaplab services, This workflow retrieves a number of sequences from 3 species: mouse, human, rat; align them, and returns a plot of the alignment result. Corresponding sequence ids are also returned. <hr /> This workflow retrieves all genes on human chromosome 22 that are associated with a disease and aligns the upstream regions with mouse and rat homologues. The alignments are plotted and corresponding sequence ids are also returned.",1, 0, ,
"http://www.myexperiment.org/workflows/1794/versions/4.html","BiomartAndEMBOSSDisease","2011-01-2717:03:03","2012-09-0409:32:08","http://www.myexperiment.org/workflows/1794/download/BiomartAndEMBOSSDisease-v4.t2flow?version=4","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/30,","Katy Wolstencroft, Alan Williams,","This workflow retrieves all genes on human chromosome 22 that are associated with a disease and aligns the upstream regions with mouse and rat homologues. The alignments are plotted and corresponding sequence ids are also returned. Using Biomart and EMBOSS soaplab services, This workflow retrieves a number of sequences from 3 species: mouse, human, rat; align them, and returns a plot of the alignment result. Corresponding sequence ids are also returned.",1, 0, ,
"http://www.myexperiment.org/workflows/1799/versions/1.html","Define one query and retrieve Molecular Interactions from PSICQUIC Services registered in the PSICQUIC registry.","2011-01-3111:36:20","2013-07-1012:33:38","http://www.myexperiment.org/workflows/1799/download/Define_one_query_and_retrieve_Molecular_Interactions_from_PSICQUIC_Services_registered_in_the_PSICQUIC_registry.-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","This workflow finds proteins located in the nucleus taking into consideration cellular component annotations and an Isoelectric Point analysis. All the accession classified with GO:0005634 or with one of its children are selected in a first round. In a second round just protein with an Isoelectric Point between 4 and are taken into account. <hr /> This workflow finds proteins located in the nucleus taking into consideration cellular component annotations and an Isolectric Point analysis. All the accession classified with GO:0005634 or with one of its childreen are selected in a first round. In a second round just protein with an Isolectric Point between 4 and are taken into account. It makes use of ENFIN webservices, the IEP EMBOSS webservice and DbFetch.",0, 0, ,
"http://www.myexperiment.org/workflows/1799/versions/2.html","Define one query and retrieve Molecular Interactions from PSICQUIC Services registered in the PSICQUIC registry.","2011-01-3111:36:20","2013-07-1012:33:38","http://www.myexperiment.org/workflows/1799/download/Define_one_query_and_retrieve_Molecular_Interactions_from_PSICQUIC_Services_registered_in_the_PSICQUIC_registry.-v2.t2flow?version=2","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Define one query and retrieve Molecular Interactions from PSICQUIC Services registered in the PSICQUIC registry.",0, 0, ,
"http://www.myexperiment.org/workflows/1799/versions/3.html","Define one query and retrieve Molecular Interactions from PSICQUIC Services registered in the PSICQUIC registry.","2011-01-3111:36:20","2013-07-1012:33:38","http://www.myexperiment.org/workflows/1799/download/Define_one_query_and_retrieve_Molecular_Interactions_from_PSICQUIC_Services_registered_in_the_PSICQUIC_registry.-v3.t2flow?version=3","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Define one query and retrieve Molecular Interactions from PSICQUIC Services registered in the PSICQUIC registry.",0, 0, ,
"http://www.myexperiment.org/workflows/1803/versions/1.html","Select redundant accessions","2011-01-3115:32:23","2011-01-3115:32:24","http://www.myexperiment.org/workflows/1803/download/Select_redundant_accessions-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Simple workflows to select accessions which appear more than once. Chose threshold to specify how many times an accession has to appear to be selected. This workflow uses a list of Comma-separated values as input. The accessions selected is the result which is presented in a String of Comma-separated values.",0, 0, ,
"http://www.myexperiment.org/workflows/1806/versions/1.html","Rank Phenotype Terms","2011-02-0111:22:14","2011-02-0111:24:42","http://www.myexperiment.org/workflows/1806/download/Rank_Phenotype_Terms-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow counts the number of articles in the pubmed database in which each term occurs, and identifies the total number of articles in the entire PubMed database. It also identified the total number of articles within pubmed so that a term enrichment score may be calculated.  The workflow also takes in a document containing abstracts that are related to a particular phenotype. Scientiifc terms are then extracted from this text and given a weighting according to the number of terms that appear in the document.  The higher the value the better the score.  This is given as: X = log((a / b) / (c / d))  where:	a = number of occurnaces of individual terms in phenotype corpus  	b = number of abstracts in entire phenotype corpus 	c = number of occurnaces of individual terms in entire pubmed 	d = number of articles in entire pubmed  Once this has been created, the pathways obtained from the QTL and microarray pathway analysis workflows are analysed. The documents from a search of each pathway in pubmed are merged into a single document of pathway abstracts. The (unweighted) phenotype terms are then searched in the pathways corpus. This will determine if the phenotype term is listed with the given pathway.  The higher the value the better the score. Each term is then assigned a weight as: Y = log((e / f) / (c /d))  where:	a = number of occurnaces of individual terms in pathway corpus  	b = number of abstracts in pathway corpus (per pathway) 	c = number of occurnaces of individual terms in entire pubmed 	d = number of articles in entire pubmed  The weighted terms are then given a link score. This is the total of: X + Y. This gives the link between the pathway and the phenotype a score / significance value. The higher the score the more &quot;appropriate/interesting&quot; the link between the pathway and the phenotype.  The terms are also ranked according to the number of pathways which have been given a weight. This is calculated as: W = Sum( X + Y). The higher the value the better the score. This workflow calculates the cosine vector space between two sets of corpora. The workflow then removes any null values from the output. this is some extra text vbeing added  It also counts the number of articles in the pubmed database in which each term occurs, and identifies the total number of articles in the entire PubMed database. It also identified the total number of articles within pubmed so that a term enrichment score may be calculated.  The workflow also takes in a document containing abstracts that are related to a particular phenotype. Scientiifc terms are then extracted from this text and given a weighting according to the number of terms that appear in the document.  The higher the value the better the score.  This is given as: X = log((a / b) / (c / d))  where:	a = number of occurnaces of individual terms in phenotype corpus  	b = number of abstracts in entire phenotype corpus 	c = number of occurnaces of individual terms in entire pubmed 	d = number of articles in entire pubmed  Once this has been created, the pathways obtained from the QTL and microarray pathway analysis workflows are analysed. The documents from a search of each pathway in pubmed are merged into a single document of pathway abstracts. The (unweighted) phenotype terms are then searched in the pathways corpus. This will determine if the phenotype term is listed with the given pathway.  The higher the value the better the score. Each term is then assigned a weight as: Y = log((e / f) / (c /d))  where:	a = number of occurnaces of individual terms in pathway corpus  	b = number of abstracts in pathway corpus (per pathway) 	c = number of occurnaces of individual terms in entire pubmed 	d = number of articles in entire pubmed  The weighted terms are then given a link score. This is the total of: X + Y. This gives the link between the pathway and the phenotype a score / significance value. The higher the score the more &quot;appropriate/interesting&quot; the link between the pathway and the phenotype.  The terms are also ranked according to the number of pathways which have been given a weight. This is calculated as: W = Sum( X + Y). The higher the value the better the score.",0, 0, ,
"http://www.myexperiment.org/workflows/1826/versions/1.html","Using a Create_List script with a dot-product to create lists","2011-02-0214:39:20","2011-02-0214:39:22","http://www.myexperiment.org/workflows/1826/download/Using_a_Create_List_script_with_a_dot-product_to_create_lists-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","Create_lots_of_strings gives implicit iteration over the service add_a_and_b - assume this is a service that returns two values which you now want to keep in a list [a,b]. The shim Create_list takes two single inputs, and returns a list of [in1, in2]. Configured with the Dot product list strategy it means that it will pipeline out [a1,b1], [a2,b2], [a3,b3] etc. <hr /> Create_lots_of_strings gives implicit iteration over the service add_a_and_b - assume this is a service that returns two values which you now want to keep in a list [a,b]. The shim Create_list takes two single inputs, and returns a list of [in1, in2]. Configured with the Dot product list strategy it means that it will pipeline out [a1,b1], [a2,b2], [a3,b3] etc. The shim can be extended to include further elements by adding ports and modifying the script.",1, 0, ,
"http://www.myexperiment.org/workflows/1833/versions/1.html","PubMed Search","2011-02-0315:24:57","2011-02-0315:25:32","http://www.myexperiment.org/workflows/1833/download/PubMed_Search-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a search term, are passed to the eSearch function and searched for in PubMed. Those abstracts found are returned to the user",1, 0, ,
"http://www.myexperiment.org/workflows/1834/versions/1.html","Remove Non-ASCII","2011-02-0315:49:07","2011-02-0315:59:08","http://www.myexperiment.org/workflows/1834/download/Remove_Non-ASCII-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","THis workflow removes any non-ascii characters from a segment of text. Any characters that are found are removed. Letters either side f the non-ASCII are concatenated - this may cause the loss of word meaning",1, 0, ,
"http://www.myexperiment.org/workflows/1835/versions/1.html","Read files from Directory","2011-02-0316:05:02","2011-02-0316:05:52","http://www.myexperiment.org/workflows/1835/download/Read_files_from_Directory-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow reads files from a given directory, based on a known file extension (e.g. .txt), and then outputs the contents of each file in a single value/single list.",0, 0, ,
"http://www.myexperiment.org/workflows/1842/versions/1.html","Gene to Pubmed","2011-02-0813:04:06","2011-02-1016:01:41","http://www.myexperiment.org/workflows/1842/download/Gene_to_Pubmed-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a list of gene names and searches the PubMed database for corresponding articles. Any matches to the genes are then retrieved (abstracts only). These abstracts are then returned to the user.",0, 0, ,
"http://www.myexperiment.org/workflows/1842/versions/2.html","Gene to Pubmed","2011-02-0813:04:06","2011-02-1016:01:41","http://www.myexperiment.org/workflows/1842/download/Gene_to_Pubmed-v2.t2flow?version=2","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a list of gene names and searches the PubMed database for corresponding articles. Any matches to the genes are then retrieved (abstracts only). These abstracts are then returned to the user.",0, 0, ,
"http://www.myexperiment.org/workflows/1842/versions/3.html","Gene to Pubmed","2011-02-0813:04:06","2011-02-1016:01:41","http://www.myexperiment.org/workflows/1842/download/Gene_to_Pubmed-v3.t2flow?version=3","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a list of gene and pathway names and searches the PubMed database for corresponding articles. Any matches to the genes are then retrieved (abstracts only). These abstracts are then returned to the user.  The end result is the calculation of cosine vector space scores between gene/pathway and phenotype corpora. The workflow then removes any null values from the output. this is some extra text vbeing added  It also counts the number of articles in the pubmed database in which each term occurs, and identifies the total number of articles in the entire PubMed database. It also identified the total number of articles within pubmed so that a term enrichment score may be calculated.  The workflow also takes in a document containing abstracts that are related to a particular phenotype. Scientiifc terms are then extracted from this text and given a weighting according to the number of terms that appear in the document.  The higher the value the better the score.  This is given as: X = log((a / b) / (c / d))  where:	a = number of occurnaces of individual terms in phenotype corpus  	b = number of abstracts in entire phenotype corpus 	c = number of occurnaces of individual terms in entire pubmed 	d = number of articles in entire pubmed  Once this has been created, the pathways obtained from the QTL and microarray pathway analysis workflows are analysed. The documents from a search of each pathway in pubmed are merged into a single document of pathway abstracts. The (unweighted) phenotype terms are then searched in the pathways corpus. This will determine if the phenotype term is listed with the given pathway.  The higher the value the better the score. Each term is then assigned a weight as: Y = log((e / f) / (c /d))  where:	a = number of occurnaces of individual terms in pathway corpus  	b = number of abstracts in pathway corpus (per pathway) 	c = number of occurnaces of individual terms in entire pubmed 	d = number of articles in entire pubmed  The weighted terms are then given a link score. This is the total of: X + Y. This gives the link between the pathway and the phenotype a score / significance value. The higher the score the more &quot;appropriate/interesting&quot; the link between the pathway and the phenotype.  The terms are also ranked according to the number of pathways which have been given a weight. This is calculated as: W = Sum( X + Y). The higher the value the better the score.",0, 0, ,
"http://www.myexperiment.org/workflows/1842/versions/4.html","Gene to Pubmed","2011-02-0813:04:06","2011-02-1016:01:41","http://www.myexperiment.org/workflows/1842/download/Gene_to_Pubmed-v4.t2flow?version=4","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a list of gene names and searches the PubMed database for corresponding articles. Any matches to the genes are then retrieved (abstracts only). These abstracts are then returned to the user.",0, 0, ,
"http://www.myexperiment.org/workflows/1846/versions/1.html","Pathway and Gene to Pubmed","2011-02-1016:10:52","2011-02-1813:47:08","http://www.myexperiment.org/workflows/1846/download/Pathway_and_Gene_to_Pubmed-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a list of gene names and searches the PubMed database for corresponding articles. Any matches to the genes are then retrieved (abstracts only). These abstracts are then returned to the user.",1, 0, ,
"http://www.myexperiment.org/workflows/1846/versions/2.html","Pathway and Gene to Pubmed","2011-02-1016:10:52","2011-02-1813:47:08","http://www.myexperiment.org/workflows/1846/download/Pathway_and_Gene_to_Pubmed-v2.t2flow?version=2","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a list of gene names and KEGG pathway descriptions, and searches the PubMed database for corresponding articles. Any matches to the genes are then retrieved (abstracts only). These abstracts are then used to calculate a cosine vector space between two sets of corpora (gene and phenotype, or pathway and phenotype).   The workflow counts the number of articles in the pubmed database in which each term occurs, and identifies the total number of articles in the entire PubMed database. It also identified the total number of articles within pubmed so that a term enrichment score may be calculated.  The workflow also takes in a document containing abstracts that are related to a particular phenotype. Scientiifc terms are then extracted from this text and given a weighting according to the number of terms that appear in the document.  The higher the value the better the score.  This is given as: X = log((a / b) / (c / d))  where:	a = number of occurnaces of individual terms in phenotype corpus  	b = number of abstracts in entire phenotype corpus 	c = number of occurnaces of individual terms in entire pubmed 	d = number of articles in entire pubmed  Once this has been created, the pathways obtained from the QTL and microarray pathway analysis workflows are analysed. The documents from a search of each pathway in pubmed are merged into a single document of pathway abstracts. The (unweighted) phenotype terms are then searched in the pathways corpus. This will determine if the phenotype term is listed with the given pathway.  The higher the value the better the score. Each term is then assigned a weight as: Y = log((e / f) / (c /d))  where:	a = number of occurnaces of individual terms in pathway corpus  	b = number of abstracts in pathway corpus (per pathway) 	c = number of occurnaces of individual terms in entire pubmed 	d = number of articles in entire pubmed  The weighted terms are then given a link score. This is the total of: X + Y. This gives the link between the pathway and the phenotype a score / significance value. The higher the score the more &quot;appropriate/interesting&quot; the link between the pathway and the phenotype.  The terms are also ranked according to the number of pathways which have been given a weight. This is calculated as: W = ( X + Y). The higher the value the better the score.",1, 0, ,
"http://www.myexperiment.org/workflows/1850/versions/1.html","Associate hessi flares with active regions","2011-02-1115:07:42","2011-10-2410:54:09","http://www.myexperiment.org/workflows/1850/download/Associate_hessi_flares_with_active_regions-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow is querying the HFC ActiveRegions list and HEC hessi_flare list.It requires a time periode and a search radius arround the centre of an Active Region as inputsIt produces two outputs: HFCout is a modified VOTable where a field is added with the number of associated hessi flares. combined_output is a 2 dimensional list with an VOTable for each Active region and one with an VOTable for all associated flares for that Active Region.",0, 0, ,
"http://www.myexperiment.org/workflows/1850/versions/2.html","Associate hessi flares with active regions","2011-02-1115:07:42","2011-10-2410:54:09","http://www.myexperiment.org/workflows/1850/download/Associate_hessi_flares_with_active_regions-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow is querying the HFC ActiveRegions list and HEC hessi_flare list.It requires a time periode and a search radius arround the centre of an Active Region as inputsIt produces two outputs: HFCout is a modified VOTable where a field is added with the number of associated hessi flares. combined_output is a 2 dimensional list with an VOTable for each Active region and one with an VOTable for all associated flares for that Active Region.",0, 0, ,
"http://www.myexperiment.org/workflows/1850/versions/3.html","Associate hessi flares with active regions","2011-02-1115:07:42","2011-10-2410:54:09","http://www.myexperiment.org/workflows/1850/download/Associate_hessi_flares_with_active_regions-v3.t2flow?version=3","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow is querying the HFC ActiveRegions list and HEC hessi_flare list.It requires a time periode and a search radius arround the centre of an Active Region as inputsIt produces two outputs: HFCout is a modified VOTable where a field is added with the number of associated hessi flares. combined_output is a 2 dimensional list with an VOTable for each Active region and one with an VOTable for all associated flares for that Active Region.",0, 0, ,
"http://www.myexperiment.org/workflows/1856/versions/1.html","Calculate Sun data from date","2011-02-1509:57:51","2011-03-0212:02:43","http://www.myexperiment.org/workflows/1856/download/Calculate_Sun_data_from_date-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","caluculates B0, position angle and sun radius (arcsec) B0 - heliographic latitude of the centre of  diskposition angle - of the north end of the axis of rotation, measured +ve if east of the north point of the diskradius - the apparent radus of the Sun in arcsec <hr /> caluculates B0, position angle and sun radius (arcsec) B0 - heliographic latitude of the centre of  diskposition angle - of the north end of the axis of rotation, measured +ve if east of the north point of the diskradius - the apparent radus of the Sun in arcsec This is created using the calculations from the IDL routine get_sun.pro",1, 0, ,
"http://www.myexperiment.org/workflows/1856/versions/2.html","Calculate Sun data from date","2011-02-1509:57:51","2011-03-0212:02:43","http://www.myexperiment.org/workflows/1856/download/Calculate_Sun_data_from_date-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","caluculates B0 (radians), position angle and sun radius (arcsec) B0 - heliographic latitude of the centre of  diskposition angle - of the north end of the axis of rotation, measured +ve if east of the north point of the diskradius - the apparent radus of the Sun in arcsec This is created using the calculations from the IDL routine get_sun.pro",1, 0, ,
"http://www.myexperiment.org/workflows/1857/versions/1.html","StRAnGER Web Service Workflow","2011-02-1517:28:17","2011-02-1517:30:37","http://www.myexperiment.org/workflows/1857/download/StRAnGER_Web_Service_Workflow-v1.t2flow?version=1","/users/14473","Elico stranger","taverna 2","/users/14473,","Elico stranger,","&nbsp; <span class=Apple-style-span>StRAnGER is a web-based application, which performs functional analysis of high-throughput genomic datasets, starting from a list of significant genes derived from statistical and empirical thresholds, by utilizing the GO database and the KEGG pathway database as well as established statistical methods in order to relate the identified significant genes with important nodes in the GO tree structure or map those genes to over-represented metabolic pathways.</span>",-1, 0, ,
"http://www.myexperiment.org/workflows/1903/versions/1.html","QSAR Descriptor Calculation Workflow","2011-02-1810:53:32","2011-07-2118:44:31","http://www.myexperiment.org/workflows/1903/download/QSAR_Descriptor_Calculation_Workflow-v1.t2flow?version=1","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow calculates QSAR properties and saves them as a CSV file. The molecules are read iteratively from a SD file. Additionally it writes out the molecules with unknown atom types, salt counter ions, curated molecule library with UUIDs and the used calculation time of every QSAR descriptor as a CSV file.Furthermore explicit hydrogens are added and a Hueckel aromaticity detection is performed.",-1, 0, ,
"http://www.myexperiment.org/workflows/1903/versions/2.html","QSAR Descriptor Calculation Workflow","2011-02-1810:53:32","2011-07-2118:44:31","http://www.myexperiment.org/workflows/1903/download/QSAR_Descriptor_Calculation_Workflow-v2.t2flow?version=2","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow calculates QSAR properties and saves them as a CSV file. The molecules are read iteratively from a SD file. Additionally it writes out the molecules with unknown atom types, salt counter ions, curated molecule library with UUIDs and the used calculation time of every QSAR descriptor as a CSV file.Furthermore explicit hydrogens are added and a Hueckel aromaticity detection is performed.",-1, 0, ,
"http://www.myexperiment.org/workflows/1905/versions/1.html","Reaction Enumeration","2011-02-1811:08:02","2011-07-2118:44:18","http://www.myexperiment.org/workflows/1905/download/Reaction_Enumeration-v1.t2flow?version=1","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow performs a reaction enumeration. Therefore it loads a generic reaction rxn file and two educt lists. The SD files contain the educt lists for the enumeration. The products of the enumerated reaction are stored as RXN files and also a PDF will be created which visualizes the resulting reactions.",-1, 0, ,
"http://www.myexperiment.org/workflows/1906/versions/1.html","Converting from heliocentric coordinate system with coordinates in arcsec to coordinates in longitude latitude","2011-02-1811:38:40","2011-02-1811:51:29","http://www.myexperiment.org/workflows/1906/download/Converting_from_heliocentric_coordinate_system_with_coordinates_in_arcsec_to_coordinates_in_longitude_latitude-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Converting from heliocentric coordinate system with coordinates in arcsec to coordinates in longitude latitude  Based on the IDL script xy2lonlat.pro  <a href=http://hesperia.gsfc.nasa.gov/ssw/gen/idl/solar/xy2lonlat.pro rel=nofollow>http://hesperia.gsfc.nasa.gov/ssw/gen/idl/solar/xy2lonlat.pro</a> Stonyhurst Heliographic Coordinate System to Helioprojective-Cartesian Coordinate System",2, 0, ,
"http://www.myexperiment.org/workflows/1907/versions/1.html","Associate goes X ray  flares with active regions","2011-02-1815:51:13","2011-02-1815:53:31","http://www.myexperiment.org/workflows/1907/download/Associate_goes_X_ray__flares_with_active_regions-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow is querying the HFC ActiveRegions list and HEC goes_xray_flare list. It requires a time periode and a search radius arround the centre of an Active Region as inputs It produces two outputs: HFCout is a modified VOTable where a field is added with the number of associated hessi flares. combined_output is a 2 dimensional list with an VOTable for each Active region and one with an VOTable for all associated flares for that Active Region.",0, 0, ,
"http://www.myexperiment.org/workflows/1909/versions/1.html","Associate flares with active regions","2011-02-2214:27:40","2011-08-2414:51:40","http://www.myexperiment.org/workflows/1909/download/Associate_flares_with_active_regions-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow is querying the HFC ActiveRegions list and HEC flare lists (names retrieved from the ontlogoy) It requires a time periode and a search radius arround the centre of an Active Region as inputs It produces two outputs: HFCout is a modified VOTable where a field per flare list is added with the number of associated flares. combined_output is a 2 dimensional list with an VOTable for each Active region and each one with an VOTable for all associated flares for that Active Region.",1, 0, ,
"http://www.myexperiment.org/workflows/1911/versions/1.html","Extract content of columns from VOTables","2011-02-2410:19:41","2012-08-2012:51:13","http://www.myexperiment.org/workflows/1911/download/Extract_content_of_columns_from_VOTables-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Extracts all values from all columns which are passed from the input ColumnNames",0, 0, ,
"http://www.myexperiment.org/workflows/1911/versions/2.html","Extract content of columns from VOTables","2011-02-2410:19:41","2012-08-2012:51:13","http://www.myexperiment.org/workflows/1911/download/Extract_content_of_columns_from_VOTables-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Extracts all values from all columns which are passed from the input ColumnNames",0, 0, ,
"http://www.myexperiment.org/workflows/1911/versions/3.html","Extract content of columns from VOTables","2011-02-2410:19:41","2012-08-2012:51:13","http://www.myexperiment.org/workflows/1911/download/Extract_content_of_columns_from_VOTables-v3.t2flow?version=3","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Extracts all values from all columns which are passed from the input ColumnNames",0, 0, ,
"http://www.myexperiment.org/workflows/1913/versions/1.html","Taverna-eScienceCentral integration demo","2011-02-2508:56:27","","http://www.myexperiment.org/workflows/1913/download/Taverna-eScienceCentral_integration_demo-v1.t2flow?version=1","/users/500","Paolo","taverna 2","","","show how a eSC workflow can be embedded into a Taverna workflow",-1, 0, ,
"http://www.myexperiment.org/workflows/1914/versions/1.html","[untitled]","2011-02-2719:36:31","2011-02-2719:36:52","http://www.myexperiment.org/workflows/1914/download/_untitled_-v1.t2flow?version=1","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","gdalinfo test",-1, 0, ,
"http://www.myexperiment.org/workflows/1924/versions/1.html","Converting from coordinates in longitude latitude to  heliocentric coordinate system with coordinates in arcsec","2011-03-0214:12:21","2011-03-0214:12:24","http://www.myexperiment.org/workflows/1924/download/Converting_from_coordinates_in_longitude_latitude_to__heliocentric_coordinate_system_with_coordinates_in_arcsec-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Based on lonlat2xy.proConverts from Helioprojective-Cartesian Coordinate System to Stonyhurst Heliographic Coordinate System <hr /> Based on lonlat2xy.pro <a href=http://hesperia.gsfc.nasa.gov/ssw/gen/idl/solar/lonlat2xy.pro rel=nofollow>http://hesperia.gsfc.nasa.gov/ssw/gen/idl/solar/lonlat2xy.pro</a> Converts from Helioprojective-Cartesian Coordinate System to Stonyhurst Heliographic Coordinate System",1, 0, ,
"http://www.myexperiment.org/workflows/1925/versions/1.html","MDES simple execution","2011-03-0215:19:52","2014-03-1213:16:40","http://www.myexperiment.org/workflows/1925/download/MDES_simple_execution-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","workflow to test DES",0, 0, ,
"http://www.myexperiment.org/workflows/1925/versions/2.html","MDES simple execution","2011-03-0215:19:52","2014-03-1213:16:40","http://www.myexperiment.org/workflows/1925/download/MDES_simple_execution-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","workflow to query MDES, obtaining the DES results and from it extracting the VOTable and the PNG plot for the time range queried.",0, 0, ,
"http://www.myexperiment.org/workflows/1928/versions/1.html","WPS orchestration example, image metadata extraction","2011-03-0309:26:24","2011-03-0309:26:28","http://www.myexperiment.org/workflows/1928/download/WPS_orchestration_example__image_metadata_extraction-v1.t2flow?version=1","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","1 image inputs (GeoTIFF, JPEG,PNG), metadata from gdalinfo and histogram analisys, histogram result is a PNG image in base64 coding (default WPS service encoding) that will be converted to binary.",0, 0, ,
"http://www.myexperiment.org/workflows/1932/versions/1.html","DevinTheDevil","2011-03-0821:16:32","","http://www.myexperiment.org/workflows/1932/download/DevinTheDevil-v1.t2flow?version=1","/users/8014","Juan Gonzalez","taverna 2","","","DevinTheDevil computes level populations for one or more ions of astrophysical interest using the XSTAR atomic database (uaDB).",0, 0, ,
"http://www.myexperiment.org/workflows/1953/versions/1.html","InterproScan without Looping","2011-03-1614:01:22","2012-08-2908:30:44","http://www.myexperiment.org/workflows/1953/download/InterproScan_without_Looping-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow performs an interproscan at the EBI on sequences provided as input. The output is provided as text or png. This workflow uses the new EBI services, which are asynchronous and require looping over the nested workflow (Status) until the workflow has finished. This workflow will not work properly until we add looping.",1, 0, ,
"http://www.myexperiment.org/workflows/1957/versions/1.html","Pathways and Gene annotations forQTL region","2011-03-1711:10:28","2011-08-3010:40:14","http://www.myexperiment.org/workflows/1957/download/Pathways_and_Gene_annotations_forQTL_region-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in Human, Homo sapiens. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",0, 0, ,
"http://www.myexperiment.org/workflows/1957/versions/2.html","Pathways and Gene annotations forQTL region","2011-03-1711:10:28","2011-08-3010:40:14","http://www.myexperiment.org/workflows/1957/download/Pathways_and_Gene_annotations_forQTL_region-v2.t2flow?version=2","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in Human, Homo sapiens. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",0, 0, ,
"http://www.myexperiment.org/workflows/1975/versions/1.html","XPath Pubmed Ids","2011-03-2311:24:23","2011-03-2311:24:58","http://www.myexperiment.org/workflows/1975/download/XPath_Pubmed_Ids-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a search term (as used in the normal PubMed interface) and retrieves a list of PubMed ids in xml",1, 0, ,
"http://www.myexperiment.org/workflows/1976/versions/1.html","XPath Pubmed Ids","2011-03-2316:19:10","2011-03-3009:28:13","http://www.myexperiment.org/workflows/1976/download/XPath_Pubmed_Ids-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a search term (as used in the normal PubMed interface) and retrieves a list of PubMed ids in xml. The xml is then parsed to retrieve a list of PubMed ids",2, 0, ,
"http://www.myexperiment.org/workflows/1976/versions/2.html","XPath Pubmed Ids","2011-03-2316:19:10","2011-03-3009:28:13","http://www.myexperiment.org/workflows/1976/download/XPath_Pubmed_Ids-v2.t2flow?version=2","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow takes in a search term (as used in the normal PubMed interface) and retrieves a list of PubMed ids in xml. The xml is then parsed to retrieve a list of PubMed ids",2, 0, ,
"http://www.myexperiment.org/workflows/1977/versions/1.html","Pathways and Gene annotations forQTL region","2011-03-2415:14:48","2011-03-2415:37:48","http://www.myexperiment.org/workflows/1977/download/Pathways_and_Gene_annotations_forQTL_region-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow searches for genes found from a set of differentially expressed probestes, in Human, Homo sapiens. The workflow requires an input human affymetrix probeset identifiers. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",0, 0, ,
"http://www.myexperiment.org/workflows/1981/versions/1.html","Extract unique proteins from blast results","2011-03-2419:49:43","2011-04-0112:26:27","http://www.myexperiment.org/workflows/1981/download/Extract_unique_proteins_from_blast_results-v1.t2flow?version=1","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","The workflow parses uses the blast results to determine the unique proteins found in the target genome that have no similairty to the source genome. Using these unique protein ids, and the original target protein fasta file, a fasta file of unique proteins is created. <hr /> <hr /> Workflow outputs a list of proteins encoded by the target genomes that do not have sequences similarity to those encoded by the source genome <hr /> This workflow allows you to configure a BioMart query to fetch sequences you want from Ensembl. These sequences are retrieved and a blast database of them is created (by default, in the directory you ran taverna from). Warning: This workflow assumes that you have blastall and formatdb installed on the machine, and that by default, these are both found or linked in /usr/local/bin. It also assumes that you have write permission to the directory you have run taverna from. The beanshells create_blastall_cmdArgs and create_formatdb_cmdArgs are what you need to edit if the default locations are not appropriate for you. Shortcomings: The names of all the files created and used is hard coded in this workflow. This means that if you run this workflow more than once without editing anything, you will overwrite files you have previously created. All files created in the working directory are not yet coded to be deleted via the workflow. Ideally there would be an option that a user could choose that would set the files to be kept or deleted after use.",1, 0, ,
"http://www.myexperiment.org/workflows/1981/versions/2.html","Extract unique proteins from blast results","2011-03-2419:49:43","2011-04-0112:26:27","http://www.myexperiment.org/workflows/1981/download/Extract_unique_proteins_from_blast_results-v2.t2flow?version=2","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","The workflow parses uses the blast results to determine the unique proteins found in the target genome that have no similarity to the source genome. Using these unique protein ids, and the original target protein fasta file, a list unique proteins is created. Workflow outputs a list of proteins encoded by the target genomes that do not have sequences similarity to those encoded by the source genome",1, 0, ,
"http://www.myexperiment.org/workflows/1981/versions/3.html","Extract unique proteins from blast results","2011-03-2419:49:43","2011-04-0112:26:27","http://www.myexperiment.org/workflows/1981/download/Extract_unique_proteins_from_blast_results-v3.t2flow?version=3","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","Workflow outputs a list of proteins encoded by the target genomes that do not have sequences similarity to those encoded by the source genome <hr /> This workflow allows you to configure a BioMart query to fetch sequences you want from Ensembl. These sequences are retrieved and a blast database of them is created (by default, in the directory you ran taverna from). Warning: This workflow assumes that you have blastall and formatdb installed on the machine, and that by default, these are both found or linked in /usr/local/bin. It also assumes that you have write permission to the directory you have run taverna from. The beanshells create_blastall_cmdArgs and create_formatdb_cmdArgs are what you need to edit if the default locations are not appropriate for you. Shortcomings: The names of all the files created and used is hard coded in this workflow. This means that if you run this workflow more than once without editing anything, you will overwrite files you have previously created. All files created in the working directory are not yet coded to be deleted via the workflow. Ideally there would be an option that a user could choose that would set the files to be kept or deleted after use. <hr /> The workflow parses uses the blast results to determine the unique proteins found in the target genome that have no similairty to the source genome. Using these unique protein ids, and the original target protein fasta file, a fasta file of unique proteins is created. <hr />",1, 0, ,
"http://www.myexperiment.org/workflows/1981/versions/4.html","Extract unique proteins from blast results","2011-03-2419:49:43","2011-04-0112:26:27","http://www.myexperiment.org/workflows/1981/download/Extract_unique_proteins_from_blast_results-v4.t2flow?version=4","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","",1, 0, ,
"http://www.myexperiment.org/workflows/1984/versions/1.html","Drug Re-Purposing Workflow","2011-03-2520:06:13","2011-04-0112:40:56","http://www.myexperiment.org/workflows/1984/download/Drug_Re-Purposing_Workflow-v1.t2flow?version=1","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","&nbsp; &nbsp; &nbsp; &nbsp; <span>This workflow will not work for anyone outside the Newcastle University domain, and may not even work past Spring 2011 due to Microbase webservices. It takes in two GI numbers and Blasts in the Cloud using Microbase, compares the results to the target proteome, and returns any proteins that are unique to the target strain.</span> &nbsp; &nbsp; <span><br /></span> &nbsp; &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/1984/versions/2.html","Drug Re-Purposing Workflow","2011-03-2520:06:13","2011-04-0112:40:56","http://www.myexperiment.org/workflows/1984/download/Drug_Re-Purposing_Workflow-v2.t2flow?version=2","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1984/versions/3.html","Drug Re-Purposing Workflow","2011-03-2520:06:13","2011-04-0112:40:56","http://www.myexperiment.org/workflows/1984/download/Drug_Re-Purposing_Workflow-v3.t2flow?version=3","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,",,0, 0, ,
"http://www.myexperiment.org/workflows/1984/versions/4.html","Drug Re-Purposing Workflow","2011-03-2520:06:13","2011-04-0112:40:56","http://www.myexperiment.org/workflows/1984/download/Drug_Re-Purposing_Workflow-v4.t2flow?version=4","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,",,-1, 0, ,
"http://www.myexperiment.org/workflows/1984/versions/5.html","Drug Re-Purposing Workflow","2011-03-2520:06:13","2011-04-0112:40:56","http://www.myexperiment.org/workflows/1984/download/Drug_Re-Purposing_Workflow-v5.t2flow?version=5","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","The drug repurposing workflow system screens at least 20 bacterial proteomes against this set of proteins that are already being treated against using established drugs. By screening the bacterial proteomes it will be possible to find proteins of highly similar structure to those that are existing drug protein targets and so this will infer that it is highly likely that the drugs can be used as antimicrobials against these proteins of highly similar structure.   Proteomes that will be screened belong to Gram positive bacteria, with special focus on  <i>Staphylococcus aureus</i> . We look at a variety of species and strains as the company advised. A mixture of screening targets could potentially identify targets for broad-spectrum antimicrobial development. The drug repurposing workflow shows where in the KEGG pathways the proteins are active and therefore where the action of the drug will be in the biochemical pathways of the bacteria. The workflow will update the Ondex database where new information on Gene Ontology annotations, functional annotation and literature references are available. All information about each unique protein is made available in an HTML document.  <hr /> Comparison of the genome of  <i>Bacillus anthracis</i>  to closely related strains will allow the discovery of proteins which may be involved in pathogenicity. Based on the biochemical pathways where the protein interacts, vaccines can be designed for these unique proteins. By gaining insight into the biochemical pathways that the unique proteins are involved in, the proteins can also be assessed for potential quality as vaccines.  The key components of the vaccine finding system are the following: The vaccine finding system reads in at least two annotated whole genome sequences in EMBL or GenBank format; the source (non-pathogen) and the target ( <i>Bacillus anthracis</i> ). At this point, the workflow runs a BlastP search to compare the two strains of bacteria. Assessment of the evolutionary relationship between the two genomes ascertains whether they are closely related enough to derive meaningful comparisons. The vaccine finding system then parses the proteins from the data set that are only coded for in the target genome  <i>Bacillus anthracis</i> , giving a new data set of unique proteins which can then be assessed in the KEGG PATHWAY database. The position of the unique proteins in the pathways will give a good indication of the enzymatic role of the proteins in  <i>Bacillus anthracis</i> .  The vaccine finding system then records its findings in an HTML file, as well as additional information such as annotations from Gene Ontology, functional annotations and literature references.",1, 0, ,
"http://www.myexperiment.org/workflows/1984/versions/6.html","Drug Re-Purposing Workflow","2011-03-2520:06:13","2011-04-0112:40:56","http://www.myexperiment.org/workflows/1984/download/Drug_Re-Purposing_Workflow-v6.t2flow?version=6","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","The drug repurposing workflow system screens at least 20 bacterial proteomes against this set of proteins that are already being treated against using established drugs. By screening the bacterial proteomes it will be possible to find proteins of highly similar structure to those that are existing drug protein targets and so this will infer that it is highly likely that the drugs can be used as antimicrobials against these proteins of highly similar structure.   Proteomes that will be screened belong to Gram positive bacteria, with special focus on  <i>Staphylococcus aureus</i> . We look at a variety of species and strains as the company advised. A mixture of screening targets could potentially identify targets for broad-spectrum antimicrobial development. The drug repurposing workflow shows where in the KEGG pathways the proteins are active and therefore where the action of the drug will be in the biochemical pathways of the bacteria. The workflow will update the Ondex database where new information on Gene Ontology annotations, functional annotation and literature references are available. All information about each unique protein is made available in an HTML document.",0, 0, ,
"http://www.myexperiment.org/workflows/1988/versions/1.html","ADR-S","2011-03-2811:34:18","2011-08-0922:38:12","http://www.myexperiment.org/workflows/1988/download/ADR-S-v1.t2flow?version=1","/users/15418","Anna Bauer-Mehren","taverna 2","/users/15418,","Anna Bauer-Mehren,","<span class=Apple-style-span>The ADR substantiation (ADR-S) workflow seeks to establish a connection between the clinical event and the drug through (i) proteins being targeted by the drug (or by its metabolites) and are associated with the clinical event and (ii) through biological pathways.&nbsp;</span> In the first connecting path, the link between the drug and the event is established through the set of proteins in common between the Drug-Target-Profile and the Event-Protein-Profile. In the second path, the link is established through a set of proteins that are part of the same biological pathway. For example, consider a protein A targeted by the drug and a protein B associated with the clinical event, and both proteins A and B are part of the same biological pathway C. Then, the drug and the event are connected through biological pathway C. <span>For more details see &quot;Bauer-Mehren et al., Automatic filtering and substantiation of drug safety signals.&quot;</span> <span>&nbsp;&lt;o:p&gt;&lt;/o:p&gt;</span>",4, 0, ,
"http://www.myexperiment.org/workflows/1988/versions/2.html","ADR-S","2011-03-2811:34:18","2011-08-0922:38:12","http://www.myexperiment.org/workflows/1988/download/ADR-S-v2.t2flow?version=2","/users/15418","Anna Bauer-Mehren","taverna 2","/users/15418,","Anna Bauer-Mehren,","&nbsp; The ADR-S pathway seeks to establish a connection between the clinical event and the drug through different paths:   	(i) through proteins in common among the proteins that are drug targets or metabolite targets and proteins associated to the clinical event  	(ii) through proteins that are drug targets or metabolite targets and proteins associated to the clinical event that participate in a common biological pathway.  The workflow proceeds as follows: <br /> First, it checks if there are proteins that are annotated both to the clinical event and to the drug (NESTED WORKFLOW ADR_substantiation_through_proteins). <br /> Second, it looks for connections between the drug and the clinical event through biological pathways. Information about tissue expression of the proteins is used to filter the results  Input of the workflow  The input of the workflow is a drug-event pair.   For the clinical events, the following types are allowed:  	1) UMLS CUI concept identifiers (single identifier or a list of identifiers 	2) clinical events observed as adverse drug reactions according to the EU-ADR project  For the drug, a ATC code (7 digit level) is required.  Output of the workflow  As result a list of connecting proteins as well as a list of pathways is provided.   The results can be visualized as a network using Cytoscape. The network is a multi-partite graph, in which the nodes are the event, the drug and the proteins, and the edges the associations between these nodes. In addition, all the evidences supporting the associations can be explored in the graph representation.  The results of the analyisis through biological pathways is summarized in an html file.",5, 0, ,
"http://www.myexperiment.org/workflows/1989/versions/1.html","Threshold BLAST results","2011-03-2811:57:51","2011-04-0112:28:38","http://www.myexperiment.org/workflows/1989/download/Threshold_BLAST_results-v1.t2flow?version=1","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","&nbsp;Takes in a tab-delimited BLAST file and thresholds the values so that only results of a certain identity or higher are included in the output.",-1, 0, ,
"http://www.myexperiment.org/workflows/1989/versions/2.html","Threshold BLAST results","2011-03-2811:57:51","2011-04-0112:28:38","http://www.myexperiment.org/workflows/1989/download/Threshold_BLAST_results-v2.t2flow?version=2","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","Thresholds tab-delimited BLAST results to a certain percent identity.",0, 0, ,
"http://www.myexperiment.org/workflows/1990/versions/1.html","NCBI Gi to Kegg Pathways","2011-03-2814:00:43","2011-03-2814:00:44","http://www.myexperiment.org/workflows/1990/download/NCBI_Gi_to_Kegg_Pathways-v1.t2flow?version=1","/users/15179","Alibukhari","taverna 2","/users/15179,","Alibukhari,","This workflow gets a series of information relating to a list of KEGG genes supplied to it. It also removes any null values from a list of strings. <hr /> This workflow gets a series of information relating to a list of KEGG genes supplied to it. It also removes any null values from a list of strings.",0, 0, ,
"http://www.myexperiment.org/workflows/1992/versions/1.html","KEGG Pathways and Additional Information from BLAST","2011-03-2911:16:17","2011-03-3016:09:01","http://www.myexperiment.org/workflows/1992/download/KEGG_Pathways_and_Additional_Information_from_BLAST-v1.t2flow?version=1","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","Takes in a tab-delimited BLAST file and finds additional information about the target proteins from KEGG, Gene Ontology, Interpro and MEDLINE.",1, 0, ,
"http://www.myexperiment.org/workflows/1992/versions/2.html","KEGG Pathways and Additional Information from BLAST","2011-03-2911:16:17","2011-03-3016:09:01","http://www.myexperiment.org/workflows/1992/download/KEGG_Pathways_and_Additional_Information_from_BLAST-v2.t2flow?version=2","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","Takes in a tab-delimited BLAST file and finds additional information about the target proteins from KEGG, Gene Ontology, Interpro and PubMed.",1, 0, ,
"http://www.myexperiment.org/workflows/1994/versions/1.html","gene subset extract","2011-03-2914:55:31","2011-03-2915:00:22","http://www.myexperiment.org/workflows/1994/download/gene_subset_extract_-v1.t2flow?version=1","/users/15427","Naser","taverna 2","/users/15427, /users/43,","Naser, Paul Fisher,","This workflow functions for matching a set of genes as a part of whole gene data set and aim to extract the subset as a separate list.",2, 0, ,
"http://www.myexperiment.org/workflows/1996/versions/1.html","Print Analysis Information to HTML","2011-03-2916:41:48","2011-04-0112:29:35","http://www.myexperiment.org/workflows/1996/download/Print_Analysis_Information_to_HTML-v1.t2flow?version=1","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","&nbsp;Takes in a lot of values and writes an HTML file to disk.",-1, 0, ,
"http://www.myexperiment.org/workflows/1996/versions/2.html","Print Analysis Information to HTML","2011-03-2916:41:48","2011-04-0112:29:35","http://www.myexperiment.org/workflows/1996/download/Print_Analysis_Information_to_HTML-v2.t2flow?version=2","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","Takes in a lot of parameters in order to construct an HTML header to display the information.",0, 0, ,
"http://www.myexperiment.org/workflows/2000/versions/1.html","Compile Protein FASTA from Target to Drug file","2011-03-3010:34:37","2011-03-3010:34:40","http://www.myexperiment.org/workflows/2000/download/Compile_Protein_FASTA_from_Target_to_Drug_file-v1.t2flow?version=1","/users/15178","Morgan Taschuk","taverna 2","/users/15178, /users/15218,","Morgan Taschuk, Andrewsmeaton,","Uses a tab-delimited file with protein target and drug information (created in Ondex) to compile a protein FASTA file including each target.",0, 0, ,
"http://www.myexperiment.org/workflows/2004/versions/1.html","Vaccine Targets Workflow","2011-03-3020:45:57","2011-04-0112:45:26","http://www.myexperiment.org/workflows/2004/download/Vaccine_Targets_Workflow-v1.t2flow?version=1","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","&nbsp;Drug re-purposing workflow",-1, 0, ,
"http://www.myexperiment.org/workflows/2004/versions/2.html","Vaccine Targets Workflow","2011-03-3020:45:57","2011-04-0112:45:26","http://www.myexperiment.org/workflows/2004/download/Vaccine_Targets_Workflow-v2.t2flow?version=2","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","The drug repurposing workflow system screens at least 20 bacterial proteomes against this set of proteins that are already being treated against using established drugs. By screening the bacterial proteomes it will be possible to find proteins of highly similar structure to those that are existing drug protein targets and so this will infer that it is highly likely that the drugs can be used as antimicrobials against these proteins of highly similar structure.   Proteomes that will be screened belong to Gram positive bacteria, with special focus on  <i>Staphylococcus aureus</i> . We look at a variety of species and strains as the company advised. A mixture of screening targets could potentially identify targets for broad-spectrum antimicrobial development. The drug repurposing workflow shows where in the KEGG pathways the proteins are active and therefore where the action of the drug will be in the biochemical pathways of the bacteria. The workflow will update the Ondex database where new information on Gene Ontology annotations, functional annotation and literature references are available. All information about each unique protein is made available in an HTML document.",0, 0, ,
"http://www.myexperiment.org/workflows/2004/versions/3.html","Vaccine Targets Workflow","2011-03-3020:45:57","2011-04-0112:45:26","http://www.myexperiment.org/workflows/2004/download/Vaccine_Targets_Workflow-v3.t2flow?version=3","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","Comparison of the genome of  <i>Bacillus anthracis</i>  to closely related strains will allow the discovery of proteins which may be involved in pathogenicity. Based on the biochemical pathways where the protein interacts, vaccines can be designed for these unique proteins. By gaining insight into the biochemical pathways that the unique proteins are involved in, the proteins can also be assessed for potential quality as vaccines.  The key components of the vaccine finding system are the following:  The vaccine finding system reads in at least two annotated whole genome sequences in EMBL or GenBank format; the source (non-pathogen) and the target ( <i>Bacillus anthracis</i> ). At this point, the workflow runs a BlastP search to compare the two strains of bacteria. Assessment of the evolutionary relationship between the two genomes ascertains whether they are closely related enough to derive meaningful comparisons. The vaccine finding system then parses the proteins from the data set that are only coded for in the target genome  <i>Bacillus anthracis</i> , giving a new data set of unique proteins which can then be assessed in the KEGG PATHWAY database. The position of the unique proteins in the pathways will give a good indication of the enzymatic role of the proteins in  <i>Bacillus anthracis</i> .  The vaccine finding system then records its findings in an HTML file, as well as additional information such as annotations from Gene Ontology, functional annotations and literature references.",1, 0, ,
"http://www.myexperiment.org/workflows/2007/versions/1.html","Diabetes_workflow","2011-03-3109:41:42","2011-03-3109:42:34","http://www.myexperiment.org/workflows/2007/download/Diabetes_workflow-v1.t2flow?version=1","/users/15456","Munasultan","taverna 2","/users/15456, /users/15449,","Munasultan, Banu,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2012/versions/1.html","Diabetes Gene and SNP identification","2011-03-3114:40:04","2011-03-3114:40:05","http://www.myexperiment.org/workflows/2012/download/Diabetes_Gene_and_SNP_identification-v1.t2flow?version=1","/users/15427","Naser","taverna 2","","",,0, 0, ,
"http://www.myexperiment.org/workflows/2013/versions/1.html","IDDM Workflow","2011-03-3114:59:03","2011-03-3115:00:38","http://www.myexperiment.org/workflows/2013/download/IDDM_Workflow-v1.t2flow?version=1","/users/15449","Banu","taverna 2","/users/15449, /users/15456,","Banu, Munasultan,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2020/versions/1.html","Vaccine drug targeting","2011-04-0109:23:14","2011-04-0109:24:37","http://www.myexperiment.org/workflows/2020/download/Vaccine_drug_targeting-v1.t2flow?version=1","/users/15175","Matthieu","taverna 2","/users/15175, /users/15177, /users/15176, /users/15214, /users/15215,","Matthieu, Alexncl, Kristiangardner123, Paulshreeve, Matt Collison,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2021/versions/1.html","Diabetes patways and SNPs","2011-04-0109:23:39","2011-04-0109:24:28","http://www.myexperiment.org/workflows/2021/download/Diabetes_patways_and_SNPs-v1.t2flow?version=1","/users/15429","Sudeep Sahadevan","taverna 2","/users/15429,","Sudeep Sahadevan,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2024/versions/1.html","Drug Repurposing Targets","2011-04-0109:33:13","2011-04-0109:34:14","http://www.myexperiment.org/workflows/2024/download/Drug_Repurposing_Targets-v1.t2flow?version=1","/users/15175","Matthieu","taverna 2","/users/15175, /users/15177, /users/15176, /users/15214, /users/15215,","Matthieu, Alexncl, Kristiangardner123, Paulshreeve, Matt Collison,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2025/versions/1.html","IDDM_Workflow","2011-04-0109:49:10","2011-04-0109:54:48","http://www.myexperiment.org/workflows/2025/download/IDDM_Workflow-v1.t2flow?version=1","/users/15456","Munasultan","taverna 2","/users/15456,","Munasultan,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2026/versions/1.html","Print Protein Information to HTML","2011-04-0112:44:20","","http://www.myexperiment.org/workflows/2026/download/Print_Protein_Information_to_HTML-v1.t2flow?version=1","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","Takes in a lot of parameters in order to construct an HTML table to display the information.",0, 0, ,
"http://www.myexperiment.org/workflows/2027/versions/1.html","UniProt to Gene Ontology","2011-04-0112:45:56","2011-04-0112:46:26","http://www.myexperiment.org/workflows/2027/download/UniProt_to_Gene_Ontology-v1.t2flow?version=1","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","Used parsed Uniprot results (see workflow  <a href=http://www.myexperiment.org/workflows/26.html rel=nofollow>http://www.myexperiment.org/workflows/26.html</a> ) to retrieve results about the protein from Gene Ontology and outputs it in text format.",1, 0, ,
"http://www.myexperiment.org/workflows/2029/versions/1.html","Use UniProt to retrieve InterPro data","2011-04-0112:50:25","","http://www.myexperiment.org/workflows/2029/download/Use_UniProt_to_retrieve_InterPro_data-v1.t2flow?version=1","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","Used parsed Uniprot results (see workflow <hr /> Used parsed Uniprot results (see workflow  <a href=http://www.myexperiment.org/workflows/26.html rel=nofollow>http://www.myexperiment.org/workflows/26.html</a> ) to retrieve results about the protein from InterPro.  <hr />",1, 0, ,
"http://www.myexperiment.org/workflows/2030/versions/1.html","Parsed UniProt to PubMed","2011-04-0112:51:20","2011-04-0112:52:02","http://www.myexperiment.org/workflows/2030/download/Parsed_UniProt_to_PubMed-v1.t2flow?version=1","/users/15178","Morgan Taschuk","taverna 2","/users/15178,","Morgan Taschuk,","Uses the parsed Uniprot results (see workflow  <a href=http://www.myexperiment.org/workflows/26.html rel=nofollow>http://www.myexperiment.org/workflows/26.html</a> ) to retrieve information from PubMed.",3, 0, ,
"http://www.myexperiment.org/workflows/2051/versions/1.html","Quality control processing of GEO datasets","2011-04-0614:59:59","2011-04-1115:46:58","","/users/221","Peter Li","taverna 2","/users/221, /users/12856,","Peter Li, Bhmecham,","The workflow performs a quality control process on gene expression data sets stored in the GeneExpression Omnibus database. The QC process is performed using Bioconductor R packages. A variety of statistics are produced by the workflow including a diagnostic plot from snm normalisation and nucleotide composition bias.",
"http://www.myexperiment.org/workflows/2051/versions/2.html","Quality control processing of GEO datasets","2011-04-0614:59:59","2011-04-1115:46:58","","/users/221","Peter Li","taverna 2","/users/221, /users/12856,","Peter Li, Bhmecham,","The workflow performs a quality control process on gene expression data sets stored in the GeneExpression Omnibus database. The QC process is performed using Bioconductor R packages. A variety of statistics are produced by the workflow including a diagnostic plot from snm normalisation and nucleotide composition bias.",
"http://www.myexperiment.org/workflows/2058/versions/1.html","Blast Report from ID","2011-04-0722:28:28","2011-04-0722:39:44","http://www.myexperiment.org/workflows/2058/download/Blast_Report_from_ID-v1.t2flow?version=1","/users/12418","Hectorj2f","taverna 2","/users/12418,","Hectorj2f,","This workflow retrieves a fasta sequence or blast report from an id. Firstly, given some inputs (e.g. ids:EDL10223.1, format:fasta, style:default and db:emblcds), it returns the sequence in fasta format associated to those inputs using the EBI's WSDbfetch web service (see  <a href=http://www.ebi.ac.uk/Tools/webservices/services/dbfetch rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/services/dbfetch</a> ). Next, we obtain a Blast report from this fasta sequence and some others parameters. The final result in that case corresponds with the same fasta sequence introduced as input parameter to the &quot;run&quot; processor. However, it could retrieve the blast report in XML format by changing BeanShell &quot;process_ResultTypes&quot;&nbsp;&nbsp; condition from the value &quot;sequence&quot; to &quot;xml&quot;.",-1, 0, ,
"http://www.myexperiment.org/workflows/2066/versions/1.html","GRASS-GIS orchestration using pyWPS","2011-04-1809:50:43","2011-04-2515:21:35","http://www.myexperiment.org/workflows/2066/download/GRASS-GIS_orchestration_using_pyWPS-v1.t2flow?version=1","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","Generic workflow that run r.watershed, with auxiliary services: r.math and geotiff2png. Watershed accumulation is calculated from DEM using r.watershed, the accumulation result is then filtered using r.math with equation: output=(if())  <hr /> Generic workflow that run r.watershed, with auxiliary services: r.math and geotiff2png. Watershed accumulation is calculated from DEM using r.watershed, the accumulation result is then filtered using r.math with equation: output=(if(a&gt;100,a,null())) The resulting geotiff is converted into a PNG for easy analysis in Taverna. Note: The DEM used contains values below 0, this affect the quality of the final result.",0, 0, ,
"http://www.myexperiment.org/workflows/2066/versions/2.html","GRASS-GIS orchestration using pyWPS","2011-04-1809:50:43","2011-04-2515:21:35","http://www.myexperiment.org/workflows/2066/download/GRASS-GIS_orchestration_using_pyWPS-v2.t2flow?version=2","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","Generic workflow that run r.watershed, with auxiliary services: r.math and geotiff2png.  Watershed accumulation is calculated from DEM using r.watershed, the accumulation result is then filtered using r.math with equation:output=(if(a&gt;10,a,null())) Generic workflow that run r.watershed, with auxiliary services: r.math and geotiff2png.  Watershed accumulation is calculated from DEM using r.watershed, the accumulation result is then filtered using r.math with equation: output=(if(a&gt;10,a,null()))   The resulting geotiff is converted into a PNG for easy analysis in Taverna.  Note: The DEM used contains values below 0, this affect the quality of the final result.",0, 0, ,
"http://www.myexperiment.org/workflows/2067/versions/1.html","M_Super_aln_boot_phylo_New","2011-04-1810:54:14","2011-04-1810:54:17","http://www.myexperiment.org/workflows/2067/download/M_Super_aln_boot_phylo_New-v1.t2flow?version=1","/users/1601","Achille Zappa","taverna 2","/users/1601,","Achille Zappa,","This workflow performs a generic protein sequence analysis. A multiple sequence alignment and finally a phylogenetic analysis. <hr /> This workflow performs a generic protein sequence analysis. In order to do that a novel protein sequence enters into the software along with a list of known protein identifiers chosen by the biologist to perform a homology search, followed by a multiple sequence alignment and finally a phylogenetic analysis. <hr /> This workflow performs parallel generic protein sequence analysis. In order to do that a list of known protein identifiers chosen by the biologist enters into the software to perform different multiple sequence alignments and finally  phylogenetic analysis.",2, 0, ,
"http://www.myexperiment.org/workflows/2079/versions/1.html","Remove_Duplicates","2011-04-2112:36:37","2011-04-2113:59:52","http://www.myexperiment.org/workflows/2079/download/Remove_Duplicates-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow removes any duplicates from a list of inputs, merges the unique values, and then removes any null values.",0, 0, ,
"http://www.myexperiment.org/workflows/2082/versions/1.html","Gene expression interpretation by the Global Test","2011-04-2608:31:51","2011-04-2608:31:52","","/users/18","Marco Roos","taverna 2","/users/18,","Marco Roos,","This workflow adds meaning to gene expresion values by performing a standard and a literature weighted Global Test. Gene expression is expected to be from Affymetrix microarrays, for which an RMA normalization and entrez Gene ID mapping/summation is performed. Original workflow is by Dennis Leenheer, edits by Marco Roos. Scripts by Kristina Hettne, acknowledging Rob Jellier, Jelle Goeman, and Peter-Bram 't Hoen. The workflow was created for the LUMC BioSemantics group, part of the Human Genetics Department, Leiden University Medical Centre.",
"http://www.myexperiment.org/workflows/2083/versions/1.html","[untitled]","2011-04-2614:50:37","2011-04-2615:04:28","http://www.myexperiment.org/workflows/2083/download/_untitled_-v1.t2flow?version=1","/users/11610","Dennis Leenheer","taverna 2","/users/11610,","Dennis Leenheer,","This workflow allows the user to search for processes that are involved with a certain gene. Using microarray-files (CEL-files), consisting of wild type and KO mice to which a stimulant is induced, the user can get an idea of the processes involved. (This is done using the global test and the literature weighted global test.) The results are then given as a text-file. Warning: workflow is not working (needs some revisions), all input is currently hardcoded! (You will have to change the file-locations and file-names by yourself! Also this version still uses the test-concept weights, do not forget to adjust them to your needs...",-1, 0, ,
"http://www.myexperiment.org/workflows/2088/versions/1.html","PUT data into RapidAnalytics","2011-04-2709:50:52","2011-12-1316:04:06","http://www.myexperiment.org/workflows/2088/download/PUT_data_into_RapidAnalytics-v1.t2flow?version=1","/users/267","James Eales","taverna 2","","","Use the example value for the input port",-1, 0, ,
"http://www.myexperiment.org/workflows/2089/versions/1.html","Voronoi polygon generation using GRASS-GIS (v.voronoi)","2011-04-2716:18:17","2011-04-2716:18:19","http://www.myexperiment.org/workflows/2089/download/Voronoi_polygon_generation_using_GRASS-GIS__v.voronoi_-v1.t2flow?version=1","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","Generic example on how to deal with vectorial data. Major pitfall is the need to process ProcessOutputs using Xpath plugin. A random point file in GML 2.1.2 is sent to the v.voronoi service and after it is sent to a service that runs v.out.svg generating a SVG image that can be rendered in Taverna (need to set output to SVG image)",0, 0, ,
"http://www.myexperiment.org/workflows/2090/versions/1.html","Agglomerative clustering of a GEO dataset using RapidAnalytics","2011-04-2814:12:33","2011-12-1316:00:52","http://www.myexperiment.org/workflows/2090/download/Agglomerative_clustering_of_a_GEO_dataset_using_RapidAnalytics-v1.t2flow?version=1","/users/267","James Eales","taverna 2","/users/267,","James Eales,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2090/versions/2.html","Agglomerative clustering of a GEO dataset using RapidAnalytics","2011-04-2814:12:33","2011-12-1316:00:52","http://www.myexperiment.org/workflows/2090/download/Agglomerative_clustering_of_a_GEO_dataset_using_RapidAnalytics-v2.t2flow?version=2","/users/267","James Eales","taverna 2","/users/267,","James Eales,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2091/versions/1.html","Distance heatmap of GEO dataset produced by RapidAnalytics","2011-04-2814:15:33","2011-12-1316:00:25","http://www.myexperiment.org/workflows/2091/download/Distance_heatmap_of_GEO_dataset_produced_by_RapidAnalytics-v1.t2flow?version=1","/users/267","James Eales","taverna 2","/users/267,","James Eales,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2091/versions/2.html","Distance heatmap of GEO dataset produced by RapidAnalytics","2011-04-2814:15:33","2011-12-1316:00:25","http://www.myexperiment.org/workflows/2091/download/Distance_heatmap_of_GEO_dataset_produced_by_RapidAnalytics-v2.t2flow?version=2","/users/267","James Eales","taverna 2","/users/267,","James Eales,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2092/versions/1.html","CGR from multiple fasta files","2011-04-2915:26:53","2011-04-2915:33:03","http://www.myexperiment.org/workflows/2092/download/CGR_from_multiple_fasta_files-v1.t2flow?version=1","/users/1938","cory (Kazuki Oshita)","taverna 2","/users/1938,","cory (Kazuki Oshita),","&nbsp;The workflow generates Chaos Game&nbsp;Represenations (CGR) image from multiple fasta files. See <span class=Apple-style-span>&nbsp;<span class=Apple-style-span><a href=http://www.g-language.org/wiki/cgr rel=nofollow>http://www.g-language.org/wiki/cgr</a> for more information about the Chaos Game Representations.</span></span>",-1, 0, ,
"http://www.myexperiment.org/workflows/2093/versions/1.html","Classification of GEO assays using RapidAnalytics","2011-05-0414:40:17","2011-12-1316:01:13","http://www.myexperiment.org/workflows/2093/download/Classification_of_GEO_assays_using_RapidAnalytics-v1.t2flow?version=1","/users/267","James Eales","taverna 2","/users/267,","James Eales,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2093/versions/2.html","Classification of GEO assays using RapidAnalytics","2011-05-0414:40:17","2011-12-1316:01:13","http://www.myexperiment.org/workflows/2093/download/Classification_of_GEO_assays_using_RapidAnalytics-v2.t2flow?version=2","/users/267","James Eales","taverna 2","/users/267,","James Eales,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2094/versions/1.html","[untitled]","2011-05-0513:01:19","2011-05-0513:01:31","http://www.myexperiment.org/workflows/2094/download/_untitled_-v1.t2flow?version=1","/users/16302","Yahmet82","taverna 2","/users/16302,","Yahmet82,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2105/versions/1.html","External Tool: Numerically adding two values with &#39;bc&#39;.","2011-05-0616:11:24","2011-05-0616:22:18","http://www.myexperiment.org/workflows/2105/download/External_Tool__Numerically_adding_two_values_with__bc_.-v1.t2flow?version=1","/users/1169","Steffen MÃ¶ller","taverna 2","/users/1169,","Steffen MÃ¶ller,","The workflow is an examples for the External Tools / UseCase plugin to integrate external tools. It wraps the &quot;bc&quot; command line calculator. Internally, it executes the following script: To develop workflows in a similar manner, i.e. avoiding the specification of beans and gain complete flexibility for local or remote execution of the workflow, please follow instructions on  <a href=http://www.mygrid.org.uk/dev/wiki/display/developer/Calling+external+commands+from+Taverna rel=nofollow>http://www.mygrid.org.uk/dev/wiki/display/developer/Calling+external+commands+from+Taverna</a> .",0, 0, ,
"http://www.myexperiment.org/workflows/2106/versions/1.html","One sentence per line","2011-05-0616:52:35","2011-12-1315:58:54","http://www.myexperiment.org/workflows/2106/download/One_sentence_per_line-v1.t2flow?version=1","/users/267","James Eales","taverna 2","/users/267,","James Eales,","This workflow accepts a plain text input and provides a single text document per input containing one sentence per line. &nbsp;Newline characters are removed from the original input. The OpenNLP sentence splitter is used to split the text, this is provided by University of Manchester Web Services.",-1, 0, ,
"http://www.myexperiment.org/workflows/2118/versions/1.html","Dot viewing","2011-05-1217:25:39","","http://www.myexperiment.org/workflows/2118/download/Dot_viewing-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/2120/versions/1.html","Generate Atom Signatures of molecules given SDF as input","2011-05-1317:14:06","2011-05-1319:47:24","http://www.myexperiment.org/workflows/2120/download/Generate_Atom_Signatures_of_molecules_given_SDF_as_input-v1.t2flow?version=1","/users/10069","Kalai","taverna 2","/users/10069,","Kalai,","<b>Reference:</b> <b>Natural Product-likeness Score and Its Application for Prioritization of Compound</b> <b>Libraries</b> <i>Peter Ertl,* Silvio Roggo, and Ansgar Schuffenhauer</i> <i>Novartis Institutes for BioMedical Research, CH-4002 Basel, Switzerland</i> <span class=s1><a href=http://peter-ertl.com/reprints/Ertl-JCIM-48-68-2008.pdf rel=nofollow>http://peter-ertl.com/reprints/Ertl-JCIM-48-68-2008.pdf</a></span> &nbsp;&nbsp;&nbsp;The natural product likeness scorer implemented by Peter Ertl was originally devised to screen large compound libraries for natural product likeness in drug designing studies. His work is re-implemented using open source and open data to validate natural product likeness of theoretical metabolite structures while predicting metabolomes. &nbsp;&nbsp;&nbsp;These workflows also finds its application in&nbsp; <i>insilico</i> &nbsp;drug designing studies to pre screen candidates for natural product likeness - the original application proposed by Dr. Peter Ertl. &nbsp; Generate Atom Signatures : - CDK -Taverna Plugin 0.5.1 <a href=http://www.ts-concepts.de/cdk-taverna2/plugin/ rel=nofollow>http://www.ts-concepts.de/cdk-taverna2/plugin/</a> <span class=s2>&nbsp;</span> <b>&nbsp;-&nbsp;</b> This workflow generates atom signatures for individual compounds given the Structural Data File as input.&nbsp; &nbsp; - The atom signatures for natural products, synthetic molecules and other structural data are calculated individually using this workflow &nbsp; <b>Description of input ports :</b> <b>Input_SDF</b> &nbsp;: The input SDF file containing compounds of interest <b>Note:</b> While passing file as input for the above port it could be passed as list of many files or single file.&nbsp; <b>Iterations&nbsp;</b> : Number of molecules to be pumped in for each iteration by the SDF file reader <b>signatures_file</b> &nbsp;: file name with full path for saving the atom signatures <b>Tagged_SDFile</b> &nbsp;: file name with full path to save the SDF file tagged with Universal Unique IDentifier (UUID). Molecules while progressing through curation steps may break down into fragments. Tagging is done to keep track of molecules while they go through curation steps and could be used to assemble them back during scoring process. <b>Curated_SDF:</b> &nbsp;file name with full path to store the structures that emerge out as curated ones. This SDF could be later used to view the curated structures by generating their JPEGS using CDK-Taverna/Renderer components or other visualizer like Bioclipse.&nbsp; &nbsp; &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/2121/versions/1.html","Scoring small molecules for metabolite likeness/ Natural product likeness","2011-05-1317:22:28","2012-03-1816:41:39","http://www.myexperiment.org/workflows/2121/download/Scoring_small_molecules_for_metabolite_likeness__Natural_product_likeness-v1.t2flow?version=1","/users/10069","Kalai","taverna 2","/users/10069,","Kalai,","<b>Prerequisite:&nbsp;</b> &nbsp; - CDK -Taverna Plugin 0.5.1 &lt;meta /&gt; <span class=Apple-style-span><a href=http://www.ts-concepts.de/cdk-taverna2/plugin/ class=external free rel=nofollow>http://www.ts-concepts.de/cdk-taverna2/plugin/</a></span> - To run this workflow the  <b>atom_signatures</b>  file of Natural product(NP), Synthetic Molecules(SM) and query structures are needed - This could be generated from GenerateAtomSignatures.t2flow &lt;meta&gt; <span class=Apple-style-span><a href=http://www.myexperiment.org/workflows/2120/download?version=1 rel=nofollow>http://www.myexperiment.org/workflows/2120/download?version=1</a></span> &lt;/meta&gt; &nbsp; <b>Description of input ports :</b> <b>NP_file</b> : needs precomputed Atom_signatures of desired Natural product structural data <b>SM_file</b> : needs precomputed Atom_signatures of desired Synthetic molecule structural data <b>Query_file</b> :&nbsp; needs precomputed Atom_signatures of desired query compound structural data <b>Note:</b> While passing file as input for all the above ports it could be passed as list of many files or single file.&nbsp;&nbsp; <b>Score_file</b> : File name to write out the computed natural product likeness scores of query structural data <b>Fragments_SDF: </b> File name to write out SDF file that has fragments corresponding to scores. Here every atom_signature generated for a molecule is converted into structure and the score generated by the particular fragment is stored as its property. In this way using visualizer we could see the fragments corresponding to score.",-1, 0, ,
"http://www.myexperiment.org/workflows/2121/versions/2.html","Scoring small molecules for metabolite likeness/ Natural product likeness","2011-05-1317:22:28","2012-03-1816:41:39","http://www.myexperiment.org/workflows/2121/download/Scoring_small_molecules_for_metabolite_likeness__Natural_product_likeness-v2.t2flow?version=2","/users/10069","Kalai","taverna 2","/users/10069,","Kalai,","&nbsp; <b>Prerequisite:&nbsp;</b> <span>&nbsp;</span> - CDK -Taverna Plugin 0.5.1 &lt;meta&gt; <a href=http://www.ts-concepts.de/cdk-taverna2/plugin/ class=external free rel=nofollow>http://www.ts-concepts.de/cdk-taverna2/plugin/</a> &lt;/meta&gt; - To run this workflow the&nbsp; <b>atom_signatures</b> &nbsp;file of Natural product(NP), Synthetic Molecules(SM) and query structures are needed - This could be generated from GenerateAtomSignatures.t2flow &lt;meta&gt; <a href=http://www.myexperiment.org/workflows/2120/download?version=1 rel=nofollow>http://www.myexperiment.org/workflows/2120/download?version=1</a> &lt;/meta&gt; &nbsp; <b>Description of input ports :</b> <b>NP_file</b> : needs precomputed Atom_signatures of desired Natural product structural data <b>SM_file</b> : needs precomputed Atom_signatures of desired Synthetic molecule structural data <b>Query_file</b> :&nbsp; needs precomputed Atom_signatures of desired query compound structural data <b>Note:</b> While passing file as input for all the above ports it could be passed as list of many files or single file. Since, it loads signatures into memory high heap-space is required. <b>Score_file</b> : File name to write out the computed natural product likeness scores of query structural data <b>Fragments_SDF:&nbsp;</b> File name to write out SDF file that has fragments corresponding to scores. Here every atom_signature generated for a molecule is converted into structure and the score generated by the particular fragment is stored as its property. In this way using visualizer we could see the fragments corresponding to score.",-1, 0, ,
"http://www.myexperiment.org/workflows/2122/versions/1.html","Plotting distribution of natural product likeness scores","2011-05-1317:34:58","2011-05-1317:35:08","http://www.myexperiment.org/workflows/2122/download/Plotting_distribution_of_natural_product_likeness_scores-v1.t2flow?version=1","/users/10069","Kalai","taverna 2","/users/10069,","Kalai,","&nbsp; <span class=Apple-style-span><b>Prerequisite:&nbsp;</b></span> &lt;meta /&gt; <span class=Apple-style-span></span> CDK -Taverna Plugin 0.5.1 <a href=http://www.ts-concepts.de/cdk-taverna2/plugin/ class=external free rel=nofollow>http://www.ts-concepts.de/cdk-taverna2/plugin/</a> - To run this workflow you need a Score file which is written to text file.&nbsp; - This could be generated from ScorerActivity.t2flow &lt;meta /&gt; <span class=Apple-style-span><a href=http://www.myexperiment.org/workflows/2121/download?version=1 rel=nofollow>http://www.myexperiment.org/workflows/2121/download?version=1</a></span> &nbsp; <b>Description of input ports :</b> <b>score_file: </b> Path to file name that has pre computed scores. <b>Note:</b> While passing file as input it could be passed as list of many files or single file.&nbsp; <b>file</b> : File name to write out the image of the distribution plot.",-1, 0, ,
"http://www.myexperiment.org/workflows/2124/versions/1.html","Molecular Interactions from IntAct PSICQUIC service (SOAP)","2011-05-1707:09:30","2011-07-2015:14:56","http://www.myexperiment.org/workflows/2124/download/Molecular_Interactions_from_IntAct_PSICQUIC_service__SOAP_-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Get molecular interaction data in psi-mitab25 format from IntAct through its PSICQUIC service. As input you can use an Uniprot Acc like &quot;P99999&quot; or a MIQL query like &quot;alias:(KHDRBS1 OR HCK)&quot;. This workflow finds by itself how many queries needs to make (SOAP service limited to 200 binary interactions per call) to be able to return all the results in one file.",1, 0, ,
"http://www.myexperiment.org/workflows/2124/versions/2.html","Molecular Interactions from IntAct PSICQUIC service (SOAP)","2011-05-1707:09:30","2011-07-2015:14:56","http://www.myexperiment.org/workflows/2124/download/Molecular_Interactions_from_IntAct_PSICQUIC_service__SOAP_-v2.t2flow?version=2","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Get molecular interaction data in psi-mitab25 from IntAct through its PSICQUIC service. As input you can use an Uniprot Acc like &quot;P99999&quot; or a MIQL query like &quot;alias:(KHDRBS1 OR HCK)&quot;. This workflow finds by itself how many queries needs to make (SOAP service limited to 200 binary interactions per call) to be able to return all the results in one file.",0, 0, ,
"http://www.myexperiment.org/workflows/2125/versions/1.html","Example for external tools with gzip and gunzip","2011-05-1809:22:50","2011-05-1809:22:54","http://www.myexperiment.org/workflows/2125/download/Example_for_external_tools_with_gzip_and_gunzip-v1.t2flow?version=1","/users/1169","Steffen MÃ¶ller","taverna 2","/users/1169, /users/30,","Steffen MÃ¶ller, Alan Williams,","This workflow is self-contained. It has a fixed URL from which a text file is downloaded (output as Original_file). That file is gzipped (output as Compressed_File) and then gunzipped again (output as Decompressed_File). The workflow wraps external tools from taverna.nordugrid.org and needs a beta version of Taverna 2.3 or later.",0, 0, ,
"http://www.myexperiment.org/workflows/2126/versions/1.html","EBI PICR, find cross-references for protein accessions","2011-05-1809:36:26","2011-05-2917:35:20","http://www.myexperiment.org/workflows/2126/download/EBI_PICR__find_cross-references_for_protein_accessions-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Find cross-references (based on 100% sequence identity) for protein accessions from more than 95 distinct databases. For instance input a list of IPI accessions and find cross-references for Swissprot and Ensembl. Mappings can be limited by source database, taxonomic ID and activity status.",2, 0, ,
"http://www.myexperiment.org/workflows/2126/versions/2.html","EBI PICR, find cross-references for protein accessions","2011-05-1809:36:26","2011-05-2917:35:20","http://www.myexperiment.org/workflows/2126/download/EBI_PICR__find_cross-references_for_protein_accessions-v2.t2flow?version=2","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Find cross-references (based on 100% sequence identity) for protein accessions from more than 95 distinct databases. For instance input a list of IPI accessions and find cross-references for Swissprot and Ensembl. Mappings can be limited by source database, taxonomic ID and activity status.",0, 0, ,
"http://www.myexperiment.org/workflows/2127/versions/1.html","Get names of proteins similar to RNA binding proteins (Simple example SADI workflow)","2011-05-1815:24:56","2011-05-1815:39:02","http://www.myexperiment.org/workflows/2127/download/Get_names_of_proteins_similar_to_RNA_binding_proteins__Simple_example_SADI_workflow_-v1.t2flow?version=1","/users/5707","hindlem","taverna 2","/users/5707,","hindlem,","A very simple demo workflow using some existing SADI services. It finds UniProt proteins of GO function &quot;RNA Binding&quot;, it then runs a BLAST service to find similar UniProt proteins and then outputs their names.",-1, 0, ,
"http://www.myexperiment.org/workflows/2131/versions/1.html","get human and mouse phenotypes for a gene","2011-05-2015:18:50","2012-03-2909:01:06","http://www.myexperiment.org/workflows/2131/download/get_human_and_mouse_phenotypes_for_a_gene-v1.t2flow?version=1","/users/16552","Tim Beck","taverna 2","/users/16552,","Tim Beck,","This workflow gets phenotype annotations associated with human genes and the mouse orthologs from human (GWAS Central) and mouse (EuroPhenome and MGI) databases.",3, 0, ,
"http://www.myexperiment.org/workflows/2131/versions/2.html","get human and mouse phenotypes for a gene","2011-05-2015:18:50","2012-03-2909:01:06","http://www.myexperiment.org/workflows/2131/download/get_human_and_mouse_phenotypes_for_a_gene-v2.t2flow?version=2","/users/16552","Tim Beck","taverna 2","/users/16552,","Tim Beck,","This workflow gets phenotype annotations associated with human genes and the mouse orthologs from human (GWAS Central) and mouse (EuroPhenome and MGI) databases.",3, 0, ,
"http://www.myexperiment.org/workflows/2139/versions/1.html","Download Structures from PubChem given chemical names","2011-05-2413:13:52","2011-05-2414:19:24","http://www.myexperiment.org/workflows/2139/download/Download_Structures_from_PubChem_given_chemical_names-v1.t2flow?version=1","/users/10069","Kalai","taverna 2","/users/10069, /users/937,","Kalai, Michael Gerlich,","This workflow takes the input file containing chemical names and returns a single SDF file&nbsp;of structures. The names are searched against pubchem compounds via e-search. If the compound name is found an XML file containing PubChem ID is returned.The max return compound_ID is set to 1 which could be increased. If the compound name is not found then no ID is returned.&nbsp; The pubchem compound_ID is then used to download structures from PubChem. &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/2152/versions/1.html","Pathways and Gene annotations for QTL region","2011-05-2711:06:11","2011-05-2711:06:52","http://www.myexperiment.org/workflows/2152/download/Pathways_and_Gene_annotations_for_QTL_region-v1.t2flow?version=1","/users/43","Paul Fisher","taverna 2","/users/43,","Paul Fisher,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in rice, Oryza sativa. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniGene identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",0, 0, ,
"http://www.myexperiment.org/workflows/2153/versions/1.html","Molecular Interactions from IntAct PSICQUIC service (REST)","2011-05-2901:32:18","2011-10-0500:20:00","http://www.myexperiment.org/workflows/2153/download/Molecular_Interactions_from_IntAct_PSICQUIC_service__REST_-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Get molecular interaction data in psi-mitab25 from IntAct through its REST PSICQUIC service. As input you can use an Uniprot Acc like P99999 or a MIQL query like alias:KHDRBS1.",0, 0, ,
"http://www.myexperiment.org/workflows/2153/versions/2.html","Molecular Interactions from IntAct PSICQUIC service (REST)","2011-05-2901:32:18","2011-10-0500:20:00","http://www.myexperiment.org/workflows/2153/download/Molecular_Interactions_from_IntAct_PSICQUIC_service__REST_-v2.t2flow?version=2","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Get molecular interaction data in psi-mitab25 from IntAct through its REST PSICQUIC service. As input you can use an Uniprot Acc like P99999 or a MIQL query like alias:KHDRBS1.",0, 0, ,
"http://www.myexperiment.org/workflows/2154/versions/1.html","Find PRIDE experiments by GO","2011-05-2919:07:59","2011-05-2919:08:01","http://www.myexperiment.org/workflows/2154/download/Find_PRIDE_experiments_by_GO-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Find PRIDE experiments in Human with related information like Cell Type and Tissue location filtering results by Gene Ontology terms. This is an example of how to use the PRIDE Biomart service in Taverna. Many other options are possible by modifying the filters and attributes of this service.",0, 0, ,
"http://www.myexperiment.org/workflows/2155/versions/1.html","Find Reactome pathways and reactions by GO","2011-05-2919:09:23","2011-05-2919:09:25","http://www.myexperiment.org/workflows/2155/download/Find_Reactome_pathways_and_reactions_by_GO-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Find Reactome pathways and reactions (names and accessions) in Human querying by a Gene Ontology term. This is an example of how to use the Reactome Biomart service in Taverna. Many other possibilities are possible by modifying the filters and attributes options of the service.",0, 0, ,
"http://www.myexperiment.org/workflows/2156/versions/1.html","Find Biological Models by GO.","2011-05-2921:44:22","2011-05-2921:44:23","http://www.myexperiment.org/workflows/2156/download/Find_Biological_Models_by_GO.-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Find Biological Models (Ids and Names) from Biomodels querying by Gene Ontology terms.",0, 0, ,
"http://www.myexperiment.org/workflows/2157/versions/1.html","DAS sequence retrieval","2011-05-3001:20:35","2011-05-3001:26:47","http://www.myexperiment.org/workflows/2157/download/DAS_sequence_retrieval-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Retrieve Protein or Genome sequences using the Distributed Annotation System (DAS).",0, 0, ,
"http://www.myexperiment.org/workflows/2157/versions/2.html","DAS sequence retrieval","2011-05-3001:20:35","2011-05-3001:26:47","http://www.myexperiment.org/workflows/2157/download/DAS_sequence_retrieval-v2.t2flow?version=2","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Retrieve Protein or Genome sequences using the Distributed Annotation System (DAS).",0, 0, ,
"http://www.myexperiment.org/workflows/2158/versions/1.html","DAS sequence retrieval and parsing with JDAS","2011-05-3003:12:23","2011-05-3003:14:03","http://www.myexperiment.org/workflows/2158/download/DAS_sequence_retrieval_and_parsing_with_JDAS-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Retrieve Protein or Genome sequences using the Distributed Annotation System (DAS) and create your own text output by modifying the JDAS component. To be able to use this workflow with JDAS, copy this file &hellip;  <a href=http://www.ebi.ac.uk/~maven/m2repo/uk/ac/ebi/das/jdas/1.0.3/jdas-1.0.3.jar rel=nofollow>http://www.ebi.ac.uk/~maven/m2repo/uk/ac/ebi/das/jdas/1.0.3/jdas-1.0.3.jar</a>  &hellip; to the lib folder inside the Taverna application. This jar file is a dependency needed to parse DAS outputs.",0, 0, ,
"http://www.myexperiment.org/workflows/2159/versions/1.html","DAS features retrieval","2011-06-0117:10:43","2011-06-0117:57:45","http://www.myexperiment.org/workflows/2159/download/DAS_features_retrieval-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Retrieve Protein or Genome features (annotations) using the Distributed Annotation System (DAS).",0, 0, ,
"http://www.myexperiment.org/workflows/2159/versions/2.html","DAS features retrieval","2011-06-0117:10:43","2011-06-0117:57:45","http://www.myexperiment.org/workflows/2159/download/DAS_features_retrieval-v2.t2flow?version=2","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Retrieve Protein or Genome features (annotations) using the Distributed Annotation System (DAS).",0, 0, ,
"http://www.myexperiment.org/workflows/2160/versions/1.html","DAS features retrieval and parsing with JDAS","2011-06-0118:06:35","2011-06-0210:24:13","http://www.myexperiment.org/workflows/2160/download/DAS_features_retrieval_and_parsing_with_JDAS-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,",,0, 0, ,
"http://www.myexperiment.org/workflows/2160/versions/2.html","DAS features retrieval and parsing with JDAS","2011-06-0118:06:35","2011-06-0210:24:13","http://www.myexperiment.org/workflows/2160/download/DAS_features_retrieval_and_parsing_with_JDAS-v2.t2flow?version=2","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,",,0, 0, ,
"http://www.myexperiment.org/workflows/2167/versions/1.html","blastn and blastx","2011-06-0815:24:57","2011-06-0815:37:27","http://www.myexperiment.org/workflows/2167/download/blastn_and_blastx-v1.t2flow?version=1","/users/17001","Niek","taverna 2","/users/17001,","Niek,","This workflow accepts an url of a fasta file as input and performs an NCBI blastn at the EBI against the bacteria database and an NCBI blastx against the uniref90 database.&nbsp; From the blast results of the blastx the hit with the lowest e-value is taken and the GO is returned. Output is blastx and blastn results and GO from the first hit of the blastx. &nbsp; Based on Katy Wolstencroft &amp;  Hamish McWilliam EBI_NCBI_BLAST <span class=title> </span> <a href=http://www.myexperiment.org/workflows/1765.html rel=nofollow>http://www.myexperiment.org/workflows/1765.html</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2169/versions/1.html","Retrieval of molecular interactions within a set of given molecules","2011-06-1014:35:39","2011-06-1014:35:41","http://www.myexperiment.org/workflows/2169/download/Retrieval_of_molecular_interactions_within_a_set_of_given_molecules-v1.t2flow?version=1","/users/17058","Skerrien","taverna 2","/users/17058,","Skerrien,","Description of the flow steps: <ol><li value=1>split the list of identifiers using allows separators,</li><li value=2>build a MIQL query with these identifier in preparation of running a PSICQUIC request,</li><li value=3>Retrieve molecular interaction from IntAct's PSICQUIC service using the generated MIQL statement,</li><li value=4>filter the list of returned MITAB using the list of identifiers and only keep those lines where both participating molecules are members of the input list,</li><li value=5>return the count and list of filtered MITAB lines.</li></ol>",0, 0, ,
"http://www.myexperiment.org/workflows/2174/versions/1.html","Detect compressed TIFF files and remove the compression","2011-06-1510:45:45","2012-03-0807:58:54","http://www.myexperiment.org/workflows/2174/download/Detect_compressed_TIFF_files_and_remove_the_compression-v1.t2flow?version=1","/users/4707","Sven","taverna 2","/users/4707,","Sven,","The workflow takes a list of TIFF images as input, identifies the Group 4 Fax comressed TIFF images and converts them to uncompressed TIFF images using GIMP. Finally it characterises the converted image.",0, 0, ,
"http://www.myexperiment.org/workflows/2174/versions/2.html","Detect compressed TIFF files and remove the compression","2011-06-1510:45:45","2012-03-0807:58:54","http://www.myexperiment.org/workflows/2174/download/Detect_compressed_TIFF_files_and_remove_the_compression-v2.t2flow?version=2","/users/4707","Sven","taverna 2","/users/4707,","Sven,","The workflow takes a list of TIFF images as input, identifies the Group 4 Fax comressed TIFF images and converts them to uncompressed TIFF images using GIMP. Finally it characterises the converted image.",0, 0, ,
"http://www.myexperiment.org/workflows/2174/versions/3.html","Detect compressed TIFF files and remove the compression","2011-06-1510:45:45","2012-03-0807:58:54","http://www.myexperiment.org/workflows/2174/download/Detect_compressed_TIFF_files_and_remove_the_compression-v3.t2flow?version=3","/users/4707","Sven","taverna 2","/users/4707,","Sven,","The workflow takes a list of TIFF images as input, identifies the &quot;Group 4 Fax&quot; comressed TIFF images and converts them to uncompressed TIFF images using convert. Finally it characterises the converted image. This version of the workflow replaces the web services of the original workflow with tool services.",0, 0, ,
"http://www.myexperiment.org/workflows/2176/versions/1.html","Extract histogram features from image file","2011-06-1617:09:20","2012-04-0408:01:37","http://www.myexperiment.org/workflows/2176/download/Extract_histogram_features_from_image_file-v1.t2flow?version=1","/users/17168","Roman","taverna 2","/users/17168,","Roman,","As a template for creation of image workflows was used xa-toolwrapper project from Sven Schlarb ( <a href=https://github.com/openplanets/scape/tree/master/xa-toolwrapper rel=nofollow>https://github.com/openplanets/scape/tree/master/xa-toolwrapper</a> ). This project enables creation of WSDL web service that wraps command line tool like &lsquo;extractFeatures&rsquo; or &lsquo;create&rsquo;. The workflow for &lsquo;extractFeatures&rsquo; tool has two input parameters. The URL to the input image file and the number of histogram bins as integer. This workflow extracts histogram features from passed image file. The output is an XML file with histogram data. Also the workflow provides output of processing log, return code (0 if successful) and image data in graphic form.",-1, 0, ,
"http://www.myexperiment.org/workflows/2177/versions/1.html","Compare histogram features of image files","2011-06-1617:22:04","2012-04-0408:00:53","http://www.myexperiment.org/workflows/2177/download/Compare_histogram_features_of_image_files-v1.t2flow?version=1","/users/17168","Roman","taverna 2","/users/17168,","Roman,","As a template for creation of image workflows was used xa-toolwrapper project from Sven Schlarb ( <a href=https://github.com/openplanets/scape/tree/master/xa-toolwrapper rel=nofollow>https://github.com/openplanets/scape/tree/master/xa-toolwrapper</a> ).  This project enables creation of WSDL web service that wraps command  line tool like &lsquo;extractFeatures&rsquo; or &lsquo;create&rsquo;. The workflow for &lsquo;compare&rsquo; tool has three input parameters. These are two URLs to the XML histogram files that comprise information about image features. These files are acquired using &lsquo;extractFeatures&rsquo; tool. The third parameter is an image histogram metric string for histogram comparison. Following metrics exist: <br /> &bull;&nbsp;&nbsp;&nbsp; CV_COMP_CHISQRCV_COMP_CORREL <br /> &bull;&nbsp;&nbsp;&nbsp; CV_COMP_INTERSECT <br /> &bull;&nbsp;&nbsp;&nbsp; CV_COMP_BHATTACHARYYA.  <br /> This workflow extracts histogram features from passed image file. The output is an XML file with comparison result. Also the workflow provides output of processing log and return code (0 if successful). <br /> &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/2178/versions/1.html","[untitled]","2011-06-1916:16:21","2011-06-1916:16:50","http://www.myexperiment.org/workflows/2178/download/_untitled_-v1.t2flow?version=1","/users/17230","Merdmann","taverna 2","/users/17230,","Merdmann,","This is simly a test fortest",-1, 0, ,
"http://www.myexperiment.org/workflows/2181/versions/1.html","Associate hessi flares with active regions","2011-06-2212:02:12","2012-07-1009:56:14","http://www.myexperiment.org/workflows/2181/download/Associate_hessi_flares_with_active_regions-v1.t2flow?version=1","/users/9056","Donal Fellows","taverna 2","/users/9056,","Donal Fellows,","This workflow is querying the HFC ActiveRegions list and HEC hessi_flare list.It requires a time periode and a search radius arround the centre of an Active Region as inputsIt produces two outputs: HFCout is a modified VOTable where a field is added with the number of associated hessi flares. combined_output is a 2 dimensional list with an VOTable for each Active region and one with an VOTable for all associated flares for that Active Region. <hr /> This workflow is querying the HFC ActiveRegions list and HEC hessi_flare list.It requires a time periode and a search radius arround the centre of an Active Region as inputsIt produces two outputs: AnnotatedFeatureTable is a modified VOTable where a field is added with the number of associated hessi flares. CombinedTable is a 2 dimensional list with an VOTable for each Active region and one with an VOTable for all associated flares for that Active Region.",0, 0, ,
"http://www.myexperiment.org/workflows/2181/versions/2.html","Associate hessi flares with active regions","2011-06-2212:02:12","2012-07-1009:56:14","http://www.myexperiment.org/workflows/2181/download/Associate_hessi_flares_with_active_regions-v2.t2flow?version=2","/users/9056","Donal Fellows","taverna 2","/users/9056,","Donal Fellows,","This workflow is querying the HFC ActiveRegions list and HEC hessi_flare list.It requires a time periode and a search radius arround the centre of an Active Region as inputsIt produces two outputs: AnnotatedFeatureTable is a modified VOTable where a field is added with the number of associated hessi flares. CombinedTable is a 2 dimensional list with an VOTable for each Active region and one with an VOTable for all associated flares for that Active Region.",0, 0, ,
"http://www.myexperiment.org/workflows/2181/versions/3.html","Associate hessi flares with active regions","2011-06-2212:02:12","2012-07-1009:56:14","http://www.myexperiment.org/workflows/2181/download/Associate_hessi_flares_with_active_regions-v3.t2flow?version=3","/users/9056","Donal Fellows","taverna 2","/users/9056,","Donal Fellows,","This workflow is querying the HFC ActiveRegions list and HEC hessi_flare list.It requires a time periode and a search radius arround the centre of an Active Region as inputsIt produces two outputs: AnnotatedFeatureTable is a modified VOTable where a field is added with the number of associated hessi flares. CombinedTable is a 2 dimensional list with an VOTable for each Active region and one with an VOTable for all associated flares for that Active Region.",0, 0, ,
"http://www.myexperiment.org/workflows/2203/versions/1.html","Extract histogram features from image file using RESTful interface","2011-07-0113:15:37","2012-04-0408:00:05","http://www.myexperiment.org/workflows/2203/download/Extract_histogram_features_from_image_file_using_RESTful_interface-v1.t2flow?version=1","/users/17168","Roman","taverna 2","/users/17168,","Roman,","The main element of this workflow is a RESTful service designed in the SCAPE QA command line tools RESTful package  <a href=https://github.com/openplanets/scape/tree/master/pc-qa-toolwrapper-rest rel=nofollow>https://github.com/openplanets/scape/tree/master/pc-qa-toolwrapper-rest</a> . The Github project  <a href=https://github.com/openplanets/scape/tree/master/xa-rester rel=nofollow>https://github.com/openplanets/scape/tree/master/xa-rester</a>  from Andy Jackson is a basis implementation for pc-qa-toolwrapper-rest package. The QA REST package enables creation of RESTful web service that wraps QA command  line tool like &lsquo;extractfeatures&rsquo; or &lsquo;create&rsquo;. The workflow for  &lsquo;extractFeatures&rsquo; tool has path to the RESTful service as an input parameter. The URL to the input  image file and the number of histogram bins as integer are attached at the end of the path separated by '/' character. This workflow  extracts histogram features from passed image file. The output is an XML string with histogram data. Also the workflow provides output of  the REST service status (200 if successful) and XPath output containing data extracted from XML. The service request example:  <a href=http://localhost:8080/scape-pc-qa-toolwrapper-rest/rest/qualityassurance/extractfeatures/scape-logo.png/7 rel=nofollow>http://localhost:8080/scape-pc-qa-toolwrapper-rest/rest/qualityassurance/extractfeatures/scape-logo.png/7</a> .",-1, 0, ,
"http://www.myexperiment.org/workflows/2204/versions/1.html","Common SCAPE QA command line tool RESTful service","2011-07-0113:48:30","2012-04-0407:59:17","http://www.myexperiment.org/workflows/2204/download/Common_SCAPE_QA_command_line_tool_RESTful_service-v1.t2flow?version=1","/users/17168","Roman","taverna 2","/users/17168,","Roman,","The QA REST package enables creation of RESTful web service  that wraps any QA command  line tools. The main element of this workflow is a RESTful service designed in the SCAPE QA command line tools RESTful package  <a href=https://github.com/openplanets/scape/tree/master/pc-qa-toolwrapper-rest rel=nofollow>https://github.com/openplanets/scape/tree/master/pc-qa-toolwrapper-rest</a> . The Github project  <a href=https://github.com/openplanets/scape/tree/master/xa-rester rel=nofollow>https://github.com/openplanets/scape/tree/master/xa-rester</a>   from Andy Jackson is a basis implementation for pc-qa-toolwrapper-rest  package. The  workflow comprises path to the RESTful service root directory as  an input parameter. The QA command line tool name and parameters separated by comma are attached at the end of the path. Adventage of this method is that user can optionally change parameters without any changes in java service source code. The output is an XML string. Also the  workflow provides output of  the REST service status (200 if successful)  and XPath output containing data extracted from XML. The service  request example for extractfeatures tool:  <a href=http://localhost:8080/scape-pc-qa-toolwrapper-rest/rest/qualityassurance/tool/extractfeatures.exe,--numbins%205,scape-logo.png rel=nofollow>http://localhost:8080/scape-pc-qa-toolwrapper-rest/rest/qualityassurance/tool/extractfeatures.exe,--numbins%205,scape-logo.png</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/2213/versions/1.html","BiomartAndEMBOSSDisease","2011-07-1212:54:05","2012-03-1915:31:14","http://www.myexperiment.org/workflows/2213/download/BiomartAndEMBOSSDisease-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/13,","Katy Wolstencroft,","This workflow retrieves all genes on human chromosome 22 that are associated with a disease and aligns the upstream regions with mouse and rat homologues. The alignments are plotted and corresponding sequence ids are also returned.",0, 0, ,
"http://www.myexperiment.org/workflows/2213/versions/2.html","BiomartAndEMBOSSDisease","2011-07-1212:54:05","2012-03-1915:31:14","http://www.myexperiment.org/workflows/2213/download/BiomartAndEMBOSSDisease-v2.t2flow?version=2","/users/30","Alan Williams","taverna 2","/users/13,","Katy Wolstencroft,","This workflow retrieves all genes on human chromosome 22 that are associated with a disease and aligns the upstream regions with mouse and rat homologues. The alignments are plotted and corresponding sequence ids are also returned.",0, 0, ,
"http://www.myexperiment.org/workflows/2214/versions/1.html","EBI_InterproScan_NewServices","2011-07-1213:02:49","2011-07-1213:02:50","http://www.myexperiment.org/workflows/2214/download/EBI_InterproScan_NewServices-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30, /users/13,","Alan Williams, Katy Wolstencroft,","This workflow performs an interproscan at the EBI on sequences provided as input. The output is provided as text, xml or png.This workflow uses the new EBI services, which are asynchronous and require looping over the nested workflow (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration.",0, 0, ,
"http://www.myexperiment.org/workflows/2215/versions/1.html","Example workflow for REST and XPath activities","2011-07-1213:07:58","2011-07-1213:07:59","http://www.myexperiment.org/workflows/2215/download/Example_workflow_for_REST_and_XPath_activities-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow fetches weather forecast for the user-specified location. First of all it uses the provided location name to obtain a WOEID (Where On Earth ID) of that location, then uses that unique identifier to fetch the weather forecast from Yahoo server. Multiple results may be obtained in case there is no unique translation of the location to a WOEID. REST activity is used to perform HTTP requests and fetch data from remote servers; XPath activity is then used to parse the XML data and extract only selected elements.",0, 0, ,
"http://www.myexperiment.org/workflows/2216/versions/1.html","Multiple choice quiz","2011-07-1213:46:40","2011-07-1213:46:42","http://www.myexperiment.org/workflows/2216/download/Multiple_choice_quiz-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30, /users/345,","Alan Williams, George,","A fun example workflow showing user-interaction and service looping",0, 0, ,
"http://www.myexperiment.org/workflows/2217/versions/1.html","Fetch Dragon images from BioMoby","2011-07-1213:52:04","2011-07-1213:52:05","http://www.myexperiment.org/workflows/2217/download/Fetch_Dragon_images_from_BioMoby-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/297,","Tomoinn,","Fetch images and annotations of snapdragons",0, 0, ,
"http://www.myexperiment.org/workflows/2218/versions/1.html","Spreadsheet Import Example","2011-07-1213:57:34","2011-07-1213:57:36","http://www.myexperiment.org/workflows/2218/download/Spreadsheet_Import_Example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/2,","David Withers,","Example using the SpreadsheetImport service to import data from an Excel spreadsheet.The workflow imports the file spreadsheet file WaterUse.xlsx and generates a graph from the date.The source data is from  <a href=http://data.gov.uk/ rel=nofollow>http://data.gov.uk/</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2219/versions/1.html","Retrieve sequence in EMBL format","2011-07-1214:01:17","2011-07-1214:01:18","http://www.myexperiment.org/workflows/2219/download/Retrieve_sequence_in_EMBL_format-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/62,","Franck Tanoh,","This workflow retrieves a sequence associated with its features in embl format",0, 0, ,
"http://www.myexperiment.org/workflows/2220/versions/1.html","Pipelined list iteration","2011-07-1214:04:39","2011-07-1214:04:41","http://www.myexperiment.org/workflows/2220/download/Pipelined_list_iteration-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/474, /users/5,","Ian Dunlop, Stian Soiland-Reyes,","Perform multiple iterations of services in order to show pipelining",0, 0, ,
"http://www.myexperiment.org/workflows/2221/versions/1.html","GBSeq test","2011-07-1214:08:40","2011-07-1214:08:41","http://www.myexperiment.org/workflows/2221/download/GBSeq_test-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/62,","Franck Tanoh,","This workflow retrieves nucleotide and protein sequences with the literature and references associatedto them given a protein and a nucleotide id.",0, 0, ,
"http://www.myexperiment.org/workflows/2222/versions/1.html","Fetch today&#39;s xkcd comic","2011-07-1214:13:35","2011-07-1214:13:36","http://www.myexperiment.org/workflows/2222/download/Fetch_today_s_xkcd_comic-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/297, /users/5,","Tomoinn, Stian Soiland-Reyes,","Use the local services and some filtering operations to fetch the comic strip image from  <a href=http://xkcd.com/ rel=nofollow>http://xkcd.com/</a> Based on the FetchDailyDilbert workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/2223/versions/1.html","Fetch PDB flatfile from RCSB server","2011-07-1214:37:08","2011-07-1214:37:10","http://www.myexperiment.org/workflows/2223/download/Fetch_PDB_flatfile_from_RCSB_server-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30, /users/297,","Alan Williams, Tomoinn,","Given an identifier such as '1crn' fetches the PDB format flatfile from the RCSB",0, 0, ,
"http://www.myexperiment.org/workflows/2224/versions/1.html","Demonstration of configurable iteration","2011-07-1214:40:22","2011-07-1214:40:24","http://www.myexperiment.org/workflows/2224/download/Demonstration_of_configurable_iteration-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30, /users/297,","Alan Williams, Tomoinn,","This workflow shows the use of the iteration strategy editor to ensure that only relevant combinations of inputs are used during an implicit iteration.",0, 0, ,
"http://www.myexperiment.org/workflows/2225/versions/1.html","BioMoby tutorial workflow","2011-07-1215:50:21","2011-07-1215:50:22","http://www.myexperiment.org/workflows/2225/download/BioMoby_tutorial_workflow-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/9981,","EdwardKawas,","A workflow from part of the BioMoby tutorial",0, 0, ,
"http://www.myexperiment.org/workflows/2226/versions/1.html","A workflow version of the EMBOSS tutorial","2011-07-1215:55:06","2011-07-1215:55:08","http://www.myexperiment.org/workflows/2226/download/A_workflow_version_of_the_EMBOSS_tutorial-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/297,","Tomoinn,","Designed to show the use of EMBOSS based Soaplab services from Taverna, this workflow has no inputs as all initial values are specified as string constants. A sequence set is fetched using the seqret tool, then simultaneously scanned for predicted transmembrane regions and subjected to a multiple alignment using emma. This alignment is then plotted to a set of PNG images and also used to build a profile using the prophecy and prophet tools.",0, 0, ,
"http://www.myexperiment.org/workflows/2229/versions/1.html","Unix tool service using string replacement","2011-07-1310:19:35","2011-07-1310:19:37","http://www.myexperiment.org/workflows/2229/download/Unix_tool_service_using_string_replacement-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","The tool service outputs a message that greets using the names specified on Greet's input ports.",0, 0, ,
"http://www.myexperiment.org/workflows/2230/versions/1.html","Unix tools with zip, unzip and diff","2011-07-1310:21:10","2011-07-1310:22:52","http://www.myexperiment.org/workflows/2230/download/Unix_tools_with_zip__unzip_and_diff-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30, /users/1169,","Alan Williams, Steffen MÃ¶ller,","This workflow only works on a Unix machine.  This workflow takes a fixed URL from which a text file is downloaded (output as Original_file). That file is zipped (output as Zipped_File) and then unzipped again (output as Unzipped_File). The orginal file and the unzipped version are then diff'd/",0, 0, ,
"http://www.myexperiment.org/workflows/2231/versions/1.html","Unix tool for numerically adding two values.","2011-07-1310:24:40","2011-07-1310:25:37","http://www.myexperiment.org/workflows/2231/download/Unix_tool_for_numerically_adding_two_values.-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30, /users/1169,","Alan Williams, Steffen MÃ¶ller,","This workflow relies on a Unix system. It wraps the &quot;bc&quot; command line calculator. It downloads the calculation script from a URL.",0, 0, ,
"http://www.myexperiment.org/workflows/2236/versions/1.html","Multi-parameter sensitivity analysis (MPSA)","2011-07-1408:50:26","2011-07-2110:08:42","http://www.myexperiment.org/workflows/2236/download/Multi-parameter_sensitivity_analysis__MPSA_-v1.t2flow?version=1","/users/6843","trybik","taverna 2","/users/6843,","trybik,","Exemplary multi-parameter sensitivity analysis (MPSA) experiment using Tav4SB ( <a href=http://bioputer.mimuw.edu.pl/tav4sb/ rel=nofollow>http://bioputer.mimuw.edu.pl/tav4sb/</a> ) WS operations. In this version of MPSA, ODEs simulations are basis of analysis of SBML model parameters space.",0, 0, ,
"http://www.myexperiment.org/workflows/2236/versions/2.html","Multi-parameter sensitivity analysis (MPSA)","2011-07-1408:50:26","2011-07-2110:08:42","http://www.myexperiment.org/workflows/2236/download/Multi-parameter_sensitivity_analysis__MPSA_-v2.t2flow?version=2","/users/6843","trybik","taverna 2","/users/6843,","trybik,","Exemplary multi-parameter sensitivity analysis (MPSA) experiment using Tav4SB ( <a href=http://bioputer.mimuw.edu.pl/tav4sb/ rel=nofollow>http://bioputer.mimuw.edu.pl/tav4sb/</a> ) WS operations. In this version of MPSA, ODEs simulations are basis of analysis of SBML model parameters space.",0, 0, ,
"http://www.myexperiment.org/workflows/2237/versions/1.html","Multi-parameter sensitivity analysis (MPSA) with PMC","2011-07-1408:59:23","2011-07-2110:08:07","http://www.myexperiment.org/workflows/2237/download/Multi-parameter_sensitivity_analysis__MPSA__with_PMC-v1.t2flow?version=1","/users/6843","trybik","taverna 2","/users/6843,","trybik,","Exemplary multi-parameter sensitivity analysis (MPSA) experiment using Tav4SB ( <a href=http://bioputer.mimuw.edu.pl/tav4sb/ rel=nofollow>http://bioputer.mimuw.edu.pl/tav4sb/</a> ) WS operations. In this version of MPSA PRISM probabilistic model checking is basis of analysis of SBML model parameters space.",1, 0, ,
"http://www.myexperiment.org/workflows/2237/versions/2.html","Multi-parameter sensitivity analysis (MPSA) with PMC","2011-07-1408:59:23","2011-07-2110:08:07","http://www.myexperiment.org/workflows/2237/download/Multi-parameter_sensitivity_analysis__MPSA__with_PMC-v2.t2flow?version=2","/users/6843","trybik","taverna 2","/users/6843,","trybik,","Exemplary multi-parameter sensitivity analysis (MPSA) experiment using Tav4SB ( <a href=http://bioputer.mimuw.edu.pl/tav4sb/ rel=nofollow>http://bioputer.mimuw.edu.pl/tav4sb/</a> ) WS operations. In this version of MPSA PRISM probabilistic model checking is basis of analysis of SBML model parameters space.",1, 0, ,
"http://www.myexperiment.org/workflows/2238/versions/1.html","Plot error surface","2011-07-1409:03:42","2011-07-1409:06:16","http://www.myexperiment.org/workflows/2238/download/Plot_error_surface-v1.t2flow?version=1","/users/6843","trybik","taverna 2","/users/6843,","trybik,","Exemplary workflow for plotting error surface using Tav4SB ( <a href=http://bioputer.mimuw.edu.pl/tav4sb/ rel=nofollow>http://bioputer.mimuw.edu.pl/tav4sb/</a> ) mahtPlot WS operation. Data input format is compatibile with Tav4SB MPSA workflows.",1, 0, ,
"http://www.myexperiment.org/workflows/2253/versions/1.html","Secure REST service call example","2011-07-1415:01:03","2011-07-1415:01:05","http://www.myexperiment.org/workflows/2253/download/Secure_REST_service_call_example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/666,","Alex Nenadic,","This is an example of a workflow that contains a call to a secure REST service that requires user to authenticate with HTTP Basic Authentication. You can use testuser/testpasswd as username and password for authentication when running the workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/2254/versions/1.html","Secure Web service call example","2011-07-1415:02:36","2011-07-1415:02:38","http://www.myexperiment.org/workflows/2254/download/Secure_Web_service_call_example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/666,","Alex Nenadic,","This is an example of a workflow that contains a call to a secure Web service that runs behind HTTPS and requires user to authenticate. The first thing you can expect to see is a pop up dialog asking if you trust the Web service to be invoked over HTTPS. You can use testuser/testpasswd as username and password for authentication when running the workflow. To see where the security is being configured, right-click the service in the diagram and select Configure security from the menu.",0, 0, ,
"http://www.myexperiment.org/workflows/2255/versions/1.html","Executes Python script","2011-07-1417:57:35","2013-04-2214:52:42","http://www.myexperiment.org/workflows/2255/download/Executes_Python_script-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","Simple workflow that uses a python script in /Users/jer directory",-1, 0, ,
"http://www.myexperiment.org/workflows/2255/versions/2.html","Executes Python script","2011-07-1417:57:35","2013-04-2214:52:42","http://www.myexperiment.org/workflows/2255/download/Executes_Python_script-v2.t2flow?version=2","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","&nbsp;Simple workflow that uses a python script to say Hello !",-1, 0, ,
"http://www.myexperiment.org/workflows/2255/versions/3.html","Executes Python script","2011-07-1417:57:35","2013-04-2214:52:42","http://www.myexperiment.org/workflows/2255/download/Executes_Python_script-v3.t2flow?version=3","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","&nbsp;Simple workflow that uses a python script to say Hello !",-1, 0, ,
"http://www.myexperiment.org/workflows/2255/versions/4.html","Executes Python script","2011-07-1417:57:35","2013-04-2214:52:42","http://www.myexperiment.org/workflows/2255/download/Executes_Python_script-v4.t2flow?version=4","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","Snippet showing how to use Taverna Tool in Service template folder for executing a Python script. This workflow needs Python to be installed on the local system, and declared in the PATH enviromental variable, so any python script could be executed from a terminal.",0, 0, ,
"http://www.myexperiment.org/workflows/2256/versions/1.html","NOR Service","2011-07-1514:11:10","2011-07-1514:41:29","http://www.myexperiment.org/workflows/2256/download/NOR_Service-v1.t2flow?version=1","/users/17635","Panos","taverna 2","/users/17635, /users/15795,","Panos, Thomas,","Automatic orthorectification of raw images, using the NOR service developed by JRC under the GENESI-DEC and GENESI-DR projects. The service supports SPOT4 and SPOT5 image types. It takes as an input a URL that points to a raw zipped image. The output is a URL to a zip file that contains the ortho-rectified image.&nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/2256/versions/2.html","NOR Service","2011-07-1514:11:10","2011-07-1514:41:29","http://www.myexperiment.org/workflows/2256/download/NOR_Service-v2.t2flow?version=2","/users/17635","Panos","taverna 2","/users/17635, /users/15795,","Panos, Thomas,","Workflow for an automatic orthorectification of raw images service, using the NOR service developed by JRC under the GENESI-DEC and GENESI-DR projects. It takes as input a URL of a zipped SPOT4|SPOT5 raw image, and generates a new URL of a zipped file of the orthorectified image.",-1, 0, ,
"http://www.myexperiment.org/workflows/2258/versions/1.html","EBI NCBI BLAST Multi FASTA","2011-07-1619:08:38","2011-07-1619:35:11","http://www.myexperiment.org/workflows/2258/download/EBI_NCBI_BLAST_Multi_FASTA-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","This workflow performs multiple sequence similarity searches using the NCBI blast at the EBI. It uses the new EBI services, which are asynchronous and require looping over the nested workflow (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration. If you want to make a blast search for more than 10 sequences I would recommend you to run the workflow using the command line. For instance: executeworkflow.bat -embedded -inputvalue email  <a href=mailto:your@email.com rel=nofollow>your@email.com</a>  -inputfile yourfile.txt EBI_NCBI_BLAST-multifasta.t2flow More docuemtnation about how to use the command line tool in  <a href=http://www.taverna.org.uk/documentation/taverna-2-x/command-line-tool/2-3/ rel=nofollow>http://www.taverna.org.uk/documentation/taverna-2-x/command-line-tool/2-3/</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2258/versions/2.html","EBI NCBI BLAST Multi FASTA","2011-07-1619:08:38","2011-07-1619:35:11","http://www.myexperiment.org/workflows/2258/download/EBI_NCBI_BLAST_Multi_FASTA-v2.t2flow?version=2","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","This workflow performs multiple sequence similarity searches using the NCBI blast at the EBI. It uses the new EBI services, which are asynchronous and require looping over the nested workflow (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration. If you want to make a blast search for more than 10 sequences I would recommend you to run the workflow using the command line. For instance: executeworkflow.bat -embedded -inputvalue email  <a href=mailto:your@email.com rel=nofollow>your@email.com</a>  -inputfile yourfile.txt EBI_NCBI_BLAST-multifasta.t2flow More docuemtnation about how to use the command line tool in  <a href=http://www.taverna.org.uk/documentation/taverna-2-x/command-line-tool/2-3/ rel=nofollow>http://www.taverna.org.uk/documentation/taverna-2-x/command-line-tool/2-3/</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2259/versions/1.html","Isoelectric Point","2011-07-1912:26:12","2011-07-2014:20:18","http://www.myexperiment.org/workflows/2259/download/Isoelectric_Point-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Calculates the Isoelectric Point for a protein sequence using a protein accession as input",0, 0, ,
"http://www.myexperiment.org/workflows/2260/versions/1.html","getFFEntry WorkFlow","2011-07-1916:14:40","","","/users/17869","Pujan Joshi","taverna 2","","",,
"http://www.myexperiment.org/workflows/2262/versions/1.html","PSICQUIC Registry (Molecular Interactions Services)","2011-07-2011:04:26","2011-07-2014:55:44","http://www.myexperiment.org/workflows/2262/download/PSICQUIC_Registry__Molecular_Interactions_Services_-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Query the PSICQUIC registry to retrieve information about services providing molecular interactions",0, 0, ,
"http://www.myexperiment.org/workflows/2264/versions/1.html","Simulate SBML-derived ODEs","2011-07-2013:57:19","2011-07-2014:02:43","http://www.myexperiment.org/workflows/2264/download/Simulate_SBML-derived_ODEs-v1.t2flow?version=1","/users/6843","trybik","taverna 2","/users/6843,","trybik,","Currently supported input XML elements are: results (with result/property and result/constant sub-elements) and timepoints (with timepoint/time and timepoint/variable sub-element).",0, 0, ,
"http://www.myexperiment.org/workflows/2264/versions/2.html","Simulate SBML-derived ODEs","2011-07-2013:57:19","2011-07-2014:02:43","http://www.myexperiment.org/workflows/2264/download/Simulate_SBML-derived_ODEs-v2.t2flow?version=2","/users/6843","trybik","taverna 2","/users/6843,","trybik,","Exemplary experiment using Tav4SB ( <a href=http://bioputer.mimuw.edu.pl/tav4sb/ rel=nofollow>http://bioputer.mimuw.edu.pl/tav4sb/</a> ) ODEs simulation and plotting Web service operations.",0, 0, ,
"http://www.myexperiment.org/workflows/2265/versions/1.html","List of PSICQUIC services (names and URLs) providing molecular interactions","2011-07-2014:10:30","2011-07-2014:58:43","http://www.myexperiment.org/workflows/2265/download/List_of_PSICQUIC_services__names_and_URLs__providing_molecular_interactions-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","PSICQUIC provides access to molecular interaction databases. This workflow queries the registry and gets a list of available PSICQUIC services (names and URLs).",0, 0, ,
"http://www.myexperiment.org/workflows/2266/versions/1.html","Probabilistic Model Checking (PMC): compute results","2011-07-2014:11:46","2011-07-2014:12:02","http://www.myexperiment.org/workflows/2266/download/Probabilistic_Model_Checking__PMC___compute_results-v1.t2flow?version=1","/users/6843","trybik","taverna 2","/users/6843,","trybik,","Exemplary experiment using Tav4SB ( <a href=http://bioputer.mimuw.edu.pl/tav4sb/ rel=nofollow>http://bioputer.mimuw.edu.pl/tav4sb/</a> ) PRISM model translation and model checking Web service operations.",0, 0, ,
"http://www.myexperiment.org/workflows/2267/versions/1.html","Probabilistic Model Checking (PMC): plot results","2011-07-2014:18:19","2011-07-2014:21:27","http://www.myexperiment.org/workflows/2267/download/Probabilistic_Model_Checking__PMC___plot_results-v1.t2flow?version=1","/users/6843","trybik","taverna 2","/users/6843,","trybik,","Exemplary experiment using Tav4SB ( <a href=http://bioputer.mimuw.edu.pl/tav4sb/ rel=nofollow>http://bioputer.mimuw.edu.pl/tav4sb/</a> )  Mathematica plotting Web service operation. This is a second-part for  the computationaly exhaustive PMC: compute results workflow ( <a href=../../../workflows/2266 rel=nofollow>http://www.myexperiment.org/workflows/2266</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/2268/versions/1.html","ELM Database Retrieval Workflow","2011-07-2016:16:18","2011-07-2016:16:20","http://www.myexperiment.org/workflows/2268/download/ELM_Database_Retrieval_Workflow-v1.xml?version=1","/users/227","Kieren Lythgow","taverna 1","/users/227,","Kieren Lythgow,","This workflow retrieves all the current entries stored in the Eukaryotic Linear Motif (ELM) Database and returns all entries in a collated readable format.This requires the ELM Database retrieval WSDL file:  <a href=http://elm.eu.org/webservice/ELMdb.wsdl rel=nofollow>http://elm.eu.org/webservice/ELMdb.wsdl</a>",3, 1, Nested_Workflow, getAllELMs, SplitXML, ,
"http://www.myexperiment.org/workflows/2270/versions/1.html","Weka Regression from XRFF file.","2011-07-2118:49:01","2011-07-2118:51:46","http://www.myexperiment.org/workflows/2270/download/Weka_Regression_from_XRFF_file.-v1.t2flow?version=1","/users/12835","Andreas Truszkowski","taverna 2","","","The here shown workflow splits the given data into a training set and a test set. Afterwards a machine learning model is created by the Weka Regression worker which is evaluated by the Evaluate Regression Results as PDF worker. The resulting sets are stored as XRFF files in the folder determined by the OUT TRAIN XRFF and OUT TEST XRFF input ports. The calcualted machine learning models and the evaluation results are saved in the folder of OUT MODEL input port",-1, 0, ,
"http://www.myexperiment.org/workflows/2271/versions/1.html","Substructure filter","2011-07-2118:57:50","2011-07-2118:57:51","http://www.myexperiment.org/workflows/2271/download/Substructure_filter-v1.t2flow?version=1","/users/12835","Andreas Truszkowski","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/2272/versions/1.html","QSAR CSV to Weka Regression Dataset","2011-07-2119:37:38","","http://www.myexperiment.org/workflows/2272/download/QSAR_CSV_to_Weka_Regression_Dataset-v1.t2flow?version=1","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow converts the molecular descriptor data from a CSV file to a Weka XRFF file. The workflow merges the retention time values from IN IDRT CSV with the molecular descriptor values from IN QSAR CSV to create a valid Weka regression set.",-1, 0, ,
"http://www.myexperiment.org/workflows/2274/versions/1.html","Get Molecular Interactions from a PSICQUIC Service","2011-07-2210:06:22","2013-07-1012:26:55","http://www.myexperiment.org/workflows/2274/download/Get_Molecular_Interactions_from_a_PSICQUIC_Service-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Check the different iput parameter you could use for this workflow in ... <a href=http://code.google.com/p/psicquic/wiki/RestAccess rel=nofollow>http://code.google.com/p/psicquic/wiki/RestAccess</a> Check available PSICQUIC Services in ... <a href=http://www.ebi.ac.uk/Tools/webservices/psicquic/registry/registry?action=STATUS rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/psicquic/registry/registry?action=STATUS</a> More about PSICQUIC ... <a href=http://code.google.com/p/psicquic/ rel=nofollow>http://code.google.com/p/psicquic/</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2274/versions/2.html","Get Molecular Interactions from a PSICQUIC Service","2011-07-2210:06:22","2013-07-1012:26:55","http://www.myexperiment.org/workflows/2274/download/Get_Molecular_Interactions_from_a_PSICQUIC_Service-v2.t2flow?version=2","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Check the different iput parameter you could use for this workflow in ... <a href=http://code.google.com/p/psicquic/wiki/RestAccess rel=nofollow>http://code.google.com/p/psicquic/wiki/RestAccess</a> Check available PSICQUIC Services in ... <a href=http://www.ebi.ac.uk/Tools/webservices/psicquic/registry/registry?action=STATUS rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/psicquic/registry/registry?action=STATUS</a> More about PSICQUIC ... <a href=http://code.google.com/p/psicquic/ rel=nofollow>http://code.google.com/p/psicquic/</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2274/versions/3.html","Get Molecular Interactions from a PSICQUIC Service","2011-07-2210:06:22","2013-07-1012:26:55","http://www.myexperiment.org/workflows/2274/download/Get_Molecular_Interactions_from_a_PSICQUIC_Service-v3.t2flow?version=3","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Check the different iput parameter you could use for this workflow in ... <a href=http://code.google.com/p/psicquic/wiki/RestAccess rel=nofollow>http://code.google.com/p/psicquic/wiki/RestAccess</a> Check available PSICQUIC Services in ... <a href=http://www.ebi.ac.uk/Tools/webservices/psicquic/registry/registry?action=STATUS rel=nofollow>http://www.ebi.ac.uk/Tools/webservices/psicquic/registry/registry?action=STATUS</a> More about PSICQUIC ... <a href=http://code.google.com/p/psicquic/ rel=nofollow>http://code.google.com/p/psicquic/</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2275/versions/1.html","Genetic Algorithm for Input Component Analysis","2011-07-2211:28:54","","http://www.myexperiment.org/workflows/2275/download/Genetic_Algorithm_for_Input_Component_Analysis-v1.t2flow?version=1","/users/12835","Andreas Truszkowski","taverna 2","","","This workflow uses a genetic algorithm to optimize the given molecular descriptor set. Afterwards the workflow splits the data into a training set and test set and evaluates the results which are stored as PDF files.",-1, 0, ,
"http://www.myexperiment.org/workflows/2276/versions/1.html","Get a PSICQUIC REST URL from a PSICQUIC SOAP URL","2011-07-2211:30:30","2011-07-2211:31:05","http://www.myexperiment.org/workflows/2276/download/Get_a_PSICQUIC_REST_URL_from_a_PSICQUIC_SOAP_URL-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Get a PSICQUIC REST URL from a PSICQUIC SOAP URL",0, 0, ,
"http://www.myexperiment.org/workflows/2279/versions/1.html","EUADR Relationship Extraction Workflow","2011-07-2716:16:16","2012-09-0718:14:57","http://www.myexperiment.org/workflows/2279/download/EUADR_Relationship_Extraction_Workflow-v1.t2flow?version=1","/users/2625","Bharat Singh","taverna 2","/users/2625,","Bharat Singh,",,3, 0, ,
"http://www.myexperiment.org/workflows/2280/versions/1.html","EUADR - Literature Analysis","2011-07-2717:12:16","2011-07-2717:24:15","http://www.myexperiment.org/workflows/2280/download/EUADR_-_Literature_Analysis-v1.t2flow?version=1","/users/14919","Avillach","taverna 2","/users/14919,","Avillach,","The aim of the &quot;Literature Analysis&quot; workflow is to automate the search of publications related to ADRs corresponding to a given drug/adverse event association. To do so, we defined an approach based on the MeSH thesaurus, using the subheadings &laquo;chemically induced&raquo; and &laquo;adverse effects&raquo; with the &ldquo;Pharmacological Action&rdquo; knowledge.",3, 0, ,
"http://www.myexperiment.org/workflows/2283/versions/1.html","Find common events in HEC tables which use the heliographic coordinate system","2011-08-0310:18:27","2012-02-0313:36:24","http://www.myexperiment.org/workflows/2283/download/Find_common_events_in_HEC_tables_which_use_the_heliographic_coordinate_system-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Use only tables which provide lat_hg and long_hg. Inputs: table names of two HEC tables; time interval in which the search is being conducted; delta for time and location to enlarge the search space. Output: VOTable which combines the resultset of the HEC by the common event.",1, 0, ,
"http://www.myexperiment.org/workflows/2283/versions/2.html","Find common events in HEC tables which use the heliographic coordinate system","2011-08-0310:18:27","2012-02-0313:36:24","http://www.myexperiment.org/workflows/2283/download/Find_common_events_in_HEC_tables_which_use_the_heliographic_coordinate_system-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Use only tables which provide lat_hg and long_hg.Inputs: table names of two HEC tables; time interval in which the search is being conducted; delta for time and location to enlarge the search space.Output: VOTable which combines the resultset of the HEC by the common event.",0, 0, ,
"http://www.myexperiment.org/workflows/2283/versions/3.html","Find common events in HEC tables which use the heliographic coordinate system","2011-08-0310:18:27","2012-02-0313:36:24","http://www.myexperiment.org/workflows/2283/download/Find_common_events_in_HEC_tables_which_use_the_heliographic_coordinate_system-v3.t2flow?version=3","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Use only tables which provide lat_hg and long_hg.Inputs: table names of two HEC tables; time interval in which the search is being conducted; delta for time and location to enlarge the search space.Output: VOTable which combines the resultset of the HEC by the common event.",0, 0, ,
"http://www.myexperiment.org/workflows/2283/versions/4.html","Find common events in HEC tables which use the heliographic coordinate system","2011-08-0310:18:27","2012-02-0313:36:24","http://www.myexperiment.org/workflows/2283/download/Find_common_events_in_HEC_tables_which_use_the_heliographic_coordinate_system-v4.t2flow?version=4","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Use only tables which provide lat_hg and long_hg.Inputs: table names of two HEC tables; time interval in which the search is being conducted; delta for time and location to enlarge the search space.Output: VOTable which combines the resultset of the HEC by the common event.",0, 0, ,
"http://www.myexperiment.org/workflows/2283/versions/5.html","Find common events in HEC tables which use the heliographic coordinate system","2011-08-0310:18:27","2012-02-0313:36:24","http://www.myexperiment.org/workflows/2283/download/Find_common_events_in_HEC_tables_which_use_the_heliographic_coordinate_system-v5.t2flow?version=5","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Use only tables which provide lat_hg and long_hg.Inputs: table names of two HEC tables; time interval in which the search is being conducted; delta for time and location to enlarge the search space.Output: VOTable which combines the resultset of the HEC by the common event.",0, 0, ,
"http://www.myexperiment.org/workflows/2284/versions/1.html","sampleDistribution Web service operation","2011-08-0322:39:02","2011-08-0411:40:14","http://www.myexperiment.org/workflows/2284/download/sampleDistribution_Web_service_operation-v1.xml?version=1","/users/6843","trybik","taverna 1","/users/6843,","trybik,","Probabilistic distribution sampling operation which uses Mathematica software ( <a href=http://www.wolfram.com/mathematica/ rel=nofollow>http://www.wolfram.com/mathematica/</a> ).",7, 1, sampleDistributionParamsXML, sampleXML, sampleDistributionResultXML, sampleDistribution, setDistributionXml, headTail, echo2DList, ,
"http://www.myexperiment.org/workflows/2285/versions/1.html","Example of a conditional execution workflow","2011-08-0414:18:09","","http://www.myexperiment.org/workflows/2285/download/Example_of_a_conditional_execution_workflow-v1.xml?version=1","/users/15","Ross Gardler","taverna 1","","","If the input is true then the string 'foo' is emited, if false then 'bar'. Just a simple example to show how the monster works, so to speak.",5, 0, Fail_if_false, Fail_if_true, foo, bar, Echo_list, ,
"http://www.myexperiment.org/workflows/2287/versions/1.html","OpenTox Upload and merge data sets","2011-08-0811:04:11","2011-08-0811:05:05","http://www.myexperiment.org/workflows/2287/download/OpenTox_Upload_and_merge_data_sets-v1.t2flow?version=1","/users/6658","Wicker","taverna 2","","","Uploads 2 data sets to OpenTox, merges them and returns the merged data set.",-1, 0, ,
"http://www.myexperiment.org/workflows/2288/versions/1.html","OpenTox Learn and evaluate model","2011-08-0914:26:16","","http://www.myexperiment.org/workflows/2288/download/OpenTox_Learn_and_evaluate_model-v1.t2flow?version=1","/users/6658","Wicker","taverna 2","","","Learns a LoMoGraph model on the TUM servers and evaluates it using 10 fold cross validation.",-1, 0, ,
"http://www.myexperiment.org/workflows/2289/versions/1.html","OpenTox Get Id","2011-08-0915:58:56","","http://www.myexperiment.org/workflows/2289/download/OpenTox_Get_Id-v1.t2flow?version=1","/users/6658","Wicker","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/2290/versions/1.html","XML-RPC example current time","2011-08-1111:43:55","2011-08-1111:43:56","http://www.myexperiment.org/workflows/2290/download/XML-RPC_example_current_time-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","Using Apache ws-xmlrpc from Beanshell scripts to call time.xmlrpc.com - see  <a href=http://www.xmlrpc.com/currentTime rel=nofollow>http://www.xmlrpc.com/currentTime</a> To use, download the JARs from  <a href=http://ws.apache.org/xmlrpc/download.html rel=nofollow>http://ws.apache.org/xmlrpc/download.html</a>  (ie.  <a href=http://apache.mirror.anlx.net//ws/xmlrpc/apache-xmlrpc-current-bin.zip rel=nofollow>http://apache.mirror.anlx.net//ws/xmlrpc/apache-xmlrpc-current-bin.zip</a>  ) - unzip and put into Taverna's home directory lib/ folder.  Right-click on the Beanshell script and check the Dependencies tab to check that all JARs have been ticked off (minimum required: ws-common-util.jar, xmlrpc-client.jar and xmlrpc-common.jar. For changing which XML RPC method to use, edit the beanshell script, supplying extra input or output ports as needed. See  <a href=http://ws.apache.org/xmlrpc/client.html rel=nofollow>http://ws.apache.org/xmlrpc/client.html</a>  for documentation on the ws-xmlrpc API. Note as Taverna's Beanshell script can only return 'simple' types like strings and integers, you might ave to use toString() metods for the beanshell output ports.",0, 0, ,
"http://www.myexperiment.org/workflows/2293/versions/1.html","Difference: Query - Reference","2011-08-1509:50:40","2011-08-1509:50:41","http://www.myexperiment.org/workflows/2293/download/Difference__Query_-_Reference-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Difference bettwen the query list and the reference list. Things that are in the query and not in the reference.",0, 0, ,
"http://www.myexperiment.org/workflows/2294/versions/1.html","Split string into string list, new line separator","2011-08-1513:05:14","2014-02-2609:33:51","http://www.myexperiment.org/workflows/2294/download/Split_string_into_string_list__new_line_separator-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Split string into string list using new line as separator. Should work in Linux, Mac and Windows.",0, 0, ,
"http://www.myexperiment.org/workflows/2299/versions/1.html","BLAST your sequences against the NucleaRDB","2011-08-1910:32:03","2011-08-1910:41:38","http://www.myexperiment.org/workflows/2299/download/BLAST_your_sequences_against_the_NucleaRDB-v1.t2flow?version=1","/users/586","Bas Vroling","taverna 2","/users/586,","Bas Vroling,","BLAST your sequences against the NucleaRDB. Input requires a sequence with amino acids only (no fasta format etc)",-1, 0, ,
"http://www.myexperiment.org/workflows/2302/versions/1.html","Find instruments of a special type in a section of space described in HCI coordinates","2011-08-2410:33:26","2011-08-2410:33:30","http://www.myexperiment.org/workflows/2302/download/Find_instruments_of_a_special_type_in_a_section_of_space_described_in_HCI_coordinates-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow takes a type of isnstrument as input and the minimum and maxium coordinates in HCI as input. Cadence for the location service is for defining the 'continues' presence.Output is a VOTable based on the ICS return where two columns are added for the time this instrument has entered and exited the Region of Interest.",0, 0, ,
"http://www.myexperiment.org/workflows/2303/versions/1.html","Find instruments of a special type in a section of space described in HCI coordinates during defined time period","2011-08-2411:30:22","2011-08-2411:30:25","http://www.myexperiment.org/workflows/2303/download/Find_instruments_of_a_special_type_in_a_section_of_space_described_in_HCI_coordinates_during_defined_time_period-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow takes a type of isnstrument as input and the minimum and maxium coordinates in HCI as input. Cadence for the location service is for defining the 'continues' presence.Output is a VOTable based on the ICS return where two columns are added for the time this instrument has entered and exited the Region of Interest.",0, 0, ,
"http://www.myexperiment.org/workflows/2313/versions/1.html","Image metadata extraction","2011-08-3112:02:29","2011-08-3112:02:31","http://www.myexperiment.org/workflows/2313/download/Image_metadata_extraction-v1.t2flow?version=1","/users/17331","Harvey","taverna 2","/users/17331,","Harvey,","This workflow invokes the  gdalinfo service and will list various information about a GDAL supported raster dataset of the image ( GeoTIFF, PNG, JPEG and GIF.).",0, 0, ,
"http://www.myexperiment.org/workflows/2314/versions/1.html","TIFF to PNG","2011-08-3112:04:44","2011-08-3112:04:47","http://www.myexperiment.org/workflows/2314/download/TIFF_to_PNG_-v1.t2flow?version=1","/users/17331","Harvey","taverna 2","/users/17331,","Harvey,","This workflow can convert Image format from TIFF to PNG. This workflow is one of the example for GENESI-DEC ontology.",0, 0, ,
"http://www.myexperiment.org/workflows/2315/versions/1.html","Convert GML to SVG","2011-08-3112:06:27","2011-08-3112:06:31","http://www.myexperiment.org/workflows/2315/download/Convert_GML_to_SVG-v1.t2flow?version=1","/users/17331","Harvey","taverna 2","/users/17331,","Harvey,","This workflow can convert the GML (Geography Markup Language) file to SVG image.",0, 0, ,
"http://www.myexperiment.org/workflows/2316/versions/1.html","GT: Sample Sheet Generation","2011-08-3122:02:25","2011-09-0822:10:26","http://www.myexperiment.org/workflows/2316/download/GT__Sample_Sheet_Generation-v1.t2flow?version=1","/users/18734","Chengc","taverna 2","/users/18734,","Chengc,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2316/versions/2.html","GT: Sample Sheet Generation","2011-08-3122:02:25","2011-09-0822:10:26","http://www.myexperiment.org/workflows/2316/download/GT__Sample_Sheet_Generation-v2.t2flow?version=2","/users/18734","Chengc","taverna 2","/users/18734,","Chengc,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2316/versions/3.html","GT: Sample Sheet Generation","2011-08-3122:02:25","2011-09-0822:10:26","http://www.myexperiment.org/workflows/2316/download/GT__Sample_Sheet_Generation-v3.t2flow?version=3","/users/18734","Chengc","taverna 2","/users/18734,","Chengc,","Creates a sample sheet from a SAMid exported file. User provides a plate number. Before running, make sure the SAMid exported file is in the correct directory under: /gne/research/data/lab-shares/gCell/_gCell/Baseline_Profiling_Cells/Genotyping/Plate_# Results will be stored under this directory: /gne/research/data/bioinfo/gcell/genotype/prd/Plate_#",0, 0, ,
"http://www.myexperiment.org/workflows/2316/versions/4.html","GT: Sample Sheet Generation","2011-08-3122:02:25","2011-09-0822:10:26","http://www.myexperiment.org/workflows/2316/download/GT__Sample_Sheet_Generation-v4.t2flow?version=4","/users/18734","Chengc","taverna 2","/users/18734,","Chengc,","Creates a sample sheet from a SAMid exported file. User provides a plate number. Before running, make sure the SAMid exported file is in the correct directory under: /gne/research/data/lab-shares/gCell/_gCell/Baseline_Profiling_Cells/Genotyping/Plate_# Results will be stored under this directory: /gne/research/data/bioinfo/gcell/genotype/prd/Plate_#",0, 0, ,
"http://www.myexperiment.org/workflows/2316/versions/5.html","GT: Sample Sheet Generation","2011-08-3122:02:25","2011-09-0822:10:26","http://www.myexperiment.org/workflows/2316/download/GT__Sample_Sheet_Generation-v5.t2flow?version=5","/users/18734","Chengc","taverna 2","/users/18734,","Chengc,","Creates a sample sheet from a SAMid exported file. User provides a plate number. Before running, make sure the SAMid exported file is in the correct directory under: /gne/research/data/lab-shares/gCell/_gCell/Baseline_Profiling_Cells/Genotyping/Plate_# Results will be stored under this directory: /gne/research/data/bioinfo/gcell/genotype/prd/Plate_#",0, 0, ,
"http://www.myexperiment.org/workflows/2316/versions/6.html","GT: Sample Sheet Generation","2011-08-3122:02:25","2011-09-0822:10:26","http://www.myexperiment.org/workflows/2316/download/GT__Sample_Sheet_Generation-v6.t2flow?version=6","/users/18734","Chengc","taverna 2","/users/18734,","Chengc,","Creates a sample sheet from a SAMid exported file. User provides a plate number. Before running, make sure the SAMid exported file is in the correct directory under: /gne/research/data/lab-shares/gCell/_gCell/Baseline_Profiling_Cells/Genotyping/Plate_# Results will be stored under this directory: /gne/research/data/bioinfo/gcell/genotype/prd/Plate_#",0, 0, ,
"http://www.myexperiment.org/workflows/2316/versions/7.html","GT: Sample Sheet Generation","2011-08-3122:02:25","2011-09-0822:10:26","http://www.myexperiment.org/workflows/2316/download/GT__Sample_Sheet_Generation-v7.t2flow?version=7","/users/18734","Chengc","taverna 2","/users/18734,","Chengc,","Creates a sample sheet from a SAMid exported file. User provides a plate number. Before running, make sure the SAMid exported file is in the correct directory under: /gne/research/data/lab-shares/gCell/_gCell/Baseline_Profiling_Cells/Genotyping/Plate_# Results will be stored under this directory: /gne/research/data/bioinfo/gcell/genotype/prd/Plate_#",0, 0, ,
"http://www.myexperiment.org/workflows/2317/versions/1.html","GT: Genotyping Comparison Analysis and Clustering/Heatmap","2011-09-0117:52:22","2011-09-1001:01:04","http://www.myexperiment.org/workflows/2317/download/GT__Genotyping_Comparison_Analysis_and_Clustering_Heatmap-v1.t2flow?version=1","/users/18734","Chengc","taverna 2","/users/18734,","Chengc,","Creates a genotyping comparison analysis Excel file and heatmap image given final report and gender call input files. User provides a plate number and can choose to either load the data into the database or not (y/n). Note that if user chooses y the script will take longer to run. Before running, make sure the final report and gender call text files are correctly named and that they are in the correct directory under: /gne/research/data/lab-shares/gCell/_gCell/Baseline_Profiling_Cells/Genotyping/Plate_# Results will be stored under this directory: /gne/research/data/bioinfo/gcell/genotype/prd/Plate_#",0, 0, ,
"http://www.myexperiment.org/workflows/2317/versions/2.html","GT: Genotyping Comparison Analysis and Clustering/Heatmap","2011-09-0117:52:22","2011-09-1001:01:04","http://www.myexperiment.org/workflows/2317/download/GT__Genotyping_Comparison_Analysis_and_Clustering_Heatmap-v2.t2flow?version=2","/users/18734","Chengc","taverna 2","/users/18734,","Chengc,","Creates a genotyping comparison analysis Excel file and heatmap image given final report and gender call input files. User provides a plate number and can choose to either load the data into the database or not (y/n). Note that if user chooses y the script will take longer to run. Before running, make sure the final report and gender call text files are correctly named and that they are in the correct directory under: /gne/research/data/lab-shares/gCell/_gCell/Baseline_Profiling_Cells/Genotyping/Plate_# Results will be stored under this directory: /gne/research/data/bioinfo/gcell/genotype/prd/Plate_#",0, 0, ,
"http://www.myexperiment.org/workflows/2317/versions/3.html","GT: Genotyping Comparison Analysis and Clustering/Heatmap","2011-09-0117:52:22","2011-09-1001:01:04","http://www.myexperiment.org/workflows/2317/download/GT__Genotyping_Comparison_Analysis_and_Clustering_Heatmap-v3.t2flow?version=3","/users/18734","Chengc","taverna 2","/users/18734,","Chengc,","Creates a genotyping comparison analysis Excel file and heatmap image given final report and gender call input files. User provides a plate number and can choose to either load the data into the database or not. Note that if user chooses to load data into database, script may take longer (few minutes) to run. Before running, make sure the final report and gender call text files are correctly named and that they are in the correct directory under: /gne/research/data/lab-shares/gCell/_gCell/Baseline_Profiling_Cells/Genotyping/Plate_# Results will be stored under this directory: /gne/research/data/bioinfo/gcell/genotype/prd/Plate_#",0, 0, ,
"http://www.myexperiment.org/workflows/2317/versions/4.html","GT: Genotyping Comparison Analysis and Clustering/Heatmap","2011-09-0117:52:22","2011-09-1001:01:04","http://www.myexperiment.org/workflows/2317/download/GT__Genotyping_Comparison_Analysis_and_Clustering_Heatmap-v4.t2flow?version=4","/users/18734","Chengc","taverna 2","/users/18734,","Chengc,","Creates a genotyping comparison analysis Excel file and heatmap image given final report and gender call input files. User provides a plate number and can choose to either load the data into the database or not. Note that if user chooses to load data into database, script may take longer (few minutes) to run. Before running, make sure the final report and gender call text files are correctly named and that they are in the correct directory under: /gne/research/data/lab-shares/gCell/_gCell/Baseline_Profiling_Cells/Genotyping/Plate_# Results will be stored under this directory: /gne/research/data/bioinfo/gcell/genotype/prd/Plate_#",0, 0, ,
"http://www.myexperiment.org/workflows/2317/versions/5.html","GT: Genotyping Comparison Analysis and Clustering/Heatmap","2011-09-0117:52:22","2011-09-1001:01:04","http://www.myexperiment.org/workflows/2317/download/GT__Genotyping_Comparison_Analysis_and_Clustering_Heatmap-v5.t2flow?version=5","/users/18734","Chengc","taverna 2","/users/18734,","Chengc,","Creates a genotyping comparison analysis Excel file and heatmap image given final report and gender call input files. User provides a plate number and can choose to either load the data into the database or not. Note that if user chooses to load data into database, script may take longer (few minutes) to run. Before running, make sure the final report and gender call text files are correctly named and that they are in the correct directory under: /gne/research/data/lab-shares/gCell/_gCell/Baseline_Profiling_Cells/Genotyping/Plate_# Results will be stored under this directory: /gne/research/data/bioinfo/gcell/genotype/prd/Plate_#",0, 0, ,
"http://www.myexperiment.org/workflows/2317/versions/6.html","GT: Genotyping Comparison Analysis and Clustering/Heatmap","2011-09-0117:52:22","2011-09-1001:01:04","http://www.myexperiment.org/workflows/2317/download/GT__Genotyping_Comparison_Analysis_and_Clustering_Heatmap-v6.t2flow?version=6","/users/18734","Chengc","taverna 2","/users/18734,","Chengc,","Creates a genotyping comparison analysis Excel file and heatmap image given final report and gender call input files. User provides either plate numbers, CLID/BIOIDs, cNames, etc. and can choose to either load the data into the database or not. Note that if user chooses to load data into database, script may take longer (few minutes) to run. Before running, make sure the final report and gender call text files are correctly named and that they are in the correct directory under: /gne/research/data/lab-shares/gCell/_gCell/Baseline_Profiling_Cells/Genotyping/Plate_# Results will be stored under this directory: /gne/research/data/bioinfo/gcell/genotype/prd/Plate_# For more details please read the SNP Genotyping Manual",0, 0, ,
"http://www.myexperiment.org/workflows/2317/versions/7.html","GT: Genotyping Comparison Analysis and Clustering/Heatmap","2011-09-0117:52:22","2011-09-1001:01:04","http://www.myexperiment.org/workflows/2317/download/GT__Genotyping_Comparison_Analysis_and_Clustering_Heatmap-v7.t2flow?version=7","/users/18734","Chengc","taverna 2","/users/18734,","Chengc,","Creates a genotyping comparison analysis Excel file and heatmap image given final report and gender call input files. User provides either plate numbers, CLID/BIOIDs, cNames, etc. and can choose to either load the data into the database or not. Note that if user chooses to load data into database, script may take longer (few minutes) to run. Before running, make sure the final report and gender call text files are correctly named and that they are in the correct directory under: /gne/research/data/lab-shares/gCell/_gCell/Baseline_Profiling_Cells/Genotyping/Plate_# Results will be stored under this directory: /gne/research/data/bioinfo/gcell/genotype/prd/Plate_# For more details please read the SNP Genotyping Manual",0, 0, ,
"http://www.myexperiment.org/workflows/2330/versions/1.html","GT: Database - Master SNP Call Table","2011-09-1000:22:14","","http://www.myexperiment.org/workflows/2330/download/GT__Database_-_Master_SNP_Call_Table-v1.t2flow?version=1","/users/18734","Chengc","taverna 2","/users/18734,","Chengc,","Either load new Master SNP call data into the database (from an Excel file) or export the master SNP data from the database into an Excel file. NOTE: Running this workflow will take a couple of minutes. If loading excel data into database, make sure the file is located in the correct directory:/gne/research/data/lab-shares/gCell/_gCell/Baseline_Profiling_Cells/Genotyping/",0, 0, ,
"http://www.myexperiment.org/workflows/2331/versions/1.html","Seven day weather by zip code","2011-09-1021:04:14","2011-09-1403:22:33","http://www.myexperiment.org/workflows/2331/download/Seven_day_weather_by_zip_code-v1.t2flow?version=1","/users/18784","Wdsnellg","taverna 2","/users/18784,","Wdsnellg,","Get the seven day weather forcast for your zip code.  Info display:  wind, visibility, temperature, sky conditions and pressure.&nbsp; Add zip code values to get weather information.",0, 0, ,
"http://www.myexperiment.org/workflows/2334/versions/1.html","Fetch today&#39;s Johnny Wander Comic","2011-09-1218:17:05","2011-09-1218:22:14","http://www.myexperiment.org/workflows/2334/download/Fetch_today_s_Johnny_Wander_Comic-v1.t2flow?version=1","/users/18785","tpacurtis","taverna 2","/users/18785, /users/62,","tpacurtis, Franck Tanoh,","Use the local java plugins and some filtering operations to fetch the comic strip image from  <a href=http://www.johnnywander.com/ rel=nofollow>http://www.johnnywander.com/</a>   Based on the FetchDailyDilbert workflow &amp; Fetch today's XKDC comic",0, 0, ,
"http://www.myexperiment.org/workflows/2336/versions/1.html","Get Recent Cards From Indexed","2011-09-1302:48:57","2011-09-1302:48:59","http://www.myexperiment.org/workflows/2336/download/Get_Recent_Cards_From_Indexed-v1.t2flow?version=1","/users/18930","Mutanthumb","taverna 2","","","This gets the jpgs from the This is Indexed URL:  <a href=http://thisisindexed.com/page/2/ rel=nofollow>http://thisisindexed.com/page/2/</a>  using the regular expression .*/uploads/*. pull everything in the uploads directory. Based on Fetch today's xkcd comic by Tom Oinn, Stian Soiland-ReyesUse the local java plugins and some filtering operations to fetch the comic strip image from  <a href=http://xkcd.com/ rel=nofollow>http://xkcd.com/</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2337/versions/1.html","Get My Weather","2011-09-1302:50:47","2011-09-1302:50:48","http://www.myexperiment.org/workflows/2337/download/Get_My_Weather-v1.t2flow?version=1","/users/18930","Mutanthumb","taverna 2","/users/18930,","Mutanthumb,","Gets a variety weather info for Cleveland and Indianapolis Based on Get weather information by Franck Tanoh",0, 0, ,
"http://www.myexperiment.org/workflows/2338/versions/1.html","ZipCodeGetWeatherInfo","2011-09-1302:51:51","2011-09-1302:51:52","http://www.myexperiment.org/workflows/2338/download/ZipCodeGetWeatherInfo-v1.t2flow?version=1","/users/18930","Mutanthumb","taverna 2","/users/18930,","Mutanthumb,","Gives the 7 day weather forecast by Zip CodeInfo display:  wind, visibility, temperature, sky conditions and pressure. Based on Get Weather Info by Franck Tanoh",0, 0, ,
"http://www.myexperiment.org/workflows/2339/versions/1.html","Get 7 Days Weather by Zip Code","2011-09-1305:29:07","2011-09-1305:30:48","http://www.myexperiment.org/workflows/2339/download/Get_7_Days_Weather_by_Zip_Code-v1.t2flow?version=1","/users/18785","tpacurtis","taverna 2","/users/18785,","tpacurtis,","This workflow allows for the input of a list of zipcodes and outputs the weather for the zip codes.",-1, 0, ,
"http://www.myexperiment.org/workflows/2340/versions/1.html","Merge list of errors to string","2011-09-1314:04:50","2011-09-1314:16:05","http://www.myexperiment.org/workflows/2340/download/Merge_list_of_errors_to_string-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","","","&lt;meta /&gt;Based on&nbsp; <a href=http://myexperiment.elda.org/workflows/27/ rel=nofollow>http://myexperiment.elda.org/workflows/27/</a> &nbsp;(but myExperiment does not allow multi-myExperiment citations) Also see&nbsp; <a href=http://taverna-users.markmail.org/search/?q=#query:+page:1+mid:cnfl53jbczhpf66b+state:results rel=nofollow>http://taverna-users.markmail.org/search/?q=#query:+page:1+mid:cnfl53jbczhpf66b+state:results</a> &lt;meta /&gt; This example shows how to&nbsp; &nbsp; &lt;meta /&gt; <span class=Apple-style-span>Summary:</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>1) Make a temporary file</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>2) Receive the list item by item - write line to file</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>3) Any failed items will simply fail writing (so errors are stripped)</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>4) Read/use file in next step of workflow</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>Now you won't be able to insert placeholders with this solution, but</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>it should work.</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>This a modified version. This uses the file-encoding &quot;utf-8&quot;</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>and so should work well also with international characters. It also</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>returns the value as a File reference, which mean that this merge</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>should consume less memory than Merge_string_list_to_a_String.</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>Note that I was not able to use this as a nested workflow shim, as the</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>processor for the nested workflow has the &quot;error bounce&quot; layer,</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>preventing executions of the nested workflow when there are errors in</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>the incoming list. Manually editing the .t2flow to disable this error</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>handling for the nested workflow unfortunately brought out an error in</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>provenance capture that meant that the nested workflow would &quot;never</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>finish&quot;.</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>Note that Taverna does not make any guarantees as to the execution</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>order when iterating over a list. It depends on the pipelining from</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>the upstream source if these will occur out of order or not. In this</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>example, the Write_text_file_append was however called in order.</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>So if anyone else wants to use this clever workaround, use &quot;Merge</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>workflow&quot; and manually delete the local workers before connecting to</span> <span class=Apple-style-span><br /></span> <span class=Apple-style-span>the real service.</span> <span class=Apple-style-span><br /></span> &nbsp; &nbsp;",1, 0, ,
"http://www.myexperiment.org/workflows/2340/versions/2.html","Merge list of errors to string","2011-09-1314:04:50","2011-09-1314:16:05","http://www.myexperiment.org/workflows/2340/download/Merge_list_of_errors_to_string-v2.t2flow?version=2","/users/5","Stian Soiland-Reyes","taverna 2","","","Based on  <a href=http://myexperiment.elda.org/workflows/27/ rel=nofollow>http://myexperiment.elda.org/workflows/27/  </a> The beanshell scripts collectively builds a temporary file of the merged string (by default using newline as separator). As each item is appended to the file separately by Write_text_append, this means it can handle occassional errors in the list, such as in the output from Sometimes_fails. Such items are not included in the merged string. To use,  <b>merge</b>  with your workflow and delete  <i>&quot;Create_Lots_if_Strings&quot;, &quot;Sometimes_Fails&quot; </i> and <i> &quot;Merge_String_List_to_A_String&quot;</i> .   Note that Taverna can't provide promises to the order of the execution of Write_text_file_append. Also see  <a href=http://taverna-users.markmail.org/search/?q=#query:+page:1+mid:cnfl53jbczhpf66b+state:results rel=nofollow>email discussion</a> .",0, 0, ,
"http://www.myexperiment.org/workflows/2341/versions/1.html","Fetch today&#39;s Dinosaur Comic (http://qwantz.com)","2011-09-1323:05:00","2011-09-1415:58:54","http://www.myexperiment.org/workflows/2341/download/Fetch_today_s_Dinosaur_Comic__http___qwantz.com_-v1.t2flow?version=1","/users/18931","Chrisser","taverna 2","","","This workflow retrieves the newest comic from  <a href=http://qwantz.com rel=nofollow>http://qwantz.com</a> . Using a string constant to input the URL, the workflow then copies the HTML code from the location indicated by the URL. A list of links to images is then taken from the HTML code. Using a regluar expression supplied by another string constant, this list is then search for the URL specificallyt for the comic. The image file for the comic is then retrieved and the comic is displayed as the workflow output.",0, 0, ,
"http://www.myexperiment.org/workflows/2343/versions/1.html","City weather information","2011-09-1403:17:00","2011-09-1403:21:25","http://www.myexperiment.org/workflows/2343/download/City_weather_information-v1.t2flow?version=1","/users/18784","Wdsnellg","taverna 2","/users/18784,","Wdsnellg,","Get the weather forcast of the day for you city.  Info display:  wind, visibility, temperature, sky conditions and pressure.  The default value is my home town.  To find out any supported city run the 'Get cities by country name' workflow",0, 0, ,
"http://www.myexperiment.org/workflows/2344/versions/1.html","Fetch today&#39;sVG Cats comic","2011-09-1404:32:48","2011-09-1405:01:30","http://www.myexperiment.org/workflows/2344/download/Fetch_today_sVG_Cats_comic-v1.t2flow?version=1","/users/18929","Gstalloch","taverna 2","/users/18929, /users/297, /users/5, /users/30,","Gstalloch, Tomoinn, Stian Soiland-Reyes, Alan Williams,","Use the local java plugins and some filtering operations to fetch the comic strip image from  <a href=http://xkcd.com/ rel=nofollow>http://xkcd.com/</a>   Based on the FetchDailyDilbert workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/2345/versions/1.html","Fetch today&#39;s cat and girl comic","2011-09-1404:38:01","2011-09-1404:39:29","http://www.myexperiment.org/workflows/2345/download/Fetch_today_s_cat_and_girl_comic-v1.t2flow?version=1","/users/19046","Atminer","taverna 2","/users/19046,","Atminer,","Use the local java plugins and some filtering operations to fetch the comic strip image from  <a href=http://catandgirl.com/ rel=nofollow>http://catandgirl.com/</a> , your major source of essential lead. Based on the Fetch today's xkcd workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/2346/versions/1.html","Fetch today&#39;s Girls with Slingshots comic","2011-09-1405:17:49","2011-09-1405:22:52","http://www.myexperiment.org/workflows/2346/download/Fetch_today_s_Girls_with_Slingshots_comic-v1.t2flow?version=1","/users/18934","Kayleigh Ayn BohÃ©mier","taverna 2","/users/18934,","Kayleigh Ayn BohÃ©mier,","This workflow uses local java plugins and filtering operations to fetch today's comic strip image from  <a href=http://www.girlswithslingshots.com/ rel=nofollow>http://www.girlswithslingshots.com/</a> . Girls with Slingshots focuses on the lives of a group of women in their twenties. It is one of the few major webcomics to pass the Bechdel test.  Based on the workflow &quot;Fetch today's xkcd comic&quot; by Tom Oinn and Stian Soiland-Reyes.",0, 0, ,
"http://www.myexperiment.org/workflows/2347/versions/1.html","Seven-Day Forecast","2011-09-1405:23:48","","http://www.myexperiment.org/workflows/2347/download/Seven-Day_Forecast-v1.t2flow?version=1","/users/18934","Kayleigh Ayn BohÃ©mier","taverna 2","/users/18934,","Kayleigh Ayn BohÃ©mier,","This workflow takes a list of zipcodes and generates their seven-day weather reports using the USA Weather Forecast from  <a href=http://www.webservicex.net/WS/WSDetails.aspx?WSID=68&amp;CATID=12 rel=nofollow>http://www.webservicex.net/WS/WSDetails.aspx?WSID=68&CATID;=12</a> The output includes maximum and minimum temperatures in both Fahrenheit and Celsius.",0, 0, ,
"http://www.myexperiment.org/workflows/2348/versions/1.html","Get 7 day weather information for selected zip codes.","2011-09-1405:46:28","2011-09-1405:46:25","http://www.myexperiment.org/workflows/2348/download/Get_7_day_weather_information_for_selected_zip_codes.-v1.t2flow?version=1","/users/18929","Gstalloch","taverna 2","/users/18929, /users/62,","Gstalloch, Franck Tanoh,","Get the weather forcast of the day for you city.Info display:  wind, visibility, temperature, sky conditions and pressure.The default value is my home town.To find out any supported city run the 'Get cities by country name' workflow",0, 0, ,
"http://www.myexperiment.org/workflows/2349/versions/1.html","7 day weather forecast for a list of cities","2011-09-1416:17:15","2011-09-1416:17:16","http://www.myexperiment.org/workflows/2349/download/7_day_weather_forecast_for_a_list_of_cities-v1.t2flow?version=1","/users/18931","Chrisser","taverna 2","/users/18931,","Chrisser,","This workflow uses an input port to take a list of zipcodes as input. Using the GetWeatherByZipcode service ('USA Weather Forecast' web services from WebserviceX.net), the weather forecast is retrieved for each of the zipcodes from the input. These forecasts are output as XML trees.",0, 0, ,
"http://www.myexperiment.org/workflows/2354/versions/1.html","Echo","2011-09-1613:20:00","","http://www.myexperiment.org/workflows/2354/download/Echo-v1.t2flow?version=1","/users/6595","Christian","taverna 2","/users/6595,","Christian,","This does a simple Echo",0, 0, ,
"http://www.myexperiment.org/workflows/2359/versions/1.html","Point coordinate projection transformation","2011-09-1617:24:33","2011-09-1617:24:36","http://www.myexperiment.org/workflows/2359/download/Point_coordinate_projection_transformation-v1.t2flow?version=1","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","Point coordinate transformation. Hard coded example of transformation from 4326 (lat/long) to 32630 (UTM 30N) for 3 points in the UK. The service is called once at the time, just to test the list interactor, since the service could work with a list of points.Metadata:  <a href=http://rsg.pml.ac.uk/wps/generic.cgi?request=describeProcess&amp;service=wps&amp;identifier=reprojectCoords&amp;version=1.0.0 rel=nofollow>http://rsg.pml.ac.uk/wps/generic.cgi?request=describeProcess&service;=wps&identifier;=reprojectCoords&version;=1.0.0</a> Library: gdaltransform",0, 0, ,
"http://www.myexperiment.org/workflows/2360/versions/1.html","Geottif image reprojection","2011-09-1617:32:25","2011-09-1617:32:29","http://www.myexperiment.org/workflows/2360/download/Geottif_image_reprojection-v1.t2flow?version=1","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","Example of a WPS  service that reprojects a geoTIFF by using a EPSG code. THe example image is in EPSG:32119, lcc projection for north caroline and it comes from GRASS-GIS spearfish dataset. The image is reprojected into EPSG:4326 (lat/long): Metadata:  <a href=http://rsg.pml.ac.uk/wps/generic.cgi?request=describeProcess&amp;service=wps&amp;identifier=reprojectImage&amp;version=1.0.0 rel=nofollow>http://rsg.pml.ac.uk/wps/generic.cgi?request=describeProcess&service;=wps&identifier;=reprojectImage&version;=1.0.0</a> Library: gdalwarp",0, 0, ,
"http://www.myexperiment.org/workflows/2370/versions/1.html","Population histogram in R (with Ask Box!)","2011-09-2102:52:40","2011-09-2103:23:11","http://www.myexperiment.org/workflows/2370/download/Population_histogram_in_R__with_Ask_Box__-v1.t2flow?version=1","/users/18785","tpacurtis","taverna 2","/users/18785, /users/30,","tpacurtis, Alan Williams,","This workflow fetches the details of the countries in the world and then uses R to produce a histogram of the log of their population. Prompts the user to enter a title for the histogram.",0, 0, ,
"http://www.myexperiment.org/workflows/2371/versions/1.html","Population histogram in R","2011-09-2103:11:29","2011-09-2103:11:26","http://www.myexperiment.org/workflows/2371/download/Population_histogram_in_R-v1.t2flow?version=1","/users/18784","Wdsnellg","taverna 2","/users/18784,","Wdsnellg,","This workflow fetches the details of the countries in the world and then uses R to produce a histogram of the log of their population",0, 0, ,
"http://www.myexperiment.org/workflows/2373/versions/1.html","Concatenated List of Values","2011-09-2103:34:19","2011-09-2103:41:15","http://www.myexperiment.org/workflows/2373/download/Concatenated_List_of_Values-v1.t2flow?version=1","/users/18785","tpacurtis","taverna 2","/users/18785,","tpacurtis,","This workflow takes multiple lists of values and finds the standard deviation and average of the provided values. It then concatenates each value into a single string.",-1, 0, ,
"http://www.myexperiment.org/workflows/2375/versions/1.html","Single list with statistics values (#2 Part 2)","2011-09-2104:31:29","2011-09-2119:24:00","http://www.myexperiment.org/workflows/2375/download/Single_list_with_statistics_values___2_Part_2_-v1.t2flow?version=1","/users/18784","Wdsnellg","taverna 2","/users/18784,","Wdsnellg,","This workflow allows one to produce a single list of statistical output with the list name, average, and standard deviation of the values.&nbsp; This workflow only produces the average and standard deviation from the input values",-1, 0, ,
"http://www.myexperiment.org/workflows/2378/versions/1.html","Spreadsheet Import Fertilizer Use","2011-09-2105:38:20","2011-09-2105:41:25","http://www.myexperiment.org/workflows/2378/download/Spreadsheet_Import_Fertilizer_Use-v1.t2flow?version=1","/users/18785","tpacurtis","taverna 2","/users/18785, /users/30,","tpacurtis, Alan Williams,","Example using the SpreadsheetImport service to import data from an Excel spreadsheet. The workflow imports the file spreadsheet file FertilizerUse.xlsx and generates a graph from the date. The source data is from  <a href=http://www.myexperiment rel=nofollow>http://www.myexperiment</a> . <br /> org/files/568/download/FertilizerUse.xls and ERS, TVA (Tennessee Valley Authority), AAPFCO (Association of American Plant Food Control Officials), TFI (The Fertilizer Institute).",0, 0, ,
"http://www.myexperiment.org/workflows/2379/versions/1.html","World Population Density - IST 600","2011-09-2105:51:09","2011-09-2105:51:06","http://www.myexperiment.org/workflows/2379/download/World_Population_Density_-_IST_600-v1.t2flow?version=1","/users/18929","Gstalloch","taverna 2","/users/18929,","Gstalloch,","This workflow fetches the details of the countries in the world and then uses R to produce a histogram of the log of their population. Based on Population Histogram in R by Alan R Williams",0, 0, ,
"http://www.myexperiment.org/workflows/2380/versions/1.html","US Consumption of Plant Nutrients","2011-09-2107:09:00","2011-09-2107:08:58","http://www.myexperiment.org/workflows/2380/download/US_Consumption_of_Plant_Nutrients-v1.t2flow?version=1","/users/18934","Kayleigh Ayn BohÃ©mier","taverna 2","/users/18934,","Kayleigh Ayn BohÃ©mier,","This workflow takes data from the ERS, TVA (Tennessee Valley Authority), AAPFCO (Association of American Plant Food Control Officials), and the TFI (The Fertilizer Institute) and represents them in a bar chart.",0, 0, ,
"http://www.myexperiment.org/workflows/2381/versions/1.html","Broccoli: A State Comparison","2011-09-2107:09:43","2011-09-2107:09:41","http://www.myexperiment.org/workflows/2381/download/Broccoli__A_State_Comparison-v1.t2flow?version=1","/users/18934","Kayleigh Ayn BohÃ©mier","taverna 2","/users/18934,","Kayleigh Ayn BohÃ©mier,","Imports data from NY and NJ to compare broccoli harvest vs. planting rates across the two states. The workflow is currently set to evaluate data from 1960 to 1965. Source: Compiled by ERS from data of USDA, National Agricultural Statistics Service, Vegetables Final Estimates.",0, 0, ,
"http://www.myexperiment.org/workflows/2382/versions/1.html","Standard Deviation and Mean Values from a Text File","2011-09-2107:14:29","2011-09-2107:41:48","http://www.myexperiment.org/workflows/2382/download/Standard_Deviation_and_Mean_Values_from_a_Text_File-v1.t2flow?version=1","/users/18934","Kayleigh Ayn BohÃ©mier","taverna 2","/users/18934,","Kayleigh Ayn BohÃ©mier,","This incredibly awkward script has another embedded script associated with it. It essentially smashes the output from the other workflows together using a Beanshell script.",0, 0, ,
"http://www.myexperiment.org/workflows/2383/versions/1.html","Standard Deviation From a Text File: Nested Workflow","2011-09-2107:16:28","2011-09-2107:16:25","http://www.myexperiment.org/workflows/2383/download/Standard_Deviation_From_a_Text_File__Nested_Workflow-v1.t2flow?version=1","/users/18934","Kayleigh Ayn BohÃ©mier","taverna 2","/users/18934,","Kayleigh Ayn BohÃ©mier,","This workflow takes an input file of a list of numbers and runs it through a simple Python script to produce the standard deviation and average.",0, 0, ,
"http://www.myexperiment.org/workflows/2384/versions/1.html","Python Average and Standard Deviation","2011-09-2107:25:25","2011-09-2107:48:54","http://www.myexperiment.org/workflows/2384/download/Python_Average_and_Standard_Deviation-v1.t2flow?version=1","/users/18934","Kayleigh Ayn BohÃ©mier","taverna 2","/users/18934,","Kayleigh Ayn BohÃ©mier,","&nbsp;This workflow uses a Python script to take a provided filename (or list of filenames) containing numbers (one per line) and return the standard deviation and average (or mean).",-1, 0, ,
"http://www.myexperiment.org/workflows/2384/versions/2.html","Python Average and Standard Deviation","2011-09-2107:25:25","2011-09-2107:48:54","http://www.myexperiment.org/workflows/2384/download/Python_Average_and_Standard_Deviation-v2.t2flow?version=2","/users/18934","Kayleigh Ayn BohÃ©mier","taverna 2","/users/18934,","Kayleigh Ayn BohÃ©mier,","This workflow uses a Python script to take a provided filename (or list of filenames) containing numbers (one per line) and return the standard deviation and average (or mean).",0, 0, ,
"http://www.myexperiment.org/workflows/2385/versions/1.html","Avg and StdDev IST 600","2011-09-2107:51:07","2011-09-2107:51:04","http://www.myexperiment.org/workflows/2385/download/Avg_and_StdDev_IST_600-v1.t2flow?version=1","/users/18929","Gstalloch","taverna 2","/users/18929,","Gstalloch,","A workflow to calculate and name the average and standard deviation of a list of numbers. Changes made to the original workflow are: an inout and output, a concatenation to list the average and standard deviation outputs, a string constant to name the list, and a concatenation to string the name znd the calculations.",0, 0, ,
"http://www.myexperiment.org/workflows/2386/versions/1.html","New York vs. New Jersey Broccoli Production","2011-09-2108:39:27","2011-09-2108:41:26","http://www.myexperiment.org/workflows/2386/download/New_York_vs._New_Jersey_Broccoli_Production-v1.t2flow?version=1","/users/18785","tpacurtis","taverna 2","/users/18785, /users/30,","tpacurtis, Alan Williams,","Uses the SpreadsheetImport service to import data from an Excel spreadsheet. The workflow imports two files and generates a single graph comparing the information from the two spreadsheets.",0, 0, ,
"http://www.myexperiment.org/workflows/2387/versions/1.html","Fertilzer Use Ist 600","2011-09-2108:52:43","2011-09-2108:52:41","http://www.myexperiment.org/workflows/2387/download/Fertilzer_Use_Ist_600-v1.t2flow?version=1","/users/18929","Gstalloch","taverna 2","/users/18929,","Gstalloch,","Example using the SpreadsheetImport service to import data from an Excel spreadsheet.The workflow imports the file spreadsheet file FertilzerUse.xlsx and generates a graph from the date.The source data is from  <a href=http://www.myexperiment.org/files/568/download/FertilizerUse.xls rel=nofollow>http://www.myexperiment.org/files/568/download/FertilizerUse.xls</a> . Based on the water use workflow by David Withers",0, 0, ,
"http://www.myexperiment.org/workflows/2389/versions/1.html","Broccoli production comparisons in NY and NJ between 1960 and 1965 Ist 600","2011-09-2115:23:11","2011-09-2115:23:08","http://www.myexperiment.org/workflows/2389/download/Broccoli_production_comparisons_in_NY_and_NJ_between_1960_and_1965_Ist_600-v1.t2flow?version=1","/users/18929","Gstalloch","taverna 2","/users/18929,","Gstalloch,","Example using the SpreadsheetImport service to import data from an Excel spreadsheet.The workflow imports the file spreadsheet file FertilzerUse.xlsx and generates a graph from the date.The source data is from  <a href=http://www.myexperiment.org/files/568/download/FertilizerUse.xls rel=nofollow>http://www.myexperiment.org/files/568/download/FertilizerUse.xls</a> . Based on the water use workflow by David Withers",0, 0, ,
"http://www.myexperiment.org/workflows/2390/versions/1.html","Name resolver of galaxies parsing the output using local services","2011-09-2117:59:49","2011-09-2118:03:58","http://www.myexperiment.org/workflows/2390/download/Name_resolver_of_galaxies_parsing_the_output_using_local_services-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","","This workflow ask for text file using Select_file local services. This file is read by the read_text_file, using utf-8 as encoding. The result of read_text_file is splitted in lines by split_string_into_string_list_by_regular_expression and each of this lines is the input for the Rest_servise. The REST service search for each line (each line contains one name of one galaxy) some information about that galaxy. The string is like: target=cig+1service=NED(ned <a href=http://www.ipac.caltech.edu rel=nofollow>www.ipac.caltech.edu</a> )coordsys=ICRSra=0.77358dec=-1.91381time(ms)=0 We convert this string into list of string using split_string_into_string_list_by_regular_expressionWe need extract the coordinates of the galaxy: the RA and DEC parameters, so we have to use two times the local services filter_list_of_string_extracting_match_to_a_regex. One of them with the regex= ra=(.*) and the other one with the regex=dec=(.*).  The result of this both filters is a list of list, so we have to use merge_string_list_to_a_string to get a list.",0, 0, ,
"http://www.myexperiment.org/workflows/2391/versions/1.html","New Population Histogram","2011-09-2118:02:12","2011-09-2118:02:09","http://www.myexperiment.org/workflows/2391/download/New_Population_Histogram-v1.t2flow?version=1","/users/18930","Mutanthumb","taverna 2","/users/18930,","Mutanthumb,","This workflow fetches the details of the countries in the world and then uses R to produce a histogram of the log of their population Based on Population histogram in R byAlan R Williams",0, 0, ,
"http://www.myexperiment.org/workflows/2393/versions/1.html","Mean Rshell","2011-09-2118:05:32","2011-09-2118:05:29","http://www.myexperiment.org/workflows/2393/download/Mean_Rshell-v1.t2flow?version=1","/users/18930","Mutanthumb","taverna 2","/users/18930,","Mutanthumb,","Used the Rshell to find the MEAN and standard deviation of a list of values.",0, 0, ,
"http://www.myexperiment.org/workflows/2394/versions/1.html","Name resolver of galaxies parsing the output using a python tool","2011-09-2118:07:25","","http://www.myexperiment.org/workflows/2394/download/Name_resolver_of_galaxies_parsing_the_output_using_a_python_tool-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","","This workflow ask for text file using Select_file local services. This file is read by the read_text_file, using utf-8 as encoding. The result of read_text_file is splitted in lines by split_string_into_string_list_by_regular_expression and each of this lines is the input for the Rest_servise. The REST service search for each line (each line contains one name of one galaxy) some information about that galaxy. The string is like: target=cig+1service=NED(ned <a href=http://www.ipac.caltech.edu rel=nofollow>www.ipac.caltech.edu</a> )coordsys=ICRSra=0.77358dec=-1.91381time(ms)=0 We have to write this string in a file using the local service Write_text_file in order to provide with a input file to the python tool. The python tool parse the text and extract the coordinates (ra and dec param) of the galaxy",0, 0, ,
"http://www.myexperiment.org/workflows/2395/versions/1.html","Nested Mean Rshell","2011-09-2118:07:43","2011-09-2118:07:44","http://www.myexperiment.org/workflows/2395/download/Nested_Mean_Rshell-v1.t2flow?version=1","/users/18930","Mutanthumb","taverna 2","/users/18930,","Mutanthumb,","This workflow uses a nested workflow. The nested workflow takes a list of values and finds the mean and standard deviation for each list. The result of the nested workflow is then concatenated with a list of names using Dot Product for list handling.",0, 0, ,
"http://www.myexperiment.org/workflows/2396/versions/1.html","Ag Spreadsheet Import","2011-09-2118:09:09","2011-09-2118:09:06","http://www.myexperiment.org/workflows/2396/download/Ag_Spreadsheet_Import-v1.t2flow?version=1","/users/18930","Mutanthumb","taverna 2","/users/18930, /users/30,","Mutanthumb, Alan Williams,","Based on Spreadsheet Import Example by David WithersSusanExample using the SpreadsheetImport service to import data from an Excel spreadsheet.The workflow imports the file spreadsheet file WaterUse.xlsx and generates a graph from the date.The source data is from  <a href=http://data.gov.uk/ rel=nofollow>http://data.gov.uk/</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2397/versions/1.html","Population histogram in R","2011-09-2118:10:49","2011-09-2118:10:53","http://www.myexperiment.org/workflows/2397/download/Population_histogram_in_R-v1.t2flow?version=1","/users/18931","Chrisser","taverna 2","/users/18931,","Chrisser,","This workflow fetches the details of the countries in the world and then uses R to produce a histogram of the log of their population",0, 0, ,
"http://www.myexperiment.org/workflows/2398/versions/1.html","Failed 2 Chart Attempt","2011-09-2118:13:12","2011-09-2118:13:09","http://www.myexperiment.org/workflows/2398/download/Failed_2_Chart_Attempt-v1.t2flow?version=1","/users/18930","Mutanthumb","taverna 2","/users/18930, /users/30,","Mutanthumb, Alan Williams,","Tried to show 2 charts simulatneously.",0, 0, ,
"http://www.myexperiment.org/workflows/2399/versions/1.html","IST600 - Spreadsheet Import Example","2011-09-2118:22:17","2011-09-2118:32:23","http://www.myexperiment.org/workflows/2399/download/IST600_-_Spreadsheet_Import_Example-v1.t2flow?version=1","/users/18931","Chrisser","taverna 2","/users/18931,","Chrisser,","Example using the SpreadsheetImport service to import data from an Excel spreadsheet. The workflow imports the file spreadsheet FertilizerUse.xls and generates a graph from the date. The spreadsheet is available at  <a href=http://www.myexperiment rel=nofollow>http://www.myexperiment</a> . <br /> org/files/568/download/FertilizerUse.xls",0, 0, ,
"http://www.myexperiment.org/workflows/2400/versions/1.html","slightly more complicated Spreadsheet Import Example","2011-09-2118:35:26","2011-09-2118:48:09","http://www.myexperiment.org/workflows/2400/download/slightly_more_complicated_Spreadsheet_Import_Example-v1.t2flow?version=1","/users/18931","Chrisser","taverna 2","/users/18931, /users/18784, /users/18785,","Chrisser, Wdsnellg, tpacurtis,","Example using two instances of the SpreadsheetImport service to import data from&nbsp; Excel spreadsheets. The workflow imports these file spreadsheets f and generates a graph comparing the data.",0, 0, ,
"http://www.myexperiment.org/workflows/2401/versions/1.html","input list example","2011-09-2118:50:23","2011-09-2119:28:04","http://www.myexperiment.org/workflows/2401/download/input_list_example-v1.t2flow?version=1","/users/18931","Chrisser","taverna 2","/users/18931,","Chrisser,","This workflow is a simple example of how to input a list of numeric values and perform some ultra-basic calculations using Rserve. The output is two separate numbers, the mean and standard deviation of the list of input values.",-1, 0, ,
"http://www.myexperiment.org/workflows/2409/versions/1.html","Comparing Quantities","2011-09-2313:32:16","","http://www.myexperiment.org/workflows/2409/download/Comparing_Quantities-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","","This workflow receives the name of the property to compare, a file with a list of names of galaxies, and a file with the list of original values of that property. The property name must be the same used in the VOtable returned by the Vizier service.The workflow calls to sesame name resolver using as input the names of the galaxies and gets the coordinates. Then it calls to Vizier service and provides to it with the coordinates as input, in order to get a VOTable with information about each galaxy. From each VOTable, it extracts the value of the property selected by the user and then compares this values with the values provided by the file with the original values.",0, 0, ,
"http://www.myexperiment.org/workflows/2442/versions/1.html","Calculating galaxies distances using data from LEDA","2011-10-0111:26:35","2011-10-0316:28:27","http://www.myexperiment.org/workflows/2442/download/Calculating_galaxies_distances_using_data_from_LEDA-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","","This workflow needs two inputs: a file with the list of the names of galaxies whose distance are going to be calculated (name galaxy file), and a file with our values of velocity for each galaxy (local velocity file).  This workflow is composed by 5 nested workflow. The first one is used to read line by line the name galaxy file. This list of names is the input for the following two nested workflows. One of them uses the line with the name of galaxy to call HyperLEDA and to extract the velocity values from this service (Extract velocity workflow). And the other one calls HyperLEDA too, but to extract the J2000 coordinates of each galaxy (Extract J2000 workflow). The fourth nested workflow makes a comparision between the velocities values extracted from HyperLEDA and our velocity values (local velocity file), and it writes a file with this comparsion.  The last nested workflow uses this comparing velocity file and the J2000 cordinates file to calculate the distance of each galaxy",0, 0, ,
"http://www.myexperiment.org/workflows/2445/versions/1.html","Biomart datasets for the Ensembl Genes mart service","2011-10-0310:17:40","","http://www.myexperiment.org/workflows/2445/download/Biomart_datasets_for_the_Ensembl_Genes_mart_service-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Retrieve Biomart datasets for the Ensembl Genes mart service (one dataset per specie).",0, 0, ,
"http://www.myexperiment.org/workflows/2446/versions/1.html","Find Orthologs for proteins in Ensembl","2011-10-0314:33:04","2011-10-0314:33:07","http://www.myexperiment.org/workflows/2446/download/Find_Orthologs_for_proteins_in_Ensembl-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Find Orthologs for proteins in Ensembl using biomart.",0, 0, ,
"http://www.myexperiment.org/workflows/2447/versions/1.html","[untitled]","2011-10-0314:34:47","2011-10-0314:35:10","http://www.myexperiment.org/workflows/2447/download/_untitled_-v1.t2flow?version=1","/users/19411","Zhaoyin...","taverna 2","/users/19411,","Zhaoyingguang,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2455/versions/1.html","Comparing Quantities using HyperLEDA","2011-10-0316:58:09","","http://www.myexperiment.org/workflows/2455/download/Comparing_Quantities_using_HyperLEDA-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","","This workflow receives the name of the property to compare, a file with a list of names of galaxies, and a file with the list of original values of that property. The property name must be typed in the same way used in the HTML returned by HyperLEDAThe workflow calls to HyperLEDA using the names of the galaxies as input, and it returns a HTML file with information about the galaxy. This file is parsed by the python tool ExtractPropertyValues, that extracts the value of the property introduced by the user. The results of this tool are written in a file, and with the file of the original values compose the input for the Make_comparing_file tool, that build a file with a comparision between the original values and the values got from LEDA.",0, 0, ,
"http://www.myexperiment.org/workflows/2458/versions/1.html","Retrieve Molecular Interactions from PSICQUIC Services for a list of Protein Accessions","2011-10-0500:40:20","2011-10-0500:40:22","http://www.myexperiment.org/workflows/2458/download/Retrieve_Molecular_Interactions_from_PSICQUIC_Services_for_a_list_of_Protein_Accessions-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Retrieve Molecular Interactions from PSICQUIC Services for a list of Protein Accessions in PSI-MITAB format",0, 0, ,
"http://www.myexperiment.org/workflows/2460/versions/1.html","What&#39;s the Season?","2011-10-0505:32:46","2011-10-0505:32:45","http://www.myexperiment.org/workflows/2460/download/What_s_the_Season_-v1.t2flow?version=1","/users/18934","Kayleigh Ayn BohÃ©mier","taverna 2","","","When given a list of astronomical object names, this workflow will check them against a simple Excel spreadsheet and return which season the object is best observed in. It will also compare the distances to the objects in a Google Charts bar chart. A later version of this may switch to a scatter plot, depending on whether or not this works with the Google Chart API. Running this workflow requires Python. Sys and string should be bundled in Python, but the numpy module will need to be downloaded and installed separately if not already on your system.",0, 0, ,
"http://www.myexperiment.org/workflows/2461/versions/1.html","Extracting Quantities from HyperLEDA","2011-10-0509:21:40","2011-10-0509:21:39","http://www.myexperiment.org/workflows/2461/download/Extracting_Quantities_from_HyperLEDA-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","","This workflow receives the name of the property to compare and a file with a list of names of galaxies. The property name must be the same used in the HTML file returned by the HyperLEDA service.The workflow calls to HyperLEda service, using as input the names of the galaxies in order to get a HTML file with information about each galaxy. From each HTML file, it extracts the value of the property selected by the user.The workflow uses a python tool to parse the HTML file (one for each galaxy) and extracts the value of the property. In order to build a file, it has to merge the output of the python tool using thel local service Merge_String_List_to_a_String",0, 0, ,
"http://www.myexperiment.org/workflows/2462/versions/1.html","HTML Citation Extraction","2011-10-0515:17:06","2011-10-0515:21:06","http://www.myexperiment.org/workflows/2462/download/HTML_Citation_Extraction-v1.t2flow?version=1","/users/19450","Jeff adamus","taverna 2","/users/19450,","Jeff adamus,","&nbsp;This workflow is a beanshell script that locates and extracts text within an html page. &nbsp;It was designed to pull citation information from the website&nbsp; <a href=http://robjhyndman.com/TSDL/ rel=nofollow>http://robjhyndman.com/TSDL/</a> .",-1, 0, ,
"http://www.myexperiment.org/workflows/2463/versions/1.html","Current Date Output","2011-10-0515:23:12","2011-10-0515:23:13","http://www.myexperiment.org/workflows/2463/download/Current_Date_Output-v1.t2flow?version=1","/users/19450","Jeff adamus","taverna 2","/users/19450,","Jeff adamus,","Returns the Current Date optionally Formatted by input. Free to copy and use by all!.",0, 0, ,
"http://www.myexperiment.org/workflows/2464/versions/1.html","Time Series Data Graphed and Cited","2011-10-0515:37:43","2011-10-0515:37:40","http://www.myexperiment.org/workflows/2464/download/Time_Series_Data_Graphed_and_Cited-v1.t2flow?version=1","/users/18933","Trisha Adamus","taverna 2","/users/18933, /users/30, /users/19450,","Trisha Adamus, Alan Williams, Jeff adamus,","This workflow uses time series data from Rob Hyndman's Time Series Data Library (TSDL) and graphs it with Google charts.  It also provides the citation information with the current date.  The outputs are a Google Chart and the corresponding citation information. The inputs are URL strings for two datasets provided by Rob Hyndman under the subject of Ecology.  These datasets include the annual number of lynx pelts and the annual unit price of lynx pelts during the year range 1857 -1911. This workflow will work with any two TSDL Andrews (D.F.Andrews and H.M.Herzberg, Data: A Collection of Problems from Many Fields for the Student and research Worker, 1985, Springer-Verlag.) sets of data with modifications to the hard coding present in the chart options of the GenerateGraphURL beanshell.  Notes have been added to the beanshell to facilitate modification of the line chart for those less familiar with Google charts.",0, 0, ,
"http://www.myexperiment.org/workflows/2466/versions/1.html","A graphical plot of White Ash, Beech, and Hemlock populations in Onondaga County, NY","2011-10-0601:13:43","2011-10-0601:15:03","http://www.myexperiment.org/workflows/2466/download/A_graphical_plot_of_White_Ash__Beech__and_Hemlock_populations_in_Onondaga_County__NY-v1.t2flow?version=1","/users/18929","Gstalloch","taverna 2","/users/18929,","Gstalloch,","This workflow graphs the numbers of White Ash, Beech and Hemlock in Onondaga, NY from 2002 to 2008.",0, 0, ,
"http://www.myexperiment.org/workflows/2468/versions/1.html","[untitled]","2011-10-0603:21:19","2011-10-0603:22:29","http://www.myexperiment.org/workflows/2468/download/_untitled_-v1.t2flow?version=1","/users/18931","Chrisser","taverna 2","/users/18931,","Chrisser,","This workflow ...tbc",-1, 0, ,
"http://www.myexperiment.org/workflows/2469/versions/1.html","Get Element ID from Gzipped GenBank file","2011-10-0603:53:12","2011-10-0604:12:18","http://www.myexperiment.org/workflows/2469/download/Get_Element_ID_from_Gzipped_GenBank_file-v1.t2flow?version=1","/users/18930","Mutanthumb","taverna 2","/users/18930, /users/30,","Mutanthumb, Alan Williams,","This workflow gunzips a *.gbk.gz file, converts it to XML (via agavewriter) and finds the Element ID. Does not work on *.gz files larger than 10MB. I upped the JVM settings on Taverna to: &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &lt;key&gt;VMOptions&lt;/key&gt; <br /> &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &lt;string&gt;-Xmx4096m -XX:MaxPermSize=1024m&lt;/string&gt; Created my own agave.dtd to get the XPath service to work the XML file generated from the Read_GenBank_File service. You will need to save the 3 dtd files to your Taverna folder for this workflow to work. This workflows works on *.gb and *.gbk files that are gzipped. It does NOT work with *.seq files, this is the error generated from the Read_GenBank_File service: &quot;Sourced file: inline evaluation of: ``import org.biojava.bio.seq.Sequence; import org.biojava.bio.seq.SequenceIterator . . . '' : Method Invocation writer.writeSequence : at Line: 36 : in file: inline evaluation of: ``import org.biojava.bio.seq.Sequence; import org.biojava.bio.seq.SequenceIterator . . . '' : writer .writeSequence ( seq , ps )  <br /> <br /> Target exception: java.lang.IllegalArgumentException: end must not be lower than start: start=561, end=560&quot;",0, 0, ,
"http://www.myexperiment.org/workflows/2470/versions/1.html","Elevation plot v.2","2011-10-0603:54:30","2011-10-0616:32:18","http://www.myexperiment.org/workflows/2470/download/Elevation_plot_v.2-v1.t2flow?version=1","/users/18931","Chrisser","taverna 2","/users/18931,","Chrisser,","This workflow accepts city and country names as user-supplied input. These value are supplied to the GetWeather webservice ( <a href=http://www.webservicex.net/globalweather.asmx?WSDL rel=nofollow>http://www.webservicex.net/globalweather.asmx?WSDL</a> ), which returns an XML record of location and weather info for each recognized city. (See the uploaded photo &quot;weather example&quot;) The XML returned from GetWeather is then searched using regular   expressions for the geogrpahic coordinates. Because the&nbsp; coordinates are   returned in a different format (with a hyphen) than is required for  the  next web service (with a period), a lot string-wrangling needs to   happen in order to format the coordinates as is needed while not loosing   values along the way. All of this happens in the two additional   workflows embedded in the main workflow, and which have been uploaded   with the titles &quot;latitudewithbeans&quot; and longitudewithbeans&quot;. The names   reference the fact that in each workflow netbeans scripts had to be   edited in order to produce the required output. From the two nested workflows, the output is two lists - one of   latitude coordinates, one of longitude coordinates, both ordered to   reflect the order in which the cities were originally entered. These   lists are then supplied as inputs for a REST Service that I've   configured to use the STRM webservice from geonames.org to fetch an   elevation for supplied latitude and longitude coordinates ( <a href=http://www.geonames.org/export/web-services.html#srtm3 rel=nofollow>http://www.geonames.org/export/web-services.html#srtm3</a> ). Because I've designed this workflow to pass blank values when cities   are not recognized, another customized regular expression matching   beanshell must follow the REST Service to catch any errors thrown from   blank input values. Now, errors default to an elevation of -450, lower   than any actual city on earth. Finally, elevations are output onto a bar chart which is labelled   with the appropriate city names. Negative elevations print as an   elevation equal to zero. !! Rserve is required for this workflow. !! &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/2470/versions/2.html","Elevation plot v.2","2011-10-0603:54:30","2011-10-0616:32:18","http://www.myexperiment.org/workflows/2470/download/Elevation_plot_v.2-v2.t2flow?version=2","/users/18931","Chrisser","taverna 2","/users/18931,","Chrisser,","Functionally identical to the original. I tried to upload a version with annotation, but somehow the notes didn't make it to myExperiment. From the prior verion: This workflow accepts city and country names as user-supplied input. These value are supplied to the GetWeather webservice ( <a href=http://www.webservicex.net/globalweather.asmx?WSDL rel=nofollow>http://www.webservicex.net/globalweather.asmx?WSDL</a> ), which returns an XML record of location and weather info for each recognized city. (See the uploaded photo &quot;weather example&quot;) The XML returned from GetWeather is then searched using regular    expressions for the geogrpahic coordinates. Because the&nbsp; coordinates are    returned in a different format (with a hyphen) than is required for   the  next web service (with a period), a lot string-wrangling needs to    happen in order to format the coordinates as is needed while not  loosing   values along the way. All of this happens in the two  additional   workflows embedded in the main workflow, and which have  been uploaded   with the titles &quot;latitudewithbeans&quot; and  longitudewithbeans&quot;. The names   reference the fact that in each  workflow netbeans scripts had to be   edited in order to produce the  required output. From the two nested workflows, the output is two lists - one of    latitude coordinates, one of longitude coordinates, both ordered to    reflect the order in which the cities were originally entered. These    lists are then supplied as inputs for a REST Service that I've    configured to use the STRM webservice from geonames.org to fetch an    elevation for supplied latitude and longitude coordinates ( <a href=http://www.geonames.org/export/web-services.html#srtm3 rel=nofollow>http://www.geonames.org/export/web-services.html#srtm3</a> ). Because I've designed this workflow to pass blank values when cities    are not recognized, another customized regular expression matching    beanshell must follow the REST Service to catch any errors thrown from    blank input values. Now, errors default to an elevation of -450, lower    than any actual city on earth. Finally, elevations are output onto a bar chart which is labelled    with the appropriate city names. Negative elevations print as an    elevation equal to zero. !! Rserve is required for this workflow. !!",-1, 0, ,
"http://www.myexperiment.org/workflows/2471/versions/1.html","Latitude with beanshell","2011-10-0603:58:11","2011-10-0604:32:39","http://www.myexperiment.org/workflows/2471/download/Latitude_with_beanshell-v1.t2flow?version=1","/users/18931","Chrisser","taverna 2","/users/18931,","Chrisser,","This workflow takes in a string value or list of values and pulls out latitude coordinates formatted as ##-##(N or S) using the following regular expression: \d\d-\d\d(N|S). The coordinates are processed and formatted to be in the form required by the web service used in my &quot;Elevation plot&quot; workflow. This workflow contains primarily string manipulation. For many of the text and list services used, the beanshell script needed to be modified in order to produce the formatting I required. All modified services contain documentation. This workflow is very similar to my &quot;Longitude with beanshell&quot; workflow, which performs similar manipulations between longitude coordinate formats.",-1, 0, ,
"http://www.myexperiment.org/workflows/2472/versions/1.html","Longitude with beanshell","2011-10-0604:06:57","2011-10-0604:29:35","http://www.myexperiment.org/workflows/2472/download/Longitude_with_beanshell-v1.t2flow?version=1","/users/18931","Chrisser","taverna 2","/users/18931,","Chrisser,","This workflow takes in a string value or list of values and pulls out  longitude coordinates formatted as ###-##(N or S) using the following  regular expression: \d\d\d-\d\d(E|W). The coordinates are processed and  formatted to be in the form required by the web service used in my  &quot;Elevation plot&quot; workflow. This workflow primarily contains string manipulation. For many of the  text and list services used, the beanshell script needed to be modified  in order to produce the formatting I required. All modified services  contain documentation. This workflow is very similar to my &quot;Latitude with Netbeans&quot; workflow, which performs similar manipulations between latitude coordinate formats.",-1, 0, ,
"http://www.myexperiment.org/workflows/2473/versions/1.html","Mapping Workflow - Attempt","2011-10-0604:41:46","2011-10-0604:46:35","http://www.myexperiment.org/workflows/2473/download/Mapping_Workflow_-_Attempt-v1.t2flow?version=1","/users/18785","tpacurtis","taverna 2","/users/18785,","tpacurtis,","PLEASE NOTE: This is an early variation of  <a href=http://www.myexperiment.org/workflows/2474.html rel=nofollow>http://www.myexperiment.org/workflows/2474.html</a> . This workflow was abandoned as the above mentioned workflow is more streamlined. This workflow may or may not work successfully.",-1, 0, ,
"http://www.myexperiment.org/workflows/2474/versions/1.html","Mapping Service","2011-10-0604:44:03","2011-10-0605:01:20","http://www.myexperiment.org/workflows/2474/download/Mapping_Service-v1.t2flow?version=1","/users/18785","tpacurtis","taverna 2","/users/18785,","tpacurtis,","This service generates a google map of a group of place names  and coordinates. The workflow will accept both coordinates and place  names. This workflow takes place names/coordinates from both a spreadsheet,  as well as on-the-fly input of a list of coordinates or place names (please note, if no supplemental data is desired, an empty link will allow the workflow to function). The Mapping Service workflow was created to assist in generating a  map of where a series of interviews took place, but can easily be  adapted for other purposes. &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/2474/versions/2.html","Mapping Service","2011-10-0604:44:03","2011-10-0605:01:20","http://www.myexperiment.org/workflows/2474/download/Mapping_Service-v2.t2flow?version=2","/users/18785","tpacurtis","taverna 2","/users/18785,","tpacurtis,","This service generates a google map of a group of place names  and  coordinates. The workflow will accept both coordinates and place  names. This workflow takes place names/coordinates from both a spreadsheet,   as well as on-the-fly input of a list of coordinates or place names  (please note, if no supplemental data is desired, an empty link will  allow the workflow to function). The Mapping Service workflow was created to assist in generating a   map of where a series of interviews took place, but can easily be   adapted for other purposes.",-1, 0, ,
"http://www.myexperiment.org/workflows/2475/versions/1.html","Simple Python example","2011-10-0614:58:34","2011-10-0614:58:36","http://www.myexperiment.org/workflows/2475/download/Simple_Python_example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow generates a random number within the range 0 to 100. The generation is done by a python script. The workflow assumes that python is in the path.",0, 0, ,
"http://www.myexperiment.org/workflows/2479/versions/1.html","Average and Standard Deviation","2011-10-0722:58:57","2011-10-0722:59:46","http://www.myexperiment.org/workflows/2479/download/Average_and_Standard_Deviation-v1.t2flow?version=1","/users/19046","Atminer","taverna 2","/users/19046,","Atminer,","This workflow takes in a list of values and a list name, and returns the list name, average, and standard deviation of the values.",-1, 0, ,
"http://www.myexperiment.org/workflows/2480/versions/1.html","Population Plot with R","2011-10-0805:42:38","","http://www.myexperiment.org/workflows/2480/download/Population_Plot_with_R-v1.t2flow?version=1","/users/19046","Atminer","taverna 2","/users/19046,","Atminer,","This script pulls the population of every country and creates a plot of them. This is based on the script at  <a href=http://www.myexperiment.org/workflows/1728.html rel=nofollow>http://www.myexperiment.org/workflows/1728.html</a>  , with a few modifications for labelling axes and the title.",0, 0, ,
"http://www.myexperiment.org/workflows/2481/versions/1.html","Broccoli Production New York State, 1960-1965","2011-10-0912:44:10","2011-10-0912:46:44","http://www.myexperiment.org/workflows/2481/download/Broccoli_Production_New_York_State__1960-1965-v1.t2flow?version=1","/users/19046","Atminer","taverna 2","/users/19046, /users/30,","Atminer, Alan Williams,","This workflow takes data about agricultural production in New Jersey and New York from 1960 -1965, to compare productivity in broccoli growing.",0, 0, ,
"http://www.myexperiment.org/workflows/2482/versions/1.html","Spreadsheet Import - Fertilizer Use","2011-10-0913:06:44","2011-10-0913:07:51","http://www.myexperiment.org/workflows/2482/download/Spreadsheet_Import_-_Fertilizer_Use-v1.t2flow?version=1","/users/19046","Atminer","taverna 2","/users/19046,","Atminer,","This workflow takes data from a spreadsheet and creates a graph of fertilizer use in NY state from 1960-1965.",0, 0, ,
"http://www.myexperiment.org/workflows/2486/versions/1.html","WPS-GRASS-Bridge r.los example","2011-10-1309:46:26","","http://www.myexperiment.org/workflows/2486/download/WPS-GRASS-Bridge_r.los_example-v1.t2flow?version=1","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","r.los generates a raster output map in which the cells that are visible from a user-specified observer position are marked with the vertical angle (in degrees) required to see those cells (viewshed). A value of 0 is directly below the specified viewing position, 90 is due horizontal, and 180 is directly above the observer. The angle to the cell containing the viewing position is undefined and set to 180. <a href=http://grass.fbk.eu/grass62/manuals/html62_user/r.los.html rel=nofollow>http://grass.fbk.eu/grass62/manuals/html62_user/r.los.html</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2488/versions/1.html","Get homologous from NCBI homoloGene","2011-10-1318:35:58","2011-10-1318:36:01","http://www.myexperiment.org/workflows/2488/download/Get_homologous_from_NCBI_homoloGene-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Get homologous from NCBI homoloGene for a list of Refseq protein accessions. Be patient, the workflows has to bring a file around 11Mb.  ftp://ftp.ncbi.nlm.nih.gov/pub/HomoloGene/README",0, 0, ,
"http://www.myexperiment.org/workflows/2490/versions/1.html","Find orthologs using a uniprot accession","2011-10-1413:07:41","2011-10-1413:07:44","http://www.myexperiment.org/workflows/2490/download/Find_orthologs_using_a_uniprot_accession-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Find orthologs based on ensembl information using as input/output uniprot accession",0, 0, ,
"http://www.myexperiment.org/workflows/2491/versions/1.html","Find orthologs using a list of uniprot accessions","2011-10-1413:12:36","2014-06-0317:39:32","http://www.myexperiment.org/workflows/2491/download/Find_orthologs_using_a_list_of_uniprot_accessions-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Find orthologs based on ensembl information using as input/output uniprot accessions",0, 0, ,
"http://www.myexperiment.org/workflows/2491/versions/2.html","Find orthologs using a list of uniprot accessions","2011-10-1413:12:36","2014-06-0317:39:32","http://www.myexperiment.org/workflows/2491/download/Find_orthologs_using_a_list_of_uniprot_accessions-v2.t2flow?version=2","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Find orthologs based on ensembl information using as input/output uniprot accessions",0, 0, ,
"http://www.myexperiment.org/workflows/2492/versions/1.html","Get homologous from NCBI homoloGene using one UniProt accession","2011-10-1417:26:32","2011-10-1417:26:28","http://www.myexperiment.org/workflows/2492/download/Get_homologous_from_NCBI_homoloGene_using_one_UniProt_accession-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Get homologous from NCBI homoloGene for one UniProt protein accession. Use PICR to convert UniProt to RefSeq, get homologous from homoloGene and convert RefSeq results to UniProt. Be patient, the workflows has to bring a file around 11Mb. ftp://ftp.ncbi.nlm.nih.gov/pub/HomoloGene/README",0, 0, ,
"http://www.myexperiment.org/workflows/2493/versions/1.html","Get homologous from NCBI homoloGene using a list of UniProt accessions","2011-10-1417:45:28","2011-10-2710:39:21","http://www.myexperiment.org/workflows/2493/download/Get_homologous_from_NCBI_homoloGene_using_a_list_of_UniProt_accessions-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Get homologous from NCBI homoloGene for a lsit of UniProt protein accession. Use PICR to convert UniProt to RefSeq, get homologous from homoloGene and convert RefSeq results to UniProt. Be patient, the workflows has to bring a file around 11Mb. ftp://ftp.ncbi.nlm.nih.gov/pub/HomoloGene/README",0, 0, ,
"http://www.myexperiment.org/workflows/2494/versions/1.html","KEGG pathway to proteins","2011-10-1715:40:01","2011-10-1804:28:57","http://www.myexperiment.org/workflows/2494/download/KEGG_pathway_to_proteins-v1.t2flow?version=1","/users/19661","Luke McCarthy","taverna 2","","","Get various information about the proteins in a KEGG pathway.Demonstrates integrating SADI services with non-SADI services.",0, 0, ,
"http://www.myexperiment.org/workflows/2494/versions/2.html","KEGG pathway to proteins","2011-10-1715:40:01","2011-10-1804:28:57","http://www.myexperiment.org/workflows/2494/download/KEGG_pathway_to_proteins-v2.t2flow?version=2","/users/19661","Luke McCarthy","taverna 2","","","Get various information about the proteins in a KEGG pathway.Demonstrates integrating SADI services with non-SADI services.",0, 0, ,
"http://www.myexperiment.org/workflows/2495/versions/1.html","Revisin Sistemtica de Software","2011-10-1816:26:44","2011-12-1212:18:32","http://www.myexperiment.org/workflows/2495/download/Revisi__n_Sistem__tica_de_Software-v1.t2flow?version=1","/users/19504","E3matheus","taverna 2","/users/19504,","E3matheus,","&nbsp;Sintesis de Datos para investigadores en el &aacute;rea de Ingenier&iacute;a de Software Experimental",-1, 0, ,
"http://www.myexperiment.org/workflows/2495/versions/2.html","Revisin Sistemtica de Software","2011-10-1816:26:44","2011-12-1212:18:32","http://www.myexperiment.org/workflows/2495/download/Revisi__n_Sistem__tica_de_Software-v2.t2flow?version=2","/users/19504","E3matheus","taverna 2","/users/19504,","E3matheus,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2495/versions/3.html","Revisin Sistemtica de Software","2011-10-1816:26:44","2011-12-1212:18:32","http://www.myexperiment.org/workflows/2495/download/Revisi__n_Sistem__tica_de_Software-v3.t2flow?version=3","/users/19504","E3matheus","taverna 2","/users/19504,","E3matheus,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2495/versions/4.html","Revisin Sistemtica de Software","2011-10-1816:26:44","2011-12-1212:18:32","http://www.myexperiment.org/workflows/2495/download/Revisi__n_Sistem__tica_de_Software-v4.t2flow?version=4","/users/19504","E3matheus","taverna 2","/users/19504,","E3matheus,","&nbsp;Workflow for sistematic software revision.",-1, 0, ,
"http://www.myexperiment.org/workflows/2498/versions/1.html","Get homologous from an NCBI homoloGene.data file using a list of UniProt accessions","2011-10-2017:53:28","2011-10-2710:38:33","http://www.myexperiment.org/workflows/2498/download/Get_homologous_from_an_NCBI_homoloGene.data_file_using_a_list_of_UniProt_accessions-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Get homologous from NCBI homoloGene for a lsit of UniProt protein accession. This workflow is useful if you have a long list of protein accessions. Use PICR to convert UniProt to RefSeq, get homologous from homoloGene and convert RefSeq results to UniProt. Be patient, the workflows has to bring a file around 11Mb. ftp://ftp.ncbi.nlm.nih.gov/pub/HomoloGene/README",0, 0, ,
"http://www.myexperiment.org/workflows/2500/versions/1.html","BLASTP with simplified results returned","2011-10-2507:24:51","2011-10-2507:24:52","http://www.myexperiment.org/workflows/2500/download/BLASTP_with_simplified_results_returned-v1.t2flow?version=1","/users/18430","Halima alshabani","taverna 2","/users/18430,","Halima alshabani,","Perform a blastp search on protein sequence and extract information based on the user input, e.g. a list of GI numbers.",1, 0, ,
"http://www.myexperiment.org/workflows/2515/versions/1.html","r.stats workflow for pixel statistics","2011-11-0209:58:42","2011-11-0210:00:42","http://www.myexperiment.org/workflows/2515/download/r.stats_workflow_for_pixel_statistics-v1.t2flow?version=1","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","r.stats operation for image. Output will group pixels by: DN, total area, relative %. This worflow is used inside the ice Class exampel as a nested workflow",-1, 0, ,
"http://www.myexperiment.org/workflows/2516/versions/1.html","date filter for ice Class Map service (NERSC)","2011-11-0210:05:35","2011-11-0410:27:00","http://www.myexperiment.org/workflows/2516/download/date_filter_for_ice_Class_Map_service__NERSC_-v1.t2flow?version=1","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","Workflow to filter available dates with ice classification images. Service provided by NERCS. Dates are filtered using a simple regular expression",-1, 0, ,
"http://www.myexperiment.org/workflows/2517/versions/1.html","Ice Class Map pixel analysis (NERSC)","2011-11-0210:08:05","2011-11-0210:10:50","http://www.myexperiment.org/workflows/2517/download/Ice_Class_Map_pixel_analysis__NERSC_-v1.t2flow?version=1","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","NERSC ice classification workflow. Avaible images for a specific date will be fecthed from the WPS service, and their color table changed to allow for a user to easly identify specific areas. Statistical analysis also run using the r.stats module. Worflow uses a list of image, the list will flow thru the workflow for process resulting in mutiple outputs",-1, 0, ,
"http://www.myexperiment.org/workflows/2524/versions/1.html","Find periods of time where two ILS objects are located at a maximum of X degrees longitude from each other","2011-11-0415:47:11","2011-11-1814:58:19","http://www.myexperiment.org/workflows/2524/download/Find_periods_of_time_where_two_ILS_objects_are_located_at_a_maximum_of_X_degrees_longitude_from_each_other-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Inputs: name of target_obj of ILS of two objects and a number of degrees which these obejcts are allowed to be appart in hci longitude coordinates.Output VOTable of time periods where these two objects are closer than +/- input angle together.",0, 0, ,
"http://www.myexperiment.org/workflows/2524/versions/2.html","Find periods of time where two ILS objects are located at a maximum of X degrees longitude from each other","2011-11-0415:47:11","2011-11-1814:58:19","http://www.myexperiment.org/workflows/2524/download/Find_periods_of_time_where_two_ILS_objects_are_located_at_a_maximum_of_X_degrees_longitude_from_each_other-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Inputs: name of target_obj of ILS of two objects and a number of degrees which these obejcts are allowed to be appart in hci longitude coordinates.Output VOTable of time periods where these two objects are closer than +/- input angle together.",0, 0, ,
"http://www.myexperiment.org/workflows/2545/versions/1.html","Basic Call of HELIO Coordinate Transformation Service","2011-11-0815:14:33","2011-11-0815:14:31","http://www.myexperiment.org/workflows/2545/download/Basic_Call_of_HELIO_Coordinate_Transformation_Service-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Transforms an input VOTable Coordinate set to a specified output VOTable Coordinate set. This workflow performs some remote computation and may take some time to complete.",0, 0, ,
"http://www.myexperiment.org/workflows/2548/versions/1.html","Basic Call of HELIO Coordinate Transformation Service","2011-11-0913:22:23","2012-07-0906:44:04","http://www.myexperiment.org/workflows/2548/download/Basic_Call_of_HELIO_Coordinate_Transformation_Service-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Transforms an input VOTable Coordinate set to a specified output VOTable Coordinate set.  This workflow performs some remote computation and may take some time to complete. Follows the UWS protocol.",0, 0, ,
"http://www.myexperiment.org/workflows/2548/versions/2.html","Basic Call of HELIO Coordinate Transformation Service","2011-11-0913:22:23","2012-07-0906:44:04","http://www.myexperiment.org/workflows/2548/download/Basic_Call_of_HELIO_Coordinate_Transformation_Service-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Transforms an input VOTable Coordinate set to a specified output VOTable Coordinate set. This workflow performs some remote computation and may take some time to complete.",0, 0, ,
"http://www.myexperiment.org/workflows/2559/versions/1.html","Sample IMPACT hackathon workflow","2011-11-1416:12:10","2012-06-1910:28:42","http://www.myexperiment.org/workflows/2559/download/Sample_IMPACT_hackathon_workflow-v1.t2flow?version=1","/users/9056","Donal Fellows","taverna 2","/users/9056,","Donal Fellows,","Workflow that implements the Use Case for Group 2 at the IMPACT/Taverna hackathon. What it does is to take the URL of a TIFF image and compute the Levenshtein difference between the OCR output of the uncompressed version with various ones compressed at various bit rates.",1, 0, ,
"http://www.myexperiment.org/workflows/2560/versions/1.html","Calculation of distances, magnitutes and luminosities using HyperLEDA","2011-11-1418:17:06","2012-01-1118:11:57","http://www.myexperiment.org/workflows/2560/download/Calculation_of_distances__magnitutes_and_luminosities_using_HyperLEDA-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","","This workflow receives a list of galaxy names (hyperLEDA names. ie: KIG0001) and a file with a the morphological type of those galaxies.Using the name of a galaxy, the workflow querys Hyperleda to extract some properties of this galaxy (J2000 Coordinates, velocity, galactic extinction,log of axis ratio, and the Total B-magnitude ). With this properties it calculates the distance of the galaxy and, in other hand, the Total apparent corrected B-magnitude.It takes account if the velocity of the galaxy is lower than a threshold (1000km/s), it can not be possible to calculate the distance so, in those cases the distance will be NaN.At the end, it calculates the Total Luminosity using the velocity and the Total apparent corrected B-magnitude.More information in the nested workflows.",0, 0, ,
"http://www.myexperiment.org/workflows/2560/versions/2.html","Calculation of distances, magnitutes and luminosities using HyperLEDA","2011-11-1418:17:06","2012-01-1118:11:57","http://www.myexperiment.org/workflows/2560/download/Calculation_of_distances__magnitutes_and_luminosities_using_HyperLEDA-v2.t2flow?version=2","/users/19173","Susana","taverna 2","","","This workflow receives a list of galaxy names (hyperLEDA names. ie: KIG0001) and a file with the morphological types of those galaxiesUsing the name of a galaxy, the workflow querys Hyperleda to extract some properties of this galaxy (J2000 Coordinates, velocity, galactic extinction,log of axis ratio, and the Total B-magnitude ). With this properties it calculates the distance of the galaxy and, in other hand, the Total apparent corrected B-magnitude.It takes account if the velocity of the galaxy is lower than a threshold (1000km/s), it can not be possible to calculate the distance so, in those cases the distance will be NaN.At the end, it calculates the Total Luminosity using the velocity and the Total apparent corrected B-magnitude.More information in the nested workflows.",0, 0, ,
"http://www.myexperiment.org/workflows/2560/versions/3.html","Calculation of distances, magnitutes and luminosities using HyperLEDA","2011-11-1418:17:06","2012-01-1118:11:57","http://www.myexperiment.org/workflows/2560/download/Calculation_of_distances__magnitutes_and_luminosities_using_HyperLEDA-v3.t2flow?version=3","/users/19173","Susana","taverna 2","","","This workflow receives a list of galaxy names (hyperLEDA names. ie: KIG0001) and a file with the morphological types of those galaxiesUsing the name of a galaxy, the workflow querys Hyperleda to extract some properties of this galaxy (J2000 Coordinates, velocity, galactic extinction,log of axis ratio, and the Total B-magnitude ). With this properties it calculates the distance of the galaxy and, in other hand, the Total apparent corrected B-magnitude.It takes account if the velocity of the galaxy is lower than a threshold (1000km/s), it can not be possible to calculate the distance so, in those cases the distance will be NaN.At the end, it calculates the Total Luminosity using the velocity and the Total apparent corrected B-magnitude.More information in the nested workflows.",0, 0, ,
"http://www.myexperiment.org/workflows/2560/versions/4.html","Calculation of distances, magnitutes and luminosities using HyperLEDA","2011-11-1418:17:06","2012-01-1118:11:57","http://www.myexperiment.org/workflows/2560/download/Calculation_of_distances__magnitutes_and_luminosities_using_HyperLEDA-v4.t2flow?version=4","/users/19173","Susana","taverna 2","","","Calculation of distances, corrected apparent B magnitude mB-corr and luminosities with values gathered from the HyperLEDA database. This workflow receives a list of galaxy names (hyperLEDA names. ie: KIG0001) and a file with the morphological types of those galaxiesUsing the name of a galaxy, the workflow querys Hyperleda to extract some properties of this galaxy (J2000 Coordinates, velocity, galactic extinction,log of axis ratio, and the Total B-magnitude ). With this properties it calculates the distance of the galaxy and, in other hand, the Total apparent corrected B-magnitude.It takes account if the velocity of the galaxy is lower than a threshold (1000km/s), it can not be possible to calculate the distance so, in those cases the distance will be NaN.At the end, it calculates the Total Luminosity using the velocity and the Total apparent corrected B-magnitude.More information in the nested workflows.The performance could be improved since only one query per galaxy is needed for the extraction of five physical properties. Nevertheless, we have decided to split the query into five different queries and provide a more modular workflow, which is best suited for aims of re-usability and re-purposability. It may happen that for other physical properties, values may come from different databases.",0, 0, ,
"http://www.myexperiment.org/workflows/2561/versions/1.html","Example of conditional invocation","2011-11-1510:20:10","2011-11-1510:20:11","http://www.myexperiment.org/workflows/2561/download/Example_of_conditional_invocation-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow demonstrates how nested workflows can be conditionally invoked",0, 0, ,
"http://www.myexperiment.org/workflows/2562/versions/1.html","Example of explicit looping","2011-11-1510:45:45","2011-11-1510:45:47","http://www.myexperiment.org/workflows/2562/download/Example_of_explicit_looping-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow demonstrates how a nested workflow can be called an explicit number of times.Note that the loop iterator does not need to be used in the logic of the loop contents. It canbe used as a sentinel (see the conditional workflow)",0, 0, ,
"http://www.myexperiment.org/workflows/2563/versions/1.html","Arc/Warc mounter","2011-11-1510:48:54","2011-11-1511:17:23","http://www.myexperiment.org/workflows/2563/download/Arc_Warc_mounter-v1.t2flow?version=1","/users/17303","Asger Askov Blekinge","taverna 2","/users/17303,","Asger Askov Blekinge,","&nbsp;This is a simple workflow to show how to do the mount/unmount stuff with fuse, as part of a taverna workflow. Use and abuse. &nbsp; The fuse-j mounter I use can be taken from here&nbsp; <a href=https://github.com/blekinge/wap rel=nofollow>https://github.com/blekinge/wap</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/2563/versions/2.html","Arc/Warc mounter","2011-11-1510:48:54","2011-11-1511:17:23","http://www.myexperiment.org/workflows/2563/download/Arc_Warc_mounter-v2.t2flow?version=2","/users/17303","Asger Askov Blekinge","taverna 2","/users/17303,","Asger Askov Blekinge,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2564/versions/1.html","Find source at Sun of SW events on Earth","2011-11-1513:51:37","2012-05-2408:56:15","http://www.myexperiment.org/workflows/2564/download/Find_source_at_Sun_of_SW_events_on_Earth-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706, /users/14723,","Anja Le Blanc, David PS,","Try to detect the solar wind source on the Sun. Use backpropagation, ILS, HEC and HFC.",0, 0, ,
"http://www.myexperiment.org/workflows/2564/versions/2.html","Find source at Sun of SW events on Earth","2011-11-1513:51:37","2012-05-2408:56:15","http://www.myexperiment.org/workflows/2564/download/Find_source_at_Sun_of_SW_events_on_Earth-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706, /users/14723,","Anja Le Blanc, David PS,","Try to detect the solar wind source on the Sun. Use backpropagation, ILS, HEC and HFC.",0, 0, ,
"http://www.myexperiment.org/workflows/2564/versions/3.html","Find source at Sun of SW events on Earth","2011-11-1513:51:37","2012-05-2408:56:15","http://www.myexperiment.org/workflows/2564/download/Find_source_at_Sun_of_SW_events_on_Earth-v3.t2flow?version=3","/users/4706","Anja Le Blanc","taverna 2","/users/4706, /users/14723,","Anja Le Blanc, David PS,","Try to detect the solar wind source on the Sun. Use backpropagation, ILS, HEC and HFC.",0, 0, ,
"http://www.myexperiment.org/workflows/2564/versions/4.html","Find source at Sun of SW events on Earth","2011-11-1513:51:37","2012-05-2408:56:15","http://www.myexperiment.org/workflows/2564/download/Find_source_at_Sun_of_SW_events_on_Earth-v4.t2flow?version=4","/users/4706","Anja Le Blanc","taverna 2","/users/4706, /users/14723,","Anja Le Blanc, David PS,","Try to detect the solar wind source on the Sun. Use backpropagation, ILS, HEC and HFC.",0, 0, ,
"http://www.myexperiment.org/workflows/2564/versions/5.html","Find source at Sun of SW events on Earth","2011-11-1513:51:37","2012-05-2408:56:15","http://www.myexperiment.org/workflows/2564/download/Find_source_at_Sun_of_SW_events_on_Earth-v5.t2flow?version=5","/users/4706","Anja Le Blanc","taverna 2","/users/4706, /users/14723,","Anja Le Blanc, David PS,","Try to detect the solar wind source on the Sun. Use backpropagation, ILS, HEC and HFC.",0, 0, ,
"http://www.myexperiment.org/workflows/2566/versions/1.html","Connect flare events with proton events on Earth via propagation model","2011-11-1513:57:35","2012-05-1513:09:09","http://www.myexperiment.org/workflows/2566/download/Connect_flare_events_with_proton_events_on_Earth_via_propagation_model-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Use case SEP of the CDAW2 as workflow",0, 0, ,
"http://www.myexperiment.org/workflows/2566/versions/2.html","Connect flare events with proton events on Earth via propagation model","2011-11-1513:57:35","2012-05-1513:09:09","http://www.myexperiment.org/workflows/2566/download/Connect_flare_events_with_proton_events_on_Earth_via_propagation_model-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow uses flares listed in the goes_sxf_flare list, checks wether this flare is connected to Earth via the Parker spiral, and looks for proton events at earth listed in the goes_proton_event list. The flare listing and the proton listing is combinded into a  VOTable output.",0, 0, ,
"http://www.myexperiment.org/workflows/2566/versions/3.html","Connect flare events with proton events on Earth via propagation model","2011-11-1513:57:35","2012-05-1513:09:09","http://www.myexperiment.org/workflows/2566/download/Connect_flare_events_with_proton_events_on_Earth_via_propagation_model-v3.t2flow?version=3","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow uses flares listed in any HELIO HEC flare catalogue (using the semantic mapping service), checks whether these flares are connected to Earth via the Parker spiral, and looks for proton events at earth listed in the goes_proton_event list. The flare listing and the proton listing are combinded into a list of  VOTable outputs (one VOTable per flare catalogue with results).",0, 0, ,
"http://www.myexperiment.org/workflows/2566/versions/4.html","Connect flare events with proton events on Earth via propagation model","2011-11-1513:57:35","2012-05-1513:09:09","http://www.myexperiment.org/workflows/2566/download/Connect_flare_events_with_proton_events_on_Earth_via_propagation_model-v4.t2flow?version=4","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow uses flares listed in the goes_sxf_flare list, checks wether this flare is connected to Earth via the Parker spiral, and looks for proton events at earth listed in the goes_proton_event list. The flare listing and the proton listing is combinded into a  VOTable output.",0, 0, ,
"http://www.myexperiment.org/workflows/2567/versions/1.html","Associate a Shock at Earth with Flare and CME event on Sun","2011-11-1514:02:29","2012-07-2013:17:35","http://www.myexperiment.org/workflows/2567/download/Associate_a_Shock_at_Earth_with_Flare_and_CME_event_on_Sun-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706, /users/14723,","Anja Le Blanc, David PS,","CME use case of CDAW2 as workflow",0, 0, ,
"http://www.myexperiment.org/workflows/2567/versions/2.html","Associate a Shock at Earth with Flare and CME event on Sun","2011-11-1514:02:29","2012-07-2013:17:35","http://www.myexperiment.org/workflows/2567/download/Associate_a_Shock_at_Earth_with_Flare_and_CME_event_on_Sun-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706, /users/14723,","Anja Le Blanc, David PS,","Using start date and end date all shock events at Earth are backpropagated to the Sun.Arround the time all flares (above certain levels) and cmes are assoicated.The possition of the flare and speed of the CME are used to forward propagate the event to Mars.",0, 0, ,
"http://www.myexperiment.org/workflows/2577/versions/1.html","Pathways and Gene annotations forQTL region","2011-11-2120:30:09","2011-11-2120:33:28","http://www.myexperiment.org/workflows/2577/download/Pathways_and_Gene_annotations_forQTL_region-v1.t2flow?version=1","/users/20240","Prashanth","taverna 2","/users/20240,","Prashanth,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in the mouse, Mus musculus. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",0, 0, ,
"http://www.myexperiment.org/workflows/2577/versions/2.html","Pathways and Gene annotations forQTL region","2011-11-2120:30:09","2011-11-2120:33:28","http://www.myexperiment.org/workflows/2577/download/Pathways_and_Gene_annotations_forQTL_region-v2.t2flow?version=2","/users/20240","Prashanth","taverna 2","/users/20240,","Prashanth,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in the mouse, Mus musculus. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",0, 0, ,
"http://www.myexperiment.org/workflows/2578/versions/1.html","Pathways and Gene annotations forQTL region","2011-11-2120:35:21","2011-11-2120:35:22","http://www.myexperiment.org/workflows/2578/download/Pathways_and_Gene_annotations_forQTL_region-v1.t2flow?version=1","/users/20240","Prashanth","taverna 2","/users/20240,","Prashanth,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in the mouse, Mus musculus. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",0, 0, ,
"http://www.myexperiment.org/workflows/2579/versions/1.html","Image files comparison using histograms and profiles V1.0","2011-11-2212:29:08","2011-11-2313:47:20","http://www.myexperiment.org/workflows/2579/download/Image_files_comparison_using_histograms_and_profiles_V1.0-v1.t2flow?version=1","/users/17168","Roman","taverna 2","/users/17168,","Roman,","This workflow extracts histogram and profile features from image file applying image processing command line tool. Necessary configuration files are stored on Github (https://github.com/openplanets/scape/tree/master/pc-qa-toolwrapper). As a template for creation of image workflows was used xa-toolwrapper project from Sven Schlarb ( <a href=https://github.com/openplanets/scape/tree/master/xa-toolwrapper rel=nofollow>https://github.com/openplanets/scape/tree/master/xa-toolwrapper</a> ). This workflow provides WSDL web service that wraps command  line tool with tho options &lsquo;extractFeatures&rsquo; and &lsquo;compare&rsquo;. The &lsquo;extractFeatures&rsquo; option expects an URL to the image file as parameter. The output is an XML  file with histogram data. Having two XML features files and passing their URLs to 'compare' option we will get comparison result in XML format. Comparison result comprises different characteristics provided with value between 0 and 1. 0 means that images are similar and 1 means they are different. Also the workflow provides output of  processing log, return code (0 if successful).",-1, 0, ,
"http://www.myexperiment.org/workflows/2579/versions/2.html","Image files comparison using histograms and profiles V1.0","2011-11-2212:29:08","2011-11-2313:47:20","http://www.myexperiment.org/workflows/2579/download/Image_files_comparison_using_histograms_and_profiles_V1.0-v2.t2flow?version=2","/users/17168","Roman","taverna 2","/users/17168,","Roman,","This workflow extracts histogram and profile features from image file applying image processing command line tool. Necessary configuration files are stored on Github ( <a href=https://github.com/openplanets/scape/tree/master/pc-qa-toolwrapper rel=nofollow>https://github.com/openplanets/scape/tree/master/pc-qa-toolwrapper</a> ). As a template for creation of image workflows was used xa-toolwrapper project from Sven Schlarb ( <a href=https://github.com/openplanets/scape/tree/master/xa-toolwrapper rel=nofollow>https://github.com/openplanets/scape/tree/master/xa-toolwrapper</a> ). This workflow provides WSDL web service that wraps command line tool with tho options &lsquo;extractFeatures&rsquo; and &lsquo;compare&rsquo;. The &lsquo;extractFeatures&rsquo; option expects an URL to the image file as parameter. The output is an XML file with histogram data. Having two XML features files and passing their URLs to 'compare' option we will get comparison result in XML format. Comparison result comprises different characteristics provided with value between 0 and 1. 0 means that images are similar and 1 means they are different. Also the workflow provides output of processing log, return code (0 if successful).",-1, 0, ,
"http://www.myexperiment.org/workflows/2581/versions/1.html","NSF Funds dataset US dollar to Euro currency converter","2011-11-2504:25:07","2011-11-2504:29:42","http://www.myexperiment.org/workflows/2581/download/NSF_Funds_dataset_US_dollar_to_Euro_currency_converter-v1.t2flow?version=1","/users/18933","Trisha Adamus","taverna 2","/users/18933,","Trisha Adamus,","This workflow uses a 2012 Fiscal Year dataset from the National Science Foundation (NSF), a currency conversion web service from WebservicesX.NET and processes data using the workflow tool Taverna. &nbsp;It converts US dollars from a spreadsheet to Euros. &lt;o:p&gt;&lt;/o:p&gt;",-1, 0, ,
"http://www.myexperiment.org/workflows/2592/versions/1.html","FetchandDisplaySpecies","2011-11-2712:44:23","2011-11-2915:34:08","http://www.myexperiment.org/workflows/2592/download/FetchandDisplaySpecies-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/30,","Alan Williams,","This workflow uses GBIF to search and report species occurrence data and then displays them on Google Earth.  An interactive step then allows you to alter the co-ordinates of data displayed.",0, 0, ,
"http://www.myexperiment.org/workflows/2592/versions/2.html","FetchandDisplaySpecies","2011-11-2712:44:23","2011-11-2915:34:08","http://www.myexperiment.org/workflows/2592/download/FetchandDisplaySpecies-v2.t2flow?version=2","/users/13","Katy Wolstencroft","taverna 2","/users/30,","Alan Williams,","This workflow uses GBIF to search and report species occurrence data and then displays them on Google Earth.  An interactive step then allows you to alter the co-ordinates of data displayed.",0, 0, ,
"http://www.myexperiment.org/workflows/2592/versions/3.html","FetchandDisplaySpecies","2011-11-2712:44:23","2011-11-2915:34:08","http://www.myexperiment.org/workflows/2592/download/FetchandDisplaySpecies-v3.t2flow?version=3","/users/13","Katy Wolstencroft","taverna 2","/users/30,","Alan Williams,","This workflow uses GBIF to search and report species occurrence data and then displays them on Google Earth.  An interactive step then allows you to alter the co-ordinates of data displayed.",0, 0, ,
"http://www.myexperiment.org/workflows/2593/versions/1.html","Comparison of Birth and Death Rates for a Country","2011-11-2720:58:46","2011-11-2721:05:49","http://www.myexperiment.org/workflows/2593/download/Comparison_of_Birth_and_Death_Rates_for_a_Country-v1.t2flow?version=1","/users/18785","tpacurtis","taverna 2","/users/18785,","tpacurtis,","This workflow extracts the relevant data from two spreadsheets, formats the data strings, and puts that data through a REST to Google Charts. Data collected for this project comes from  <a href=http://data.un.org rel=nofollow>data.un.org</a> . Currently, the workflow supports data from only one country at a time (data from data.un.org can be filtered and exported directly from the website). Data from the  <i>Live births by month</i>  and  <i>Deaths by month&nbsp;</i> works best with this workflow.",-1, 0, ,
"http://www.myexperiment.org/workflows/2594/versions/1.html","[untitled]","2011-11-2723:05:31","2011-11-2723:10:52","http://www.myexperiment.org/workflows/2594/download/_untitled_-v1.t2flow?version=1","/users/18934","Kayleigh Ayn BohÃ©mier","taverna 2","/users/18934,","Kayleigh Ayn BohÃ©mier,","This is a workflow for a Cyberinfrastructure class (Fall 2011) at Syracuse University. It takes information from GapMinder and runs it through a workflow to produce a graph. The original data sets can be found here: <a href=https://spreadsheets.google.com/pub?key=pyj6tScZqmEdrsBnj2ROXAg&amp;gid=0 rel=nofollow>https://spreadsheets.google.com/pub?key=pyj6tScZqmEdrsBnj2ROXAg&amp;gid=0</a> &nbsp;(Literacy rate, adult total) <a href=https://spreadsheets.google.com/pub?key=pyj6tScZqmEdIyrBS31XAaw&amp;gid=0 rel=nofollow>https://spreadsheets.google.com/pub?key=pyj6tScZqmEdIyrBS31XAaw&amp;gid=0</a> &nbsp;(Income share of poorest 20%)",-1, 0, ,
"http://www.myexperiment.org/workflows/2594/versions/2.html","[untitled]","2011-11-2723:05:31","2011-11-2723:10:52","http://www.myexperiment.org/workflows/2594/download/_untitled_-v2.t2flow?version=2","/users/18934","Kayleigh Ayn BohÃ©mier","taverna 2","/users/18934,","Kayleigh Ayn BohÃ©mier,","This is a workflow for a Cyberinfrastructure class (Fall 2011) at Syracuse University. It takes information from GapMinder and runs it through a workflow to produce a graph.The original data sets can be found here: <a href=https://spreadsheets.google.com/pub?key=pyj6tScZqmEdrsBnj2ROXAg&amp;gid=0 rel=nofollow>https://spreadsheets.google.com/pub?key=pyj6tScZqmEdrsBnj2ROXAg&gid;=0</a>  (Literacy rate, adult total) <a href=https://spreadsheets.google.com/pub?key=pyj6tScZqmEdIyrBS31XAaw&amp;gid=0 rel=nofollow>https://spreadsheets.google.com/pub?key=pyj6tScZqmEdIyrBS31XAaw&gid;=0</a>  (Income share of poorest 20%)",-1, 0, ,
"http://www.myexperiment.org/workflows/2601/versions/1.html","A Comparison of China and US populations","2011-11-2816:51:34","2011-11-2817:12:37","http://www.myexperiment.org/workflows/2601/download/A_Comparison_of_China_and_US_populations-v1.t2flow?version=1","/users/18929","Gstalloch","taverna 2","/users/18929,","Gstalloch,","This workflow is a comparison of China's population with the United States. It also compared the population of males and females from ages 0 - 4 to illustrate any gender gaps that may be occurring in the birth rates. The graphs are produced through the google chart API service. The data is from world population spreadsheets obtained from Gapminder.org.",0, 0, ,
"http://www.myexperiment.org/workflows/2601/versions/2.html","A Comparison of China and US populations","2011-11-2816:51:34","2011-11-2817:12:37","http://www.myexperiment.org/workflows/2601/download/A_Comparison_of_China_and_US_populations-v2.t2flow?version=2","/users/18929","Gstalloch","taverna 2","/users/18929,","Gstalloch,","This workflow is a comparison of China's population with the United States. It also compared the population of males and females from ages 0 - 4 to illustrate any gender gaps that may be occurring in the birth rates. The graphs are produced through the google chart API service. The data is from world population spreadsheets obtained from Gapminder.org.",0, 0, ,
"http://www.myexperiment.org/workflows/2603/versions/1.html","Literacy Rate and GDP/Capita Increase (Percentage)","2011-11-2818:33:01","2011-11-2818:33:03","http://www.myexperiment.org/workflows/2603/download/Literacy_Rate_and_GDP_Capita_Increase__Percentage_-v1.t2flow?version=1","/users/18934","Kayleigh Ayn BohÃ©mier","taverna 2","/users/18934,","Kayleigh Ayn BohÃ©mier,","This is a workflow for a Cyberinfrastructure class (Fall 2011) at Syracuse University. It takes information from GapMinder and runs it through a workflow to produce a graph.The original data sets can be found here: <a href=https://spreadsheets.google.com/pub?key=pyj6tScZqmEdrsBnj2ROXAg&amp;gid=0 rel=nofollow>https://spreadsheets.google.com/pub?key=pyj6tScZqmEdrsBnj2ROXAg&gid;=0</a>  (Literacy rate, adult total) <a href=https://spreadsheets.google.com/pub?key=phAwcNAVuyj1jiMAkmq1iMg&amp;gid=0 rel=nofollow>https://spreadsheets.google.com/pub?key=phAwcNAVuyj1jiMAkmq1iMg&gid;=0</a>  (Income per person)",0, 0, ,
"http://www.myexperiment.org/workflows/2613/versions/1.html","Propagation of physical quantities in the calculation of luminosities of galaxies","2011-11-3016:31:30","2013-04-2216:07:16","http://www.myexperiment.org/workflows/2613/download/Propagation_of_physical_quantities_in_the_calculation_of_luminosities_of_galaxies-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","","This workflow takes as input a file for each of this properties: J2000 Coordinates, velocity, galactic extinction,log of axis ratio, and the Total B-magnitude. With this properties it calculates the distance of the galaxy and, in other hand, the total apparent corrected B-magnitude.It takes account if the velocity of the galaxy is lower than a threshold (1000km/s), it can not be possible to calculate the distance so, in those cases the distance will be NaN.At the end, it calculates the total luminosity using the velocity and the total apparent corrected B-magnitude.More information in the nested workflows.",-1, 0, ,
"http://www.myexperiment.org/workflows/2613/versions/2.html","Propagation of physical quantities in the calculation of luminosities of galaxies","2011-11-3016:31:30","2013-04-2216:07:16","http://www.myexperiment.org/workflows/2613/download/Propagation_of_physical_quantities_in_the_calculation_of_luminosities_of_galaxies-v2.t2flow?version=2","/users/19173","Susana","taverna 2","","","This workflow takes as input a file for each of this properties: J2000 Coordinates, velocity, galactic extinction,log of axis ratio, and the Total B-magnitude. With this properties it calculates the distance of the galaxy and, in other hand, the total apparent corrected B-magnitude.It takes account if the velocity of the galaxy is lower than a threshold (1000km/s), it can not be possible to calculate the distance so, in those cases the distance will be NaN.At the end, it calculates the total luminosity using the velocity and the total apparent corrected B-magnitude.More information in the nested workflows.",0, 0, ,
"http://www.myexperiment.org/workflows/2613/versions/3.html","Propagation of physical quantities in the calculation of luminosities of galaxies","2011-11-3016:31:30","2013-04-2216:07:16","http://www.myexperiment.org/workflows/2613/download/Propagation_of_physical_quantities_in_the_calculation_of_luminosities_of_galaxies-v3.t2flow?version=3","/users/19173","Susana","taverna 2","","","This workflow takes as input a file for each of this properties: J2000 Coordinates, velocity, galactic extinction, log of axis ratio, and the Total B-magnitude. With this properties it calculates the distance of the galaxy and, in other hand, the total apparent corrected B-magnitude.It takes account if the velocity of the galaxy is lower than a threshold (1000km/s), it can not be possible to calculate the distance so, in those cases the distance will be NaN.At the end, it calculates the total luminosity using the velocity and the total apparent corrected B-magnitude.More information in the nested workflows.",0, 0, ,
"http://www.myexperiment.org/workflows/2614/versions/1.html","Gathering galaxy properties using HyperLEDA","2011-11-3016:49:48","2013-03-0808:07:14","http://www.myexperiment.org/workflows/2614/download/Gathering_galaxy_properties_using_HyperLEDA-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","","The user provides an ASCII text file with a list of galaxy names, and the workflow queries the HyperLEDA database and parses the response with the help of regular expressions included in simple Python scripts. The result of the workflow is a series of ASCII text files with the values of the equatorial coordinates in J2000 epoch, the velocities in km/s, the dust extinction coefficient Ag, the axis ratio of the isophote 25 mag/arcsec2 logr25 and the apparent total B magnitude BT.The performance could be improved since only one query per galaxy is needed for the extraction of five physical properties. Nevertheless, we have decided to split the query into five different queries and provide a more modular workflow, which is best suited for aims of re-usability and re-purposability. It may happen that for other physical properties, values may come from different databases.",0, 0, ,
"http://www.myexperiment.org/workflows/2614/versions/2.html","Gathering galaxy properties using HyperLEDA","2011-11-3016:49:48","2013-03-0808:07:14","http://www.myexperiment.org/workflows/2614/download/Gathering_galaxy_properties_using_HyperLEDA-v2.t2flow?version=2","/users/19173","Susana","taverna 2","","","The user provides an ASCII text file with a list of galaxy names, and the workflow queries the HyperLEDA database and parses the response with the help of regular expressions included in simple Python scripts. The result of the workflow is a series of ASCII text files with the values of the equatorial coordinates in J2000 epoch, the velocities in km/s, the dust extinction coefficient Ag, the axis ratio of the isophote 25 mag/arcsec2 logr25 and the apparent total B magnitude BT. The performance could be improved since only one query per galaxy is needed for the extraction of five physical properties. Nevertheless, we have decided to split the query into five different queries and provide a more modular workflow, which is best suited for aims of re-usability and re-purposability. It may happen that for other physical properties, values may come from different databases.",0, 0, ,
"http://www.myexperiment.org/workflows/2615/versions/1.html","Comparison and update values","2011-11-3016:53:51","2011-11-3016:53:52","http://www.myexperiment.org/workflows/2615/download/Comparison_and_update_values-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","","This workflow receives two files, the name of a table and the name of a field as input.One of the file should be contain a list of old values (name galaxy and value), and the other one should be a list of new values (name galaxy,value)The workflow makes a comparison between the two files. This comparison will be a list of 7 columns: name of the galaxy, old value, old error, new value, new error, difference of value, difference of error. In other hand, this workflow makes a sql script with the command to update/create the table and filed given, with the new values.",0, 0, ,
"http://www.myexperiment.org/workflows/2620/versions/1.html","Match concept profiles","2011-12-0209:07:34","2014-07-1413:31:23","http://www.myexperiment.org/workflows/2620/download/Match_concept_profiles-v1.t2flow?version=1","/users/18","Marco Roos","taverna 2","/users/18, /users/2642, /users/2780, /users/12548,","Marco Roos, Kristina Hettne, Martijn Schuemie, Reinout van Schouwen,","The workflow can be used to match a set of concept profiles with another set of concept profiles.",0, 0, ,
"http://www.myexperiment.org/workflows/2620/versions/2.html","Match concept profiles","2011-12-0209:07:34","2014-07-1413:31:23","http://www.myexperiment.org/workflows/2620/download/Match_concept_profiles-v2.t2flow?version=2","/users/18","Marco Roos","taverna 2","/users/18, /users/2642, /users/2780, /users/12548,","Marco Roos, Kristina Hettne, Martijn Schuemie, Reinout van Schouwen,","The workflow can be used to match a set of concept profiles with another set of concept profiles. The result is a list of concepts ordered by their match to the query concept profiles. The workflow matches two sets of concept profiles. At the time of writing the concepts are derived from human, rat, and mouse terminologies, ontologies, and database identifiers. The profiles are lists of concepts ranked by their association with the identifying concept, as determined by co-location statistics computed from MedLine (up until 2009 at the time of writing).",0, 0, ,
"http://www.myexperiment.org/workflows/2620/versions/3.html","Match concept profiles","2011-12-0209:07:34","2014-07-1413:31:23","http://www.myexperiment.org/workflows/2620/download/Match_concept_profiles-v3.t2flow?version=3","/users/18","Marco Roos","taverna 2","/users/18, /users/2642, /users/2780, /users/12548,","Marco Roos, Kristina Hettne, Martijn Schuemie, Reinout van Schouwen,","The workflow can be used to match a set of concept profiles with another set of concept profiles. The result is a list of concepts ordered by their match to the query concept profiles. The workflow matches two sets of concept profiles. At the time of writing the concepts are derived from human, rat, and mouse terminologies, ontologies, and database identifiers. The profiles are lists of concepts ranked by their association with the identifying concept, as determined by co-location statistics computed from MedLine (up until 2009 at the time of writing). This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2620/versions/4.html","Match concept profiles","2011-12-0209:07:34","2014-07-1413:31:23","http://www.myexperiment.org/workflows/2620/download/Match_concept_profiles-v4.t2flow?version=4","/users/18","Marco Roos","taverna 2","/users/18, /users/2642, /users/2780, /users/12548,","Marco Roos, Kristina Hettne, Martijn Schuemie, Reinout van Schouwen,","Purpose of workflow: The workflow can be used to match a set of concept profiles with another set of concept profiles. The result is a list of concepts ordered by their match to the query concept profiles. The workflow matches two sets of concept profiles. At the time of writing the concepts are derived from human, rat, and mouse terminologies, ontologies, and database identifiers. The profiles are lists of concepts ranked by their association with the identifying concept, as determined by co-location statistics computed from MedLine (up until 2009 at the time of writing). Author's comments: This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2620/versions/5.html","Match concept profiles","2011-12-0209:07:34","2014-07-1413:31:23","http://www.myexperiment.org/workflows/2620/download/Match_concept_profiles-v5.t2flow?version=5","/users/18","Marco Roos","taverna 2","/users/18, /users/2642, /users/2780, /users/12548,","Marco Roos, Kristina Hettne, Martijn Schuemie, Reinout van Schouwen,","Purpose of workflow: The workflow can be used to match a set of concept profiles with another set of concept profiles. The result is a list of concepts ordered by their match to the query concept profiles. The workflow matches two sets of concept profiles. At the time of writing the concepts are derived from human, rat, and mouse terminologies, ontologies, and database identifiers. The profiles are lists of concepts ranked by their association with the identifying concept, as determined by co-location statistics computed from MedLine (up until 2009 at the time of writing). Author's comments: This workflow can be used together with other workflows in this pack:  <a rel=nofollow href=http://www.myexperiment.org/packs/282>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2620/versions/6.html","Match concept profiles","2011-12-0209:07:34","2014-07-1413:31:23","http://www.myexperiment.org/workflows/2620/download/Match_concept_profiles-v6.t2flow?version=6","/users/18","Marco Roos","taverna 2","/users/18, /users/2642, /users/2780, /users/12548,","Marco Roos, Kristina Hettne, Martijn Schuemie, Reinout van Schouwen,","Purpose of workflow: The workflow can be used to match a set of concept profiles with another set of concept profiles. Result: A list of concepts ordered by their match to the query concept profiles.",0, 0, ,
"http://www.myexperiment.org/workflows/2625/versions/1.html","dcraw (NoConversion, NoInterpretation, FixedWhitelevel)","2011-12-0818:22:28","2011-12-1617:52:34","http://www.myexperiment.org/workflows/2625/download/dcraw__NoConversion__NoInterpretation__FixedWhitelevel_-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","","","Read a RAW image from a file path with the parameters.",-1, 0, ,
"http://www.myexperiment.org/workflows/2625/versions/2.html","dcraw (NoConversion, NoInterpretation, FixedWhitelevel)","2011-12-0818:22:28","2011-12-1617:52:34","http://www.myexperiment.org/workflows/2625/download/dcraw__NoConversion__NoInterpretation__FixedWhitelevel_-v2.t2flow?version=2","/users/20122","Markus Plangg","taverna 2","","","Reads a RAW image with these parameters using dcraw and returns the image data as byte array.",0, 0, ,
"http://www.myexperiment.org/workflows/2625/versions/3.html","dcraw (NoConversion, NoInterpretation, FixedWhitelevel)","2011-12-0818:22:28","2011-12-1617:52:34","http://www.myexperiment.org/workflows/2625/download/dcraw__NoConversion__NoInterpretation__FixedWhitelevel_-v3.t2flow?version=3","/users/20122","Markus Plangg","taverna 2","","","Reads a RAW image with these parameters using dcraw and returns the image data as byte array.",0, 0, ,
"http://www.myexperiment.org/workflows/2625/versions/4.html","dcraw (NoConversion, NoInterpretation, FixedWhitelevel)","2011-12-0818:22:28","2011-12-1617:52:34","http://www.myexperiment.org/workflows/2625/download/dcraw__NoConversion__NoInterpretation__FixedWhitelevel_-v4.t2flow?version=4","/users/20122","Markus Plangg","taverna 2","","","Reads a RAW image with these parameters using dcraw and returns the image data as byte array.",0, 0, ,
"http://www.myexperiment.org/workflows/2626/versions/1.html","dcraw (sRGB, ColorInterpolated, FixedWhitelevel)","2011-12-0818:55:19","2011-12-1617:53:02","http://www.myexperiment.org/workflows/2626/download/dcraw__sRGB__ColorInterpolated__FixedWhitelevel_-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","","","&nbsp;Read a RAW image from a file path with the parameters",-1, 0, ,
"http://www.myexperiment.org/workflows/2626/versions/2.html","dcraw (sRGB, ColorInterpolated, FixedWhitelevel)","2011-12-0818:55:19","2011-12-1617:53:02","http://www.myexperiment.org/workflows/2626/download/dcraw__sRGB__ColorInterpolated__FixedWhitelevel_-v2.t2flow?version=2","/users/20122","Markus Plangg","taverna 2","","","Reads a RAW image with these parameters using dcraw and returns the image data as byte array.",0, 0, ,
"http://www.myexperiment.org/workflows/2627/versions/1.html","dcraw (sRGB, ColorInterpolated, FixedWhitebalance)","2011-12-0818:57:06","2011-12-1617:54:02","http://www.myexperiment.org/workflows/2627/download/dcraw__sRGB__ColorInterpolated__FixedWhitebalance_-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","","","Read a RAW image from a file path with the parameters",-1, 0, ,
"http://www.myexperiment.org/workflows/2627/versions/2.html","dcraw (sRGB, ColorInterpolated, FixedWhitebalance)","2011-12-0818:57:06","2011-12-1617:54:02","http://www.myexperiment.org/workflows/2627/download/dcraw__sRGB__ColorInterpolated__FixedWhitebalance_-v2.t2flow?version=2","/users/20122","Markus Plangg","taverna 2","","","Reads a RAW image with these parameters using dcraw and returns the image data as byte array.",0, 0, ,
"http://www.myexperiment.org/workflows/2630/versions/1.html","Connect flare events with proton events on Earth via propagation model (SMS)","2011-12-0911:27:45","2011-12-1315:27:02","http://www.myexperiment.org/workflows/2630/download/Connect_flare_events_with_proton_events_on_Earth_via_propagation_model__SMS_-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow uses flares listed in any HELIO HEC flare catalogue (using the semantic mapping service), checks whether these flares are connected to Earth via the Parker spiral, and looks for proton events at earth listed in the goes_proton_event list.  The flare listing and the proton listing are combinded into a list of  VOTable outputs (one VOTable per flare catalogue with results).",0, 0, ,
"http://www.myexperiment.org/workflows/2630/versions/2.html","Connect flare events with proton events on Earth via propagation model (SMS)","2011-12-0911:27:45","2011-12-1315:27:02","http://www.myexperiment.org/workflows/2630/download/Connect_flare_events_with_proton_events_on_Earth_via_propagation_model__SMS_-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow uses flares listed in any HELIO HEC flare catalogue (using the semantic mapping service), checks whether these flares are connected to Earth via the Parker spiral, and looks for proton events at earth listed in the goes_proton_event list. The flare listing and the proton listing are combinded into a list of  VOTable outputs (one VOTable per flare catalogue with results).",0, 0, ,
"http://www.myexperiment.org/workflows/2632/versions/1.html","Propagation of the Co-roationg interaction region from the Sun","2011-12-1311:09:59","2012-02-0315:39:23","http://www.myexperiment.org/workflows/2632/download/Propagation_of_the_Co-roationg_interaction_region_from_the_Sun-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","use of the processing service to calculate time delays to the planetsInputs:time when propagation should startlongitude of starting point on the sunspeed of the solar wind",0, 0, ,
"http://www.myexperiment.org/workflows/2632/versions/2.html","Propagation of the Co-roationg interaction region from the Sun","2011-12-1311:09:59","2012-02-0315:39:23","http://www.myexperiment.org/workflows/2632/download/Propagation_of_the_Co-roationg_interaction_region_from_the_Sun-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","use of the processing service to calculate time delays to the planetsInputs:time when propagation should startlongitude of starting point on the sunspeed of the solar winderror speed of the solar wind",0, 0, ,
"http://www.myexperiment.org/workflows/2633/versions/1.html","Propagation of the Solar Energetic Particles from the Sun","2011-12-1313:21:33","2012-02-0315:14:15","http://www.myexperiment.org/workflows/2633/download/Propagation_of_the_Solar_Energetic_Particles_from_the_Sun-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","use of the processing service to calculate time delays to the planetsInputs:time when propagation should startlongitude of starting point on the sunspeed of the solar winderror value of solar wind speedtraveling speed of energetic particals as percentage of the speed of light",0, 0, ,
"http://www.myexperiment.org/workflows/2633/versions/2.html","Propagation of the Solar Energetic Particles from the Sun","2011-12-1313:21:33","2012-02-0315:14:15","http://www.myexperiment.org/workflows/2633/download/Propagation_of_the_Solar_Energetic_Particles_from_the_Sun-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","use of the processing service to calculate time delays to the planetsInputs:time when propagation should startlongitude of starting point on the sunspeed of the solar winderror value of solar wind speedtraveling speed of energetic particals as percentage of the speed of light",0, 0, ,
"http://www.myexperiment.org/workflows/2639/versions/1.html","Mock-Up mp3 To Wav Migrate And QA","2011-12-1512:03:42","2014-05-1409:01:22","http://www.myexperiment.org/workflows/2639/download/Mock-Up_mp3_To_Wav_Migrate_And_QA-v1.t2flow?version=1","/users/19098","Bolette Jurik","taverna 2","/users/19098,","Bolette Jurik,","SO4 mp3 To Wav Migrate And QA Mock Up",-1, 0, ,
"http://www.myexperiment.org/workflows/2639/versions/2.html","Mock-Up mp3 To Wav Migrate And QA","2011-12-1512:03:42","2014-05-1409:01:22","http://www.myexperiment.org/workflows/2639/download/Mock-Up_mp3_To_Wav_Migrate_And_QA-v2.t2flow?version=2","/users/19098","Bolette Jurik","taverna 2","/users/19098,","Bolette Jurik,","SO4 mp3 To Wav Migrate And QA Mock Up",-1, 0, ,
"http://www.myexperiment.org/workflows/2639/versions/3.html","Mock-Up mp3 To Wav Migrate And QA","2011-12-1512:03:42","2014-05-1409:01:22","http://www.myexperiment.org/workflows/2639/download/Mock-Up_mp3_To_Wav_Migrate_And_QA-v3.t2flow?version=3","/users/19098","Bolette Jurik","taverna 2","/users/19098,","Bolette Jurik,","SO4 mp3 To Wav Migrate And QA Mock Up",-1, 0, ,
"http://www.myexperiment.org/workflows/2639/versions/4.html","Mock-Up mp3 To Wav Migrate And QA","2011-12-1512:03:42","2014-05-1409:01:22","http://www.myexperiment.org/workflows/2639/download/Mock-Up_mp3_To_Wav_Migrate_And_QA-v4.t2flow?version=4","/users/19098","Bolette Jurik","taverna 2","/users/19098,","Bolette Jurik,","This is a Mock-Up Workflow illustrating  <span><span>SCAPE solution '</span></span> SO4 mp3 To Wav Migrate And QA Mock Up' <span><span>, see </span></span> <span><span><a href=http://wiki.opf-labs.org/display/SP/SO4+Audio+mp3+to+wav+Migration+and+QA+Workflow rel=nofollow>wiki.opf-labs.org/display/SP/SO4+Audio+mp3+to+wav+Migration+and+QA+Workflow</a></span></span> &nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/2644/versions/1.html","Discretize by Binning","2011-12-2016:40:18","2011-12-2016:52:06","http://www.myexperiment.org/workflows/2644/download/Discretize_by_Binning-v1.t2flow?version=1","/users/16695","Rishi Ramgolam","taverna 2","/users/16695,","Rishi Ramgolam,","&nbsp;Choosing an attribute ('a1') with an attribute filter type condition (single).",-1, 0, ,
"http://www.myexperiment.org/workflows/2646/versions/1.html","[untitled]","2012-01-0311:57:05","2012-01-0311:58:43","http://www.myexperiment.org/workflows/2646/download/_untitled_-v1.t2flow?version=1","/users/7800","Charala...","taverna 2","/users/7800,","Charalampos,","&nbsp;A KUP domain image segmentation workflow that identifies ans annotates important regions on microscopic Kidney biopsy images (vessels and glomerulus)",-1, 0, ,
"http://www.myexperiment.org/workflows/2648/versions/1.html","Hello World","2012-01-0315:38:03","2014-03-0308:14:43","http://www.myexperiment.org/workflows/2648/download/Hello_World-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","One of the simplest workflows possible. No workflow input ports, a single workflow output port &quot;greeting&quot;,  outputting &quot;Hello, world!&quot; as produced by the String Constant &quot;hello&quot;.",0, 0, ,
"http://www.myexperiment.org/workflows/2649/versions/1.html","Hello Anyone","2012-01-0315:39:47","2014-03-0308:15:01","http://www.myexperiment.org/workflows/2649/download/Hello_Anyone-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","An extension to  <a href=http://www.myexperiment.org/workflows/2648 rel=nofollow>helloworld.t2flow</a>  - this workflow takes a workflow input &quot;name&quot; which is combined with the string constant &quot;Hello, &quot; using the local worker &quot;Concatenate two strings&quot;, and outputs the produced string to the workflow output &quot;greeting&quot;.",1, 0, ,
"http://www.myexperiment.org/workflows/2653/versions/1.html","Calculation of distances, magnitutes and luminosities using HyperLEDA","2012-01-1011:01:26","2012-01-1614:01:32","http://www.myexperiment.org/workflows/2653/download/Calculation_of_distances__magnitutes_and_luminosities_using_HyperLEDA-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","Calculation of distances, corrected apparent B magnitude mB-corr and luminosities with values gathered from the HyperLEDA database. This workflow receives a list of galaxy names (hyperLEDA names. ie: KIG0001) and a file with the morphological types of those galaxiesUsing the name of a galaxy, the workflow querys Hyperleda to extract some properties of this galaxy (J2000 Coordinates, velocity, galactic extinction,log of axis ratio, and the Total B-magnitude ). With this properties it calculates the distance of the galaxy and, in other hand, the Total apparent corrected B-magnitude.It takes account if the velocity of the galaxy is lower than a threshold (1000km/s), it can not be possible to calculate the distance so, in those cases the distance will be NaN.At the end, it calculates the Total Luminosity using the velocity and the Total apparent corrected B-magnitude.More information in the nested workflows.The performance could be improved since only one query per galaxy is needed for the extraction of five physical properties. Nevertheless, we have decided to split the query into five different queries and provide a more modular workflow, which is best suited for aims of re-usability and re-purposability. It may happen that for other physical properties, values may come from different databases.",0, 0, ,
"http://www.myexperiment.org/workflows/2653/versions/2.html","Calculation of distances, magnitutes and luminosities using HyperLEDA","2012-01-1011:01:26","2012-01-1614:01:32","http://www.myexperiment.org/workflows/2653/download/Calculation_of_distances__magnitutes_and_luminosities_using_HyperLEDA-v2.t2flow?version=2","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","Calculation of distances, corrected apparent B magnitude mB-corr and luminosities with values gathered from the HyperLEDA database. This workflow receives a list of galaxy names (hyperLEDA names. ie: KIG0001) and a file with the morphological types of those galaxiesUsing the name of a galaxy, the workflow querys Hyperleda to extract some properties of this galaxy (J2000 Coordinates, velocity, galactic extinction,log of axis ratio, and the Total B-magnitude ). With this properties it calculates the distance of the galaxy and, in other hand, the Total apparent corrected B-magnitude.It takes account if the velocity of the galaxy is lower than a threshold (1000km/s), it can not be possible to calculate the distance so, in those cases the distance will be NaN.At the end, it calculates the Total Luminosity using the velocity and the Total apparent corrected B-magnitude.More information in the nested workflows.The performance could be improved since only one query per galaxy is needed for the extraction of five physical properties. Nevertheless, we have decided to split the query into five different queries and provide a more modular workflow, which is best suited for aims of re-usability and re-purposability. It may happen that for other physical properties, values may come from different databases.",0, 0, ,
"http://www.myexperiment.org/workflows/2659/versions/1.html","NCBI Gi to Kegg Pathway Descriptions","2012-01-1209:46:31","2013-01-3013:36:27","http://www.myexperiment.org/workflows/2659/download/NCBI_Gi_to_Kegg_Pathway_Descriptions-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow accepts a list of genbank gene identifiers and returns descriptions of gene functions and a list of all pathways each gene is involved in, according to the KEGG database.",0, 0, ,
"http://www.myexperiment.org/workflows/2659/versions/2.html","NCBI Gi to Kegg Pathway Descriptions","2012-01-1209:46:31","2013-01-3013:36:27","http://www.myexperiment.org/workflows/2659/download/NCBI_Gi_to_Kegg_Pathway_Descriptions-v2.t2flow?version=2","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow accepts a list of genbank gene identifiers and returns descriptions of gene functions and a list of all pathways each gene is involved in, according to the KEGG database.",0, 0, ,
"http://www.myexperiment.org/workflows/2659/versions/3.html","NCBI Gi to Kegg Pathway Descriptions","2012-01-1209:46:31","2013-01-3013:36:27","http://www.myexperiment.org/workflows/2659/download/NCBI_Gi_to_Kegg_Pathway_Descriptions-v3.t2flow?version=3","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow accepts a list of Unigene gene identifiers and returns descriptions of gene functions and a list of all pathways each gene is involved in (plus pathway image) from the KEGG database.This workflow replaces the earlier SOAP version with the new KEGG REST services",0, 0, ,
"http://www.myexperiment.org/workflows/2659/versions/4.html","NCBI Gi to Kegg Pathway Descriptions","2012-01-1209:46:31","2013-01-3013:36:27","http://www.myexperiment.org/workflows/2659/download/NCBI_Gi_to_Kegg_Pathway_Descriptions-v4.t2flow?version=4","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow accepts a list of NCBI gene identifiers and returns descriptions of gene functions and a list of all pathways each gene is involved in (plus pathway image) from the KEGG database.This workflow replaces the earlier SOAP version with the new KEGG REST services",0, 0, ,
"http://www.myexperiment.org/workflows/2659/versions/5.html","NCBI Gi to Kegg Pathway Descriptions","2012-01-1209:46:31","2013-01-3013:36:27","http://www.myexperiment.org/workflows/2659/download/NCBI_Gi_to_Kegg_Pathway_Descriptions-v5.t2flow?version=5","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow accepts a list of NCBI gene identifiers and returns descriptions of gene functions and a list of all pathways each gene is involved in (plus pathway image) from the KEGG database.This workflow replaces the earlier SOAP version with the new KEGG REST services",0, 0, ,
"http://www.myexperiment.org/workflows/2663/versions/1.html","getFirstElementDFS","2012-01-1319:25:22","2012-02-1320:59:49","http://www.myexperiment.org/workflows/2663/download/getFirstElementDFS-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","","","Returns the first element of a nested list using depth first search. The maximum depth of the input is set to 2. You can savely increase this by increasing the depth of the workflow input port and the beanshell input port. Taverna will wrap the input into a list with correct depth. However this will create a little overhead.",0, 0, ,
"http://www.myexperiment.org/workflows/2663/versions/2.html","getFirstElementDFS","2012-01-1319:25:22","2012-02-1320:59:49","http://www.myexperiment.org/workflows/2663/download/getFirstElementDFS-v2.t2flow?version=2","/users/20122","Markus Plangg","taverna 2","","","Returns the first element of a nested list using depth first search.  The maximum depth of the input is set to 2. You can savely increase this by increasing the depth of the workflow input port and the beanshell input port. Taverna will wrap the input into a list with correct depth. However this will create a little overhead.",-1, 0, ,
"http://www.myexperiment.org/workflows/2665/versions/1.html","Import and convert gene list","2012-01-1510:23:33","2012-03-1211:59:15","http://www.myexperiment.org/workflows/2665/download/Import_and_convert_gene_list-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow extracts a column of RefSeq gene IDs from a CSV file and then converts them to Unigene identifiers",0, 0, ,
"http://www.myexperiment.org/workflows/2673/versions/1.html","UnigeneID to KEGG Pathways","2012-01-1610:54:39","2012-12-1712:41:13","http://www.myexperiment.org/workflows/2673/download/UnigeneID_to_KEGG_Pathways-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/43,","Katy Wolstencroft, Paul Fisher,","This workflow accepts a list of Unigene gene identifiers and returns descriptions of gene functions and a list of all pathways each gene is involved in, according to the KEGG database.",0, 0, ,
"http://www.myexperiment.org/workflows/2673/versions/2.html","UnigeneID to KEGG Pathways","2012-01-1610:54:39","2012-12-1712:41:13","http://www.myexperiment.org/workflows/2673/download/UnigeneID_to_KEGG_Pathways-v2.t2flow?version=2","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/43,","Katy Wolstencroft, Paul Fisher,","This workflow accepts a list of Unigene gene identifiers and returns descriptions of gene functions and a list of all pathways each gene is involved in, according to the KEGG database. It also displays each pathway diagram.",0, 0, ,
"http://www.myexperiment.org/workflows/2673/versions/3.html","UnigeneID to KEGG Pathways","2012-01-1610:54:39","2012-12-1712:41:13","http://www.myexperiment.org/workflows/2673/download/UnigeneID_to_KEGG_Pathways-v3.t2flow?version=3","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/43,","Katy Wolstencroft, Paul Fisher,","This workflow accepts a list of Unigene gene identifiers and returns descriptions of gene functions and a list of all pathways each gene is involved in (plus pathway image) from the KEGG database.This workflow replaces the earlier SOAP version with the new KEGG REST services",0, 0, ,
"http://www.myexperiment.org/workflows/2676/versions/1.html","Reactome pathways","2012-01-1615:31:40","","http://www.myexperiment.org/workflows/2676/download/Reactome_pathways-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow returns a list of pathways gene products are involved in, along with their descriptions and Gene Ontology annotations",0, 0, ,
"http://www.myexperiment.org/workflows/2677/versions/1.html","FFmpeg convert audio2aac (REST)","2012-01-1618:09:04","2012-01-1618:26:32","http://www.myexperiment.org/workflows/2677/download/FFmpeg_convert_audio2aac__REST_-v1.t2flow?version=1","/users/16931","Rui Castro","taverna 2","/users/16931,","Rui Castro,","<span>Converts supported audio files to AAC using FFmpeg through a REST webservice.</span>",-1, 0, ,
"http://www.myexperiment.org/workflows/2679/versions/1.html","ImageMagick convert image2jp2 (REST)","2012-01-1618:19:48","2012-01-1618:21:38","http://www.myexperiment.org/workflows/2679/download/ImageMagick_convert_image2jp2__REST_-v1.t2flow?version=1","/users/16931","Rui Castro","taverna 2","/users/16931,","Rui Castro,","<span>Converts supported image files to JPEG2000 using ImageMagick through a REST webservice.</span>",-1, 0, ,
"http://www.myexperiment.org/workflows/2680/versions/1.html","ImageMagick convert image2jp2 (SOAP)","2012-01-1618:23:53","2012-01-1618:25:15","http://www.myexperiment.org/workflows/2680/download/ImageMagick_convert_image2jp2__SOAP_-v1.t2flow?version=1","/users/16931","Rui Castro","taverna 2","/users/16931,","Rui Castro,","<span>Converts supported image files to JPEG2000 using ImageMagick through a SOAP webservice.</span>",-1, 0, ,
"http://www.myexperiment.org/workflows/2681/versions/1.html","FFmpeg convert audio2aac (SOAP)","2012-01-1618:28:11","2012-01-1618:31:31","http://www.myexperiment.org/workflows/2681/download/FFmpeg_convert_audio2aac__SOAP_-v1.t2flow?version=1","/users/16931","Rui Castro","taverna 2","/users/16931,","Rui Castro,","<span>Converts supported audio files to AAC using FFmpeg through a SOAP webservice.</span>",-1, 0, ,
"http://www.myexperiment.org/workflows/2686/versions/1.html","Pathways and Gene annotations forQTL region","2012-01-2009:32:55","2012-01-2009:32:56","http://www.myexperiment.org/workflows/2686/download/Pathways_and_Gene_annotations_forQTL_region-v1.t2flow?version=1","/users/21155","Bonilla","taverna 2","/users/21155,","Bonilla,","This workflow searches for genes which reside in a QTL (Quantitative Trait Loci) region in the mouse, Mus musculus. The workflow requires an input of: a chromosome name or number; a QTL start base pair position; QTL end base pair position. Data is then extracted from BioMart to annotate each of the genes found in this region. The Entrez and UniProt identifiers are then sent to KEGG to obtain KEGG gene identifiers. The KEGG gene identifiers are then used to searcg for pathways in the KEGG pathway database.",0, 0, ,
"http://www.myexperiment.org/workflows/2724/versions/1.html","A heuristic measure for detecting undesired influence of lossy JP2 compression on OCR in the absence of ground truth","2012-02-0612:27:23","2012-03-0914:33:19","http://www.myexperiment.org/workflows/2724/download/A_heuristic_measure_for_detecting_undesired_influence_of_lossy_JP2_compression_on_OCR_in_the_absence_of_ground_truth-v1.t2flow?version=1","/users/4707","Sven","taverna 2","/users/4707,","Sven,","Analysing the impact of JPEG2000 compression on the OCR. Requires the following tools to be installed: Workflow has been designed to be executed on a linux system, some variables, like the temporary directory &quot;/tmp/&quot; would have to be changed for other operating systems.",0, 0, ,
"http://www.myexperiment.org/workflows/2724/versions/2.html","A heuristic measure for detecting undesired influence of lossy JP2 compression on OCR in the absence of ground truth","2012-02-0612:27:23","2012-03-0914:33:19","http://www.myexperiment.org/workflows/2724/download/A_heuristic_measure_for_detecting_undesired_influence_of_lossy_JP2_compression_on_OCR_in_the_absence_of_ground_truth-v2.t2flow?version=2","/users/4707","Sven","taverna 2","/users/4707,","Sven,","The workflow takes TIFF image instances as input,  applies a list of JP2 compression parameter values, executes OCR  using an open source OCR engine, evaluates the results, and creates a diagram visualising the results. Dependencies on external tools for the tool service components: Dependencies on external Java libraries of beanshells:",0, 0, ,
"http://www.myexperiment.org/workflows/2725/versions/1.html","Explain concept scores","2012-02-0711:05:50","2014-07-1409:41:34","http://www.myexperiment.org/workflows/2725/download/Explain_concept_scores-v1.t2flow?version=1","/users/12548","Reinout van Schouwen","taverna 2","/users/12548,","Reinout van Schouwen,","&nbsp;This workflow demonstrates the 'explain scores' functionality from Anni 2.1, made available as a web service.",-1, 0, ,
"http://www.myexperiment.org/workflows/2725/versions/2.html","Explain concept scores","2012-02-0711:05:50","2014-07-1409:41:34","http://www.myexperiment.org/workflows/2725/download/Explain_concept_scores-v2.t2flow?version=2","/users/12548","Reinout van Schouwen","taverna 2","/users/12548,","Reinout van Schouwen,","&nbsp;This workflow demonstrates the explainScores method from the Anni web services.",-1, 0, ,
"http://www.myexperiment.org/workflows/2725/versions/3.html","Explain concept scores","2012-02-0711:05:50","2014-07-1409:41:34","http://www.myexperiment.org/workflows/2725/download/Explain_concept_scores-v3.t2flow?version=3","/users/12548","Reinout van Schouwen","taverna 2","/users/12548,","Reinout van Schouwen,","Explain concept scores of concept profiles (enrichment with concept set)",0, 0, ,
"http://www.myexperiment.org/workflows/2725/versions/4.html","Explain concept scores","2012-02-0711:05:50","2014-07-1409:41:34","http://www.myexperiment.org/workflows/2725/download/Explain_concept_scores-v4.t2flow?version=4","/users/12548","Reinout van Schouwen","taverna 2","/users/12548,","Reinout van Schouwen,","Explain concept scores of concept profiles (enrichment with concept set). This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2725/versions/5.html","Explain concept scores","2012-02-0711:05:50","2014-07-1409:41:34","http://www.myexperiment.org/workflows/2725/download/Explain_concept_scores-v5.t2flow?version=5","/users/12548","Reinout van Schouwen","taverna 2","/users/12548,","Reinout van Schouwen,","Purpose of workflow: This workflow takes two concept ids as input and returns the top ranking B concepts according to Swanson's ABC model of discovery, where the relationships AB and BC are known and reported in the literature, and the implicit relationship AC is a putative new discovery. It might also be the case that AC is already known. In that case AC does not represent a new discovery but will still be returned (see workflow example values). The B concepts are returned sorted on the percentage of the contributions of the individual concepts to the coherence score (the average of the inner product scores of all possible concept pairs within the group). This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2725/versions/6.html","Explain concept scores","2012-02-0711:05:50","2014-07-1409:41:34","http://www.myexperiment.org/workflows/2725/download/Explain_concept_scores-v6.t2flow?version=6","/users/12548","Reinout van Schouwen","taverna 2","/users/12548,","Reinout van Schouwen,","Purpose of workflow: This workflow takes two concept ids as input and returns the top ranking B concepts according to Swanson's ABC model of discovery, where the relationships AB and BC are known and reported in the literature, and the implicit relationship AC is a putative new discovery. It might also be the case that AC is already known. In that case AC does not represent a new discovery but will still be returned (see workflow example values). The B concepts are returned sorted on the percentage of the contributions of the individual concepts to the coherence score (the average of the inner product scores of all possible concept pairs within the group). This workflow can be used together with other workflows in this pack:  <a rel=nofollow href=http://www.myexperiment.org/packs/282>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2725/versions/7.html","Explain concept scores","2012-02-0711:05:50","2014-07-1409:41:34","http://www.myexperiment.org/workflows/2725/download/Explain_concept_scores-v7.t2flow?version=7","/users/12548","Reinout van Schouwen","taverna 2","/users/12548,","Reinout van Schouwen,","Purpose of workflow: This workflow takes two concept ids as input and returns the top ranking B concepts according to Swanson's ABC model of discovery, where the relationships AB and BC are known and reported in the literature, and the implicit relationship AC is a putative new discovery. It might also be the case that AC is already known. In that case AC does not represent a new discovery but will still be returned (see workflow example values). The B concepts are returned sorted on the percentage of the contributions of the individual concepts to the coherence score (the average of the inner product scores of all possible concept pairs within the group).",0, 0, ,
"http://www.myexperiment.org/workflows/2726/versions/1.html","Define Associated Regions and Genes","2012-02-0816:08:08","2012-05-0909:52:18","http://www.myexperiment.org/workflows/2726/download/Define_Associated_Regions_and_Genes-v1.t2flow?version=1","/users/21160","Paul martin","taverna 2","/users/21160,","Paul martin,","Defines regions and genes from associated SNPs A  <a href=http://www.mysql.com/downloads/connector/j/ rel=nofollow>JAVA MySQL connector</a>  is required to run the workflow and must be placed in the $TAVERNA_HOME/lib directory.",0, 0, ,
"http://www.myexperiment.org/workflows/2726/versions/2.html","Define Associated Regions and Genes","2012-02-0816:08:08","2012-05-0909:52:18","http://www.myexperiment.org/workflows/2726/download/Define_Associated_Regions_and_Genes-v2.t2flow?version=2","/users/21160","Paul martin","taverna 2","/users/21160,","Paul martin,","Defines regions and genes from associated SNPs A  <a href=http://www.mysql.com/downloads/connector/j/ rel=nofollow>JAVA MySQL connector</a>  is required to run the workflow and must be placed in the $TAVERNA_HOME/lib directory.",0, 0, ,
"http://www.myexperiment.org/workflows/2727/versions/1.html","Make XML Parameters","2012-02-0816:10:48","2012-02-0816:12:39","http://www.myexperiment.org/workflows/2727/download/Make_XML_Parameters-v1.t2flow?version=1","/users/21160","Paul martin","taverna 2","/users/21160,","Paul martin,","Reformats a SNP list with optional p-value into the required XML input for the 'Define Associated Regions and Genes' workflow. Additional parameters can be supplied to add to the XML document.",-1, 0, ,
"http://www.myexperiment.org/workflows/2728/versions/1.html","Associated Region to Gene List","2012-02-0816:14:17","2012-02-0816:14:47","http://www.myexperiment.org/workflows/2728/download/Associated_Region_to_Gene_List-v1.t2flow?version=1","/users/21160","Paul martin","taverna 2","/users/21160,","Paul martin,","Produces a gene list from the Associated Region XML file",0, 0, ,
"http://www.myexperiment.org/workflows/2734/versions/1.html","Render gene via BioGPS","2012-02-1020:06:56","2012-02-1521:12:35","http://www.myexperiment.org/workflows/2734/download/Render_gene_via_BioGPS-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow uses the REST API of BioGPS tolist the plugins and then allow the user to select whichplugin to use to display the input gene id",0, 0, ,
"http://www.myexperiment.org/workflows/2734/versions/2.html","Render gene via BioGPS","2012-02-1020:06:56","2012-02-1521:12:35","http://www.myexperiment.org/workflows/2734/download/Render_gene_via_BioGPS-v2.t2flow?version=2","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow uses the REST API of BioGPS tolist the plugins and then allow the user to select whichplugin to use to display the input gene id",0, 0, ,
"http://www.myexperiment.org/workflows/2735/versions/1.html","Radio lists search over time period","2012-02-1312:02:47","2012-02-1415:05:42","http://www.myexperiment.org/workflows/2735/download/Radio_lists_search_over_time_period-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow searches thewind stereo II IV radioburst list,wind tyhpe II soho cme list,hfc radioburst type IV list,tsrs solar radio event listand combines the return of these lists chronologically. Only time_start, time_end, and comment sectionsare preserved in the result list.",0, 0, ,
"http://www.myexperiment.org/workflows/2735/versions/2.html","Radio lists search over time period","2012-02-1312:02:47","2012-02-1415:05:42","http://www.myexperiment.org/workflows/2735/download/Radio_lists_search_over_time_period-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow searches thewind stereo II IV radioburst list,wind tyhpe II soho cme list,hfc radioburst type III list,tsrs solar radio event listand combines the return of these lists chronologically. Only time_start, time_end, and comment sectionsare preserved in the result list.",0, 0, ,
"http://www.myexperiment.org/workflows/2739/versions/1.html","Simulation workflow for flooding emergency simulation","2012-02-1519:49:52","","","/users/19224","Jribault","taverna 2","","","Simulation workflow for flooding emergency simulation.This workflow cannot be executed as is due to authentification restriction, and local tools dependancies.",
"http://www.myexperiment.org/workflows/2740/versions/1.html","Run a Workflow on Taverna Server","2012-02-1716:30:51","2012-02-1716:30:52","","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Uses the URL to a t2flow file to submit and run this workflow on the taverna server.You need a user name and password to execute this workflow. Input to the workflow which runs remotely will be requested interactively.",
"http://www.myexperiment.org/workflows/2741/versions/1.html","Run a Workflow on Taverna Server (local t2flow)","2012-02-2011:38:53","","","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Uses a local t2flow file to submit and run this workflow on the taverna server.You need a user name and password to execute this workflow. Input to the workflow which runs remotely will be requested interactively.",
"http://www.myexperiment.org/workflows/2742/versions/1.html","Get a list of proteins from a Gene Ontology (GO) term","2012-02-2023:00:06","2012-02-2221:08:54","http://www.myexperiment.org/workflows/2742/download/Get_a_list_of_proteins_from_a_Gene_Ontology__GO__term-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Get a list of UniProt proteins that have been annotated with the same Gene Ontology (GO) term. This workflow uses the the QuickGO service",0, 0, ,
"http://www.myexperiment.org/workflows/2743/versions/1.html","WCP-04 Exclusive choice - if/else branching","2012-02-2023:20:08","2012-02-2023:23:59","http://www.myexperiment.org/workflows/2743/download/WCP-04_Exclusive_choice_-_if_else_branching-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","The choice of executing choiceA or choiceB is determined by using String_List_Intersection and String_List_Difference.   If in=&quot;true&quot; then the intersection will yield a non-empty list, triggering execution of choiceA. This list will however not differ from the input, and so choiceB will iterate over an empty list (ie. not execute). Note how using 'difference' for the else-case here means that if you run the workflow with in=&quot;bob&quot;, choiceB would still run. Some early if/else workflows for Taverna 1 using Fail_if_false and conditional run would in these cases run both choices. To extend this workflow with multiple choices, add several intersections, but use String_list_Union to feed the intersected lists to list2 of String_list_difference. If no else-case is needed, simply delete String_list_difference and choiceB. The nested workflows wrap the chosen services A and B, thereby the services do not need to support receiving the token. <i>It is important to note that in this workflow 'in' is an input port at depth 0 so that only a single value is 'chosen' over the same time. If this was made depth 1, then several choices could be triggered. If you want to perform iterations over A and B (presumably taking some inputs), with individual choices, you need to wrap this workflow as a nested workflow and iterate over it.</i>",0, 0, ,
"http://www.myexperiment.org/workflows/2744/versions/1.html","Parse QuickGO &quot;proteinList&quot; file format","2012-02-2023:28:03","2013-07-1013:53:44","http://www.myexperiment.org/workflows/2744/download/Parse_QuickGO__proteinList__file_format-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Parse QuickGO proteinList file format.  <a href=http://www.ebi.ac.uk/QuickGO/reference.html rel=nofollow>http://www.ebi.ac.uk/QuickGO/reference.html</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2744/versions/2.html","Parse QuickGO &quot;proteinList&quot; file format","2012-02-2023:28:03","2013-07-1013:53:44","http://www.myexperiment.org/workflows/2744/download/Parse_QuickGO__proteinList__file_format-v2.t2flow?version=2","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Parse QuickGO proteinList file format.  <a href=http://www.ebi.ac.uk/QuickGO/reference.html rel=nofollow>http://www.ebi.ac.uk/QuickGO/reference.html</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2746/versions/1.html","Get a list of Protein Identification experiments from PRIDE by a Gene Ontology query","2012-02-2100:30:44","2013-07-1014:32:03","http://www.myexperiment.org/workflows/2746/download/Get_a_list_of_Protein_Identification_experiments_from_PRIDE_by_a_Gene_Ontology_query-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Get a list of Protein Identification experiments from PRIDE by a Gene Ontology query",0, 0, ,
"http://www.myexperiment.org/workflows/2746/versions/2.html","Get a list of Protein Identification experiments from PRIDE by a Gene Ontology query","2012-02-2100:30:44","2013-07-1014:32:03","http://www.myexperiment.org/workflows/2746/download/Get_a_list_of_Protein_Identification_experiments_from_PRIDE_by_a_Gene_Ontology_query-v2.t2flow?version=2","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Get a list of Protein Identification experiments from PRIDE by a Gene Ontology query",0, 0, ,
"http://www.myexperiment.org/workflows/2746/versions/3.html","Get a list of Protein Identification experiments from PRIDE by a Gene Ontology query","2012-02-2100:30:44","2013-07-1014:32:03","http://www.myexperiment.org/workflows/2746/download/Get_a_list_of_Protein_Identification_experiments_from_PRIDE_by_a_Gene_Ontology_query-v3.t2flow?version=3","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Get a list of Protein Identification experiments from PRIDE by a Gene Ontology query",0, 0, ,
"http://www.myexperiment.org/workflows/2749/versions/1.html","Convert by target path","2012-02-2117:21:20","2012-08-1412:35:59","http://www.myexperiment.org/workflows/2749/download/Convert_by_target_path-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Converts a file to a target format depending on the target path extension.",0, 0, ,
"http://www.myexperiment.org/workflows/2750/versions/1.html","Get image mimetype","2012-02-2117:24:40","2012-02-2117:24:41","http://www.myexperiment.org/workflows/2750/download/Get_image_mimetype-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Returns the mimetype of an image.",0, 0, ,
"http://www.myexperiment.org/workflows/2752/versions/1.html","RAWverna Image evaluation - Read images (RAW, NonRAW)","2012-02-2117:37:37","2012-02-2117:37:38","http://www.myexperiment.org/workflows/2752/download/RAWverna_Image_evaluation_-_Read_images__RAW__NonRAW_-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Reads images for evaluation by RAWverna. The read parameters depend on the type of the images.",0, 0, ,
"http://www.myexperiment.org/workflows/2753/versions/1.html","RAWverna Image evaluation - Read Image (RAW)","2012-02-2117:39:52","2012-02-2117:39:53","http://www.myexperiment.org/workflows/2753/download/RAWverna_Image_evaluation_-_Read_Image__RAW_-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Reads an image from the given path using dcraw for image comparison.",0, 0, ,
"http://www.myexperiment.org/workflows/2754/versions/1.html","RAWverna image evaluation - Read images (RAW)","2012-02-2117:40:54","","http://www.myexperiment.org/workflows/2754/download/RAWverna_image_evaluation_-_Read_images__RAW_-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Reads RAW images for evaluation by RAWverna.",0, 0, ,
"http://www.myexperiment.org/workflows/2755/versions/1.html","RAWverna Image Evaluator - Evaluate Equals","2012-02-2117:46:15","2012-02-2117:46:16","http://www.myexperiment.org/workflows/2755/download/RAWverna_Image_Evaluator_-_Evaluate_Equals-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Takes two images as byte array and compares them for equality using the RAWverna Image Evaluator.",0, 0, ,
"http://www.myexperiment.org/workflows/2757/versions/1.html","RAWverna Image Evaluator - Evaluate relative","2012-02-2117:47:34","2012-02-2117:47:35","http://www.myexperiment.org/workflows/2757/download/RAWverna_Image_Evaluator_-_Evaluate_relative-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Takes two images as byte array and compares them using the RAWverna Image Evaluator.",0, 0, ,
"http://www.myexperiment.org/workflows/2759/versions/1.html","Find protein identifications in PRIDE","2012-02-2123:09:14","2012-02-2221:00:14","http://www.myexperiment.org/workflows/2759/download/Find_protein_identifications_in_PRIDE-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Find protein Identifications in PRIDE by protein accession",0, 0, ,
"http://www.myexperiment.org/workflows/2759/versions/2.html","Find protein identifications in PRIDE","2012-02-2123:09:14","2012-02-2221:00:14","http://www.myexperiment.org/workflows/2759/download/Find_protein_identifications_in_PRIDE-v2.t2flow?version=2","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","Find protein identifications information in the PRIDE database using a protein accession as input.",0, 0, ,
"http://www.myexperiment.org/workflows/2761/versions/1.html","Propagation of the Solar Energetic Particles to the Sun","2012-02-2213:51:13","2012-02-2213:51:14","http://www.myexperiment.org/workflows/2761/download/Propagation_of_the_Solar_Energetic_Particles_to_the_Sun-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","use of the processing service to calculate time delays to the planetsInputs:time when propagation should start from the hit objecthit_object where was the SEP event observedspeed of the solar winderror value of solar wind speedbeta traveling speed of energetic particals as percentage of the speed of light",0, 0, ,
"http://www.myexperiment.org/workflows/2762/versions/1.html","CME backwards propagation","2012-02-2315:23:26","2012-02-2315:23:27","http://www.myexperiment.org/workflows/2762/download/CME_backwards_propagation-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Workflow propagates an CME event from its observing point (planet/spacecraft) back to the sun.The propagation also provides the timing of this event at other points in space (planet/spacecraft)",0, 0, ,
"http://www.myexperiment.org/workflows/2763/versions/1.html","VAMDC VALD query with SME processing","2012-02-2408:10:28","2012-09-1212:56:49","http://www.myexperiment.org/workflows/2763/download/VAMDC_VALD_query_with_SME_processing-v1.t2flow?version=1","/users/19019","Stormsh...","taverna 2","","","Queries a particular observation file extracting the needed wavelength range and call SME.  The output will be a PS image plot along with txt report. VALD: The Vienna Atomic Line Database (VALD) is a collection of atomic line parameters of astronomical interest and provides tools for selecting subsets of lines for typical astrophysical applications: line identification, chemical composition and radial velocity measurements, model atmosphere calculations etc. The VALD database is maintained at three sites: Uppsala Universitet; Universitaet Wien; Institute for Astronomy RAS, Moscow. SME: Spectroscopy Made Easy (SME) is a software package that calculates syn- thetic spectra of stars and fits observed spectra.",-1, 0, ,
"http://www.myexperiment.org/workflows/2763/versions/2.html","VAMDC VALD query with SME processing","2012-02-2408:10:28","2012-09-1212:56:49","http://www.myexperiment.org/workflows/2763/download/VAMDC_VALD_query_with_SME_processing-v2.t2flow?version=2","/users/19019","Stormsh...","taverna 2","","","VAMDC workflow that queries the VALD Atomic database in Moscow and runs SME (Spectroscopy Made Easy)VAMDC Taverna Plugin:  <a href=http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide rel=nofollow>http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2764/versions/1.html","Propagation of CME from the Sun","2012-02-2708:59:22","2012-02-2708:59:23","http://www.myexperiment.org/workflows/2764/download/Propagation_of_CME_from_the_Sun-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Uses the processing service to calculate the objects (planets and observatories) which a CME might hit. Required longitude input is the longitude of the associated flare event.",0, 0, ,
"http://www.myexperiment.org/workflows/2766/versions/1.html","Image QA - Read image (RAW/NonRAW)","2012-02-2715:54:18","2012-02-2715:54:19","http://www.myexperiment.org/workflows/2766/download/Image_QA_-_Read_image__RAW_NonRAW_-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Reads an image for evaluation. How the file is read depends on the image type (RAW, NonRAW) of the current image and the image to compare with.",0, 0, ,
"http://www.myexperiment.org/workflows/2767/versions/1.html","Image QA (RAW/NonRAW, Ssim, Equals)","2012-02-2715:58:20","2012-02-2715:58:21","http://www.myexperiment.org/workflows/2767/download/Image_QA__RAW_NonRAW__Ssim__Equals_-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Reads images either by reading the file directly or using dcraw depending on the image mimetype. Then runs QA algorithms to compare the images.",0, 0, ,
"http://www.myexperiment.org/workflows/2768/versions/1.html","Image Characterisation - Fits (Simple)","2012-02-2716:04:46","2012-02-2716:04:47","http://www.myexperiment.org/workflows/2768/download/Image_Characterisation_-_Fits__Simple_-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Extracts metadata from images.",0, 0, ,
"http://www.myexperiment.org/workflows/2769/versions/1.html","Planning Overview (Scp, Migration, Characterisation, QA)","2012-02-2808:54:03","","http://www.myexperiment.org/workflows/2769/download/Planning_Overview__Scp__Migration__Characterisation__QA_-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Copies an image from a remote path using scp. Then starts a migration action on the image and extracts properties from the original and migrated image. The properties are compared and on the image data itself, QA algorithms are started.",0, 0, ,
"http://www.myexperiment.org/workflows/2770/versions/1.html","Disability estimates by year","2012-02-2816:16:13","","http://www.myexperiment.org/workflows/2770/download/Disability_estimates_by_year-v1.t2flow?version=1","/users/474","Ian Dunlop","taverna 2","/users/474,","Ian Dunlop,","Uses census and health survey for england together with R to estimate disability for districts in the UK",0, 0, ,
"http://www.myexperiment.org/workflows/2775/versions/1.html","Filter CME events to events which could have been observed at Earth and Mars","2012-02-2914:59:28","2012-02-2914:59:30","http://www.myexperiment.org/workflows/2775/download/Filter_CME_events_to_events_which_could_have_been_observed_at_Earth_and_Mars-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow uses the initial time period to search for time periods where Earth and Mars are not further appart than 80 degrees. These time periods are used to find Halo CME events. The CME events are forward propagated to Earth and Sun. Only events were the propagation model predicts that both planets are on the propagation path will be included in the final VOTable",0, 0, ,
"http://www.myexperiment.org/workflows/2779/versions/1.html","Example of interaction via HTML page","2012-03-0511:26:45","2012-03-0511:35:12","http://www.myexperiment.org/workflows/2779/download/Example_of_interaction_via_HTML_page-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2781/versions/1.html","RISE Atomic Service: Create Account","2012-03-0521:44:39","2012-03-0521:47:46","http://www.myexperiment.org/workflows/2781/download/RISE_Atomic_Service__Create_Account-v1.t2flow?version=1","/users/19224","Jribault","taverna 2","/users/19224,","Jribault,","&nbsp;This workflow create an new user account on the RISE server",-1, 0, ,
"http://www.myexperiment.org/workflows/2783/versions/1.html","RISE Atomic Service: Create Framework","2012-03-0521:49:49","2012-03-0521:50:43","http://www.myexperiment.org/workflows/2783/download/RISE_Atomic_Service__Create_Framework-v1.t2flow?version=1","/users/19224","Jribault","taverna 2","/users/19224,","Jribault,","&nbsp;This workflow create a new framework on the RISE Server",-1, 0, ,
"http://www.myexperiment.org/workflows/2784/versions/1.html","RISE Atomic Service: Delete Framework","2012-03-0521:51:20","2012-03-0521:51:53","http://www.myexperiment.org/workflows/2784/download/RISE_Atomic_Service__Delete_Framework-v1.t2flow?version=1","/users/19224","Jribault","taverna 2","/users/19224,","Jribault,","&nbsp;This workflow delete an existing framework on the RISE Server.",-1, 0, ,
"http://www.myexperiment.org/workflows/2786/versions/1.html","RISE Atomic Service: Execute Simulation","2012-03-0521:56:40","2012-03-0521:57:36","http://www.myexperiment.org/workflows/2786/download/RISE_Atomic_Service__Execute_Simulation-v1.t2flow?version=1","/users/19224","Jribault","taverna 2","/users/19224,","Jribault,","&nbsp;This workflow execute a simulation on the RISE server, and wait for its completion.",-1, 0, ,
"http://www.myexperiment.org/workflows/2787/versions/1.html","RISE Atomic Service: Get Simulation Result","2012-03-0521:58:12","2012-03-0521:59:00","http://www.myexperiment.org/workflows/2787/download/RISE_Atomic_Service__Get_Simulation_Result-v1.t2flow?version=1","/users/19224","Jribault","taverna 2","/users/19224,","Jribault,","&nbsp;This workflow get the simulation result of an existing simulation on the RISE server.",-1, 0, ,
"http://www.myexperiment.org/workflows/2788/versions/1.html","RISE Atomic Service: Upload ZIP Model File","2012-03-0522:00:01","2012-03-0522:00:58","http://www.myexperiment.org/workflows/2788/download/RISE_Atomic_Service__Upload_ZIP_Model_File-v1.t2flow?version=1","/users/19224","Jribault","taverna 2","/users/19224,","Jribault,","&nbsp;This workflow upload a ZIP file of the simulation model on the RISE server.",-1, 0, ,
"http://www.myexperiment.org/workflows/2789/versions/1.html","RISE UI: Ask Framework Name","2012-03-0522:01:34","2012-03-2222:15:49","http://www.myexperiment.org/workflows/2789/download/RISE_UI__Ask_Framework_Name-v1.t2flow?version=1","/users/19224","Jribault","taverna 2","/users/19224,","Jribault,","&nbsp;This workflow ask the user to enter a framework name.",-1, 0, ,
"http://www.myexperiment.org/workflows/2789/versions/2.html","RISE UI: Ask Framework Name","2012-03-0522:01:34","2012-03-2222:15:49","http://www.myexperiment.org/workflows/2789/download/RISE_UI__Ask_Framework_Name-v2.t2flow?version=2","/users/19224","Jribault","taverna 2","/users/19224,","Jribault,","&nbsp; <span>&nbsp;This workflow ask the user to enter a new framework name.</span>",0, 0, ,
"http://www.myexperiment.org/workflows/2790/versions/1.html","RISE UI: Choose Framework","2012-03-0522:02:59","2012-03-0522:03:48","http://www.myexperiment.org/workflows/2790/download/RISE_UI__Choose_Framework-v1.t2flow?version=1","/users/19224","Jribault","taverna 2","/users/19224,","Jribault,","This workflow ask the user to choose a framework among those present on the RISE server.",-1, 0, ,
"http://www.myexperiment.org/workflows/2791/versions/1.html","RISE UI: Choose Service Type","2012-03-0522:04:18","2012-03-0522:05:04","http://www.myexperiment.org/workflows/2791/download/RISE_UI__Choose_Service_Type-v1.t2flow?version=1","/users/19224","Jribault","taverna 2","/users/19224,","Jribault,","This workflow ask the user to select a service type among those present on the RISE server.",-1, 0, ,
"http://www.myexperiment.org/workflows/2792/versions/1.html","RISE UI: Choose User Workspace","2012-03-0522:05:36","2012-03-0522:06:25","http://www.myexperiment.org/workflows/2792/download/RISE_UI__Choose_User_Workspace-v1.t2flow?version=1","/users/19224","Jribault","taverna 2","/users/19224,","Jribault,","This workflow ask the user to select a user workspace among those present on the RISE server.",-1, 0, ,
"http://www.myexperiment.org/workflows/2793/versions/1.html","RISE UI: Create a Framework XML File","2012-03-0522:07:23","2012-03-0522:08:31","http://www.myexperiment.org/workflows/2793/download/RISE_UI__Create_a_Framework_XML_File-v1.t2flow?version=1","/users/19224","Jribault","taverna 2","/users/19224,","Jribault,","This workflow create a framework configuration XML file based on user interaction.",-1, 0, ,
"http://www.myexperiment.org/workflows/2794/versions/1.html","RISE UI: Select XML file","2012-03-0522:09:01","2012-03-0522:12:04","http://www.myexperiment.org/workflows/2794/download/RISE_UI__Select_XML_file-v1.t2flow?version=1","/users/19224","Jribault","taverna 2","/users/19224,","Jribault,","&nbsp;This workflow ask the user to select an existing XML file on his own computer.",-1, 0, ,
"http://www.myexperiment.org/workflows/2795/versions/1.html","RISE UI: Select ZIP file","2012-03-0522:10:17","2012-03-0522:11:41","http://www.myexperiment.org/workflows/2795/download/RISE_UI__Select_ZIP_file-v1.t2flow?version=1","/users/19224","Jribault","taverna 2","/users/19224,","Jribault,","&nbsp;This workflow ask the user to select a ZIP file on his own computer.",-1, 0, ,
"http://www.myexperiment.org/workflows/2798/versions/1.html","VAMDC VALD query with SME processing","2012-03-0718:03:01","2012-11-2911:56:21","http://www.myexperiment.org/workflows/2798/download/VAMDC_VALD_query_with_SME_processing-v1.t2flow?version=1","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","This workflow will query VALD and call the SME application. This workflow will ask for temperature, logg, and observation file location (url). See  <a href=http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/ rel=nofollow>http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/</a>  for more plugin information and zip file that contains default values for inputs. ValD information: The Vienna Atomic Line Database (VALD) is a collection of atomic line parameters of astronomical interest and provides tools for selecting subsets of lines for typical astrophysical applications: line identification, chemical composition and radial velocity measurements, model atmosphere calculations etc. The VALD database is maintained at three sites: Uppsala Universitet; Universitaet Wien; Institute for Astronomy RAS, Moscow. SME: Spectroscopy Made Easy (SME) is a software package that calculates syn- thetic spectra of stars and fits observed spectra.",-1, 0, ,
"http://www.myexperiment.org/workflows/2798/versions/2.html","VAMDC VALD query with SME processing","2012-03-0718:03:01","2012-11-2911:56:21","http://www.myexperiment.org/workflows/2798/download/VAMDC_VALD_query_with_SME_processing-v2.t2flow?version=2","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","VAMDC workflow that queries the VALD Atomic database in Moscow and runs SME (Spectroscopy Made Easy) VAMDC Taverna Plugin:  <a href=http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide rel=nofollow>http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2798/versions/3.html","VAMDC VALD query with SME processing","2012-03-0718:03:01","2012-11-2911:56:21","http://www.myexperiment.org/workflows/2798/download/VAMDC_VALD_query_with_SME_processing-v3.t2flow?version=3","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","VAMDC workflow that queries the VALD Atomic database in Moscow and runs SME (Spectroscopy Made Easy)VAMDC Taverna Plugin:  <a href=http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide rel=nofollow>http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2798/versions/4.html","VAMDC VALD query with SME processing","2012-03-0718:03:01","2012-11-2911:56:21","http://www.myexperiment.org/workflows/2798/download/VAMDC_VALD_query_with_SME_processing-v4.t2flow?version=4","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","VAMDC workflow that queries the VALD Atomic database in Moscow and runs SME (Spectroscopy Made Easy)VAMDC Taverna Plugin:  <a href=http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide rel=nofollow>http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2800/versions/1.html","Workflow to Query TAP-XSAMS node.","2012-03-0718:17:22","2012-09-1213:02:04","http://www.myexperiment.org/workflows/2800/download/Workflow_to_Query_TAP-XSAMS_node.-v1.t2flow?version=1","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","Most Basic Node Query(Hitran). &nbsp;Which will ask for the full TAP/SQL. i.e.&nbsp;SELECT * WHERE MoleculeStoichiometricFormula='CO' More plugin information can be found here:&nbsp;&nbsp; <a href=http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/ rel=nofollow>http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/2800/versions/2.html","Workflow to Query TAP-XSAMS node.","2012-03-0718:17:22","2012-09-1213:02:04","http://www.myexperiment.org/workflows/2800/download/Workflow_to_Query_TAP-XSAMS_node.-v2.t2flow?version=2","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","Basic Node Query to Hitran which will ask for the full 'Select....' query.     Hitran: HITRAN is an acronym for high-resolution transmission molecular absorption database. HITRAN is a compilation of spectroscopic parameters that a variety of computer codes use to predict and simulate the transmission and emission of light in the atmosphere. Keywords: Spectroscopy Linelists Atmospheric Radiative Transfer   More plugin information at:   <a href=http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/ rel=nofollow>http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/2800/versions/3.html","Workflow to Query TAP-XSAMS node.","2012-03-0718:17:22","2012-09-1213:02:04","http://www.myexperiment.org/workflows/2800/download/Workflow_to_Query_TAP-XSAMS_node.-v3.t2flow?version=3","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","Workflow to just one TAP-XSAMS Node.  This workflow queries the Hitran Node for MoleculeChemicalName of 'HF' VAMDC Taverna Plugin:  <a href=http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide rel=nofollow>http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2801/versions/1.html","VAMDC to query on ChemicalName &#39;OR&#39; StoichiometricFormula","2012-03-0718:21:33","2012-09-1213:09:20","http://www.myexperiment.org/workflows/2801/download/VAMDC_to_query_on_ChemicalName__OR__StoichiometricFormula-v1.t2flow?version=1","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","&nbsp;Basic Hitran Node query using the Restrictables as helper processes using an 'OR' statement. More plugin information at: <a href=http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/ rel=nofollow>http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/2801/versions/2.html","VAMDC to query on ChemicalName &#39;OR&#39; StoichiometricFormula","2012-03-0718:21:33","2012-09-1213:09:20","http://www.myexperiment.org/workflows/2801/download/VAMDC_to_query_on_ChemicalName__OR__StoichiometricFormula-v2.t2flow?version=2","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","&nbsp;Basic Query of a Node - Hitran using the Restrictable processors as helpers on constructing the query and does an 'OR' statement. More plugin information at: <a href=http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/ rel=nofollow>http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/2801/versions/3.html","VAMDC to query on ChemicalName &#39;OR&#39; StoichiometricFormula","2012-03-0718:21:33","2012-09-1213:09:20","http://www.myexperiment.org/workflows/2801/download/VAMDC_to_query_on_ChemicalName__OR__StoichiometricFormula-v3.t2flow?version=3","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","Basic Node Query using the Restrictables with the 'OR' constraint. Hitran: HITRAN is an acronym for high-resolution transmission molecular absorption database. HITRAN is a compilation of spectroscopic parameters that a variety of computer codes use to predict and simulate the transmission and emission of light in the atmosphere. Keywords: Spectroscopy Linelists Atmospheric Radiative Transfer",-1, 0, ,
"http://www.myexperiment.org/workflows/2801/versions/4.html","VAMDC to query on ChemicalName &#39;OR&#39; StoichiometricFormula","2012-03-0718:21:33","2012-09-1213:09:20","http://www.myexperiment.org/workflows/2801/download/VAMDC_to_query_on_ChemicalName__OR__StoichiometricFormula-v4.t2flow?version=4","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","Workflow to query just one TAP-XSAMS Node.  This workflow queries the Hitran Node for MoleculeChemicalName of 'HF' and StoichimetricFormula of 'HV'Demonstrates building a query for two Restrictables. VAMDC Taverna Plugin:  <a href=http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide rel=nofollow>http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2802/versions/1.html","VAMDC Query to Two Nodes using HTML Consumer Service","2012-03-0718:30:34","2012-09-1213:07:17","http://www.myexperiment.org/workflows/2802/download/VAMDC_Query_to_Two_Nodes_using_HTML_Consumer_Service-v1.t2flow?version=1","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","Shows a VAMDC Tap query to two Nodes Hitran and CDMS and placing the output to a Consumer Service and finally calling a small Beanshell scrip to call up the default browser to show results. CDMS - The Cologne Database for Molecular Spectroscopy (CDMS) contains a catalog of radio frequency and microwave to far-infrared spectral lines of atomic and molecular species that (may) occur in the interstellar or circumstellar medium or in planetary atmospheres. The catalog is continuously updated. Hitran - HITRAN is an acronym for high-resolution transmission molecular absorption database. HITRAN is a compilation of spectroscopic parameters that a variety of computer codes use to predict and simulate the transmission and emission of light in the atmosphere. Keywords: Spectroscopy Linelists Atmospheric Radiative Transfer More plugin information at: <a href=http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/ rel=nofollow>http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/2802/versions/2.html","VAMDC Query to Two Nodes using HTML Consumer Service","2012-03-0718:30:34","2012-09-1213:07:17","http://www.myexperiment.org/workflows/2802/download/VAMDC_Query_to_Two_Nodes_using_HTML_Consumer_Service-v2.t2flow?version=2","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","Workflow to two TAP-XSAMS Node and see results in a HTML view using a Consumer Service.  This workflow queries the Hitran and CDMS Node for MoleculeStoichiometricForumua of 'CO' VAMDC Taverna Plugin:  <a href=http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide rel=nofollow>http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2803/versions/1.html","VAMDC SpectCol tool using Full VAMDC-Tap Queries","2012-03-0718:34:54","2012-09-1213:58:05","http://www.myexperiment.org/workflows/2803/download/VAMDC_SpectCol_tool_using_Full_VAMDC-Tap_Queries-v1.t2flow?version=1","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","Runs the SpectCol tool bundled with the plugin and can handle a list of URLS. This version asks for the full vamdc URL. SpectCol information: SPECTCOL is a tool that implements VAMDC standards, retrieve relevant information from different databases such as CDMS, HITRAN, BASECOL, and can upload local files. All transfer of data between the client and the databases use the VAMDC-XSAMS schema. The spectroscopic and collisional information is combined and useful outputs (ascii or xsams) are provided for the study of the interstellar medium. This sample uses CDMS and BaseCol as two sample urls. CDMS - The Cologne Database for Molecular Spectroscopy (CDMS) contains a catalog of radio frequency and microwave to far-infrared spectral lines of atomic and molecular species that (may) occur in the interstellar or circumstellar medium or in planetary atmospheres. The catalog is continuously updated.BaseCol - This database, called BASECOL is devoted to collisional ro-vibrational excitation of molecules by colliders such as atom, ion, molecule or electron. It is supervised by an international working group of molecular physicists and astrophysicits involved in the calculations and use of ro-vibrational cross-sections, in order to ensure the continuity and the quality of the database. Two sample urls: <a href=http://cdms.ph1.uni-koeln.de/DjCDMSdev/tap/sync?LANG=VSS2REQUEST=doQueryFORMAT=XSAMSQUERY=select+*+where+%28%28MoleculeStoichiometricFormula+%3D+%27CO%27%29%29 rel=nofollow>http://cdms.ph1.uni-koeln.de/DjCDMSdev/tap/sync?LANG=VSS2REQUEST=doQueryFORMAT=XSAMSQUERY=select+*+where+%28%28MoleculeStoichiometricFormula+%3D+%27CO%27%29%29</a> <a href=http://batz.lpma.jussieu.fr:8080/tapservice_11_12/TAP/sync?LANG=VSS2REQUEST=doQueryFORMAT=XSAMSQUERY=select+*+where+%28%28MoleculeStoichiometricFormula+%3D+%27CO%27%29%29 rel=nofollow>http://batz.lpma.jussieu.fr:8080/tapservice_11_12/TAP/sync?LANG=VSS2REQUEST=doQueryFORMAT=XSAMSQUERY=select+*+where+%28%28MoleculeStoichiometricFormula+%3D+%27CO%27%29%29</a> More plugin Information at: <a href=http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/ rel=nofollow>http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/2803/versions/2.html","VAMDC SpectCol tool using Full VAMDC-Tap Queries","2012-03-0718:34:54","2012-09-1213:58:05","http://www.myexperiment.org/workflows/2803/download/VAMDC_SpectCol_tool_using_Full_VAMDC-Tap_Queries-v2.t2flow?version=2","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","Runs the SpectCol tool bundled with the plugin and can handle a list of URLS. This version asks for the full vamdc URL.SpectCol information: SPECTCOL is a tool that implements VAMDC standards, retrieve relevant information from different databases such as CDMS, HITRAN, BASECOL,and can upload local files.All transfer of data between the client and the databases use the VAMDC-XSAMS schema.The spectroscopic and collisional information is combined and useful outputs (ascii or xsams)are provided for the study of the interstellar medium.This sample uses CDMS and BaseCol as two sample urls.CDMS - The Cologne Database for Molecular Spectroscopy (CDMS) contains acatalog of radio frequency and microwave to far-infrared spectral lines of atomic and molecular species that (may) occur in the interstellar or circumstellar medium or in planetary atmospheres.The catalog is continuously updated.BaseCol - This database, called BASECOL is devoted to collisional ro-vibrational excitation of molecules bycolliders such as atom, ion, molecule or electron.  It is supervised by an international working group of molecular physicists and astrophysicits involved in the calculations and use of ro-vibrational cross-sections,in order to ensure the continuity and the quality of the database. More plugin Information at:  <a href=http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/ rel=nofollow>http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2804/versions/1.html","VAMDC Query to Two Nodes using HTML Consumer Service and SpectCol","2012-03-0718:48:58","2012-09-1215:07:33","http://www.myexperiment.org/workflows/2804/download/VAMDC_Query_to_Two_Nodes_using_HTML_Consumer_Service_and_SpectCol-v1.t2flow?version=1","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","This Queries two VAMDC nodes and having the url references go to a SpectCol tool that is bundled with the plugin. SpectCol Information: SPECTCOL is a tool that implements VAMDC standards, retrieve relevant information from different databases such as CDMS, HITRAN, BASECOL, and can upload local files. All transfer of data between the client and the databases use the VAMDC-XSAMS schema. The spectroscopic and collisional information is combined and useful outputs (ascii or xsams) are provided for the study of the interstellar medium. This example uses CDMS and BaseCol.BaseCol - This database, called BASECOL is devoted to collisional ro-vibrational excitation of molecules by colliders such as atom, ion, molecule or electron. It is supervised by an international working group of molecular physicists and astrophysicits involved in the calculations and use of ro-vibrational cross-sections, in order to ensure the continuity and the quality of the database.CDMS - The Cologne Database for Molecular Spectroscopy (CDMS) contains a catalog of radio frequency and microwave to far-infrared spectral lines of atomic and molecular species that (may) occur in the interstellar or circumstellar medium or in planetary atmospheres. The catalog is continuously updated. More plugin information at: <a href=http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/ rel=nofollow>http://vamdc.mssl.ucl.ac.uk/taverna/vamdc/</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/2804/versions/2.html","VAMDC Query to Two Nodes using HTML Consumer Service and SpectCol","2012-03-0718:48:58","2012-09-1215:07:33","http://www.myexperiment.org/workflows/2804/download/VAMDC_Query_to_Two_Nodes_using_HTML_Consumer_Service_and_SpectCol-v2.t2flow?version=2","/users/19019","Stormsh...","taverna 2","/users/19019,","Stormshadow,","Workflow to two TAP-XSAMS Node and see results in a HTML view using a Consumer Service.  This workflow queries the BaseCol and CDMS Node for MoleculeStoichiometricForumua of 'CO' VAMDC Taverna Plugin:  <a href=http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide rel=nofollow>http://voparis-twiki.obspm.fr/twiki/bin/view/VAMDC/TavernaUserGuide</a> **NOTE an update to the plugin will need to be released later to handle prefixes on certain query nodes and their restrictables.  For instance BaseCol expects 'Target.MoleculeStoichiometricFormula' instead of just 'MoleculeStoichiometricFormula'.  This is only possible by building the filling out the Query parameter instead of using the helper ports provided by the plugin.  This workflow does exactly that for BaseCol.",0, 0, ,
"http://www.myexperiment.org/workflows/2805/versions/1.html","Get Pathway-Genes by Entrez gene id","2012-03-0811:47:39","2012-04-1415:14:49","http://www.myexperiment.org/workflows/2805/download/Get_Pathway-Genes_by_Entrez_gene_id-v1.t2flow?version=1","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","Given a specific entrez gene id, returns the pathways that this gene participates in and for each of those pathways which genes are associated with.",0, 0, ,
"http://www.myexperiment.org/workflows/2805/versions/2.html","Get Pathway-Genes by Entrez gene id","2012-03-0811:47:39","2012-04-1415:14:49","http://www.myexperiment.org/workflows/2805/download/Get_Pathway-Genes_by_Entrez_gene_id-v2.t2flow?version=2","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","Given a specific entrez gene id, returns the pathways that this gene participates in and for each of those pathways which genes are associated with.",0, 0, ,
"http://www.myexperiment.org/workflows/2805/versions/3.html","Get Pathway-Genes by Entrez gene id","2012-03-0811:47:39","2012-04-1415:14:49","http://www.myexperiment.org/workflows/2805/download/Get_Pathway-Genes_by_Entrez_gene_id-v3.t2flow?version=3","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","Given a specific entrez gene id, returns the pathways that this gene participates in and for each of those pathways which genes are associated with. The workflow outputs also a KEGG pathway map andthe objects are colored according to the input color values.",0, 0, ,
"http://www.myexperiment.org/workflows/2805/versions/4.html","Get Pathway-Genes by Entrez gene id","2012-03-0811:47:39","2012-04-1415:14:49","http://www.myexperiment.org/workflows/2805/download/Get_Pathway-Genes_by_Entrez_gene_id-v4.t2flow?version=4","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","Given a specific entrez gene id, returns the pathways that this gene participates in and for each of those pathways which genes are associated with. The workflow outputs also a KEGG pathway map andthe objects are colored according to the input color values.",0, 0, ,
"http://www.myexperiment.org/workflows/2815/versions/1.html","Associate SEP events at Earth with flare, cme and radio events on the Sun","2012-03-1314:38:31","2012-03-1314:53:22","http://www.myexperiment.org/workflows/2815/download/Associate_SEP_events_at_Earth_with_flare__cme_and_radio_events_on_the_Sun-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706, /users/21522,","Anja Le Blanc, Rositsa,","This is the implementation of a use case worked on during CDAW3 of the HELIO project. SEP events propagated backward from Earth to the Sun. We allow for +- 30 min around the predicted time to search for flare events. The timing of the flare event informs the search time for Type III radio event (time_start to time_peak) and for the CME event (time_start to time_start+1h). Results are presented in a mulitlayered VOTable.",0, 0, ,
"http://www.myexperiment.org/workflows/2816/versions/1.html","Propagation of the Solar Energetic Particles to the Sun","2012-03-1315:19:39","2012-03-1315:19:41","http://www.myexperiment.org/workflows/2816/download/Propagation_of_the_Solar_Energetic_Particles_to_the_Sun-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","use of the processing service to calculate time delays to the planetsInputs:time when propagation should start from the hit objecthit_object where was the SEP event observedspeed of the solar winderror value of solar wind speedbeta traveling speed of energetic particals as percentage of the speed of light",0, 0, ,
"http://www.myexperiment.org/workflows/2817/versions/1.html","Co-rotating Interaction Regions backwards propagation","2012-03-1411:56:05","2012-03-1411:56:06","http://www.myexperiment.org/workflows/2817/download/Co-rotating_Interaction_Regions_backwards_propagation-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Run the cir backwards propagation code on the HELIO processing service.Required inputs: time start of backwards propagation, the object (planet/spacecraft) from where the propagation should start, assumed solar wind speed at the time, assumed error of solar wind speedOutput: VOTable with times at different points in solar system",0, 0, ,
"http://www.myexperiment.org/workflows/2819/versions/1.html","Split VOTable into its values","2012-03-1415:17:34","2012-03-1415:17:35","http://www.myexperiment.org/workflows/2819/download/Split_VOTable_into_its_values-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow takes a single VOTable and splits it up in a vector for the names of fields, a vector for the UCDs of the fields, a vector for the UTypes of the fields, and a two dimensional vector for the values.",0, 0, ,
"http://www.myexperiment.org/workflows/2820/versions/1.html","Jane&#39;s Final Workflow","2012-03-1416:31:34","2012-03-1416:35:55","http://www.myexperiment.org/workflows/2820/download/Jane_s_Final_Workflow-v1.t2flow?version=1","/users/22254","Bart Lamiroy","taverna 2","/users/22254,","Bart Lamiroy,","Example workflow demonstrating the use of the  <a href=http://dae.cse.lehigh.edu rel=nofollow>DAE platform</a> 's web service capabilities, as published &quot; <a href=http://hal.inria.fr/hal-00658281/en rel=nofollow>The Non-Geek's Guide to the DAE Platform</a> &quot;,&nbsp;Bart Lamiroy &amp; Daniel Lopresti,&nbsp;DAS - 10th IAPR International Workshop on Document Analysis Systems (2012).",-1, 0, ,
"http://www.myexperiment.org/workflows/2821/versions/1.html","Jpylyzer Review Demonstration","2012-03-1500:20:38","2012-03-1500:22:37","http://www.myexperiment.org/workflows/2821/download/Jpylyzer_Review_Demonstration-v1.t2flow?version=1","/users/16585","Carl","taverna 2","/users/16585,","Carl,","&nbsp;Review demonstration workflow that compares the jpylyzer tool with the struct checker and jhove. &nbsp;Runs on British Library JISC 1 content, looking for invalid images.",-1, 0, ,
"http://www.myexperiment.org/workflows/2822/versions/1.html","Check in UOC which instruments were observing at a given time period and place","2012-03-1514:25:44","2012-03-1516:07:40","http://www.myexperiment.org/workflows/2822/download/Check_in_UOC_which_instruments_were_observing_at_a_given_time_period_and_place-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Query of the UOC to find the instrument_observatory keys for instruments which were observing at a given time period and a given location.",0, 0, ,
"http://www.myexperiment.org/workflows/2822/versions/2.html","Check in UOC which instruments were observing at a given time period and place","2012-03-1514:25:44","2012-03-1516:07:40","http://www.myexperiment.org/workflows/2822/download/Check_in_UOC_which_instruments_were_observing_at_a_given_time_period_and_place-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Query of the UOC to find the instrument_observatory keys for instruments which were observing at a given time period and a given location.",0, 0, ,
"http://www.myexperiment.org/workflows/2824/versions/1.html","Simple Tesseract-Ocrad comparison","2012-03-1610:41:15","2012-03-1610:43:04","http://www.myexperiment.org/workflows/2824/download/Simple_Tesseract-Ocrad_comparison-v1.t2flow?version=1","/users/22254","Bart Lamiroy","taverna 2","/users/22254,","Bart Lamiroy,","Simple demonstration workflow for use with the on-line Lehigh-based DAE server, comparing the results of Tesseract and Ocrad OCR engines on a specific document image.",-1, 0, ,
"http://www.myexperiment.org/workflows/2825/versions/1.html","localhost Tesseract-Ocrad comparison","2012-03-1610:44:02","2012-05-1608:44:46","http://www.myexperiment.org/workflows/2825/download/localhost_Tesseract-Ocrad_comparison-v1.t2flow?version=1","/users/22254","Bart Lamiroy","taverna 2","/users/22254,","Bart Lamiroy,","&nbsp; <span>Simple demo workflow, for use with a standalone (localhost) version of the DAE platform. Compares Tesseract and Ocrad OCR results.</span>",-1, 0, ,
"http://www.myexperiment.org/workflows/2825/versions/2.html","localhost Tesseract-Ocrad comparison","2012-03-1610:44:02","2012-05-1608:44:46","http://www.myexperiment.org/workflows/2825/download/localhost_Tesseract-Ocrad_comparison-v2.t2flow?version=2","/users/22254","Bart Lamiroy","taverna 2","/users/22254,","Bart Lamiroy,","&nbsp; <span>Simple demo workflow, for use with a standalone (localhost) version of the DAE platform. Compares Tesseract and Ocrad OCR results.</span> For demonstration reasons and ease of use, this workflow has hardcoded username/password values. This is, obviously, very bad.",-1, 0, ,
"http://www.myexperiment.org/workflows/2825/versions/3.html","localhost Tesseract-Ocrad comparison","2012-03-1610:44:02","2012-05-1608:44:46","http://www.myexperiment.org/workflows/2825/download/localhost_Tesseract-Ocrad_comparison-v3.t2flow?version=3","/users/22254","Bart Lamiroy","taverna 2","/users/22254,","Bart Lamiroy,","<span>Simple demo workflow, for  use with a <a href=http://dae.cse.lehigh.edu/DAE/VirtualBox rel=nofollow>standalone (localhost) version</a> of the DAE platform. Compares  Tesseract and Ocrad OCR results.</span> For demonstration reasons and ease of use, this workflow has hardcoded username/password values. This is, obviously, very bad, but since it relates only to a sandboxed virtual server, potential damage is null.",-1, 0, ,
"http://www.myexperiment.org/workflows/2828/versions/1.html","Example of Execute_SQL_Query with parameters","2012-03-1614:12:35","2012-03-1614:16:18","http://www.myexperiment.org/workflows/2828/download/Example_of_Execute_SQL_Query_with_parameters-v1.t2flow?version=1","/users/20993","Helen Hulme","taverna 2","/users/20993,","Helen Hulme,","This workflow connects to a mysql on localhost, queries the &quot;world&quot; database which is one of the test databases on MySQL 5.5, queries it about which countries have Dutch as a language, and emits answers in both Lists and in xml.  This workflow is intended as an example to help you see the syntax for the various inputs to this local service beanshell.  see:  <a href=http://www.mygrid.org.uk/dev/wiki/display/taverna/Execute+SQL+Query rel=nofollow>http://www.mygrid.org.uk/dev/wiki/display/taverna/Execute+SQL+Query</a>  for instructions on jars, dependencies etc.  The jar used here is: mysql-connector-java-5.1.18-bin.jar  To run this workflow example, you'll also need    * to have root access to a mysql database server on your machine on the default port. If your database is elsewhere or on another port, edit the url_value accordingly.    * Have a database on there called &quot;world&quot; - this is one of the test databases which comes bundled with MySQL 5.5.        By default, it has access by root user.   Note that the beanshell PutEachElementInAList is not necessary for the workflow to run with a single input value (say &quot;Dutch&quot;. But if you want to add more languages to the list of queries (Say, &quot;Dutch&quot;, &quot;Japanese&quot;, then it is necessary, because each set of parameters needs to be in its own list.",0, 0, ,
"http://www.myexperiment.org/workflows/2829/versions/1.html","Available instruments through DPAS which are not part of ICS instruments table","2012-03-1615:45:57","2012-03-1615:55:59","http://www.myexperiment.org/workflows/2829/download/Available_instruments_through_DPAS_which_are_not_part_of_ICS_instruments_table-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow uses a DPAS servlet to obtain all available intrument keys in the DPAS (Data Provider Access Service) and formats the return as VOTable.",0, 0, ,
"http://www.myexperiment.org/workflows/2834/versions/1.html","(Updated)Retrieve sequence in EMBL format.","2012-03-1911:59:57","2012-04-0222:51:40","http://www.myexperiment.org/workflows/2834/download/_Updated_Retrieve_sequence_in_EMBL_format.-v1.t2flow?version=1","/users/19710","Ankit upadhyay","taverna 2","/users/19710,","Ankit upadhyay,","This workflow retrieves a sequence associated with its features in embl format.",0, 0, ,
"http://www.myexperiment.org/workflows/2837/versions/1.html","DemoWorkflow","2012-03-2222:37:05","2012-03-2222:37:45","http://www.myexperiment.org/workflows/2837/download/DemoWorkflow-v1.t2flow?version=1","/users/19224","Jribault","taverna 2","/users/19224,","Jribault,","&nbsp;Demo Workflow",-1, 0, ,
"http://www.myexperiment.org/workflows/2843/versions/1.html","Get Pathway-Genes and gene description by Entrez gene id","2012-03-2710:52:31","2012-04-0309:20:02","http://www.myexperiment.org/workflows/2843/download/Get_Pathway-Genes_and_gene_description_by_Entrez_gene_id_-v1.t2flow?version=1","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","Given a specific entrez gene id, returns the pathways that this gene participates in and for each of those pathways which genes are associated with.",0, 0, ,
"http://www.myexperiment.org/workflows/2843/versions/2.html","Get Pathway-Genes and gene description by Entrez gene id","2012-03-2710:52:31","2012-04-0309:20:02","http://www.myexperiment.org/workflows/2843/download/Get_Pathway-Genes_and_gene_description_by_Entrez_gene_id_-v2.t2flow?version=2","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","Given a specific entrez gene id, returns the pathways that this gene participates in and for each of those pathways which genes (including their description) are associated with.",0, 0, ,
"http://www.myexperiment.org/workflows/2846/versions/1.html","BiomartAndEMBOSSMouseRat","2012-04-0513:55:03","","http://www.myexperiment.org/workflows/2846/download/BiomartAndEMBOSSMouseRat-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/13,","Katy Wolstencroft,","This workflow retrieves all genes on human chromosome 22 that are associated with a disease and aligns the upstream regions of the mouse and rat homologues. The alignments are plotted and corresponding sequence ids are also returned.",0, 0, ,
"http://www.myexperiment.org/workflows/2847/versions/1.html","BiomartAndEMBOSSMouseRat","2012-04-0516:38:25","","http://www.myexperiment.org/workflows/2847/download/BiomartAndEMBOSSMouseRat-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow retrieves all genes on human chromosome 22 that are associated with a disease and aligns the upstream regions of the mouse and rat homologues. The alignments are plotted and corresponding sequence ids are also returned.",0, 0, ,
"http://www.myexperiment.org/workflows/2848/versions/1.html","BioMoby tutorial workflow","2012-04-0516:39:26","2012-04-0516:39:27","http://www.myexperiment.org/workflows/2848/download/BioMoby_tutorial_workflow-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","A workflow from part of the BioMoby tutorial",0, 0, ,
"http://www.myexperiment.org/workflows/2849/versions/1.html","Demonstration of configurable iteration","2012-04-0516:40:09","2012-04-0516:40:10","http://www.myexperiment.org/workflows/2849/download/Demonstration_of_configurable_iteration-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow shows the use of the iteration strategy editor to ensure that only relevant combinations of inputs are used during an implicit iteration.",0, 0, ,
"http://www.myexperiment.org/workflows/2850/versions/1.html","EBI_InterproScan_NewServices","2012-04-0516:41:00","2014-04-0913:29:33","http://www.myexperiment.org/workflows/2850/download/EBI_InterproScan_NewServices-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow performs an interproscan at the EBI on sequences provided as input. The output is provided as text, xml or png.This workflow uses the new EBI services, which are asynchronous and require looping over the nested workflow (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration.",0, 0, ,
"http://www.myexperiment.org/workflows/2850/versions/2.html","EBI_InterproScan_NewServices","2012-04-0516:41:00","2014-04-0913:29:33","http://www.myexperiment.org/workflows/2850/download/EBI_InterproScan_NewServices-v2.t2flow?version=2","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow performs an interproscan at the EBI on sequences provided as input. The output is provided as text and xml.This workflow uses the new EBI services, which are asynchronous and require looping over the nested workflow (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration.",0, 0, ,
"http://www.myexperiment.org/workflows/2851/versions/1.html","Example for external tools with zip and unzip","2012-04-0516:42:09","2012-04-0516:42:10","http://www.myexperiment.org/workflows/2851/download/Example_for_external_tools_with_zip_and_unzip-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow only works on a Unix machine. This workflow takes a fixed URL from which a text file is downloaded (output as Original_file). That file is zipped (output as Zipped_File) and then unzipped again (output as Unzipped_File). The orginal file and the unzipped version are then diff'd/",0, 0, ,
"http://www.myexperiment.org/workflows/2852/versions/1.html","Example of conditional invocation","2012-04-0516:42:56","2012-04-0516:42:57","http://www.myexperiment.org/workflows/2852/download/Example_of_conditional_invocation-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow demonstrates how nested workflows can be conditionally invoked",0, 0, ,
"http://www.myexperiment.org/workflows/2853/versions/1.html","Example of explicit looping","2012-04-0516:43:52","","http://www.myexperiment.org/workflows/2853/download/Example_of_explicit_looping-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow demonstrates how a nested workflow can be called an explicit number of times.Note that the loop iterator does not need to be used in the logic of the loop contents. It canbe used as a sentinel (see the conditional workflow)",0, 0, ,
"http://www.myexperiment.org/workflows/2854/versions/1.html","Example workflow for REST and XPath activities","2012-04-0516:44:54","2012-04-0516:44:55","http://www.myexperiment.org/workflows/2854/download/Example_workflow_for_REST_and_XPath_activities-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow fetches weather forecast for the user-specified location. First of all it uses the provided location name to obtain a WOEID (Where On Earth ID) of that location, then uses that unique identifier to fetch the weather forecast from Yahoo server. Multiple results may be obtained in case there is no unique translation of the location to a WOEID. REST activity is used to perform HTTP requests and fetch data from remote servers; XPath activity is then used to parse the XML data and extract only selected elements.",0, 0, ,
"http://www.myexperiment.org/workflows/2855/versions/1.html","Fetch PDB flatfile from RCSB server","2012-04-0516:45:56","","http://www.myexperiment.org/workflows/2855/download/Fetch_PDB_flatfile_from_RCSB_server-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","Given an identifier such as '1crn' fetches the PDB format flatfile from the RCSB",0, 0, ,
"http://www.myexperiment.org/workflows/2856/versions/1.html","Fetch today&#39;s xkcd comic","2012-04-0516:46:52","","http://www.myexperiment.org/workflows/2856/download/Fetch_today_s_xkcd_comic-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","Use the local services and some filtering operations to fetch the comic strip image from  <a href=http://xkcd.com/ rel=nofollow>http://xkcd.com/</a> Based on the FetchDailyDilbert workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/2857/versions/1.html","Fetch Dragon images from BioMoby","2012-04-0516:47:46","2012-04-0516:47:47","http://www.myexperiment.org/workflows/2857/download/Fetch_Dragon_images_from_BioMoby-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","Fetch images and annotations of snapdragons",0, 0, ,
"http://www.myexperiment.org/workflows/2858/versions/1.html","GBSeq test","2012-04-0516:48:49","2012-04-0516:48:50","http://www.myexperiment.org/workflows/2858/download/GBSeq_test-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow retrieves nucleotide and protein sequences with the literature and references associatedto them given a protein and a nucleotide id.",0, 0, ,
"http://www.myexperiment.org/workflows/2859/versions/1.html","Hello Anyone","2012-04-0516:49:31","2014-03-0308:15:06","http://www.myexperiment.org/workflows/2859/download/Hello_Anyone-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","An extension to helloworld.t2flow - this workflow takes a workflow input name which is combined with the string constant Hello,  using the local worker Concatenate two strings, and outputs the produced string to the workflow output greeting.",0, 0, ,
"http://www.myexperiment.org/workflows/2860/versions/1.html","Hello World","2012-04-0516:50:09","2014-03-0308:15:37","http://www.myexperiment.org/workflows/2860/download/Hello_World-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","One of the simplest workflows possible. No workflow input ports, a single workflow output port greeting,  outputting Hello, world! as produced by the String Constant hello.",0, 0, ,
"http://www.myexperiment.org/workflows/2861/versions/1.html","Multiple choice quiz","2012-04-0516:50:57","2012-04-0516:50:58","http://www.myexperiment.org/workflows/2861/download/Multiple_choice_quiz-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","A fun example workflow showing user-interaction and service looping",0, 0, ,
"http://www.myexperiment.org/workflows/2862/versions/1.html","Numerically adding two values.","2012-04-0516:51:49","","http://www.myexperiment.org/workflows/2862/download/Numerically_adding_two_values.-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow relies on a Unix system. It wraps the bc command line calculator. It downloads the calculation script from a URL.",0, 0, ,
"http://www.myexperiment.org/workflows/2863/versions/1.html","Pipelined list iteration","2012-04-0516:52:35","","http://www.myexperiment.org/workflows/2863/download/Pipelined_list_iteration-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","Perform multiple iterations of services in order to show pipelining",0, 0, ,
"http://www.myexperiment.org/workflows/2864/versions/1.html","Render gene via BioGPS","2012-04-0516:53:22","2012-05-2311:34:35","http://www.myexperiment.org/workflows/2864/download/Render_gene_via_BioGPS-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow uses the REST API of BioGPS tolist the plugins and then allow the user to select whichplugin to use to display the input gene id",0, 0, ,
"http://www.myexperiment.org/workflows/2864/versions/2.html","Render gene via BioGPS","2012-04-0516:53:22","2012-05-2311:34:35","http://www.myexperiment.org/workflows/2864/download/Render_gene_via_BioGPS-v2.t2flow?version=2","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow uses the REST API of BioGPS tolist the plugins and then allow the user to select whichplugin to use to display the input gene id",0, 0, ,
"http://www.myexperiment.org/workflows/2864/versions/3.html","Render gene via BioGPS","2012-04-0516:53:22","2012-05-2311:34:35","http://www.myexperiment.org/workflows/2864/download/Render_gene_via_BioGPS-v3.t2flow?version=3","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow uses the REST API of BioGPS tolist the plugins and then allow the user to select whichplugin to use to display the input gene id",0, 0, ,
"http://www.myexperiment.org/workflows/2865/versions/1.html","Retrieve sequence in EMBL format","2012-04-0516:54:02","2012-04-0516:54:03","http://www.myexperiment.org/workflows/2865/download/Retrieve_sequence_in_EMBL_format-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow retrieves a sequence associated with its features in embl format",0, 0, ,
"http://www.myexperiment.org/workflows/2866/versions/1.html","Secure REST service call example","2012-04-0516:54:44","2014-01-1610:56:59","http://www.myexperiment.org/workflows/2866/download/Secure_REST_service_call_example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This is an example of a workflow that contains a call to a secure REST service that requires user to authenticate with HTTP Basic Authentication. You can use testuser/testpasswd as username and password for authentication when running the workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/2866/versions/2.html","Secure REST service call example","2012-04-0516:54:44","2014-01-1610:56:59","http://www.myexperiment.org/workflows/2866/download/Secure_REST_service_call_example-v2.t2flow?version=2","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This is an example of a workflow that contains a call to a secure REST service that requires user to authenticate with HTTP Basic Authentication. You can use testuser/testpasswd as username and password for authentication when running the workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/2867/versions/1.html","Secure Web service call example","2012-04-0516:55:34","2013-06-1113:10:10","http://www.myexperiment.org/workflows/2867/download/Secure_Web_service_call_example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This is an example of a workflow that contains a call to a secure Web service that runs behind HTTPS and requires user to authenticate. The first thing you can expect to see is a pop up dialog asking if you trust the Web service to be invoked over HTTPS. You can use testuser/testpasswd as username and password for authentication when running the workflow. To see where the security is being configured, right-click the service in the diagram and select Configure security from the menu.",0, 0, ,
"http://www.myexperiment.org/workflows/2867/versions/2.html","Secure Web service call example","2012-04-0516:55:34","2013-06-1113:10:10","http://www.myexperiment.org/workflows/2867/download/Secure_Web_service_call_example-v2.t2flow?version=2","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This is an example of a workflow that contains a call to a secure Web service that runs behind HTTPS and requires user to authenticate. The first thing you can expect to see is a pop up dialog asking if you trust the Web service to be invoked over HTTPS. You can use testuser/testpasswd as username and password for authentication when running the workflow. To see where the security is being configured, right-click the service in the diagram and select Configure security from the menu. You may experience problems running this workflow under versions of Java greater than 1.6. This is due to a change in security handling.",0, 0, ,
"http://www.myexperiment.org/workflows/2868/versions/1.html","Simple Python example","2012-04-0516:56:16","","http://www.myexperiment.org/workflows/2868/download/Simple_Python_example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow generates a random number within the range 0 to 100. The generation is done by a python script. The workflow assumes that python is in the path.",0, 0, ,
"http://www.myexperiment.org/workflows/2869/versions/1.html","Spreadsheet Import Example","2012-04-0516:56:53","","http://www.myexperiment.org/workflows/2869/download/Spreadsheet_Import_Example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","Example using the SpreadsheetImport service to import data from an Excel spreadsheet.The workflow imports the file spreadsheet file WaterUse.xlsx and generates a graph from the date.The source data is from  <a href=http://data.gov.uk/ rel=nofollow>http://data.gov.uk/</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2870/versions/1.html","Unix tool service using string replacement","2012-04-0516:57:40","","http://www.myexperiment.org/workflows/2870/download/Unix_tool_service_using_string_replacement-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","The tool service outputs a message that greets using the names specified on Greet's input ports.",0, 0, ,
"http://www.myexperiment.org/workflows/2873/versions/1.html","Create and execute a simulation on the RISE server.","2012-04-0917:48:11","","http://www.myexperiment.org/workflows/2873/download/Create_and_execute_a_simulation_on_the_RISE_server.-v1.t2flow?version=1","/users/19224","Jribault","taverna 2","","","Create and execute a simulation on the RISE server. This workflow take 3 inputs: the XML to configure the RISE framework, the URL of the ZIP file model (a zipped directory containing the model files), and the new framework name.This workflow produce on the output the simulation LOG file.",0, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/1.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v1.t2flow?version=1","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,","&nbsp;&nbsp;This workflow brings together various sub-workflows in one integrated workflow. This includes, - Synonym Expansion / Occurrence Retrieval&nbsp; - BioSTIFF Data Selection Tool&nbsp; - Google Refine Data Quality Installation instructions for this workflow can be found&nbsp; <a href=https://wiki.biovel.eu/display/BioVeL/Taxonomic+Data+Refinement+Workflow+Installation rel=nofollow>here</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/2.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v2.t2flow?version=2","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,","&nbsp; <span>&nbsp;&nbsp;This workflow brings together various sub-workflows in one integrated workflow. This includes,</span> - Synonym Expansion / Occurrence Retrieval&nbsp; - BioSTIFF Data Selection Tool&nbsp; - Google Refine Data Quality Installation instructions for this workflow can be found&nbsp; <a href=https://wiki.biovel.eu/display/BioVeL/Taxonomic+Data+Refinement+Workflow+Installation rel=nofollow>here</a> <span>This workflow depends on&nbsp;</span> <a href=http://www.myexperiment.org/files/767/download/DCWorkflow.jar rel=nofollow>DCWorkflow.jar</a> <span>, which must be installed in Taverna's local user lib directory.</span>",-1, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/3.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v3.t2flow?version=3","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,","This workflow brings together various sub-workflows in one integrated workflow. This includes,- Synonym Expansion / Occurrence Retrieval- BioSTIFF Data Selection Tool- Google Refine Data QualityInstallation instructions for this workflow can be foundhere This workflow depends onDCWorkflow.jar, which must be installed in Taverna's local user lib directory.",-1, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/4.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v4.t2flow?version=4","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,","&nbsp; <span>This workflow brings together various sub-workflows in one integrated workflow. This includes, - Synonym Expansion / Occurrence Retrieval - BioSTIFF Data Selection Tool - Google Refine Data Quality Installation instructions for this workflow can be foundhere</span> This workflow depends onDCWorkflow.jar, which must be installed in Taverna's local user lib directory.",-1, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/5.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v5.t2flow?version=5","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,","<span>This workflow brings together various sub-workflows in one integrated workflow. This includes, - Synonym Expansion / Occurrence Retrieval - BioSTIFF Data Selection Tool - Google Refine Data Quality Installation instructions for this workflow can be found here&nbsp;</span> <a href=https://wiki.biovel.eu/display/BioVeL/Taxonomic+Data+Refinement+Workflow+Installation rel=nofollow>https://wiki.biovel.eu/display/BioVeL/Taxonomic+Data+Refinement+Workflow+Installation</a> . This workflow depends on DCWorkflow.jar, which must be installed in Taverna's local user lib directory.",-1, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/6.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v6.t2flow?version=6","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,","&nbsp; <span>This workflow brings together various sub-workflows in one integrated workflow. This includes, - Synonym Expansion / Occurrence Retrieval - BioSTIFF Data Selection Tool - Google Refine Data Quality Installation instructions for this workflow can be found here&nbsp;</span> <a href=https://wiki.biovel.eu/display/BioVeL/Taxonomic+Data+Refinement+Workflow+Installation rel=nofollow>https://wiki.biovel.eu/display/BioVeL/Taxonomic+Data+Refinement+Workflow+Installation</a> <span>.</span> This workflow depends on DCWorkflow.jar, which must be installed in Taverna's local user lib directory.",-1, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/7.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v7.t2flow?version=7","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,","&nbsp;&nbsp; <span>This workflow brings together various sub-workflows in one integrated workflow. This includes, - Synonym Expansion / Occurrence Retrieval - BioSTIFF Data Selection Tool - Google Refine Data Quality Installation instructions for this workflow can be found here&nbsp;</span> <a href=https://wiki.biovel.eu/display/BioVeL/Taxonomic+Data+Refinement+Workflow+Installation rel=nofollow>https://wiki.biovel.eu/display/BioVeL/Taxonomic+Data+Refinement+Workflow+Installation</a> <span>.</span> This workflow depends on DCWorkflow.jar, which must be installed in Taverna's local user lib directory.",-1, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/8.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v8.t2flow?version=8","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,",,0, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/9.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v9.t2flow?version=9","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,",,0, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/10.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v10.t2flow?version=10","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,",,0, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/11.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v11.t2flow?version=11","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,",,0, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/12.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v12.t2flow?version=12","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,",,0, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/13.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v13.t2flow?version=13","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,",,0, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/14.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v14.t2flow?version=14","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,",,0, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/15.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v15.t2flow?version=15","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,",,0, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/16.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v16.t2flow?version=16","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,",,0, 0, ,
"http://www.myexperiment.org/workflows/2874/versions/17.html","Data Refinement Workflow v17","2012-04-1110:08:25","2014-12-1712:51:15","http://www.myexperiment.org/workflows/2874/download/Data_Refinement_Workflow_v17-v17.t2flow?version=17","/users/20575","Cherian Mathew","taverna 2","/users/20575,","Cherian Mathew,",,0, 0, ,
"http://www.myexperiment.org/workflows/2875/versions/1.html","ICDAR 2011 End-to-End Applications contest, including contributed algorithms.","2012-04-1420:15:26","2012-04-1420:28:02","http://www.myexperiment.org/workflows/2875/download/ICDAR_2011_End-to-End_Applications_contest__including_contributed_algorithms.-v1.t2flow?version=1","/users/22254","Bart Lamiroy","taverna 2","/users/22254,","Bart Lamiroy,","Full workflow for use with the DAE platform and as used for the ICDAR 2011 &quot; <a href=http://dae.cse.lehigh.edu/ICDAR2011Contest rel=nofollow>Document Analysis Algorithm Contributions in End-to-End Applications</a> &quot; contest, including contributed algorithms.",-1, 0, ,
"http://www.myexperiment.org/workflows/2876/versions/1.html","Match gene lists based on information in literature","2012-04-1708:55:46","2012-04-2507:54:26","http://www.myexperiment.org/workflows/2876/download/Match_gene_lists_based_on_information_in_literature-v1.t2flow?version=1","/users/18","Marco Roos","taverna 2","/users/18, /users/12548, /users/17730, /users/2642,","Marco Roos, Reinout van Schouwen, Eleni, Kristina Hettne,","<span>Note: this workflow and its services are in beta testing stage</span> . This workflow computes the match between a list of proteins and a term of interest by means of concept profile matching (Jelier et al., van Haagen et al.). The result of this is a list of concepts ordered by their matching score (the length of the list set by maxMatchNr). Of this list the summed scores are explained by computing the concepts that contribute most to the combination of the matching protein and the query term.   E.g. (by analogy) when a group of informaticians is matched against biology, the informaticians working in biology may be ranked on top, while the most enriched concept among such an informatician and biology may be 'bioinformatics'.",-1, 0, ,
"http://www.myexperiment.org/workflows/2876/versions/2.html","Match gene lists based on information in literature","2012-04-1708:55:46","2012-04-2507:54:26","http://www.myexperiment.org/workflows/2876/download/Match_gene_lists_based_on_information_in_literature-v2.t2flow?version=2","/users/18","Marco Roos","taverna 2","/users/18, /users/12548, /users/17730, /users/2642,","Marco Roos, Reinout van Schouwen, Eleni, Kristina Hettne,","<span><span>Note: this workflow and its services are in beta testing stage</span>.</span> This workflow computes the match between a list of proteins and a term of interest by means of concept profile matching (Jelier et al., van Haagen et al.). The result of this is a list of concepts ordered by their matching score (the length of the list set by maxMatchNr). Of this list the summed scores are explained by computing the concepts that contribute most to the combination of the matching protein and the query term.   E.g. (by analogy) when a group of informaticians is matched against biology, the informaticians working in biology may be ranked on top, while the most enriched concept among such an informatician and biology may be 'bioinformatics'.",-1, 0, ,
"http://www.myexperiment.org/workflows/2876/versions/3.html","Match gene lists based on information in literature","2012-04-1708:55:46","2012-04-2507:54:26","http://www.myexperiment.org/workflows/2876/download/Match_gene_lists_based_on_information_in_literature-v3.t2flow?version=3","/users/18","Marco Roos","taverna 2","/users/18, /users/12548, /users/17730, /users/2642,","Marco Roos, Reinout van Schouwen, Eleni, Kristina Hettne,","This workflow computes the match between a list of proteins and a term of interest by means of concept profile matching (Jelier et al., van Haagen et al.). The result of this is a list of concepts ordered by their matching score (the length of the list set by maxMatchNr). Of this list the summed scores are explained by computing the concepts that contribute most to the combination of the matching protein and the query term. E.g. (by analogy) when a group of informaticians is matched against biology, the informaticians working in biology may be ranked on top, while the most enriched concept among such an informatician and biology may be 'bioinformatics'.",-1, 0, ,
"http://www.myexperiment.org/workflows/2876/versions/4.html","Match gene lists based on information in literature","2012-04-1708:55:46","2012-04-2507:54:26","http://www.myexperiment.org/workflows/2876/download/Match_gene_lists_based_on_information_in_literature-v4.t2flow?version=4","/users/18","Marco Roos","taverna 2","/users/18, /users/12548, /users/17730, /users/2642,","Marco Roos, Reinout van Schouwen, Eleni, Kristina Hettne,","[THIS WORKFLOW IS IN BETA STAGE] This workflow computes the match between two lists of Entrez Gene Identifiers by means of concept profile matching (Jelier et al., van Haagen et al.). The result of this is a list of concepts ordered by their matching score (the length of the list set by maxMatchNr). Of this list the summed scores are explained by computing the concepts that contribute most to the combination of the matching genes. Example to explain (by analogy): When a group of informaticians is matched against biology, the informaticians working in biology may be ranked on top, while the most enriched concept among such an informatician and biology may be 'bioinformatics'.",0, 0, ,
"http://www.myexperiment.org/workflows/2876/versions/5.html","Match gene lists based on information in literature","2012-04-1708:55:46","2012-04-2507:54:26","http://www.myexperiment.org/workflows/2876/download/Match_gene_lists_based_on_information_in_literature-v5.t2flow?version=5","/users/18","Marco Roos","taverna 2","/users/18, /users/12548, /users/17730, /users/2642,","Marco Roos, Reinout van Schouwen, Eleni, Kristina Hettne,","[THIS WORKFLOW IS IN BETA STAGE] This workflow computes the match between two lists of Entrez Gene Identifiers by means of concept profile matching (Jelier et al., van Haagen et al.). The result of this is a list of concepts ordered by their matching score (the length of the list set by maxMatchNr). Of this list the summed scores are explained by computing the concepts that contribute most to the combination of the matching genes. Example to explain (by analogy): When a group of informaticians is matched against biology, the informaticians working in biology may be ranked on top, while the most enriched concept among such an informatician and biology may be 'bioinformatics'.",0, 0, ,
"http://www.myexperiment.org/workflows/2876/versions/6.html","Match gene lists based on information in literature","2012-04-1708:55:46","2012-04-2507:54:26","http://www.myexperiment.org/workflows/2876/download/Match_gene_lists_based_on_information_in_literature-v6.t2flow?version=6","/users/18","Marco Roos","taverna 2","/users/18, /users/12548, /users/17730, /users/2642,","Marco Roos, Reinout van Schouwen, Eleni, Kristina Hettne,","[THIS WORKFLOW IS IN BETA STAGE] This workflow computes the match between two lists of Entrez Gene Identifiers by means of concept profile matching (Jelier et al., van Haagen et al.). The result of this is a list of concepts ordered by their matching score (the length of the list set by maxMatchNr). Of this list the summed scores are explained by computing the concepts that contribute most to the combination of the matching genes. Example to explain (by analogy): When a group of informaticians is matched against biology, the informaticians working in biology may be ranked on top, while the most enriched concept among such an informatician and biology may be 'bioinformatics'.",0, 0, ,
"http://www.myexperiment.org/workflows/2876/versions/7.html","Match gene lists based on information in literature","2012-04-1708:55:46","2012-04-2507:54:26","http://www.myexperiment.org/workflows/2876/download/Match_gene_lists_based_on_information_in_literature-v7.t2flow?version=7","/users/18","Marco Roos","taverna 2","/users/18, /users/12548, /users/17730, /users/2642,","Marco Roos, Reinout van Schouwen, Eleni, Kristina Hettne,","[THIS WORKFLOW IS IN BETA STAGE] This workflow computes the match between two lists of Entrez Gene Identifiers by means of concept profile matching (Jelier et al., van Haagen et al.). The result of this is a list of concepts ordered by their matching score (the length of the list set by maxMatchNr). Of this list the summed scores are explained by computing the concepts that contribute most to the combination of the matching genes. Example to explain (by analogy): When a group of informaticians is matched against biology, the informaticians working in biology may be ranked on top, while the most enriched concept among such an informatician and biology may be 'bioinformatics'.",0, 0, ,
"http://www.myexperiment.org/workflows/2877/versions/1.html","SNP Position Information","2012-04-1710:10:59","2012-04-1710:15:57","http://www.myexperiment.org/workflows/2877/download/SNP_Position_Information-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow extracts information about the position of SNPs and the genes they are associated with, using BioMart (ENSEMBL Variation 66).",0, 0, ,
"http://www.myexperiment.org/workflows/2880/versions/1.html","GetCities2","2012-05-0307:43:58","2012-05-0307:45:08","http://www.myexperiment.org/workflows/2880/download/GetCities2-v1.t2flow?version=1","/users/22050","Xiaoxia...","taverna 2","/users/22050,","Xiaoxiaoshijie,","&nbsp;Get cities by entering a country name",-1, 0, ,
"http://www.myexperiment.org/workflows/2881/versions/1.html","Get FlyTED Gene Expression Images for a Gene using Restful Services","2012-05-0411:45:57","2012-05-0411:51:54","http://www.myexperiment.org/workflows/2881/download/Get_FlyTED_Gene_Expression_Images_for_a_Gene_using_Restful_Services-v1.t2flow?version=1","/users/23249","Junzhao","taverna 2","/users/23249,","Junzhao,","This is a simple workflow testing running a restful service in Taverna. This restful service  <span><a href=http://www.open-biomed.org.uk/service/flyted/records/probe/{probe} rel=nofollow>http://www.open-biomed.org.uk/service/flyted/records/probe/{probe}</a> is part of the flykit/flyted services <a href=http://code.google.com/p/open-biomed/wiki/Flyted rel=nofollow>http://code.google.com/p/open-biomed/wiki/Flyted</a>, which is built using the Talis Puelia Linked Data API (<a href=http://code.google.com/p/puelia-php/ rel=nofollow>http://code.google.com/p/puelia-php/</a>).</span> We want to use this simple workflow to test the idea of bridging linked data and scientific workflows using Restful services. A test input gene name can be: schuy, Act5C or Adh",-1, 0, ,
"http://www.myexperiment.org/workflows/2882/versions/1.html","Get Alternative Gene Names for a Drosophila Gene","2012-05-0411:58:27","2012-05-0411:59:58","http://www.myexperiment.org/workflows/2882/download/Get_Alternative_Gene_Names_for_a_Drosophila_Gene-v1.t2flow?version=1","/users/23249","Junzhao","taverna 2","/users/23249,","Junzhao,","This is a simple workflow testing running a restful service in Taverna. This  restful service  <span><a href=http://www.open-biomed.org.uk/service/flybase/features/name/{name} rel=nofollow>http://www.open-biomed.org.uk/service/flybase/features/name/{name}</a></span>  is  part of the flykit/flybase services   <a href=http://code.google.com/p/open-biomed/wiki/Flybase rel=nofollow>http://code.google.com/p/open-biomed/wiki/Flybase</a> , which is built using  the Talis Puelia Linked Data API ( <a href=http://code.google.com/p/puelia-php/ rel=nofollow>http://code.google.com/p/puelia-php/</a> ). We want to use this simple workflow to test the idea of bridging linked  data and scientific workflows using Restful services. A test input gene name can be: schuy, Act5C or Adh.",-1, 0, ,
"http://www.myexperiment.org/workflows/2883/versions/1.html","Search for Gene Expression Images using any Gene Name","2012-05-0412:00:53","2012-05-0810:05:24","http://www.myexperiment.org/workflows/2883/download/Search_for_Gene_Expression_Images_using_any_Gene_Name-v1.t2flow?version=1","/users/23249","Junzhao","taverna 2","/users/23249,","Junzhao,","This is a simple workflow demonstrating how to integrate multiple linked data sources using restful services in Taverna. In this workflow it first searches for all possible gene names for a query gene from FlyBase repository, an authorative genetic database for Drosophila research, and then it uses returned gene names to search for gene expression images from Oxford FlyTED image repository. Two Restful services were used: Both services are part of the FlyKit toolkit and they are built using the Talis Puelia Linked Data API to expose a Restful service interface for Linked Data resources. Some test input can be: schuy, Adh, or Act5C.",-1, 0, ,
"http://www.myexperiment.org/workflows/2884/versions/1.html","Run on amazon cloud","2012-05-0412:36:29","2012-05-0412:57:54","http://www.myexperiment.org/workflows/2884/download/Run_on_amazon_cloud-v1.t2flow?version=1","/users/22954","Georgeg9","taverna 2","/users/22954,","Georgeg9,","&nbsp;Execute commands on amazon cloud machines Manual and documentation at:  <a href=http://www.students.ncl.ac.uk/g.georgiou/newweb/ rel=nofollow>http://www.students.ncl.ac.uk/g.georgiou/newweb/</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/2885/versions/1.html","FINAL VERSION","2012-05-0412:42:03","2012-05-0413:00:37","http://www.myexperiment.org/workflows/2885/download/FINAL_VERSION-v1.t2flow?version=1","/users/22954","Georgeg9","taverna 2","/users/22954,","Georgeg9,","&nbsp;From genome to genbank file and annotations Manual and documentation at:  <a href=http://www.students.ncl.ac.uk/g.georgiou/newweb/ rel=nofollow>http://www.students.ncl.ac.uk/g.georgiou/newweb/</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/2886/versions/1.html","Get top blastx hit of a list of contigs","2012-05-0412:44:27","2012-05-0413:31:22","http://www.myexperiment.org/workflows/2886/download/Get_top_blastx_hit_of_a_list_of_contigs-v1.t2flow?version=1","/users/23002","BioCo Consultants","taverna 2","/users/23002,","BioCo Consultants,","This workflow takes a contigs.fasta file , gets all the ORF's present in it , runs blastx on each ORF, gets the FASTA file of the top blastX hit and its GI number.",-1, 0, ,
"http://www.myexperiment.org/workflows/2888/versions/1.html","generateWholeSeqAnnotation","2012-05-0413:00:47","2012-05-0413:30:34","http://www.myexperiment.org/workflows/2888/download/generateWholeSeqAnnotation-v1.t2flow?version=1","/users/23002","BioCo Consultants","taverna 2","/users/23002,","BioCo Consultants,","&nbsp;This work flow is used for genereating all the known genes together to annotate a whole or a large region of genome sequence. &nbsp; outputfilrURL: &nbsp;the location of the output file Ginumber: &nbsp; the input gi gene number wholeGenomeSeq: &nbsp; &nbsp;the whold sequence annotation information output: &nbsp; &nbsp;the output of genbank text",-1, 0, ,
"http://www.myexperiment.org/workflows/2889/versions/1.html","ConcatStringTogether","2012-05-0413:02:31","2012-05-0413:49:36","http://www.myexperiment.org/workflows/2889/download/ConcatStringTogether-v1.t2flow?version=1","/users/23002","BioCo Consultants","taverna 2","/users/23002,","BioCo Consultants,","&nbsp;This workflow is as simple as you can imagine! It can be used to remove the information tags in a fasta file and concat the sequence together &nbsp; fastaURL : &nbsp;the input fasta reads file location seqURL : the outcome sequence file location wholeSeq : the output sequence as an entire string",-1, 0, ,
"http://www.myexperiment.org/workflows/2890/versions/1.html","filterDifferenceInLists","2012-05-0413:05:16","2012-05-0413:38:54","http://www.myexperiment.org/workflows/2890/download/filterDifferenceInLists-v1.t2flow?version=1","/users/23002","BioCo Consultants","taverna 2","/users/23002,","BioCo Consultants,","&nbsp;This workflow output a list of the protein or any string hits in the first list but not in the second list.&nbsp; &nbsp; output : output file location com : comparision protein list our : interested protein list out1: output as a string",-1, 0, ,
"http://www.myexperiment.org/workflows/2891/versions/1.html","extractGInumber","2012-05-0413:08:06","2012-05-0413:36:13","http://www.myexperiment.org/workflows/2891/download/extractGInumber-v1.t2flow?version=1","/users/23002","BioCo Consultants","taverna 2","/users/23002,","BioCo Consultants,","&nbsp;This workflow uses regex pattern to compare the identity percentage of each hits against the input sequnece and return the whole information of the hits and the GI number of them (if they including the GI number as a sub information) &nbsp; inputfileURL: &nbsp;the location of the Gi number &nbsp; outputText &nbsp;: the list of all the hits and the GI number of them",-1, 0, ,
"http://www.myexperiment.org/workflows/2898/versions/1.html","Check Java Cryptography Unlimited Strength","2012-05-0810:19:49","2012-05-0810:19:50","http://www.myexperiment.org/workflows/2898/download/Check_Java_Cryptography_Unlimited_Strength-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","Checks if Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files is installed, and redirects user to correct download page and relevant lib/security folder if not.",0, 0, ,
"http://www.myexperiment.org/workflows/2899/versions/1.html","Find workflow ancestors","2012-05-0811:15:30","2012-07-0910:56:06","http://www.myexperiment.org/workflows/2899/download/Find_workflow_ancestors-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","Given a  <i>t2flow </i> file (Taverna 2 workflow), extract ancestor workflow UUIDs and search myExperiment for matching workflow entries.  Note that this will also match the workflow itself and nested workflows, but does not match against other workflows having the same ancestors (but newer UUIDs). This workflow requires  <a href=http://www.taverna.org.uk/download/workbench/2-4/ rel=nofollow>Taverna 2.4</a>  or later and uses  <a href=http://rdf.myexperiment.org/sparql rel=nofollow>myExperiment's SPARQL endpoint</a> , which is refreshed weekly and contains only public workflow entries.",0, 0, ,
"http://www.myexperiment.org/workflows/2899/versions/2.html","Find workflow ancestors","2012-05-0811:15:30","2012-07-0910:56:06","http://www.myexperiment.org/workflows/2899/download/Find_workflow_ancestors-v2.t2flow?version=2","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","Given a t2flow file (Taverna 2 workflow), extract ancestor workflow UUIDs and search myExperiment for matching workflow entries. Note that this will also match the workflow itself and nested workflows, but does not match against other workflows having the same ancestors (but newer UUIDs).",0, 0, ,
"http://www.myexperiment.org/workflows/2900/versions/1.html","Simple image migration","2012-05-0817:08:17","2012-05-0817:08:18","http://www.myexperiment.org/workflows/2900/download/Simple_image_migration-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Then starts a migration action on an image and extracts properties from the original and migrated image. The properties are compared and a QA algorithms is started on the image data itself .",0, 0, ,
"http://www.myexperiment.org/workflows/2902/versions/1.html","Extract DEC and RA from whitespace separated file","2012-05-1014:40:38","2012-09-2416:13:28","http://www.myexperiment.org/workflows/2902/download/Extract_DEC_and_RA_from_whitespace_separated_file-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","&nbsp;Given an input like: 1 <span class=Apple-tab-span> </span> 0.77345 <span class=Apple-tab-span> </span> -1.91430 <br /> 2 <span class=Apple-tab-span> </span> 0.83487 <span class=Apple-tab-span> </span> 29.79720 <br /> 3 <span class=Apple-tab-span> </span> 0.84108 <span class=Apple-tab-span> </span> 30.78210 <br /> 4 <span class=Apple-tab-span> </span> 0.99487 <span class=Apple-tab-span> </span> 20.75240 this workflow extracts the second and third column as RA and DEC.",-1, 0, ,
"http://www.myexperiment.org/workflows/2902/versions/2.html","Extract DEC and RA from whitespace separated file","2012-05-1014:40:38","2012-09-2416:13:28","http://www.myexperiment.org/workflows/2902/download/Extract_DEC_and_RA_from_whitespace_separated_file-v2.t2flow?version=2","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","This workflow extracts DEC and RA coordinates from a whitespace seperated file and this is a silly description.",-1, 0, ,
"http://www.myexperiment.org/workflows/2914/versions/1.html","Mp3ToWav Mig+QA","2012-05-2110:53:07","2013-04-2409:12:25","http://www.myexperiment.org/workflows/2914/download/Mp3ToWav_Mig_QA-v1.t2flow?version=1","/users/19098","Bolette Jurik","taverna 2","/users/19098,","Bolette Jurik,","This workflow migrates a list of mp3 files to wav files using the  <i>MP3 to WAV Migrate Validate Compare</i>  workflow.  <a href=http://www.myexperiment.org/workflows/2687.html rel=nofollow>See description here.</a>  The workflow uses SCAPE web services, which are set up locally. The webservices are set up using the  <a href=https://github.com/openplanets/scape rel=nofollow>github.com/openplanets/scape</a>  project tool descriptors. The used SCAPE web services are the ffmpeg, jhove2 and ffprobe  web services. This workflow matches (most of) solution SO4 on the  SCAPE opf wiki, see  <a href=http://wiki.opf-labs.org/display/SP/SO4+Audio+mp3+to+wav+Migration+and+QA+Workflow rel=nofollow>http://wiki.opf-labs.org/display/SP/SO4+Audio+mp3+to+wav+Migration+and+QA+Workflow</a> . The workflow input value is a fileURL containing a list of input MP3 URLs. The output is a list of Wav fileURLs, a list of validation outputs (valid / not valid ) and a list of comparison outputs (properties alike / not alike).",-1, 0, ,
"http://www.myexperiment.org/workflows/2914/versions/2.html","Mp3ToWav Mig+QA","2012-05-2110:53:07","2013-04-2409:12:25","http://www.myexperiment.org/workflows/2914/download/Mp3ToWav_Mig_QA-v2.t2flow?version=2","/users/19098","Bolette Jurik","taverna 2","/users/19098,","Bolette Jurik,","Migrates Mp3 files from input List to Wav files and performs QA. The QA steps include File Format Validation, Significant Property Comparison and migrationQA file content comparison (all CLI). This workflow matches solution SO4 on the SCAPE opf wiki, see  <a href=http://wiki.opf-labs.org/display/SP/SO4+Audio+mp3+to+wav+Migration+and+QA+Workflow rel=nofollow>http://wiki.opf-labs.org/display/SP/SO4+Audio+mp3+to+wav+Migration+and+QA+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2915/versions/1.html","Watershed","2012-05-2112:58:17","2012-05-2113:44:51","http://www.myexperiment.org/workflows/2915/download/Watershed-v1.t2flow?version=1","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","Local watershed example for local run",0, 0, ,
"http://www.myexperiment.org/workflows/2915/versions/2.html","Watershed","2012-05-2112:58:17","2012-05-2113:44:51","http://www.myexperiment.org/workflows/2915/download/Watershed-v2.t2flow?version=2","/users/12139","Jorgejesus","taverna 2","/users/12139,","Jorgejesus,","Local machine example",0, 0, ,
"http://www.myexperiment.org/workflows/2917/versions/1.html","Sesame service to get the RA and DEC of a list of objects","2012-05-2318:40:08","","http://www.myexperiment.org/workflows/2917/download/Sesame_service_to_get_the_RA_and_DEC_of_a_list_of_objects-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/2918/versions/1.html","Getting information from LEDA service","2012-05-2318:41:14","","http://www.myexperiment.org/workflows/2918/download/Getting_information_from_LEDA_service-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/2919/versions/1.html","Extract logr25 from LEDA service","2012-05-2318:44:25","2012-05-2407:43:54","http://www.myexperiment.org/workflows/2919/download/Extract_logr25_from_LEDA_service-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/2920/versions/1.html","Calculating the internal extinction with data from leda","2012-05-2319:12:49","2015-03-2511:15:25","http://www.myexperiment.org/workflows/2920/download/Calculating_the_internal_extinction_with_data_from_leda-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/2920/versions/2.html","Calculating the internal extinction with data from leda","2012-05-2319:12:49","2015-03-2511:15:25","http://www.myexperiment.org/workflows/2920/download/Calculating_the_internal_extinction_with_data_from_leda-v2.t2flow?version=2","/users/19173","Susana","taverna 2","","","This workflow queries to Sesame service to extract the RA and DEC coordinates. Then, with these coordinates, it queries the ConeSearch services of SLOAN to get the Morphological Type and the logr25. The last step of the workflow is a python tool which calculates the internal extinction using the data obtained before.",-1, 0, ,
"http://www.myexperiment.org/workflows/2920/versions/3.html","Calculating the internal extinction with data from leda","2012-05-2319:12:49","2015-03-2511:15:25","http://www.myexperiment.org/workflows/2920/download/Calculating_the_internal_extinction_with_data_from_leda-v3.t2flow?version=3","/users/19173","Susana","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/2921/versions/1.html","Example of jdbc","2012-05-2407:37:33","2012-05-2407:39:06","http://www.myexperiment.org/workflows/2921/download/Example_of_jdbc-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/2922/versions/1.html","Get data and images for a date +/- 12 hours from MLSO_CHIP","2012-05-2409:26:10","2012-05-2409:29:11","http://www.myexperiment.org/workflows/2922/download/Get_data_and_images_for_a_date___-_12_hours_from_MLSO_CHIP-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","From the date as input date +/- 12 hours of data from the MLSO web page is collated. Images for up to three images (closest to date; -1; +1) are created via autoplot",0, 0, ,
"http://www.myexperiment.org/workflows/2925/versions/1.html","Convert table to CDS format","2012-05-2812:04:36","2012-05-2812:15:24","http://www.myexperiment.org/workflows/2925/download/Convert_table_to_CDS_format-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","It converts a csv file (comma separated values) to the CDS format. It also provides relevant information to create the ReadMe file. The first row in the input file must be the column names. If you want to run this workflow, you have to install astrotaverna plugin. You can easyly cusomize the workflow to provide a votable or fits table as input.",-1, 0, ,
"http://www.myexperiment.org/workflows/2926/versions/1.html","Anatomical Atlas Generation","2012-05-2907:05:03","2012-05-2907:06:36","http://www.myexperiment.org/workflows/2926/download/Anatomical_Atlas_Generation-v1.t2flow?version=1","/users/23858","Gimias","taverna 2","/users/23858,","Gimias,","Computes an anatomical atlas based on a set of patient images using registration methods. This workflow is automatic and does not require user interaction. The anatomical atlas is composed of a mean image and the set of transformations for each patient's between the mean image and the patient image. The atlas can be used to segment the mean image once and propagate the segmentation results to each patient image automatically. This workflow has been tested using GIMIAS-1.5 (open source) with a set of 10 patient images and 10 iterations. Notes: - Some thresholds are configured as fixed values. Depending on the input image, you should change these. Technical details: The spatial normalization follows the classic iterative approach presented by Guimond et al. [2]. No intensity normalization is done. For the registration, we use diffeomorphic transformations [4], which are invertible. We cannot blindly average diffeomorphic transformations; the result would not be  diffeomorphic [6]. Therefore we use Arsigny&rsquo;s log-euclidean framework [1], which makes the whole process a lot more complex [1]	Arsigny, Commowick, Pennec, Ayache. &ldquo;A log-euclidean framework for statistics on diffeomorphisms,&rdquo; Proc. MICCAI 2006, LNCS vol. 4190, pp. 924-931. Doi: 10.1007/11866565_113 [2]	Guimond, Meunier, Thirion. &ldquo;Average brain models: A convergence study,&rdquo; Computer Vision and Image Understanding 77(2):192-210, February 2000. Doi: 10.1006/cviu.1999.0815 [4]	Rueckert, Aljabar, Heckemann, Hajnal, Hammers. &ldquo;Diffeomorphic registration using B-splines,&rdquo; Proc. MICCAI 2006, LNCS vol. 4191, pp. 702-709. Doi: 10.1007/11866763_86 [6]	Trouv&eacute;. &ldquo;Diffeomorphisms groups and pattern matching in image analysis,&rdquo; International Journal of Computer Vision 28(3):213-221, July 1998. Doi: 10.1023/A:1008001603737",0, 0, ,
"http://www.myexperiment.org/workflows/2931/versions/1.html","[untitled]","2012-06-0223:23:02","2012-06-0223:23:29","http://www.myexperiment.org/workflows/2931/download/_untitled_-v1.t2flow?version=1","/users/29235","Neroptit","taverna 2","/users/29235,","Neroptit,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2934/versions/1.html","Image Characterisation - Fits (Extended)","2012-06-0613:21:43","2012-06-0613:21:44","http://www.myexperiment.org/workflows/2934/download/Image_Characterisation_-_Fits__Extended_-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Extracts metadata from images.",0, 0, ,
"http://www.myexperiment.org/workflows/2940/versions/1.html","Gaussian Blur","2012-06-1310:26:52","2012-06-1320:06:19","http://www.myexperiment.org/workflows/2940/download/Gaussian_Blur-v1.t2flow?version=1","/users/23858","Gimias","taverna 2","","","Convolves the image with a Gaussian kernel wherein the Gaussian has a standard deviation specified by the user (&quot;sigma&quot;) and the kernel width in each dimension is 6 times the standard deviation of the Gaussian.  You can find more details  <a href=http://sourceforge.net/apps/mediawiki/gimias/index.php?title=Gaussian_Blur_CLP rel=nofollow>here</a>",0, 0, ,
"http://www.myexperiment.org/workflows/2941/versions/1.html","ASA_IM__0P","2012-06-1314:54:27","2012-06-1314:54:30","http://www.myexperiment.org/workflows/2941/download/ASA_IM__0P-v1.t2flow?version=1","/users/17342","Joel Wright","taverna 2","/users/17342,","Joel Wright,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2942/versions/1.html","[untitled]","2012-06-1315:00:14","2012-06-1315:00:19","http://www.myexperiment.org/workflows/2942/download/_untitled_-v1.t2flow?version=1","/users/17342","Joel Wright","taverna 2","/users/17342,","Joel Wright,",,-1, 0, ,
"http://www.myexperiment.org/workflows/2969/versions/1.html","DatabaseID to ConceptID","2012-06-2520:48:28","2014-07-1409:23:46","http://www.myexperiment.org/workflows/2969/download/DatabaseID_to_ConceptID-v1.t2flow?version=1","/users/18","Marco Roos","taverna 2","/users/18, /users/68, /users/12548,","Marco Roos, Martijn Schuemie, Reinout van Schouwen,","Purpose: This workflow maps input Identifiers, common database identifiers, to the Concept Identifiers from the EMC ontology. Result: Concept Identifiers from the EMC ontology. Resources: Table of database identifiers and concept identifiers.Database identifiers from ...EMC ontology compiled from ...",0, 0, ,
"http://www.myexperiment.org/workflows/2969/versions/2.html","DatabaseID to ConceptID","2012-06-2520:48:28","2014-07-1409:23:46","http://www.myexperiment.org/workflows/2969/download/DatabaseID_to_ConceptID-v2.t2flow?version=2","/users/18","Marco Roos","taverna 2","/users/18, /users/68, /users/12548,","Marco Roos, Martijn Schuemie, Reinout van Schouwen,","Purpose: This workflow maps input Identifiers, common database identifiers, to the Concept Identifiers from the EMC ontology. Result: Concept Identifiers from the EMC ontology. Resources: Table of database identifiers and concept identifiers.Database identifiers from ...EMC ontology compiled from ...",0, 0, ,
"http://www.myexperiment.org/workflows/2969/versions/3.html","DatabaseID to ConceptID","2012-06-2520:48:28","2014-07-1409:23:46","http://www.myexperiment.org/workflows/2969/download/DatabaseID_to_ConceptID-v3.t2flow?version=3","/users/18","Marco Roos","taverna 2","/users/18, /users/68, /users/12548,","Marco Roos, Martijn Schuemie, Reinout van Schouwen,","Purpose: This workflow maps input Identifiers, common database identifiers, to the Concept Identifiers from the EMC ontology. Result: Concept Identifiers from the EMC ontology. Resources: Table of database identifiers and concept identifiers.Database identifiers from ...EMC ontology compiled from ... Comments: This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2969/versions/4.html","DatabaseID to ConceptID","2012-06-2520:48:28","2014-07-1409:23:46","http://www.myexperiment.org/workflows/2969/download/DatabaseID_to_ConceptID-v4.t2flow?version=4","/users/18","Marco Roos","taverna 2","/users/18, /users/68, /users/12548,","Marco Roos, Martijn Schuemie, Reinout van Schouwen,","Purpose: This workflow maps input Identifiers, common database identifiers, to the Concept Identifiers from the EMC ontology. Result: Concept Identifiers from the EMC ontology. Resources: Table of database identifiers and concept identifiers.Database identifiers from ...EMC ontology compiled from ... Comments: This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2969/versions/5.html","DatabaseID to ConceptID","2012-06-2520:48:28","2014-07-1409:23:46","http://www.myexperiment.org/workflows/2969/download/DatabaseID_to_ConceptID-v5.t2flow?version=5","/users/18","Marco Roos","taverna 2","/users/18, /users/68, /users/12548,","Marco Roos, Martijn Schuemie, Reinout van Schouwen,","Purpose: This workflow maps input Identifiers, common database identifiers, to the Concept Identifiers from the EMC ontology. Result: Concept Identifiers from the EMC ontology. Resources: Table of database identifiers and concept identifiers.Database identifiers from ...EMC ontology compiled from ... Comments: This workflow can be used together with other workflows in this pack:  <a rel=nofollow href=http://www.myexperiment.org/packs/282>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2969/versions/6.html","DatabaseID to ConceptID","2012-06-2520:48:28","2014-07-1409:23:46","http://www.myexperiment.org/workflows/2969/download/DatabaseID_to_ConceptID-v6.t2flow?version=6","/users/18","Marco Roos","taverna 2","/users/18, /users/68, /users/12548,","Marco Roos, Martijn Schuemie, Reinout van Schouwen,","Purpose: This workflow maps input Identifiers, common database identifiers, to the Concept Identifiers from the EMC ontology. Result: Concept Identifiers from the EMC ontology. Comments: Database: one of CAS, DRUG, etc. The supported databases are listed below. Database 	Description 	ExampleCAS 	Chemical Abstracts Service registry number 	64-17-5DRUG 	Drug Bank 	DB00316AF 	Affymetrix 	200007_atCHEB 	ChEBI 	16236CHID 	ChemIDplus 	0000050000EG 	Entrez-Gene 	3064GO 	Gene Ontology 	GO:0008219HG 	HGNC 	4851HMBD 	Human Metabolome Database 	HMDB01859KEGD 	KEGD 	D00217KEGG 	KEGG 	C12345MESH 	Medical Subject Headings 	D000082MGI 	Mouse Genome Database 	96067OM 	OMIM 	143100PUBC 	PubChem Compound 	1983PUBS 	PubChem Substance 	7847284RGD 	Rat Genome Database 	68337UG 	UniGene 	Mm.281700UMLS 	Unified Medical Language System 	C0027439UP 	UniProt 	P42858",0, 0, ,
"http://www.myexperiment.org/workflows/2969/versions/7.html","DatabaseID to ConceptID","2012-06-2520:48:28","2014-07-1409:23:46","http://www.myexperiment.org/workflows/2969/download/DatabaseID_to_ConceptID-v7.t2flow?version=7","/users/18","Marco Roos","taverna 2","/users/18, /users/68, /users/12548,","Marco Roos, Martijn Schuemie, Reinout van Schouwen,","Purpose: This workflow maps input Identifiers, common database identifiers, to the Concept Identifiers from the EMC ontology. Result: Concept Identifiers from the EMC ontology. Comments: Database: one of CAS, DRUG, etc. The supported databases are listed below (database, description, example). CAS, Chemical Abstracts Service registry number, 64-17-5.DRUG, Drug Bank, DB00316.AF, Affymetrix, 200007_at.CHEB, ChEBI, 16236.CHID, ChemIDplus, 0000050000.EG, Entrez-Gene, 3064.GO, Gene Ontology, GO:0008219.HG, HGNC, 4851.HMBD, Human Metabolome Database, HMDB01859.KEGD, KEGD, D00217.KEGG, KEGG, C12345.MESH, Medical Subject Headings, D000082.MGI, Mouse Genome Database, 96067.OM, OMIM, 143100.PUBC, PubChem Compound, 1983.PUBS, PubChem Substance, 7847284.RGD, Rat Genome Database, 68337.UG, UniGene, Mm.281700.UMLS, Unified Medical Language System, C0027439.UP, UniProt, P42858.",0, 0, ,
"http://www.myexperiment.org/workflows/2971/versions/1.html","SNP_ID2EntrezGene_ID","2012-06-2609:50:25","2013-03-1113:56:56","http://www.myexperiment.org/workflows/2971/download/SNP_ID2EntrezGene_ID-v1.t2flow?version=1","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/17633,","Kristina Hettne, Harish Dharuri,","Maps a SNP, or a list of SNPs, to EntrezGene ID(s).",0, 0, ,
"http://www.myexperiment.org/workflows/2971/versions/2.html","SNP_ID2EntrezGene_ID","2012-06-2609:50:25","2013-03-1113:56:56","http://www.myexperiment.org/workflows/2971/download/SNP_ID2EntrezGene_ID-v2.t2flow?version=2","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/17633,","Kristina Hettne, Harish Dharuri,","Purpose: The workflow maps a SNP (dbSNP id) to a gene (EntrezGene id). Author comments: The window for gene inclusion can be set using the set_width parameter. This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2971/versions/3.html","SNP_ID2EntrezGene_ID","2012-06-2609:50:25","2013-03-1113:56:56","http://www.myexperiment.org/workflows/2971/download/SNP_ID2EntrezGene_ID-v3.t2flow?version=3","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/17633,","Kristina Hettne, Harish Dharuri,","Purpose: The workflow maps a SNP (dbSNP id) to a gene (EntrezGene id). The default value for the SNP region is 300 kb (i.e. the set_witdth parameter is set to 300000). Author comments: The window for gene inclusion can be set using the set_width parameter. This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2971/versions/4.html","SNP_ID2EntrezGene_ID","2012-06-2609:50:25","2013-03-1113:56:56","http://www.myexperiment.org/workflows/2971/download/SNP_ID2EntrezGene_ID-v4.t2flow?version=4","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/17633,","Kristina Hettne, Harish Dharuri,","Purpose: The workflow maps a SNP (dbSNP id) to a gene (EntrezGene id). Author comments: The window for gene inclusion can be set using the set_width parameter. This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2972/versions/1.html","Find Supporting Documents","2012-06-2610:21:17","2014-07-1410:47:12","http://www.myexperiment.org/workflows/2972/download/Find_Supporting_Documents-v1.t2flow?version=1","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/18, /users/12548, /users/2780,","Kristina Hettne, Marco Roos, Reinout van Schouwen, Martijn Schuemie,","The workflow find supporting evidence for a concept profile match by performing and intersection between the (related documents of) the entire concept profile of the first argument and the related documents (in the concept profile database) of the second argument.",0, 0, ,
"http://www.myexperiment.org/workflows/2972/versions/2.html","Find Supporting Documents","2012-06-2610:21:17","2014-07-1410:47:12","http://www.myexperiment.org/workflows/2972/download/Find_Supporting_Documents-v2.t2flow?version=2","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/18, /users/12548, /users/2780,","Kristina Hettne, Marco Roos, Reinout van Schouwen, Martijn Schuemie,","This workflow finds documents that serve as evidence for the association between two concepts. Results: Document titlesDocument identifiers Author comment: This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2972/versions/3.html","Find Supporting Documents","2012-06-2610:21:17","2014-07-1410:47:12","http://www.myexperiment.org/workflows/2972/download/Find_Supporting_Documents-v3.t2flow?version=3","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/18, /users/12548, /users/2780,","Kristina Hettne, Marco Roos, Reinout van Schouwen, Martijn Schuemie,","This workflow finds documents that serve as evidence for the association between two concepts. Results: Document titlesDocument identifiers Author comment: This workflow can be used together with other workflows in this pack:  <a rel=nofollow href=http://www.myexperiment.org/packs/282>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2972/versions/4.html","Find Supporting Documents","2012-06-2610:21:17","2014-07-1410:47:12","http://www.myexperiment.org/workflows/2972/download/Find_Supporting_Documents-v4.t2flow?version=4","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/18, /users/12548, /users/2780,","Kristina Hettne, Marco Roos, Reinout van Schouwen, Martijn Schuemie,","This workflow finds documents that serve as evidence for the association between two concepts. Results: Document titlesDocument identifiers Author comment: This workflow can be used together with other workflows in this pack:  <a rel=nofollow href=http://www.myexperiment.org/packs/282>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2972/versions/5.html","Find Supporting Documents","2012-06-2610:21:17","2014-07-1410:47:12","http://www.myexperiment.org/workflows/2972/download/Find_Supporting_Documents-v5.t2flow?version=5","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/18, /users/12548, /users/2780,","Kristina Hettne, Marco Roos, Reinout van Schouwen, Martijn Schuemie,","This workflow finds documents that serve as evidence for the association between two concepts. Results: Document titlesDocument identifiers",0, 0, ,
"http://www.myexperiment.org/workflows/2972/versions/6.html","Find Supporting Documents","2012-06-2610:21:17","2014-07-1410:47:12","http://www.myexperiment.org/workflows/2972/download/Find_Supporting_Documents-v6.t2flow?version=6","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/18, /users/12548, /users/2780,","Kristina Hettne, Marco Roos, Reinout van Schouwen, Martijn Schuemie,","This workflow finds documents that serve as evidence for the association between two concepts. Results: Document titlesDocument identifiers There seems to be a bug at the moment, since it returns empty values.",0, 0, ,
"http://www.myexperiment.org/workflows/2973/versions/1.html","SNPs to Concept Set through Concept Profile Matching v2","2012-06-2610:27:33","2013-02-0520:49:12","http://www.myexperiment.org/workflows/2973/download/SNPs_to_Concept_Set_through_Concept_Profile_Matching_v2-v1.t2flow?version=1","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/17730, /users/17633, /users/12548, /users/18, /users/2780,","Kristina Hettne, Eleni, Harish Dharuri, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","Purpose: Currently, this workflow takes one SNP and one GO process as input, calculates the matching score between these, finds the concept that contributes the most to the match, and the documents that support this finding. Author comments: The workflow is in Beta stage. It runs, but needs more testing with different parameter settings.",0, 0, ,
"http://www.myexperiment.org/workflows/2973/versions/2.html","SNPs to Concept Set through Concept Profile Matching v2","2012-06-2610:27:33","2013-02-0520:49:12","http://www.myexperiment.org/workflows/2973/download/SNPs_to_Concept_Set_through_Concept_Profile_Matching_v2-v2.t2flow?version=2","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/17730, /users/17633, /users/12548, /users/18, /users/2780,","Kristina Hettne, Eleni, Harish Dharuri, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","Purpose: Currently, this workflow takes one SNP and a concept set ID as input, calculates the matching score between the SNP and the concepts in the concept set, ranks the concepts in the concept set according to best match with the SNP, finds the concept that contributes the most to the match, and the documents that support this finding.  Author comments: The workflow is in Beta stage. It runs, but needs more testing with different parameter settings.",0, 0, ,
"http://www.myexperiment.org/workflows/2973/versions/3.html","SNPs to Concept Set through Concept Profile Matching v2","2012-06-2610:27:33","2013-02-0520:49:12","http://www.myexperiment.org/workflows/2973/download/SNPs_to_Concept_Set_through_Concept_Profile_Matching_v2-v3.t2flow?version=3","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/17730, /users/17633, /users/12548, /users/18, /users/2780,","Kristina Hettne, Eleni, Harish Dharuri, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","Purpose: Currently, this workflow takes one SNP and a concept set as input, calculates the matching score between these, finds co-occuring documents between the query concept and the match concept, finds the concept that contributes the most to the match, and the documents that support this finding.  Author comments: The workflow is in Beta stage. It runs, but needs more testing with different parameter settings.",0, 0, ,
"http://www.myexperiment.org/workflows/2973/versions/4.html","SNPs to Concept Set through Concept Profile Matching v2","2012-06-2610:27:33","2013-02-0520:49:12","http://www.myexperiment.org/workflows/2973/download/SNPs_to_Concept_Set_through_Concept_Profile_Matching_v2-v4.t2flow?version=4","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/17730, /users/17633, /users/12548, /users/18, /users/2780,","Kristina Hettne, Eleni, Harish Dharuri, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","Purpose: Currently, this workflow takes one SNP and a concept set as input, calculates the matching score between these, finds co-occuring documents between the query concept and the match concept, finds the concept that contributes the most to the match, and the documents that support this finding.  Author comments: The workflow is in Beta stage. It runs, but needs more testing with different parameter settings. This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2973/versions/5.html","SNPs to Concept Set through Concept Profile Matching v2","2012-06-2610:27:33","2013-02-0520:49:12","http://www.myexperiment.org/workflows/2973/download/SNPs_to_Concept_Set_through_Concept_Profile_Matching_v2-v5.t2flow?version=5","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/17730, /users/17633, /users/12548, /users/18, /users/2780,","Kristina Hettne, Eleni, Harish Dharuri, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","Purpose: Currently, this workflow takes one SNP and a concept set as input, calculates the matching score between these, finds co-occuring documents between the query concept and the match concept, finds the concept that contributes the most to the match, and the documents that support this finding. Author comments: The workflow is in Beta stage. It runs, but needs more testing with different parameter settings. This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2973/versions/6.html","SNPs to Concept Set through Concept Profile Matching v2","2012-06-2610:27:33","2013-02-0520:49:12","http://www.myexperiment.org/workflows/2973/download/SNPs_to_Concept_Set_through_Concept_Profile_Matching_v2-v6.t2flow?version=6","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/17730, /users/17633, /users/12548, /users/18, /users/2780,","Kristina Hettne, Eleni, Harish Dharuri, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","Purpose: Currently, this workflow takes one SNP and a concept set as input, calculates the matching score between these, finds co-occuring documents between the query concept and the match concept, finds the concept that contributes the most to the match, and the documents that support this finding. Author comments: The workflow is in Beta stage. It runs, but needs more testing with different parameter settings. This workflow can be used together with other workflows in this pack:  <a rel=nofollow href=http://www.myexperiment.org/packs/282>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2980/versions/1.html","VOTables from NED Web Services","2012-06-2818:08:20","2013-04-1223:04:37","http://www.myexperiment.org/workflows/2980/download/VOTables_from_NED_Web_Services-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","Extraction of a sample of VOTables from all the NED Web Services present in paper&nbsp; <a href=http://adsabs.harvard.edu/abs/2007ASPC..382..165M rel=nofollow>2007ASPC..382..165M</a> &nbsp;Web-based Tools -&nbsp;NED VO Services (Mazzarella, J. M.; NED Team). The National Virtual Observatory: Tools and Techniques for Astronomical Research. ASP Conference Series, Vol. 382. Edited by M.J. Graham, M.J. Fitzpatrick, and T.A. McGlynn. San Francisco: Astronomical Society of the Pacific, 2007., p.165",-1, 0, ,
"http://www.myexperiment.org/workflows/2981/versions/1.html","Simple executable plan example","2012-06-2915:48:43","","http://www.myexperiment.org/workflows/2981/download/Simple_executable_plan_example-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","A simple executable plan containing a migration action component and a QA component. The migration action uses imagemagick convert. The QA component consists of two characterisation components (fits) and another QA components (imagemagick compare).",0, 0, ,
"http://www.myexperiment.org/workflows/2982/versions/1.html","Astronomical object name to equatorial coordinates Resolver","2012-06-3017:06:50","2012-07-0111:51:11","http://www.myexperiment.org/workflows/2982/download/Astronomical_object_name_to_equatorial_coordinates_Resolver-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","&nbsp;Resolve equatorial coordinates of a list of objects (names) with AstroTaverna plugin",-1, 0, ,
"http://www.myexperiment.org/workflows/2983/versions/1.html","VOTable of NED Images from a List of Objects","2012-07-0111:45:05","2012-07-0111:54:24","http://www.myexperiment.org/workflows/2983/download/VOTable_of_NED_Images_from_a_List_of_Objects-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","Extraction of metadata using NED Image Virtual Observatory Service into a single VOTable, providing a list of objects and the width for each field in arcmin. Among the most relevant metadata are the URL link to the FITS images. This Wf makes use of a Tool developed as an internal pyhton script file.",-1, 0, ,
"http://www.myexperiment.org/workflows/2986/versions/1.html","Get all applications available on the HPS","2012-07-0313:26:33","","http://www.myexperiment.org/workflows/2986/download/Get_all_applications_available_on_the_HPS-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow requests all available applications on the HPS which do not require authentication to run. No inputs.Outputs contain all information to execute the application on the HPS such as the ID of the application and the names of all parameters.",0, 0, ,
"http://www.myexperiment.org/workflows/2992/versions/1.html","Task Data Pattern (BeanShell)","2012-07-0611:48:01","","http://www.myexperiment.org/workflows/2992/download/Task_Data_Pattern__BeanShell_-v1.t2flow?version=1","/users/21620","Bamdad Dashtban","taverna 2","","","This is a sample implementation of Task Data pattern intoduced workflowPatterns.comIt defines a variable inside a Beanshell and uses the passed value through the processors input.Details: <a href=http://www.workflowpatterns.com/patterns/data/visibility/wdp1.php rel=nofollow>http://www.workflowpatterns.com/patterns/data/visibility/wdp1.php</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/2997/versions/1.html","Get Concept IDs","2012-07-0614:17:35","2014-07-1411:04:55","http://www.myexperiment.org/workflows/2997/download/Get_Concept_IDs-v1.t2flow?version=1","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/2780, /users/18,","Kristina Hettne, Reinout van Schouwen, Martijn Schuemie, Marco Roos,","The workflow takes as input the internal ID of a Concept Set and gives a list of Concept IDs contained within the set as output.",0, 0, ,
"http://www.myexperiment.org/workflows/2997/versions/2.html","Get Concept IDs","2012-07-0614:17:35","2014-07-1411:04:55","http://www.myexperiment.org/workflows/2997/download/Get_Concept_IDs-v2.t2flow?version=2","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/2780, /users/18,","Kristina Hettne, Reinout van Schouwen, Martijn Schuemie, Marco Roos,","The workflow takes as input the internal ID of a Concept Set and gives a list of Concept IDs contained within the set as output.",0, 0, ,
"http://www.myexperiment.org/workflows/2997/versions/3.html","Get Concept IDs","2012-07-0614:17:35","2014-07-1411:04:55","http://www.myexperiment.org/workflows/2997/download/Get_Concept_IDs-v3.t2flow?version=3","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/2780, /users/18,","Kristina Hettne, Reinout van Schouwen, Martijn Schuemie, Marco Roos,","Purpose: The workflow retrieves the concepts within a concept set. Author comments: This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2997/versions/4.html","Get Concept IDs","2012-07-0614:17:35","2014-07-1411:04:55","http://www.myexperiment.org/workflows/2997/download/Get_Concept_IDs-v4.t2flow?version=4","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/2780, /users/18,","Kristina Hettne, Reinout van Schouwen, Martijn Schuemie, Marco Roos,","Purpose: The workflow retrieves the concepts within a concept set. Author comments: This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2997/versions/5.html","Get Concept IDs","2012-07-0614:17:35","2014-07-1411:04:55","http://www.myexperiment.org/workflows/2997/download/Get_Concept_IDs-v5.t2flow?version=5","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/2780, /users/18,","Kristina Hettne, Reinout van Schouwen, Martijn Schuemie, Marco Roos,","Purpose: The workflow retrieves the concepts within a concept set. The Web service/workflow currently returns no values (bug).",0, 0, ,
"http://www.myexperiment.org/workflows/2998/versions/1.html","Get concept information","2012-07-0614:20:40","2014-07-1411:18:46","http://www.myexperiment.org/workflows/2998/download/Get_concept_information-v1.t2flow?version=1","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/18, /users/2780,","Kristina Hettne, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","The workflow takes a concept ID as input and returns the ID, definition and name of the concept.",0, 0, ,
"http://www.myexperiment.org/workflows/2998/versions/2.html","Get concept information","2012-07-0614:20:40","2014-07-1411:18:46","http://www.myexperiment.org/workflows/2998/download/Get_concept_information-v2.t2flow?version=2","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/18, /users/2780,","Kristina Hettne, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","The workflow takes a concept ID as input and returns the ID, definition and name of the concept. This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2998/versions/3.html","Get concept information","2012-07-0614:20:40","2014-07-1411:18:46","http://www.myexperiment.org/workflows/2998/download/Get_concept_information-v3.t2flow?version=3","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/18, /users/2780,","Kristina Hettne, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","The workflow takes a concept ID as input and returns the ID, definition and name of the concept. This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2998/versions/4.html","Get concept information","2012-07-0614:20:40","2014-07-1411:18:46","http://www.myexperiment.org/workflows/2998/download/Get_concept_information-v4.t2flow?version=4","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/18, /users/2780,","Kristina Hettne, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","The workflow takes a concept ID as input and returns the ID, definition and name of the concept. This workflow can be used together with other workflows in this pack:  <a rel=nofollow href=http://www.myexperiment.org/packs/282>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2998/versions/5.html","Get concept information","2012-07-0614:20:40","2014-07-1411:18:46","http://www.myexperiment.org/workflows/2998/download/Get_concept_information-v5.t2flow?version=5","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/18, /users/2780,","Kristina Hettne, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","The workflow takes a (list of) concept ID(s) as input and returns the profile, ID, definition and name of the concept.",0, 0, ,
"http://www.myexperiment.org/workflows/2999/versions/1.html","List Concept Sets","2012-07-0614:25:52","2014-07-1411:00:55","http://www.myexperiment.org/workflows/2999/download/List_Concept_Sets-v1.t2flow?version=1","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/18, /users/12548, /users/2780,","Kristina Hettne, Marco Roos, Reinout van Schouwen, Martijn Schuemie,","The workflow returns a list of all Concept Set IDs currently available in the database. The Concept Sets have an hierarchical structure that can be inferred by referring to the parent Concept Set ID.",0, 0, ,
"http://www.myexperiment.org/workflows/2999/versions/2.html","List Concept Sets","2012-07-0614:25:52","2014-07-1411:00:55","http://www.myexperiment.org/workflows/2999/download/List_Concept_Sets-v2.t2flow?version=2","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/18, /users/12548, /users/2780,","Kristina Hettne, Marco Roos, Reinout van Schouwen, Martijn Schuemie,","Pupose: The workflow returns a list of all Concept Set IDs currently available in the database. The Concept Sets have an hierarchical structure that can be inferred by referring to the parent Concept Set ID. Author comments: This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/2999/versions/3.html","List Concept Sets","2012-07-0614:25:52","2014-07-1411:00:55","http://www.myexperiment.org/workflows/2999/download/List_Concept_Sets-v3.t2flow?version=3","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/18, /users/12548, /users/2780,","Kristina Hettne, Marco Roos, Reinout van Schouwen, Martijn Schuemie,","Pupose: The workflow returns a list of all Concept Set IDs currently available in the database. The Concept Sets have an hierarchical structure that can be inferred by referring to the parent Concept Set ID.",0, 0, ,
"http://www.myexperiment.org/workflows/3001/versions/1.html","Gene to Pathways","2012-07-0918:27:21","2012-07-1008:02:44","http://www.myexperiment.org/workflows/3001/download/Gene_to_Pathways-v1.t2flow?version=1","/users/204","Khalid Belhajjame","taverna 2","/users/204,","Khalid Belhajjame,","This is a Taverna workflow that given a gene ID fetches the corespondondings pathways. To do so, the workflow make use of two KEGG web services.",-1, 0, ,
"http://www.myexperiment.org/workflows/3006/versions/1.html","Find co-occurring documents","2012-07-1307:45:39","2014-07-1410:29:26","http://www.myexperiment.org/workflows/3006/download/Find_co-occurring_documents-v1.t2flow?version=1","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/18, /users/2780,","Kristina Hettne, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","This workflow search an indexed literature database for documents mentioning both of the input concepts.",0, 0, ,
"http://www.myexperiment.org/workflows/3006/versions/2.html","Find co-occurring documents","2012-07-1307:45:39","2014-07-1410:29:26","http://www.myexperiment.org/workflows/3006/download/Find_co-occurring_documents-v2.t2flow?version=2","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/18, /users/2780,","Kristina Hettne, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","Purpose:This workflow search an indexed literature database for documents mentioning both of the input concepts. Author comments: This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/3006/versions/3.html","Find co-occurring documents","2012-07-1307:45:39","2014-07-1410:29:26","http://www.myexperiment.org/workflows/3006/download/Find_co-occurring_documents-v3.t2flow?version=3","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/18, /users/2780,","Kristina Hettne, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","Purpose:This workflow search an indexed literature database for documents mentioning both of the input concepts. Author comments: This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/3006/versions/4.html","Find co-occurring documents","2012-07-1307:45:39","2014-07-1410:29:26","http://www.myexperiment.org/workflows/3006/download/Find_co-occurring_documents-v4.t2flow?version=4","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/18, /users/2780,","Kristina Hettne, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","Purpose:This workflow search an indexed literature database for documents mentioning both of the input concepts. Author comments: This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/3006/versions/5.html","Find co-occurring documents","2012-07-1307:45:39","2014-07-1410:29:26","http://www.myexperiment.org/workflows/3006/download/Find_co-occurring_documents-v5.t2flow?version=5","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/18, /users/2780,","Kristina Hettne, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","Purpose:This workflow search an indexed literature database for documents mentioning both of the input concepts. Author comments: This workflow can be used together with other workflows in this pack:  <a rel=nofollow href=http://www.myexperiment.org/packs/282>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/3006/versions/6.html","Find co-occurring documents","2012-07-1307:45:39","2014-07-1410:29:26","http://www.myexperiment.org/workflows/3006/download/Find_co-occurring_documents-v6.t2flow?version=6","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/18, /users/2780,","Kristina Hettne, Reinout van Schouwen, Marco Roos, Martijn Schuemie,","Purpose:This workflow search an indexed literature database for documents mentioning both of the input concepts. Author comments: Currently, PubMed is the underlying data source.",0, 0, ,
"http://www.myexperiment.org/workflows/3012/versions/1.html","Example of how to use Sesame service and Virtual Observatory services","2012-07-1418:23:39","","http://www.myexperiment.org/workflows/3012/download/Example_of_how_to_use_Sesame_service_and_Virtual_Observatory_services-v1.t2flow?version=1","/users/19173","Susana","taverna 2","","","This workflow needs as input a list of names of galaxies. Then it queries Sesame services to get the coordinates of this galaxies, and finally with this coordinates queries a Virtual Observatory Services (a cone service).",0, 0, ,
"http://www.myexperiment.org/workflows/3039/versions/1.html","Check registry for wrongly registed and un registered HEC tables","2012-07-2414:29:17","2012-07-2414:36:29","http://www.myexperiment.org/workflows/3039/download/Check_registry_for_wrongly_registed_and_un_registered_HEC_tables-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","HELIO registry contains a list of tables available in the HEC. The HEC contains a table with available talbes itself. This workflow shows the differences between these two lists.",0, 0, ,
"http://www.myexperiment.org/workflows/3039/versions/2.html","Check registry for wrongly registed and un registered HEC tables","2012-07-2414:29:17","2012-07-2414:36:29","http://www.myexperiment.org/workflows/3039/download/Check_registry_for_wrongly_registed_and_un_registered_HEC_tables-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","HELIO registry contains a list of tables available in the HEC. The HEC contains a table with available talbes itself. This workflow shows the differences between these two lists.",0, 0, ,
"http://www.myexperiment.org/workflows/3040/versions/1.html","Check the content of the Registry for mismaches of content of UOC","2012-07-2509:17:50","","http://www.myexperiment.org/workflows/3040/download/Check_the_content_of_the_Registry_for_mismaches_of_content_of_UOC-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow check for tables which are registered in the HELIO registry but not available in the UOC and for tables which are in the UOC but which are not registred.",0, 0, ,
"http://www.myexperiment.org/workflows/3044/versions/1.html","Create configuration files from a template and a votable","2012-07-2610:56:46","2012-09-0407:30:55","http://www.myexperiment.org/workflows/3044/download/Create_configuration_files_from_a_template_and_a_votable_-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","This workflow uses astrotaverna artifacts. It creates files by using a template whose keys are replaced by data from a votable. A configuration file is created for every row in the votable. The keys must appear also in the vocabulary file and match column names in the votable. A column in the votable must contain the name of the result configuration file.",-1, 0, ,
"http://www.myexperiment.org/workflows/3046/versions/1.html","Run sextractor using a votable","2012-07-2611:23:30","2012-09-0712:25:41","http://www.myexperiment.org/workflows/3046/download/Run_sextractor_using_a_votable-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","It runs sextractor and adjust the paramenters specified.  This workflow has a dependency on the stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ).  Sextractor is called by an bash script as 'sex'.  Sextractor is called for every row in the votable. Columns where the configuration file and the image file name are defined must be especified.  These files should be accesibles from taverna.  ExperimentFolder provides the root folder for the experiment.  If the configuration files contain references to other files, they must be accesible from taverna.",0, 0, ,
"http://www.myexperiment.org/workflows/3046/versions/2.html","Run sextractor using a votable","2012-07-2611:23:30","2012-09-0712:25:41","http://www.myexperiment.org/workflows/3046/download/Run_sextractor_using_a_votable-v2.t2flow?version=2","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","It runs sextractor and adjust the paramenters specified.This workflow has a dependency on the stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ).Sextractor is called by an bash script as 'sex'.Sextractor is called for every row in the votable.Columns where the configuration file and the image file name are defined must be especified.These files should be accesibles from taverna.ExperimentFolder provides the root folder for the experiment.If the configuration files contain references to other files, they must be accesible from taverna.",0, 0, ,
"http://www.myexperiment.org/workflows/3047/versions/1.html","Create votable from sextractor results","2012-07-2611:39:53","2012-08-2108:20:36","http://www.myexperiment.org/workflows/3047/download/Create_votable_from_sextractor_results-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","The workflow creates a votable from the results provided by sextractor.  It returns this table and an aditional table that is joined to the input table.  It requires a votable that contains a column with the file name resulting from running sextractor and such files must be accesible from taverna.  It uses astrotaverna plugin  ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3047/versions/2.html","Create votable from sextractor results","2012-07-2611:39:53","2012-08-2108:20:36","http://www.myexperiment.org/workflows/3047/download/Create_votable_from_sextractor_results-v2.t2flow?version=2","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","The workflow creates a votable from the results provided by sextractor (votables).It returns this table and an aditional table that is joined to the input table.It requires a votable that contains a column with the file name resulting from running sextractor and such files accesible from taverna.It uses astrotaverna plugin  ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3048/versions/1.html","Ajusting galaxy paramenters using sextractor","2012-07-2612:02:48","2012-09-0712:29:00","http://www.myexperiment.org/workflows/3048/download/Ajusting_galaxy_paramenters_using_sextractor-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","This workflow creates configuration files for sextractor, it runs sextractor using this configuration files, it adds sextractor results to the input votable and adds new calculated columns.  This task requires a votable as input, a template, a vocabulary and the specification of the column names that contain some required files (configuration files, image files, ...). These files must be accesible from taverna. Sextractor is called by an bash script as 'sex'. Every row in the votable cotains information for an object i.e a galaxy. The subworkflows have dependencies on astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ) and stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3048/versions/2.html","Ajusting galaxy paramenters using sextractor","2012-07-2612:02:48","2012-09-0712:29:00","http://www.myexperiment.org/workflows/3048/download/Ajusting_galaxy_paramenters_using_sextractor-v2.t2flow?version=2","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","This workflow creates configuration files for sextractor, it runs sextractor using this configuration files, it adds sextractor results to the input votable and adds new calculated columns.This task requires a votable as input, a template, a vocabulary and the specification of the column names that contain some required files (configuration files, image files, ...). These files must be accesible from taverna.Sextractor is called by an bash script as 'sex'. Every row in the votable cotains information for an object i.e a galaxy.The subworkflows has dependencies on astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ) and stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3048/versions/3.html","Ajusting galaxy paramenters using sextractor","2012-07-2612:02:48","2012-09-0712:29:00","http://www.myexperiment.org/workflows/3048/download/Ajusting_galaxy_paramenters_using_sextractor-v3.t2flow?version=3","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","This workflow creates configuration files for sextractor, it runs sextractor using this configuration files, it adds sextractor results to the input votable and adds new calculated columns.  This task requires a votable as input, a template, a vocabulary and the specification of the column names that contain some required files (configuration files, image files, ...). These files must be accesible from taverna. Sextractor is called by an bash script as 'sex'. Every row in the votable cotains information for an object i.e a galaxy. The subworkflows have dependencies on astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ) and stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3048/versions/4.html","Ajusting galaxy paramenters using sextractor","2012-07-2612:02:48","2012-09-0712:29:00","http://www.myexperiment.org/workflows/3048/download/Ajusting_galaxy_paramenters_using_sextractor-v4.t2flow?version=4","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","This workflow creates configuration files for sextractor, it runs sextractor using this configuration files, it adds sextractor results to the input votable and adds new calculated columns.  This task requires a votable as input, a template, a vocabulary and the specification of the column names that contain some required files (configuration files, image files, ...). These files must be accesible from taverna. Sextractor is called by an bash script as 'sex'. Every row in the votable cotains information for an object i.e a galaxy. The subworkflows have dependencies on astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ) and stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3048/versions/5.html","Ajusting galaxy paramenters using sextractor","2012-07-2612:02:48","2012-09-0712:29:00","http://www.myexperiment.org/workflows/3048/download/Ajusting_galaxy_paramenters_using_sextractor-v5.t2flow?version=5","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","This workflow creates configuration files for sextractor, it runs sextractor using this configuration files, it adds sextractor results to the input votable and adds new calculated columns.This task requires a votable as input, a template, a vocabulary and the specification of the column names that contain some required files (configuration files, image files, ...). These files must be accesible from taverna.Sextractor is called by an bash script as 'sex'. Every row in the votable cotains information for an object i.e a galaxy.The subworkflows have dependencies on astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ) and stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3049/versions/1.html","Run galfit using a votable","2012-07-2612:20:52","2012-09-0712:39:42","http://www.myexperiment.org/workflows/3049/download/Run_galfit_using_a_votable-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","It runs galfit and adjust the paramenters specified. This workflow has a dependency on the stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ). Galfit is called by a bash script as 'galfit'. Galfit is called for every row in the votable. Columns where the result file name and the configuration file name are defined must be especified. These files should be accesibles from taverna. ExperimentFolder provides the root folder for the experiment. If the configuration files contain references to other files, they must be accesible from taverna.",0, 0, ,
"http://www.myexperiment.org/workflows/3049/versions/2.html","Run galfit using a votable","2012-07-2612:20:52","2012-09-0712:39:42","http://www.myexperiment.org/workflows/3049/download/Run_galfit_using_a_votable-v2.t2flow?version=2","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","It runs galfit and adjust the paramenters specified. This workflow has a dependency on the stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ). Galfit is called by a bash script as 'galfit'. Galfit is called for every row in the votable. Columns where the result file name and the configuration file name are defined must be especified. These files should be accesibles from taverna. ExperimentFolder provides the root folder for the experiment. If the configuration files contain references to other files, they must be accesible from taverna.",0, 0, ,
"http://www.myexperiment.org/workflows/3050/versions/1.html","Create votable from galfit results","2012-07-2612:27:41","2012-09-0712:47:12","http://www.myexperiment.org/workflows/3050/download/Create_votable_from_galfit_results_-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","The workflow creates a votable from the results provided by galfit. It returns this table and an aditional table that is joined to the input table. It requires a votable that contains a column with the file name resulting from running galfit and such files must be accesible from taverna. It uses astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ) and it has a dependency on stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3050/versions/2.html","Create votable from galfit results","2012-07-2612:27:41","2012-09-0712:47:12","http://www.myexperiment.org/workflows/3050/download/Create_votable_from_galfit_results_-v2.t2flow?version=2","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","The workflow creates a votable from the results provided by galfit. It returns this table and an aditional table that is joined to the input table. It requires a votable that contains a column with the file name resulting from running galfit and such files must be accesible from taverna. It uses astrotaverna plugin ( <a rel=nofollow href=http://wf4ever.github.com/astrotaverna/>http://wf4ever.github.com/astrotaverna/</a> ) and it has a dependency on stil library ( <a rel=nofollow href=http://www.star.bris.ac.uk/~mbt/stil/>http://www.star.bris.ac.uk/~mbt/stil/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3050/versions/3.html","Create votable from galfit results","2012-07-2612:27:41","2012-09-0712:47:12","http://www.myexperiment.org/workflows/3050/download/Create_votable_from_galfit_results_-v3.t2flow?version=3","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","The workflow creates a votable from the results provided by galfit. It returns this table and an aditional table that is joined to the input table. It requires a votable that contains a column with the file name resulting from running galfit and such files must be accesible from taverna. It uses astrotaverna plugin ( <a rel=nofollow href=http://wf4ever.github.com/astrotaverna/>http://wf4ever.github.com/astrotaverna/</a> ) and it has a dependency on stil library ( <a rel=nofollow href=http://www.star.bris.ac.uk/~mbt/stil/>http://www.star.bris.ac.uk/~mbt/stil/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3050/versions/4.html","Create votable from galfit results","2012-07-2612:27:41","2012-09-0712:47:12","http://www.myexperiment.org/workflows/3050/download/Create_votable_from_galfit_results_-v4.t2flow?version=4","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","The workflow creates a votable from the results provided by galfit. It returns this table and an aditional table that is joined to the input table. It requires a votable that contains a column with the file name resulting from running galfit and such files must be accesible from taverna. It uses astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ) and it has a dependency on stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3051/versions/1.html","Create galfit configuration files with partition criteria using votable","2012-07-2612:41:51","2012-07-2612:44:09","http://www.myexperiment.org/workflows/3051/download/Create_galfit_configuration_files_with_partition_criteria_using_votable-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","This workflow creates galfit configuration files using a partition criteria. The resulting configuration files are different depending on whether the galaxy has o doesn't have a bar.  They are created (one for every row in the votable) using a template whose keys are replaced by data from a votable. Keys must appear also in the vocabulary file and match column names in the votable. A column in the votable must contain the name of the result configuration file. This workflow uses astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3052/versions/1.html","Adjusting galaxy parameters using galfit","2012-07-2612:56:18","2012-09-0712:57:59","http://www.myexperiment.org/workflows/3052/download/Adjusting_galaxy_parameters_using_galfit-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","This workflow creates galfit configuration files using data from a votable, it runs galfit, its results is added to the votable, it creates new config files for galfit using the previous results and it runs galfit a second time considering galaxies that have and do not have bars in order to adjust the objective parameters. It requires the specification of the columns that contain file names (these files should be accesibles from taverna). If the configuration files contain references to other files, they must be accesible from taverna. Configuration files are created (one for every row in the votable) using a template whose keys are replaced by data from a votable. Keys must appear also in the vocabulary file and match column names in the votable. It uses astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ) and it has a dependency on stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3052/versions/2.html","Adjusting galaxy parameters using galfit","2012-07-2612:56:18","2012-09-0712:57:59","http://www.myexperiment.org/workflows/3052/download/Adjusting_galaxy_parameters_using_galfit-v2.t2flow?version=2","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","This workflow creates galfit configuration files using data from a votable, it runs galfit, its results is added to the votable, it creates new config files for galfit using the previous results, it runs galfit a second time considering galaxies that have and do not have bars in order to adjust the objective parameters and it finally includes the results into the votable. It requires the specification of the columns that contain file names (these files should be accesibles from taverna). If the configuration files contain references to other files, they must be accesible from taverna. Configuration files are created (one for every row in the votable) using a template whose keys are replaced by data from a votable. Keys must appear also in the vocabulary file and match column names in the votable. It uses astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ) and it has a dependency on stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3052/versions/3.html","Adjusting galaxy parameters using galfit","2012-07-2612:56:18","2012-09-0712:57:59","http://www.myexperiment.org/workflows/3052/download/Adjusting_galaxy_parameters_using_galfit-v3.t2flow?version=3","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","This workflow creates galfit configuration files using data from a votable, it runs galfit, its results is added to the votable, it creates new config files for galfit using the previous results, it runs galfit a second time considering galaxies that have and do not have bars in order to adjust the objective parameters and it finally includes the results into the votable. It requires the specification of the columns that contain file names (these files should be accesibles from taverna). If the configuration files contain references to other files, they must be accesible from taverna.Configuration files are created (one for every row in the votable) using a template whose keys are replaced by data from a votable.Keys must appear also in the vocabulary file and match column names in the votable.It uses astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ) and it has a dependency on stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3052/versions/4.html","Adjusting galaxy parameters using galfit","2012-07-2612:56:18","2012-09-0712:57:59","http://www.myexperiment.org/workflows/3052/download/Adjusting_galaxy_parameters_using_galfit-v4.t2flow?version=4","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","This workflow creates galfit configuration files using data from a votable, it runs galfit, its results is added to the votable, it creates new config files for galfit using the previous results, it runs galfit a second time considering galaxies that have and do not have bars in order to adjust the objective parameters and it finally includes the results into the votable. It requires the specification of the columns that contain file names (these files should be accesibles from taverna). If the configuration files contain references to other files, they must be accesible from taverna.Configuration files are created (one for every row in the votable) using a template whose keys are replaced by data from a votable.Keys must appear also in the vocabulary file and match column names in the votable.It uses astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ) and it has a dependency on stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3053/versions/1.html","Check the content of the Registry for mismaches to content of HFC","2012-07-2614:29:14","","http://www.myexperiment.org/workflows/3053/download/Check_the_content_of_the_Registry_for_mismaches_to_content_of_HFC-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow check for tables which are registered in the HELIO registry but not available in the HFC and for tables which are in the UOC but which are not registred.",0, 0, ,
"http://www.myexperiment.org/workflows/3054/versions/1.html","Extract SDSS field information and PSF","2012-07-2617:59:02","2012-09-0710:21:26","http://www.myexperiment.org/workflows/3054/download/Extract_SDSS_field_information_and_PSF-v1.t2flow?version=1","/users/19173","Susana","taverna 2","/users/19173,","Susana,","This workflow download from SDSS the information about the field of the image. It receives as a input a table. Each row of this table has information of one image, specifically it contains run, rerun, camcol and field, needed to query SDSS and get the saturation, gain, Extinction coefficient, Zero-point. The workflow also get the band of the image from its header and build a new table with all this data, needed for applications like Sextractor.",-1, 0, ,
"http://www.myexperiment.org/workflows/3054/versions/2.html","Extract SDSS field information and PSF","2012-07-2617:59:02","2012-09-0710:21:26","http://www.myexperiment.org/workflows/3054/download/Extract_SDSS_field_information_and_PSF-v2.t2flow?version=2","/users/19173","Susana","taverna 2","/users/19173,","Susana,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3054/versions/3.html","Extract SDSS field information and PSF","2012-07-2617:59:02","2012-09-0710:21:26","http://www.myexperiment.org/workflows/3054/download/Extract_SDSS_field_information_and_PSF-v3.t2flow?version=3","/users/19173","Susana","taverna 2","/users/19173,","Susana,","This workflow gathers information needed by the execution of Sextractor, Galfit and Ellipse, from the SDSS VO service. It receives as input a ascii table with 10 columns: <br /> - Coordinates: Right Ascension, Declination <br /> - Data of the field: run, rerun, camcol and field <br /> - Path of the fits image. <br /> - A value to indicate if the galaxy is barred or not. A 0 if it is not barred and 1 if it is barred. <br /> - Path where the psfield file will be downloaded. <br /> - Path where the psf file wil be generated. <br /> <br /> The workflow generates paths of some files that should be provided to Sextractor, Galfit or Ellipse. This paths are generated using the path of the image as suffix, and creating this structure: <br /> +Eliipse: which will contain the files needed to execute Ellipse <br /> +Galfit: which will contain the files needed to execute Galfit <br /> +Plots: which will contain the plots that will be generates <br /> +psf: which will contain the psf files  <br /> +Sex: which will contain the files needed to execute Sextractor <br /> +votables: which will contain the votables with the information obtained from the execution of the applications. <br /> <br /> This workflow extract the band from the image header, and&nbsp; the information about the field (kk, saturation, aa, airmass, gain) from the SDSS DR7 drfield VO service. <br /> The psfield file is downloaded in the path provided in the input ascii table, and the program &quot;read_psf&quot; is executed to extract the psf field corresponding with the specific band of the image. <br /> <br /> The output of this workflow is made up of 14 lists: <br /> - Filenames: Paths where store files that are going to be generated (i.e. the output file of Sextractor) <br /> - psf: Paths where the psf files have been stored. <br /> - Band: List of bands correspondig to the image <br /> - image: List of paths of images <br /> - nx and ny: NAXIS1 and NAXIS2 <br /> - kk : List of&nbsp; extinction coefficient values <br /> - saturation: List of saturation level values <br /> - aa: List of&nbsp; zero-point values <br /> - airmass: List of airmass values <br /> - gain: List of Gain Averaged over Amplifiers values <br /> - ra,dec: List of coordinates <br /> - Bar: list of 1/0 indicating if the image of the corresponding row is barred or not",-1, 0, ,
"http://www.myexperiment.org/workflows/3054/versions/4.html","Extract SDSS field information and PSF","2012-07-2617:59:02","2012-09-0710:21:26","http://www.myexperiment.org/workflows/3054/download/Extract_SDSS_field_information_and_PSF-v4.t2flow?version=4","/users/19173","Susana","taverna 2","/users/19173,","Susana,","This workflow gathers information needed by the execution of Sextractor, Galfit and Ellipse, from the SDSS VO service. It receives as input a ascii table with 10 columns: - Coordinates: Right Ascension, Declination- Data of the field: run, rerun, camcol and field- Path of the fits image.- A value to indicate if the galaxy is barred or not. A 0 if it is not barred and 1 if it is barred.- Path where the psfield file will be downloaded.- Path where the psf file wil be generated. The workflow generates paths of some files that should be provided to Sextractor, Galfit or Ellipse. This paths are generated using the path of the image as suffix, and creating this structure: +Eliipse: which will contain the files needed to execute Ellipse+Galfit: which will contain the files needed to execute Galfit+Plots: which will contain the plots that will be generates+psf: which will contain the psf files+Sex: which will contain the files needed to execute Sextractor+votables: which will contain the votables with the information obtained from the execution of the applications. This workflow extract the band from the image header, and  the information about the field (kk, saturation, aa, airmass, gain) from the SDSS DR7 drfield VO service.The psfield file is downloaded in the path provided in the input ascii table, and the program read_psf is executed to extract the psf field corresponding with the specific band of the image. The output of this workflow is made up of 14 lists: - Filenames: Paths where store files that are going to be generated (i.e. the output file of Sextractor)- psf: Paths where the psf files have been stored.- Band: List of bands correspondig to the image- image: List of paths of images- nx and ny: NAXIS1 and NAXIS2- kk : List of  extinction coefficient values- saturation: List of saturation level values- aa: List of  zero-point values- airmass: List of airmass values- gain: List of Gain Averaged over Amplifiers values- ra,dec: List of coordinates- Bar: list of 1/0 indicating if the image of the corresponding row is barred or not",0, 0, ,
"http://www.myexperiment.org/workflows/3054/versions/5.html","Extract SDSS field information and PSF","2012-07-2617:59:02","2012-09-0710:21:26","http://www.myexperiment.org/workflows/3054/download/Extract_SDSS_field_information_and_PSF-v5.t2flow?version=5","/users/19173","Susana","taverna 2","/users/19173,","Susana,","This workflow gathers information needed by the execution of Sextractor, Galfit and Ellipse, from the SDSS VO service. It receives two inputs: 1) An ascii table with information about the image such as data of the field, name of the fits file or if it is barred or not.2) A configuration file with the paths where the files needed by the workflow can be found and other paths where to store the files generated by the workflow This workflow extracts the band from the image header, and  the information about the field (kk, saturation, aa, airmass, gain) from the SDSS DR7 drfield VO service.Then it downloads the psfield file into the path provided by the configuration file, and it runs the program read_psf in order to build the psf file corresponding with the specific band of the image. The output of this workflow is made up of 13 lists: - Filenames: Paths where store files that are going to be generated (i.e. the output file of Sextractor)- psf: Paths where the psf files have been stored.- Band: List of bands correspondig to the image- nx and ny: NAXIS1 and NAXIS2- kk : List of  extinction coefficient values- saturation: List of saturation level values- aa: List of  zero-point values- airmass: List of airmass values- gain: List of Gain Averaged over Amplifiers values- ra,dec: List of coordinates- Bar: list of 1/0 indicating if the image of the corresponding row is barred or not",0, 0, ,
"http://www.myexperiment.org/workflows/3055/versions/1.html","Genome variant to Protein change","2012-07-2711:26:11","2012-10-2910:35:52","http://www.myexperiment.org/workflows/3055/download/Genome_variant_to_Protein_change-v1.t2flow?version=1","/users/20993","Helen Hulme","taverna 2","/users/20993,","Helen Hulme,","Reports protein change, given a genomic variant, using mutalyzer",0, 0, ,
"http://www.myexperiment.org/workflows/3056/versions/1.html","Find Duplicates using Matchbox command line tool","2012-07-3111:00:21","2012-07-3111:35:12","http://www.myexperiment.org/workflows/3056/download/Find_Duplicates_using_Matchbox_command_line_tool-v1.t2flow?version=1","/users/17168","Roman","taverna 2","/users/17168,","Roman,","The workflow takes a list of digital documents as input, extracts SIFT features using image processing algorithms, creates dictionary of visual words, generates BoW (Bag of Words) histogramms and finds duplicates. The count of parallel threads can be passed as a parameter. Finally search results are stored in a text file that contains a list of possible duplicates with associated similarity score. This score values are spread between 0 (low similarity) and 1 (high similarity). Image comparison is performed by Matchbox command line tool and associated python scripts. The sources of the Matchbox tool are located in  <a href=https://github.com/openplanets/scape/tree/master/pc-qa-matchbox rel=nofollow>https://github.com/openplanets/scape/tree/master/pc-qa-matchbox</a> .",-1, 0, ,
"http://www.myexperiment.org/workflows/3057/versions/1.html","Plasma Precipitation Analysis","2012-07-3116:04:54","2012-07-3116:16:40","http://www.myexperiment.org/workflows/3057/download/Plasma_Precipitation_Analysis-v1.t2flow?version=1","/users/23068","Magnus Palmblad","taverna 2","/users/23068, /users/57863, /users/17146,","Magnus Palmblad, Kate Mostovenko, Yassene,","ABOUT THE WORKFLOW  This workflow was used to analyze the data in a manuscript  by Mostovenko et al. (2012, submitted), comparing proteins in the precipitate with those left in solution after organic solvent precipitation. However, the workflow is generally applicable in comparisons of any binary fractionation method in proteomics, where the fractions are analyzed by liquid chromatography-tandem mass spectrometry.  The workflow identifies proteins by SpectraST spectral library search and X!Tandem database search, validates the results using PeptideProphet and combines them with InterProphet. The proteins are quantified by spectral counting and the fractions compared with respect to protein molecular weight, isoelectric point and GRAVY hydrophobicity score. In the end, an Rshell script produces the figures as presented in the manuscript.  Executing the workflow requires Rserve running and the Trans-Proteomic Pipeline ( <a href=http://tools.proteomecenter.org/wiki/index.php?title=Software:TPP rel=nofollow>http://tools.proteomecenter.org/wiki/index.php?title=Software:TPP</a> ) installed with default settings and in the default location. The Rshell script contains the location where the figures will be generated. All other output files are stored in the input data folders by default. The version of X!Tandem called from this workflow is separate from the one installed with the Trans-Proteomic Pipeline (the location specified in the Tandem components).    COPYRIGHT NOTICE  This workflow is based on open software and the workflow itself is shared under the Creative Commons Attribution-ShareAlike 3.0 Unported License (CC BY-SA) (see  <a href=http://creativecommons.org/licenses/by-sa/3.0/ rel=nofollow>http://creativecommons.org/licenses/by-sa/3.0/</a> )  Copyright&copy; 2012 Ekaterina Mostovenko, Jeroen de Bruin, Yassene Mohammed and Magnus Palmblad",0, 0, ,
"http://www.myexperiment.org/workflows/3058/versions/1.html","de Bruin et al. Workflow 1","2012-08-0108:50:28","2012-08-0108:54:59","http://www.myexperiment.org/workflows/3058/download/de_Bruin_et_al._Workflow_1-v1.t2flow?version=1","/users/23068","Magnus Palmblad","taverna 2","/users/23068,","Magnus Palmblad,","This is &quot;Workflow 1&quot; from de Bruin et al., Mol. Cell. Proteomics 2012.",-1, 0, ,
"http://www.myexperiment.org/workflows/3059/versions/1.html","de Bruin et al. Workflow 2","2012-08-0109:00:25","2012-08-0109:02:17","http://www.myexperiment.org/workflows/3059/download/de_Bruin_et_al._Workflow_2-v1.t2flow?version=1","/users/23068","Magnus Palmblad","taverna 2","/users/23068,","Magnus Palmblad,","This is &quot;Workflow 2&quot; from de Bruin et al., Mol. Cell. Proteomics 2012.",-1, 0, ,
"http://www.myexperiment.org/workflows/3060/versions/1.html","de Bruin et al. Workflow 3","2012-08-0109:03:01","2012-08-0109:07:18","http://www.myexperiment.org/workflows/3060/download/de_Bruin_et_al._Workflow_3-v1.t2flow?version=1","/users/23068","Magnus Palmblad","taverna 2","/users/23068,","Magnus Palmblad,","This is &quot;Workflow 3&quot; from de Bruin et al., Mol. Cell. Proteomics 2012.",-1, 0, ,
"http://www.myexperiment.org/workflows/3061/versions/1.html","de Bruin et al. Workflow 4","2012-08-0109:08:13","2012-08-0109:08:58","http://www.myexperiment.org/workflows/3061/download/de_Bruin_et_al._Workflow_4-v1.t2flow?version=1","/users/23068","Magnus Palmblad","taverna 2","/users/23068,","Magnus Palmblad,","This is &quot;Workflow 4&quot; from de Bruin et al., Mol. Cell. Proteomics 2012.",-1, 0, ,
"http://www.myexperiment.org/workflows/3062/versions/1.html","Gene_To_Pathways","2012-08-0610:48:10","2012-09-0714:43:21","http://www.myexperiment.org/workflows/3062/download/Gene_To_Pathways-v1.t2flow?version=1","/users/204","Khalid Belhajjame","taverna 2","/users/204, /users/5,","Khalid Belhajjame, Stian Soiland-Reyes,","&nbsp;This workflow identifier the pathways that are associated with given Kegg gene identifiers. Example inputs that can be used to run the workflow are&nbsp; <span>eco:b0002, eco:b0078</span>",-1, 0, ,
"http://www.myexperiment.org/workflows/3066/versions/1.html","Run scripts from a column in a votable","2012-08-0709:13:45","2012-09-0713:07:40","http://www.myexperiment.org/workflows/3066/download/Run_scripts_from_a_column_in_a_votable-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","It runs pyraf scripts whose pathname are values of a column in a votable. The iraf folder where login.cl is allocated must be provided. It requires astrotaverna, iraf (ellipse task) and pyraf for its execution",0, 0, ,
"http://www.myexperiment.org/workflows/3066/versions/2.html","Run scripts from a column in a votable","2012-08-0709:13:45","2012-09-0713:07:40","http://www.myexperiment.org/workflows/3066/download/Run_scripts_from_a_column_in_a_votable-v2.t2flow?version=2","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","It runs scripts whose pathname are values of a column in a votable",0, 0, ,
"http://www.myexperiment.org/workflows/3067/versions/1.html","Create votable from ellipse results","2012-08-0709:21:19","2012-09-0713:20:03","http://www.myexperiment.org/workflows/3067/download/Create_votable_from_ellipse_results_-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","The workflow takes from a votable the names of files where the ellipse result is stored. These files contain data for several ellipses and the workflow takes the center from the inner ellipse and the ellipticitiy from one of the outter ones. It uses astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ) and it requires pyraf installation (ellipse task).",0, 0, ,
"http://www.myexperiment.org/workflows/3067/versions/2.html","Create votable from ellipse results","2012-08-0709:21:19","2012-09-0713:20:03","http://www.myexperiment.org/workflows/3067/download/Create_votable_from_ellipse_results_-v2.t2flow?version=2","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","The workflow takes from a votable the names of files where the ellipse result is stored. These files contain data for several ellipses and the workflow takes the center from the inner ellipse and the ellipticitiy from one of the outter ones. It uses astrotaverna plugin ( <a rel=nofollow href=http://wf4ever.github.com/astrotaverna/>http://wf4ever.github.com/astrotaverna/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3068/versions/1.html","Calculate ellipses that describe a galaxy using iraf","2012-08-0709:32:01","2012-09-1106:41:01","http://www.myexperiment.org/workflows/3068/download/Calculate_ellipses_that_describe_a_galaxy_using_iraf-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","This workflow calculate the ellipses that better match a galaxy by doing to iterations. In the first one the center and the outer ellipse are aproximated because there might be bars that affect to the inner ellipses. In the second one, files with the ellipse data are built.It creates ellipse scripts using data from a votable, it runs ellipse, its results are added to the votable, it creates new scripts for ellipse using the previous results, it runs ellipse a second time and it finally includes the results into the votable. It requires the specification of the columns that contain file names (these files should be accesibles from taverna).Scripts are created (one for every row in the votable) using a template whose keys are replaced by data from a votable.Keys must appear also in the vocabulary file and match column names in the votable.It uses, pyraf (ellipse task), astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3068/versions/2.html","Calculate ellipses that describe a galaxy using iraf","2012-08-0709:32:01","2012-09-1106:41:01","http://www.myexperiment.org/workflows/3068/download/Calculate_ellipses_that_describe_a_galaxy_using_iraf-v2.t2flow?version=2","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","This workflow calculates the ellipses that better match a galaxy by doing two iterations. In the first one the center and the outer ellipse are aproximated because there might be bars that affect to the inner ellipses. In the second one, files with the ellipse data are built.  It creates ellipse scripts using data from a votable, it runs ellipse, its results are added to the votable, it creates new scripts for ellipse using the previous results, it runs ellipse a second time and it finally includes the results into the votable. It requires the specification of the columns that contain file names (these files should be accesibles from taverna).  Scripts are created (one for every row in the votable) using a template whose keys are replaced by data from a votable. Keys must appear also in the vocabulary file and match column names in the votable. It uses, pyraf (ellipse task), astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3069/versions/1.html","Hadoop hOCR parser","2012-08-0715:01:44","2012-08-0715:10:07","http://www.myexperiment.org/workflows/3069/download/Hadoop_hOCR_parser-v1.t2flow?version=1","/users/4707","Sven","taverna 2","/users/4707,","Sven,","Big data processing: chaining Hadoop jobs using Taverna. This workflow demonstrates a simple way of linking different hadoop job components using the standard output of the hadoop jobs. It is not for thought for productive use, but for demonstration using small data sets. The code for the hadoop jobs is available on Github:  <a href=https://github.com/openplanets/scape/tree/master/tb-lsdr-hocrparser rel=nofollow>tb-lsdr-hocrparser</a>  and  <a href=https://github.com/openplanets/scape/tree/master/tb-lsdr-seqfilecreator rel=nofollow>tb-lsdr-seqfilecreator</a> .",0, 0, ,
"http://www.myexperiment.org/workflows/3076/versions/1.html","Delete this","2012-08-0813:45:58","","http://www.myexperiment.org/workflows/3076/download/Delete_this-v1.t2flow?version=1","/users/21504","Wotan","taverna 2","/users/21504,","Wotan,",,0, 0, ,
"http://www.myexperiment.org/workflows/3078/versions/1.html","Oryza Sativa QTLs and genes retrieval from TropGene, Gramene and Ensembl","2012-08-0814:34:48","2012-09-2815:02:53","http://www.myexperiment.org/workflows/3078/download/Oryza_Sativa_QTLs_and_genes_retrieval_from_TropGene__Gramene_and_Ensembl-v1.t2flow?version=1","/users/58177","Julien wollbrett","taverna 2","/users/58177,","Julien wollbrett,","species: Oriza Sativa Take a TO term as input. Retrieve QTL information (accession number, mapping position) from both TropGene and Gramene databases. Also detect QTLs annotated with same TO term and having common mapping position in the two databases. <br /> <br /> A BioMart Web Service is used to retrieve genes for each QTL mapping position",-1, 0, ,
"http://www.myexperiment.org/workflows/3078/versions/2.html","Oryza Sativa QTLs and genes retrieval from TropGene, Gramene and Ensembl","2012-08-0814:34:48","2012-09-2815:02:53","http://www.myexperiment.org/workflows/3078/download/Oryza_Sativa_QTLs_and_genes_retrieval_from_TropGene__Gramene_and_Ensembl-v2.t2flow?version=2","/users/58177","Julien wollbrett","taverna 2","/users/58177,","Julien wollbrett,","For a given trait and QTL maximum size, retrieve accession numbers of the QTLs along with their mapping positions in Oryza sativa and retrieve genes present in the mapping genomic interval of a given QTL. Data integration from TropGene, Gramene and Ensembl relational databases. Semi-automatic creation of 7 Semantic Web Services for TropGene and Gramene with BioSemantic Use of BioMart Web Services for Ensembl interrogation",-1, 0, ,
"http://www.myexperiment.org/workflows/3083/versions/1.html","Convert a list into a VO Column","2012-08-1311:02:43","2013-03-0812:09:01","http://www.myexperiment.org/workflows/3083/download/Convert_a_list_into_a_VO_Column-v1.t2flow?version=1","/users/19173","Susana","taverna 2","/users/19173,","Susana,","This workflow converts a list of values into a VO table with only one column. It receives two inputs: the list of values and the header name of the column to be build.",0, 0, ,
"http://www.myexperiment.org/workflows/3083/versions/2.html","Convert a list into a VO Column","2012-08-1311:02:43","2013-03-0812:09:01","http://www.myexperiment.org/workflows/3083/download/Convert_a_list_into_a_VO_Column-v2.t2flow?version=2","/users/19173","Susana","taverna 2","/users/19173,","Susana,","This workflow converts a list of values into a VO table with only one column. It receives two inputs: the list of values and the header name of the column to be built.",0, 0, ,
"http://www.myexperiment.org/workflows/3084/versions/1.html","Joining VOtables with information to execute Sextractor, Galfit and Ellipse.","2012-08-1311:03:33","2013-03-0812:09:08","http://www.myexperiment.org/workflows/3084/download/Joining_VOtables_with_information_to_execute_Sextractor__Galfit_and_Ellipse.-v1.t2flow?version=1","/users/19173","Susana","taverna 2","/users/19173,","Susana,","This workflow join 14 votables, obtained from the workflow Extract SDSS field information and PSF in order to get a only one votable with all the information. Also it adds the columns zp and magzeropoint that are calculated from values provided in the inputs. The zp is -( aa + kk * airmass ) and the magzeropoint is zp + 2.5 * log10(53.907456)",0, 0, ,
"http://www.myexperiment.org/workflows/3084/versions/2.html","Joining VOtables with information to execute Sextractor, Galfit and Ellipse.","2012-08-1311:03:33","2013-03-0812:09:08","http://www.myexperiment.org/workflows/3084/download/Joining_VOtables_with_information_to_execute_Sextractor__Galfit_and_Ellipse.-v2.t2flow?version=2","/users/19173","Susana","taverna 2","/users/19173,","Susana,","This workflow join 14 votables, obtained from the workflow Extract SDSS field information and PSF in order to get a only one votable with all the information. Also it adds the columns zp and magzeropoint that are calculated from values provided in the inputs. The zp is -( aa + kk * airmass ) and the magzeropoint is zp + 2.5 * log10(53.907456)",0, 0, ,
"http://www.myexperiment.org/workflows/3084/versions/3.html","Joining VOtables with information to execute Sextractor, Galfit and Ellipse.","2012-08-1311:03:33","2013-03-0812:09:08","http://www.myexperiment.org/workflows/3084/download/Joining_VOtables_with_information_to_execute_Sextractor__Galfit_and_Ellipse.-v3.t2flow?version=3","/users/19173","Susana","taverna 2","/users/19173,","Susana,","This workflow join 13 votables, obtained from the workflow Extract SDSS field information and PSF in order to get a only one votable with all the information. Also it adds the columns zp, magzeropoint, xconvsize, yconvsize that are calculated from values provided in the inputs. The zp is -( aa + kk * airmass ), the magzeropoint is zp + 2.5 * log10(53.907456), the xconvsize is roundUp(nx/10) and the yconvsize isroundUp(ny/10)",0, 0, ,
"http://www.myexperiment.org/workflows/3085/versions/1.html","Gathering info from SDSS into a VOTable to execute Sextractor, Galfit and Ellipse.","2012-08-1311:04:27","2013-03-0812:09:18","http://www.myexperiment.org/workflows/3085/download/Gathering_info_from_SDSS_into_a_VOTable_to_execute_Sextractor__Galfit_and_Ellipse.-v1.t2flow?version=1","/users/19173","Susana","taverna 2","/users/19173,","Susana,","This workflow joins two main nested workflows: - Extract SDSS field information and PSF, which gathers information from SDSS VO service and from the header image in several VOtable. It alse generate the psf files. - Joining VOtables with information to execute Sextractor, Galfit and Ellipse, which joins the VOtables generated by the previus workflow to get only one VOtable with all the information",0, 0, ,
"http://www.myexperiment.org/workflows/3085/versions/2.html","Gathering info from SDSS into a VOTable to execute Sextractor, Galfit and Ellipse.","2012-08-1311:04:27","2013-03-0812:09:18","http://www.myexperiment.org/workflows/3085/download/Gathering_info_from_SDSS_into_a_VOTable_to_execute_Sextractor__Galfit_and_Ellipse.-v2.t2flow?version=2","/users/19173","Susana","taverna 2","/users/19173,","Susana,","This workflow joins two main nested workflows: - Extract SDSS field information and PSF, which gathers information from SDSS VO service and from the header image in several VOtable. It alse generate the psf files. - Joining VOtables with information to execute Sextractor, Galfit and Ellipse, which joins the VOtables generated by the previus workflow to get only one VOtable with all the information",0, 0, ,
"http://www.myexperiment.org/workflows/3085/versions/3.html","Gathering info from SDSS into a VOTable to execute Sextractor, Galfit and Ellipse.","2012-08-1311:04:27","2013-03-0812:09:18","http://www.myexperiment.org/workflows/3085/download/Gathering_info_from_SDSS_into_a_VOTable_to_execute_Sextractor__Galfit_and_Ellipse.-v3.t2flow?version=3","/users/19173","Susana","taverna 2","/users/19173,","Susana,","This workflow joins two main nested workflows: - Extract SDSS field information and PSF workflow, which gathers information from SDSS VO service and from the header image in several VOtable. It also generates the psf files. - Joining VOtables with information to execute Sextractor, Galfit and Ellipse workflow, which joins the VOtables generated by the previous workflow to get only one VOtable with all the information",0, 0, ,
"http://www.myexperiment.org/workflows/3085/versions/4.html","Gathering info from SDSS into a VOTable to execute Sextractor, Galfit and Ellipse.","2012-08-1311:04:27","2013-03-0812:09:18","http://www.myexperiment.org/workflows/3085/download/Gathering_info_from_SDSS_into_a_VOTable_to_execute_Sextractor__Galfit_and_Ellipse.-v4.t2flow?version=4","/users/19173","Susana","taverna 2","/users/19173,","Susana,","This workflow joins two main nested workflows: - Extract SDSS field information and PSF workflow, which gathers information from SDSS VO service and from the header image in several VOtable. It also generates the psf files. - Joining VOtables with information to execute Sextractor, Galfit and Ellipse workflow, which joins the VOtables generated by the previous workflow to get only one VOtable with all the information",0, 0, ,
"http://www.myexperiment.org/workflows/3086/versions/1.html","KEGG:Pathway Scheme","2012-08-1414:25:06","2013-08-2707:47:51","http://www.myexperiment.org/workflows/3086/download/KEGG_Pathway_Scheme-v1.t2flow?version=1","/users/17633","Harish Dharuri","taverna 2","/users/17633,","Harish Dharuri,","The purpose of the workflow is to determine all the genes operating in the pathways that the input metabolite participates in. The overall idea is to generate a set of genes that potentially influence the levels of a metabolite due to the common pathways that they share.",0, 0, ,
"http://www.myexperiment.org/workflows/3086/versions/2.html","KEGG:Pathway Scheme","2012-08-1414:25:06","2013-08-2707:47:51","http://www.myexperiment.org/workflows/3086/download/KEGG_Pathway_Scheme-v2.t2flow?version=2","/users/17633","Harish Dharuri","taverna 2","/users/17633,","Harish Dharuri,","The purpose of the workflow is to determine all the genes operating in the pathways that the input metabolite participates in. The overall idea is to generate a set of genes that potentially influence the levels of a metabolite due to the common pathways that they share.",0, 0, ,
"http://www.myexperiment.org/workflows/3105/versions/1.html","Hadoop Large Document Collection Data Preparation","2012-08-1712:19:39","2012-08-1818:39:26","http://www.myexperiment.org/workflows/3105/download/Hadoop_Large_Document_Collection_Data_Preparation_-v1.t2flow?version=1","/users/4707","Sven","taverna 2","/users/4707,","Sven,","Workflow for preparing large document collections for data analysis. Different types of hadoop jobs (Hadoop-Streaming-API, Hadoop Map/Reduce, and Hive) are used for specific purposes. The *PathCreator components create text files with absolute file paths using the unix command 'find'. The workflow then uses 1) a Hadoop Streaming API component (HadoopStreamingExiftoolRead) based on a bash script for reading image metadata using Exiftool, 2) the Map/Reduce component (HadoopHocrAvBlockWidthMapReduce) presented above, and 3) Hive components for creating data tables (HiveLoad*Data) and performing queries on the result files (HiveSelect). The code for the two hadoop jobs is available on Github:  <a href=https://github.com/openplanets/scape/tree/master/tb-lsdr-seqfilecreator rel=nofollow>tb-lsdr-seqfilecreator</a>  and&nbsp;  <a href=https://github.com/openplanets/scape/tree/master/tb-lsdr-hocrparser rel=nofollow>tb-lsdr-hocrparser</a> .",0, 0, ,
"http://www.myexperiment.org/workflows/3106/versions/1.html","Check HEC instances for diverging content","2012-08-2012:48:37","2012-08-2015:05:19","http://www.myexperiment.org/workflows/3106/download/Check_HEC_instances_for_diverging_content-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow check all tables in HEC on festung1 and festung3 for diverging content by comparing the last 1000 entries in each table. Output is a list of tabel names with different content.",0, 0, ,
"http://www.myexperiment.org/workflows/3106/versions/2.html","Check HEC instances for diverging content","2012-08-2012:48:37","2012-08-2015:05:19","http://www.myexperiment.org/workflows/3106/download/Check_HEC_instances_for_diverging_content-v2.t2flow?version=2","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow check all tables in HEC on festung1 and festung3 for diverging content by comparing the last 1000 entries in each table. Output is a list of tabel names with different content.",0, 0, ,
"http://www.myexperiment.org/workflows/3107/versions/1.html","Kegg:Reactions Scheme","2012-08-2022:09:16","2013-08-2708:06:54","http://www.myexperiment.org/workflows/3107/download/Kegg_Reactions_Scheme-v1.t2flow?version=1","/users/17633","Harish Dharuri","taverna 2","/users/17633,","Harish Dharuri,","The purpose of this workflow is to determine all the enzymes/genes that participate in a radius of 2 reaction steps around a given metabolite. Broadly, the scheme involves the following steps: <ol><li value=1>determine all the reactions that the given metabolite participates in</li><li value=2>determine all the compounds that participate in these reactions</li><li value=3>filter certain compounds like H2O, ATP etc to avoid non-specific connections</li><li value=4>determine all the reactions that the compounds passing through step 3 participate in</li><li value=5>determine the enzymes that drive the reactions from step 4</li><li value=6>determine genes corresponding to the enzymes in step 5</li><li value=7>store the entrez gene ids as a text file</li></ol>",0, 0, ,
"http://www.myexperiment.org/workflows/3107/versions/2.html","Kegg:Reactions Scheme","2012-08-2022:09:16","2013-08-2708:06:54","http://www.myexperiment.org/workflows/3107/download/Kegg_Reactions_Scheme-v2.t2flow?version=2","/users/17633","Harish Dharuri","taverna 2","/users/17633,","Harish Dharuri,","The purpose of this workflow is to determine all the enzymes/genes that participate in a radius of 2 reaction steps around a given metabolite. Broadly, the scheme involves the following steps: <ol><li value=1>determine all the reactions that the given metabolite participates in</li><li value=2>determine all the compounds that participate in these reactions</li><li value=3>filter certain compounds like H2O, ATP etc to avoid non-specific connections</li><li value=4>determine all the reactions that the compounds passing through step 3 participate in</li><li value=5>determine the enzymes that drive the reactions from step 4</li><li value=6>determine genes corresponding to the enzymes in step 5</li><li value=7>store the entrez gene ids as a text file</li></ol>",0, 0, ,
"http://www.myexperiment.org/workflows/3108/versions/1.html","Create_SNP_Set","2012-08-2101:50:23","","http://www.myexperiment.org/workflows/3108/download/Create_SNP_Set-v1.t2flow?version=1","/users/17633","Harish Dharuri","taverna 2","/users/17633,","Harish Dharuri,","The purpose of the workflow is to determine SNPs in the vicinity of the genes and create a SNP set for a given set of genes. The user has the freedom to choose the flanking width around the gene for determining the SNPs. The input is in the form of entrez gene ids. Biomart services are used to determine the chromosome and position of the gene as well as determining Affy gene chip 6k ids. The final report is stored as a tab-delimited text file with Affy 6 gene chip ids for the SNP and Kegg info for the gene that it is associated with.",0, 0, ,
"http://www.myexperiment.org/workflows/3109/versions/1.html","Create votable from different galfit paramenter adjustments","2012-08-2109:15:17","2012-09-0712:56:08","http://www.myexperiment.org/workflows/3109/download/Create_votable_from_different_galfit_paramenter_adjustments-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","The workflow creates a votable from the results provided by galfit when fiting exp_disc, sersic and sky functions or exp_disc, two sersic and sky functions. It returns this table and an aditional table that is joined to the input table. If the galfit file does not exists then fills the row with -999.00 values. It requires a votable that contains a column with the file name resulting from running galfit and such files must be accesible from taverna. It uses astrotaverna plugin ( <a rel=nofollow href=http://wf4ever.github.com/astrotaverna/>http://wf4ever.github.com/astrotaverna/</a> ) and it has a dependency on stil library ( <a rel=nofollow href=http://www.star.bris.ac.uk/~mbt/stil/>http://www.star.bris.ac.uk/~mbt/stil/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3109/versions/2.html","Create votable from different galfit paramenter adjustments","2012-08-2109:15:17","2012-09-0712:56:08","http://www.myexperiment.org/workflows/3109/download/Create_votable_from_different_galfit_paramenter_adjustments-v2.t2flow?version=2","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","The workflow creates a votable from the results provided by galfit. It returns this table and an aditional table that is joined to the input table. It requires a votable that contains a column with the file name resulting from running galfit and such files must be accesible from taverna. It uses astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ) and it has a dependency on stil library ( <a href=http://www.star.bris.ac.uk/~mbt/stil/ rel=nofollow>http://www.star.bris.ac.uk/~mbt/stil/</a> ).The galfit files may come from adjusting 'disk, bulb, bar and sky' or 'disk, bulb and sky'.",0, 0, ,
"http://www.myexperiment.org/workflows/3110/versions/1.html","Number of features in a month in a year","2012-08-2110:57:12","","http://www.myexperiment.org/workflows/3110/download/Number_of_features_in_a_month_in_a_year-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","Returns the number of features in a HFC catalogue which occured in a month in a year given as inputs.",0, 0, ,
"http://www.myexperiment.org/workflows/3112/versions/1.html","Get models from BioModels including the input protein.","2012-08-2206:18:53","2012-08-2402:30:55","http://www.myexperiment.org/workflows/3112/download/Get_models_from_BioModels_including_the_input_protein.-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,",,0, 0, ,
"http://www.myexperiment.org/workflows/3112/versions/2.html","Get models from BioModels including the input protein.","2012-08-2206:18:53","2012-08-2402:30:55","http://www.myexperiment.org/workflows/3112/download/Get_models_from_BioModels_including_the_input_protein.-v2.t2flow?version=2","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","A service to look for models in BioModels using a UniProt accession as input. If the input protein is found in one model the workflow will provide the BioModels Id, the SBML and a link to the BioModels database. Please use taverna 2.4 and above.",0, 0, ,
"http://www.myexperiment.org/workflows/3112/versions/3.html","Get models from BioModels including the input protein.","2012-08-2206:18:53","2012-08-2402:30:55","http://www.myexperiment.org/workflows/3112/download/Get_models_from_BioModels_including_the_input_protein.-v3.t2flow?version=3","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","A service to look for models in BioModels using a UniProt accession as input. If the input protein is found in one model the workflow will provide the BioModels Id, the SBML and a link to the BioModels database. Please use taverna 2.4 or above.",0, 0, ,
"http://www.myexperiment.org/workflows/3113/versions/1.html","Get a list of proteins annotated with an Ontology term and use these proteins to query BioModels","2012-08-2208:05:33","2013-07-1013:58:29","http://www.myexperiment.org/workflows/3113/download/Get_a_list_of_proteins_annotated_with_an_Ontology_term_and_use_these_proteins_to_query_BioModels-v1.t2flow?version=1","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","&nbsp;Get a list of proteins annotated with an Ontology term and use these proteins to query BioModels",0, 0, ,
"http://www.myexperiment.org/workflows/3113/versions/2.html","Get a list of proteins annotated with an Ontology term and use these proteins to query BioModels","2012-08-2208:05:33","2013-07-1013:58:29","http://www.myexperiment.org/workflows/3113/download/Get_a_list_of_proteins_annotated_with_an_Ontology_term_and_use_these_proteins_to_query_BioModels-v2.t2flow?version=2","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","A service to look for models in BioModels using an Ontology Id as input. First the workflow will look in QuickGO for UniProt accessions annotated with the provided Ontology Id. Then it will look for models using the list of proteins. If one of the input protein is found in one model the workflow will provide the BioModels Id, the SBML and a link to the BioModels database. Please use taverna 2.4 or above.",0, 0, ,
"http://www.myexperiment.org/workflows/3113/versions/3.html","Get a list of proteins annotated with an Ontology term and use these proteins to query BioModels","2012-08-2208:05:33","2013-07-1013:58:29","http://www.myexperiment.org/workflows/3113/download/Get_a_list_of_proteins_annotated_with_an_Ontology_term_and_use_these_proteins_to_query_BioModels-v3.t2flow?version=3","/users/13207","Rafael C. Jimenez","taverna 2","/users/13207,","Rafael C. Jimenez,","A service to look for models in BioModels using an Ontology Id as input. First the workflow will look in QuickGO for UniProt accessions annotated with the provided Ontology Id. Then it will look for models using the list of proteins. If one of the input protein is found in one model the workflow will provide the BioModels Id, the SBML and a link to the BioModels database. Please use taverna 2.4 or above.",0, 0, ,
"http://www.myexperiment.org/workflows/3114/versions/1.html","Number of recorded features in catalogue per month","2012-08-2209:24:03","","http://www.myexperiment.org/workflows/3114/download/Number_of_recorded_features_in_catalogue_per_month-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","The number of features of the specified catalogue are counted per month between beginning of the year_start und the end of the year_end. Return format is VOTable",0, 0, ,
"http://www.myexperiment.org/workflows/3115/versions/1.html","Monthly counts for feature occurences between beginning of year_start and end of year_end","2012-08-2212:37:58","","http://www.myexperiment.org/workflows/3115/download/Monthly_counts_for_feature_occurences_between_beginning_of_year_start_and_end_of_year_end-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow provides monthly counts of features in HFC between the beginning of year_start and the end of year_end.Returns the result as comma separated file (csv) and as list of lists.",0, 0, ,
"http://www.myexperiment.org/workflows/3116/versions/1.html","Counts number of events per month in HEC table","2012-08-2214:46:16","","http://www.myexperiment.org/workflows/3116/download/Counts_number_of_events_per_month_in_HEC_table-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow counts the monthly  number of events in a HEC table from the begining of year year_start to the end of year year_end.Returns a VOTable with the count",0, 0, ,
"http://www.myexperiment.org/workflows/3119/versions/1.html","Monthly counts for event occurences between beginning of year_start and end of year_end","2012-08-2309:40:25","","http://www.myexperiment.org/workflows/3119/download/Monthly_counts_for_event_occurences_between_beginning_of_year_start_and_end_of_year_end-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow provides monthly counts of events in HEC between the beginning of year_start and the end of year_end.Returns the result as comma separated file (csv) and as list of lists.",0, 0, ,
"http://www.myexperiment.org/workflows/3120/versions/1.html","Read file from S3 bucket","2012-08-2315:46:21","","http://www.myexperiment.org/workflows/3120/download/Read_file_from_S3_bucket-v1.t2flow?version=1","/users/18916","Robert Haines","taverna 2","/users/18916,","Robert Haines,","This workflow simply loads a text file that is stored in an AWS S3 bucket. It is provided as an example of how to do this, rather than be a complete, reusable solution. You need to have s3fs installed and configured with your AWS credentials to use this workflow (see  <a rel=nofollow href=http://code.google.com/p/s3fs/>http://code.google.com/p/s3fs/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3121/versions/1.html","Write file to S3 bucket","2012-08-2315:50:50","","http://www.myexperiment.org/workflows/3121/download/Write_file_to_S3_bucket-v1.t2flow?version=1","/users/18916","Robert Haines","taverna 2","/users/18916,","Robert Haines,","This workflow simply writes a text file to an AWS S3 bucket. It is provided as an example of how to do this, rather than be a complete, reusable solution. You need to have s3fs installed and configured with your AWS credentials to use this workflow (see  <a rel=nofollow href=http://code.google.com/p/s3fs/>http://code.google.com/p/s3fs/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3124/versions/1.html","Mining the Kegg pathway database with the top hits from a GWAS, thereby predicting which gene regulatory pathways may be altered as a result of genetic mutations in a subpopulation.","2012-08-2918:28:47","2013-05-1514:37:36","http://www.myexperiment.org/workflows/3124/download/Mining_the_Kegg_pathway_database_with_the_top_hits_from_a_GWAS__thereby_predicting_which_gene_regulatory_pathways_may_be_altered_as_a_result_of_genetic_mutations_in_a_subpopulation.-v1.t2flow?version=1","/users/17633","Harish Dharuri","taverna 2","/users/17633,","Harish Dharuri,",,0, 0, ,
"http://www.myexperiment.org/workflows/3124/versions/2.html","Mining the Kegg pathway database with the top hits from a GWAS, thereby predicting which gene regulatory pathways may be altered as a result of genetic mutations in a subpopulation.","2012-08-2918:28:47","2013-05-1514:37:36","http://www.myexperiment.org/workflows/3124/download/Mining_the_Kegg_pathway_database_with_the_top_hits_from_a_GWAS__thereby_predicting_which_gene_regulatory_pathways_may_be_altered_as_a_result_of_genetic_mutations_in_a_subpopulation.-v2.t2flow?version=2","/users/17633","Harish Dharuri","taverna 2","/users/17633,","Harish Dharuri,",,0, 0, ,
"http://www.myexperiment.org/workflows/3126/versions/1.html","Sort 1000 fastest CMEs from a given list according to their pa_width (measured visible angle).","2012-08-3008:51:48","2012-08-3008:52:39","http://www.myexperiment.org/workflows/3126/download/Sort_1000_fastest_CMEs_from_a_given_list_according_to_their_pa_width__measured_visible_angle_.-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","The fastest 1000 CME of the input list are bined in categories by factor of 10 according to their pa_width value.List must contain fields v and pa_width. Output VOTable with the counts in the categories.",0, 0, ,
"http://www.myexperiment.org/workflows/3127/versions/1.html","Add columns to a votable resulting from executing sextractor.","2012-08-3009:33:55","","http://www.myexperiment.org/workflows/3127/download/Add_columns_to_a_votable_resulting_from_executing_sextractor.-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","Addcolumns that are needed to run galfit and ellipse. it requires columns coming from sextractor and the astrotaverna plugin.",0, 0, ,
"http://www.myexperiment.org/workflows/3129/versions/1.html","Build plots from galfit and ellipse results","2012-08-3009:51:58","2012-09-0713:33:55","http://www.myexperiment.org/workflows/3129/download/Build_plots_from_galfit_and_ellipse_results_-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","Build plots from galfit and ellipse results ( <a href=http://www.myexperiment.org/workflows/3068.html rel=nofollow>http://www.myexperiment.org/workflows/3068.html</a> ,  <a href=http://www.myexperiment.org/workflows/3052.html rel=nofollow>http://www.myexperiment.org/workflows/3052.html</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3129/versions/2.html","Build plots from galfit and ellipse results","2012-08-3009:51:58","2012-09-0713:33:55","http://www.myexperiment.org/workflows/3129/download/Build_plots_from_galfit_and_ellipse_results_-v2.t2flow?version=2","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","Build plots from galfit and ellipse results ( <a href=http://www.myexperiment.org/workflows/3068.html rel=nofollow>http://www.myexperiment.org/workflows/3068.html</a> ,  <a href=http://www.myexperiment.org/workflows/3052.html rel=nofollow>http://www.myexperiment.org/workflows/3052.html</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3130/versions/1.html","Cocatenates several VOTables into one","2012-08-3010:05:29","2013-04-2216:52:00","http://www.myexperiment.org/workflows/3130/download/Cocatenates_several_VOTables_into_one-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","Cat four votables into one.",0, 0, ,
"http://www.myexperiment.org/workflows/3130/versions/2.html","Cocatenates several VOTables into one","2012-08-3010:05:29","2013-04-2216:52:00","http://www.myexperiment.org/workflows/3130/download/Cocatenates_several_VOTables_into_one-v2.t2flow?version=2","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","Snippet showing how to use AstroTaverna tool for concatenating several VOTables. The input is four VOTables with the same number of columns. The result if using sample values provided will be a four times vertically duplicated VOTable.",0, 0, ,
"http://www.myexperiment.org/workflows/3130/versions/3.html","Cocatenates several VOTables into one","2012-08-3010:05:29","2013-04-2216:52:00","http://www.myexperiment.org/workflows/3130/download/Cocatenates_several_VOTables_into_one-v3.t2flow?version=3","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","Snippet showing how to use AstroTaverna tool for concatenating several VOTables. The input is four VOTables with the same number of columns. The result if using sample values provided will be a four times vertically duplicated VOTable.",0, 0, ,
"http://www.myexperiment.org/workflows/3133/versions/1.html","Get completion function V / Vm using the apparent magnitude list","2012-09-0309:51:15","2012-09-0309:53:16","http://www.myexperiment.org/workflows/3133/download/Get_completion_function_V___Vm_using_the_apparent_magnitude_list-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","Get completion function V / Vm using the apparent magnitude list of a set of galaxies",0, 0, ,
"http://www.myexperiment.org/workflows/3134/versions/1.html","Retention Time Prediction with X!Tandem","2012-09-0310:43:31","2012-09-0310:44:33","http://www.myexperiment.org/workflows/3134/download/Retention_Time_Prediction_with_X_Tandem-v1.t2flow?version=1","/users/23068","Magnus Palmblad","taverna 2","/users/23068, /users/17146, /users/17730,","Magnus Palmblad, Yassene, Eleni,","This workflow identifies peptides from tandem mass spectra using X!Tandem as in a standard installation of the Trans-Proteomic Pipeline (TPP, version 4.6, but earlier versions should also work). The peptide-spectrum matches are validates using PeptideProphet (also from a standard installation of TPP) and peptides with at least a probability 0.95 are used to train a linear retention time predictor (Palmblad et al., 2002), whereby retention coefficients are also derived. These indirectly provide information on the chromatographic stationary and mobile phase (composition and pH) and the gradient.  The two Rshell scrips visualize the prediction versus measured retention times and amino acid coefficients colored by physico-chemical properties (basic/acidic/polar etc.).",0, 0, ,
"http://www.myexperiment.org/workflows/3136/versions/1.html","Associate Active Regions and Filaments to the 100 fastest CME","2012-09-0313:32:23","","http://www.myexperiment.org/workflows/3136/download/Associate_Active_Regions_and_Filaments_to_the_100_fastest_CME-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,","This workflow is querying the HEC for the fastest 100 CME of a given list (input parameter); it calculates the latitude from the postion angle; last step is to query the HFC for Active Regions and Filaments for the given time where the bounding box of the feature contains the longitude (feature must be on the correct side of the Sun.) Inputs: HEC list name (must contain fields: v, time_start, pa_width, pa)Outputs: v, time_start, pa_width, pa of the 100 fastest CME, VOTables for associated Active Regions and Filaments, counts for associated features",0, 0, ,
"http://www.myexperiment.org/workflows/3144/versions/1.html","READ_MULTI_FASTA_FILE","2012-09-0419:19:06","2012-09-0419:36:55","http://www.myexperiment.org/workflows/3144/download/READ_MULTI_FASTA_FILE-v1.t2flow?version=1","/users/22240","Mcasfrox","taverna 2","/users/22240,","Mcasfrox,","Read multi fasta file and split into a list of fasta sequences",-1, 0, ,
"http://www.myexperiment.org/workflows/3146/versions/1.html","[untitled]","2012-09-0512:10:44","2012-09-0512:11:02","http://www.myexperiment.org/workflows/3146/download/_untitled_-v1.t2flow?version=1","/users/22240","Mcasfrox","taverna 2","/users/22240,","Mcasfrox,","complete part one of assignment",-1, 0, ,
"http://www.myexperiment.org/workflows/3147/versions/1.html","SNP Workflow","2012-09-0512:19:44","","http://www.myexperiment.org/workflows/3147/download/SNP_Workflow-v1.t2flow?version=1","/users/59084","Aishualex","taverna 2","/users/59084,","Aishualex,","This workflow extracts information about the position of SNPs and the genes they are associated with",0, 0, ,
"http://www.myexperiment.org/workflows/3148/versions/1.html","SNP Workflow","2012-09-0512:22:45","","http://www.myexperiment.org/workflows/3148/download/SNP_Workflow-v1.t2flow?version=1","/users/59082","Vishalkpp","taverna 2","/users/59082,","Vishalkpp,","This workflow extracts information about the position of SNPs and the genes they are associated with",0, 0, ,
"http://www.myexperiment.org/workflows/3149/versions/1.html","LASCO_CME_QUERY","2012-09-0515:39:47","","http://www.myexperiment.org/workflows/3149/download/LASCO_CME_QUERY-v1.t2flow?version=1","/users/21398","Gab","taverna 2","/users/21398, /users/59168, /users/4706,","Gab, Eoincar, Anja Le Blanc,","This workflows 	queries the LASCO CME list and returns a VOTable with the following fields pa, pa_width, v_final and v_diff which is abs(v_init-v_final)/2",0, 0, ,
"http://www.myexperiment.org/workflows/3150/versions/1.html","Get SecchiRH composites images","2012-09-0607:45:26","2012-09-0607:48:04","http://www.myexperiment.org/workflows/3150/download/Get_SecchiRH_composites_images-v1.t2flow?version=1","/users/59183","Baptiste Cecconi","taverna 2","/users/59183,","Baptiste Cecconi,","&nbsp;This workflow extracts the composite image from the  <a rel=nofollow href=http://secchirh.obspm.fr>http://secchirh.obspm.fr</a>  survey page.",-1, 0, ,
"http://www.myexperiment.org/workflows/3152/versions/1.html","timeToTimeRange","2012-09-0608:46:13","","http://www.myexperiment.org/workflows/3152/download/timeToTimeRange-v1.t2flow?version=1","/users/59185","Shanem","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/3153/versions/1.html","Goes Flare Check WF","2012-09-0612:36:41","2012-09-0612:58:10","http://www.myexperiment.org/workflows/3153/download/Goes_Flare_Check_WF-v1.t2flow?version=1","/users/59183","Baptiste Cecconi","taverna 2","/users/59183,","Baptiste Cecconi,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3153/versions/2.html","Goes Flare Check WF","2012-09-0612:36:41","2012-09-0612:58:10","http://www.myexperiment.org/workflows/3153/download/Goes_Flare_Check_WF-v2.t2flow?version=2","/users/59183","Baptiste Cecconi","taverna 2","/users/59183,","Baptiste Cecconi,","This workflow is part of the 100-CME-Challenge developed during the HELIO-CDAW-4",-1, 0, ,
"http://www.myexperiment.org/workflows/3153/versions/3.html","Goes Flare Check WF","2012-09-0612:36:41","2012-09-0612:58:10","http://www.myexperiment.org/workflows/3153/download/Goes_Flare_Check_WF-v3.t2flow?version=3","/users/59183","Baptiste Cecconi","taverna 2","/users/59183,","Baptiste Cecconi,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3156/versions/1.html","LASCO_CME_QUERY","2012-09-0614:06:22","2012-09-0614:15:27","http://www.myexperiment.org/workflows/3156/download/LASCO_CME_QUERY-v1.t2flow?version=1","/users/59183","Baptiste Cecconi","taverna 2","/users/59183,","Baptiste Cecconi,","This workflows 	queries the LASCO CME list and returns a VOTable with the following fields pa, pa_width, v_final and v_diff which is abs(v_init-v_final)/2",0, 0, ,
"http://www.myexperiment.org/workflows/3156/versions/2.html","LASCO_CME_QUERY","2012-09-0614:06:22","2012-09-0614:15:27","http://www.myexperiment.org/workflows/3156/download/LASCO_CME_QUERY-v2.t2flow?version=2","/users/59183","Baptiste Cecconi","taverna 2","/users/59183,","Baptiste Cecconi,","This workflows 	queries the LASCO CME list and returns a VOTable with the following fields pa, pa_width, v_final and v_diff which is abs(v_init-v_final)/2",0, 0, ,
"http://www.myexperiment.org/workflows/3157/versions/1.html","100CME_task1","2012-09-0614:08:35","2012-09-0614:13:20","http://www.myexperiment.org/workflows/3157/download/100CME_task1-v1.t2flow?version=1","/users/59183","Baptiste Cecconi","taverna 2","/users/59183,","Baptiste Cecconi,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3158/versions/1.html","xlmPath","2012-09-0614:30:41","2012-09-0614:36:22","http://www.myexperiment.org/workflows/3158/download/xlmPath-v1.t2flow?version=1","/users/19798","Natasha","taverna 2","","","xml path",-1, 0, ,
"http://www.myexperiment.org/workflows/3158/versions/2.html","xlmPath","2012-09-0614:30:41","2012-09-0614:36:22","http://www.myexperiment.org/workflows/3158/download/xlmPath-v2.t2flow?version=2","/users/19798","Natasha","taverna 2","","","xml path",-1, 0, ,
"http://www.myexperiment.org/workflows/3162/versions/1.html","ACE Average Speed","2012-09-0615:31:51","","http://www.myexperiment.org/workflows/3162/download/ACE_Average_Speed-v1.t2flow?version=1","/users/21398","Gab","taverna 2","/users/21398,","Gab,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3163/versions/1.html","WIND/Waves radio quicklook from CDAWeb WSDL interface","2012-09-0615:44:58","","http://www.myexperiment.org/workflows/3163/download/WIND_Waves_radio_quicklook_from_CDAWeb_WSDL_interface-v1.t2flow?version=1","/users/59183","Baptiste Cecconi","taverna 2","/users/59183,","Baptiste Cecconi,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3165/versions/1.html","Ulysses/URAP radio quicklook from CDAWeb WSDL interface","2012-09-0615:50:06","","http://www.myexperiment.org/workflows/3165/download/Ulysses_URAP_radio_quicklook_from_CDAWeb_WSDL_interface-v1.t2flow?version=1","/users/59183","Baptiste Cecconi","taverna 2","/users/59183,","Baptiste Cecconi,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3167/versions/1.html","Detect ellipse failures and get votable without ellipse failures","2012-09-0713:26:05","","http://www.myexperiment.org/workflows/3167/download/Detect_ellipse_failures_and_get_votable_without_ellipse_failures-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","It detects if ellipse has failed by checking if the resulting data file exists.It adds a column (validellipse) that contains 1 if ellipse didn't fail and 0 if ellipse failed.It returns a votable that contains all the data with the new column and a votable that contains only the rows where ellipse didn't failed.It uses astrotaverna plugin ( <a href=http://wf4ever.github.com/astrotaverna/ rel=nofollow>http://wf4ever.github.com/astrotaverna/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3168/versions/1.html","Cloud Parallel Processing of Tandem Mass Spectrometry Based Proteomics Data: X!Tandem","2012-09-1009:49:08","","http://www.myexperiment.org/workflows/3168/download/Cloud_Parallel_Processing_of_Tandem_Mass_Spectrometry_Based_Proteomics_Data__X_Tandem-v1.t2flow?version=1","/users/17146","Yassene","taverna 2","/users/17146,","Yassene,","A workflow for searching LC&minus;MS/MS mass spectrometry data using X!Tandem on the cloud. The workflow consists of 5 processors. The objectLogic processor prepares all inputs in the right format, i.e. keeping or converting strings into file object according to the following processor. The mzxmlDecomposer and pepxmlComposer run the decomposing/recomposing algorithms. objectLogic, mzxmlDecomposer and pepxmlComposer are Beanshell processors and they run locally. Xtandem runs X!Tandem on a remote machine and pepxmlUnzip unzip the pepXML files to a local directory; both are Tool processors. more details can be found here:  <a href=http://pubs.acs.org/doi/abs/10.1021/pr300561q rel=nofollow>http://pubs.acs.org/doi/abs/10.1021/pr300561q</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3171/versions/1.html","Cloud Parallel Processing of Tandem Mass Spectrometry Based Proteomics Data: SpectraST","2012-09-1012:20:30","","http://www.myexperiment.org/workflows/3171/download/Cloud_Parallel_Processing_of_Tandem_Mass_Spectrometry_Based_Proteomics_Data__SpectraST-v1.t2flow?version=1","/users/17146","Yassene","taverna 2","/users/17146,","Yassene,","A workflow for searching LC&minus;MS/MS data using SpectraST on the cloud. The processor mzxmlDecomposer, pepxmlUnzip, and pepxmlComposer are identical to the one in the X!Tandem workflow (Figure 2). The only difference is that the Xtandem processor is exchanged with the Spectrast processor and the constant inputs are adjusted to SpectraST. This approach is also possible for other search engines as described in <br /> Data Decomposition and Recomposition Algorithms. More details can be found here:  <a rel=nofollow href=http://pubs.acs.org/doi/abs/10.1021/pr300561q>http://pubs.acs.org/doi/abs/10.1021/pr300561q</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3172/versions/1.html","Cloud Parallel Processing of Tandem Mass Spectrometry Based Proteomics Data: SpectraST Advanced","2012-09-1012:22:32","2015-08-1909:31:09","","/users/17146","Yassene","taverna 2","/users/17146,","Yassene,","An advanced scientific workflow for searching LC&minus;MS data using SpectraST on the cloud. Uploading the libraries is optimized to achieve better performance, which makes this workflow more suitable for processing mzXML spectra files from human samples, as the corresponding NIST library needed by SpectraST is larger than 2 GB. Here we connect 3 nested workflows, in which the first 2, i.e., decomposeMzxml and uploadToCloud, run in parallel, while the third nested workflow, i.e. runSpectrastOnCloud will start only if uploadToCloud finished all iteration. runSpectrastOnCloud and decomposeMzxml can still run in parallel. More details can be found here:  <a rel=nofollow href=http://pubs.acs.org/doi/abs/10.1021/pr300561q>http://pubs.acs.org/doi/abs/10.1021/pr300561q</a> &nbsp;",
"http://www.myexperiment.org/workflows/3178/versions/1.html","Filter concepts with profiles","2012-09-1410:14:12","2014-07-1410:12:32","http://www.myexperiment.org/workflows/3178/download/Filter_concepts_with_profiles-v1.t2flow?version=1","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/2780,","Kristina Hettne, Reinout van Schouwen, Martijn Schuemie,","Purpose: This workflow can be used to check if a concept has a concept profile in the database.  <br /> <br /> Author comments: <br /> <br /> This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/3178/versions/2.html","Filter concepts with profiles","2012-09-1410:14:12","2014-07-1410:12:32","http://www.myexperiment.org/workflows/3178/download/Filter_concepts_with_profiles-v2.t2flow?version=2","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/2780,","Kristina Hettne, Reinout van Schouwen, Martijn Schuemie,","Purpose: This workflow can be used to check if a concept has a concept profile in the database. Author comments: This workflow can be used together with other workflows in this pack:  <a href=http://www.myexperiment.org/packs/282 rel=nofollow>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/3178/versions/3.html","Filter concepts with profiles","2012-09-1410:14:12","2014-07-1410:12:32","http://www.myexperiment.org/workflows/3178/download/Filter_concepts_with_profiles-v3.t2flow?version=3","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/2780,","Kristina Hettne, Reinout van Schouwen, Martijn Schuemie,","This workflow removes concepts that have no concept profile in the concept profile database, since only concepts with a concept profile can be used for concept profile matching.",0, 0, ,
"http://www.myexperiment.org/workflows/3178/versions/4.html","Filter concepts with profiles","2012-09-1410:14:12","2014-07-1410:12:32","http://www.myexperiment.org/workflows/3178/download/Filter_concepts_with_profiles-v4.t2flow?version=4","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/2780,","Kristina Hettne, Reinout van Schouwen, Martijn Schuemie,","Purpose: Filter a list of concept id(s) by returning only those with a concept profile in the database.",0, 0, ,
"http://www.myexperiment.org/workflows/3200/versions/1.html","Blah","2012-09-2610:42:08","2012-09-2610:42:29","http://www.myexperiment.org/workflows/3200/download/Blah-v1.wfbundle?version=1","/users/30","Alan Williams","taverna 3","/users/30,","Alan Williams,",,
"http://www.myexperiment.org/workflows/3201/versions/1.html","The title","2012-09-2614:32:59","","http://www.myexperiment.org/workflows/3201/download/The_title-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","The description. This could be quite long.",0, 0, ,
"http://www.myexperiment.org/workflows/3202/versions/1.html","The title","2012-09-2614:36:34","2012-09-2614:36:38","http://www.myexperiment.org/workflows/3202/download/The_title-v1.wfbundle?version=1","/users/5","Stian Soiland-Reyes","taverna 3 wfbundle","/users/5,","Stian Soiland-Reyes,",,
"http://www.myexperiment.org/workflows/3204/versions/1.html","Searching for near galaxies in NED service","2012-09-2617:12:45","2012-10-0908:20:18","http://www.myexperiment.org/workflows/3204/download/Searching_for_near_galaxies_in_NED_service-v1.t2flow?version=1","/users/19173","Susana","taverna 3","/users/19173,","Susana,","This workflow needs as input an ascii table with a list of galaxies. This table contains the PGC name of the galaxy, the CIG number, the radius of searching, Z1 and Z2. The workflow uses the radius, Z1, Z2 and the PGC name of the galaxy to query NED service and get the html with the list of companions. This html is parsed and it is built a VOTable with the RA, DEC, Magnitud, Redshift, Separation, Velocity of each companion.",
"http://www.myexperiment.org/workflows/3204/versions/2.html","Searching for near galaxies in NED service","2012-09-2617:12:45","2012-10-0908:20:18","http://www.myexperiment.org/workflows/3204/download/Searching_for_near_galaxies_in_NED_service-v2.t2flow?version=2","/users/19173","Susana","taverna 2","/users/19173,","Susana,","This workflow needs as input an ascii table with a list of galaxies. This table contains the PGC name of the galaxy, the CIG number, the radius of searching, Z1 and Z2. The workflow uses the radius, Z1, Z2 and the PGC name of the galaxy to query NED service and get the html with the list of companions. This html is parsed and it is built a VOTable with the RA, DEC, Magnitud, Redshift, Separation, Velocity of each companion.",0, 0, ,
"http://www.myexperiment.org/workflows/3205/versions/1.html","Querying SDSS DR8 to get magnitude properties","2012-09-2617:24:51","2013-03-0812:08:17","http://www.myexperiment.org/workflows/3205/download/Querying_SDSS_DR8_to_get_magnitude_properties-v1.t2flow?version=1","/users/19173","Susana","taverna 3","/users/19173,","Susana,",,
"http://www.myexperiment.org/workflows/3205/versions/2.html","Querying SDSS DR8 to get magnitude properties","2012-09-2617:24:51","2013-03-0812:08:17","http://www.myexperiment.org/workflows/3205/download/Querying_SDSS_DR8_to_get_magnitude_properties-v2.t2flow?version=2","/users/19173","Susana","taverna 2","/users/19173,","Susana,","This workflow gets a VOTable with the RA and DEC  among others values of a list of galaxies. The workflow queries the SDSS DR8 VO conesearch service, to extract the objID, specObjID, ra, dec, u, g, r, i, z.",0, 0, ,
"http://www.myexperiment.org/workflows/3212/versions/1.html","Matchbox Evaluation","2012-10-0212:37:08","2012-10-0212:40:04","http://www.myexperiment.org/workflows/3212/download/Matchbox_Evaluation-v1.t2flow?version=1","/users/4707","Sven","taverna 2","/users/4707,","Sven,","Matchbox evaluation against ground truth. The evaluation process firstcreates the matchbox output and ground truth lists. It then counts each pagetuple from the matchbox output that is in the ground truth as correctlyidentified tuple (true positive). Those that are not in the ground truth arecounted as incorrectly identified tuples (false positives), and finally,those that are in the ground truth but not in the matchbox output are countedas missed tuples (false negatives).The precision is then calculated as the number of true positives (i.e. thenumber of items correctly labeled as duplicate page pairs) divided by thetotal number of elements assumed to be duplicate page pairs (i.e. the sum oftrue positives and false positives, which are items incorrectly labeled asbeing duplicate page pairs ). Recall is then defined as the number oftrue positives divided by the total number of elements of duplicate pagepairs (i.e. the sum of true positives and false negatives, which are itemshave not been labeled as being duplicate page pairs but actually should havebeen).The ground truth contains single page instances without duplicates andn-tuples (duplicates, triples, quadruples, etc.). n-tuples with n&gt;2 areexpanded, the result is a list of 2-tuples which is used to determine thenumber of missed duplicates (false negatives).",0, 0, ,
"http://www.myexperiment.org/workflows/3226/versions/1.html","Relation Extraction","2012-10-0411:38:27","2014-04-0912:14:32","","/users/6731","cneudecker","taverna 2","/users/6731,","cneudecker,","Perform relation extraction using AlchemyAPI. See here for more information: <a href=http://www.alchemyapi.com/api/relation/ rel=nofollow>http://www.alchemyapi.com/api/relation/</a>",
"http://www.myexperiment.org/workflows/3227/versions/1.html","Sentiment Analysis","2012-10-0411:38:59","","","/users/6731","cneudecker","taverna 2","/users/6731,","cneudecker,","Perform sentiment analysis using AlchemyAPI. See here for more information: <a href=http://www.alchemyapi.com/api/sentiment/ rel=nofollow>http://www.alchemyapi.com/api/sentiment/</a>",
"http://www.myexperiment.org/workflows/3228/versions/1.html","Entity Extraction","2012-10-0411:39:27","","","/users/6731","cneudecker","taverna 2","/users/6731,","cneudecker,","Perform entity extraction using AlchemyAPI. See here for more information: <a href=http://www.alchemyapi.com/api/entity/ rel=nofollow>http://www.alchemyapi.com/api/entity/</a>",
"http://www.myexperiment.org/workflows/3230/versions/1.html","Concept Tagging","2012-10-0411:43:02","","","/users/6731","cneudecker","taverna 2","/users/6731,","cneudecker,","Perform concept tagging using AlchemyAPI. See here for more information: <a href=http://www.alchemyapi.com/api/relation/ rel=nofollow>http://www.alchemyapi.com/api/relation/</a>",
"http://www.myexperiment.org/workflows/3232/versions/1.html","OpenCalais","2012-10-0415:22:27","","","/users/6731","cneudecker","taverna 2","/users/6731,","cneudecker,","Perform various enrichments using the OpenCalais API. See here for more information: <a href=http://www.opencalais.com/about rel=nofollow>http://www.opencalais.com/about</a>",
"http://www.myexperiment.org/workflows/3234/versions/1.html","Keyword Extraction","2012-10-0510:35:13","2014-04-0912:17:22","","/users/6731","cneudecker","taverna 2","/users/6731,","cneudecker,","Perform keyword extraction using AlchemyAPI. See here for more information: <a href=http://www.alchemyapi.com/api/keyword/ rel=nofollow>http://www.alchemyapi.com/api/keyword/</a>",
"http://www.myexperiment.org/workflows/3236/versions/1.html","Levenshtein edit distance words","2012-10-0511:37:19","","","/users/6731","cneudecker","taverna 2","/users/6731,","cneudecker,",,
"http://www.myexperiment.org/workflows/3246/versions/1.html","Data publication example","2012-10-1110:33:56","","http://www.myexperiment.org/workflows/3246/download/Data_publication_example-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","/users/30,","Alan Williams,","This workflow gives an example of an interaction that makes use of published input data. The data is published on the webdav and the URL passed to the HTML page.",0, 0, ,
"http://www.myexperiment.org/workflows/3249/versions/1.html","Tesseract 2.04 Basic Workflow","2012-10-1613:37:21","","http://www.myexperiment.org/workflows/3249/download/Tesseract_2.04_Basic_Workflow-v1.t2flow?version=1","/users/22254","Bart Lamiroy","taverna 2","/users/22254,","Bart Lamiroy,","&nbsp;Elementary workflow for execution on the on-line  <a href=http://dae.cse.lehigh.edu rel=nofollow>DAE platform</a> . (requires an uncompressed tiff image URL as input or will fail otherwise)",-1, 0, ,
"http://www.myexperiment.org/workflows/3250/versions/1.html","Ocrad 0.19 Basic Workflow","2012-10-1619:03:28","2012-10-1619:15:50","http://www.myexperiment.org/workflows/3250/download/Ocrad_0.19_Basic_Workflow-v1.t2flow?version=1","/users/22254","Bart Lamiroy","taverna 2","/users/22254,","Bart Lamiroy,","Elementary OCR workflow for execution on the on-line&nbsp; <a href=http://dae.cse.lehigh.edu/ rel=nofollow>DAE platform</a> . Implement v0.19 of the ocrad OCR engine. (requires an PGM or PMB input image URL)&nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/3251/versions/1.html","Convert","2012-10-1619:13:40","2012-10-1619:17:45","http://www.myexperiment.org/workflows/3251/download/Convert-v1.t2flow?version=1","/users/22254","Bart Lamiroy","taverna 2","/users/22254,","Bart Lamiroy,","Elementary workflow for execution on the on-line&nbsp; <a href=http://dae.cse.lehigh.edu/ rel=nofollow>DAE platform</a> . Converts an input image into another format by using the  <a href=http://www.imagemagick.org/ rel=nofollow>ImageMagick</a> &nbsp;&quot;convert&quot; program.",-1, 0, ,
"http://www.myexperiment.org/workflows/3252/versions/1.html","Standford Named Entity Detection","2012-10-1619:24:27","","http://www.myexperiment.org/workflows/3252/download/Standford_Named_Entity_Detection-v1.t2flow?version=1","/users/22254","Bart Lamiroy","taverna 2","/users/22254,","Bart Lamiroy,","&nbsp;Elementary OCR workflow for execution on the on-line&nbsp; <a href=http://dae.cse.lehigh.edu/ rel=nofollow>DAE platform</a> . Takes a text file as input. Implements a&nbsp; <span>Named entity detection algorithm by Jenny Finkel and Christopher Manning as described in Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. &quot;</span> <a href=http://nlp.stanford.edu/~manning/papers/gibbscrf3.pdf rel=nofollow>Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling</a> <span>&quot;. Proceedings of the 43nd Annual Meeting of the Association for Computational Linguistics (ACL 2005), pp. 363-370.</span> &nbsp; &nbsp; &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/3253/versions/1.html","NCC Document Layout Segmentation","2012-10-1619:32:39","","http://www.myexperiment.org/workflows/3253/download/NCC_Document_Layout_Segmentation-v1.t2flow?version=1","/users/22254","Bart Lamiroy","taverna 2","/users/22254,","Bart Lamiroy,","<span>Segments a black-and-white input image into text, line drawing and picture images. Contribution by the&nbsp;</span> <a href=http://cactus.nci.nih.gov/ rel=nofollow>NCI/CADD group</a> <span>&nbsp;at the National Institutes of Health for the&nbsp;</span> <a href=http://dae.cse.lehigh.edu/DAE/?q=node/60 rel=nofollow>ICDAR 2011 Document Analysis Algorithm Contributions in End-to-End Applications Contest</a> <span>.</span>",-1, 0, ,
"http://www.myexperiment.org/workflows/3254/versions/1.html","NCC Image Binarization","2012-10-1619:34:12","","http://www.myexperiment.org/workflows/3254/download/NCC_Image_Binarization-v1.t2flow?version=1","/users/22254","Bart Lamiroy","taverna 2","/users/22254,","Bart Lamiroy,","<span>Converts color or grayscale image to black-and-white. Winning contribution by the&nbsp;</span> <a href=http://cactus.nci.nih.gov/ rel=nofollow>NCI/CADD group</a> <span>&nbsp;at the National Institutes of Health for the&nbsp;</span> <a href=http://dae.cse.lehigh.edu/DAE/?q=node/60 rel=nofollow>ICDAR 2011 Document Analysis Algorithm Contributions in End-to-End Applications Contest</a> <span>.</span>",-1, 0, ,
"http://www.myexperiment.org/workflows/3255/versions/1.html","DAE Random Image Selector","2012-10-1619:36:42","","http://www.myexperiment.org/workflows/3255/download/DAE_Random_Image_Selector-v1.t2flow?version=1","/users/22254","Bart Lamiroy","taverna 2","/users/22254,","Bart Lamiroy,","DAE Webservice providing n random images from a given data set.&nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/3257/versions/1.html","APIS EPN-TAP Query","2012-10-1814:41:15","","http://www.myexperiment.org/workflows/3257/download/APIS_EPN-TAP_Query-v1.t2flow?version=1","/users/59183","Baptiste Cecconi","taverna 2","/users/59183,","Baptiste Cecconi,","Use this workflow to query APIS (Auroral Planetary Imaging and Spectroscopy) using the EPN-TAP protocol.",-1, 0, ,
"http://www.myexperiment.org/workflows/3258/versions/1.html","Retrieve_Pubmed_Publication_by_kegg_pathway_id","2012-10-1815:06:12","","http://www.myexperiment.org/workflows/3258/download/Retrieve_Pubmed_Publication_by_kegg_pathway_id-v1.t2flow?version=1","/users/59917","Massimo La Rosa","taverna 2","/users/59917, /users/60189,","Massimo La Rosa, Antonino Fiannaca,","This workflow shows in your browser pubmed articles related to input pathway",0, 0, ,
"http://www.myexperiment.org/workflows/3259/versions/1.html","get_Disease_Id_by_Pathway","2012-10-1910:26:30","","http://www.myexperiment.org/workflows/3259/download/get_Disease_Id_by_Pathway-v1.t2flow?version=1","/users/59917","Massimo La Rosa","taverna 2","/users/59917, /users/60189,","Massimo La Rosa, Antonino Fiannaca,","retrieve Disease Id related to a gien pathway in KEGG db",0, 0, ,
"http://www.myexperiment.org/workflows/3260/versions/1.html","When did the fastest type II CME happened?","2012-10-2117:26:24","","http://www.myexperiment.org/workflows/3260/download/When_did_the_fastest_type_II_CME_happened_-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723, /users/59168,","David PS, Eoincar,","Simple query to the HELIO Event Catalogue to extract the start and end time of the fastest CME from the Wind Type II catalogue.  Also it extracts the Xray Class from the flare associated to the CME",0, 0, ,
"http://www.myexperiment.org/workflows/3261/versions/1.html","Forward CME propagation model (SHEBA) - defined outputs","2012-10-2118:25:38","","http://www.myexperiment.org/workflows/3261/download/Forward_CME_propagation_model__SHEBA__-_defined_outputs-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723,","David PS,","Extract Objects, HitOrMiss, ETAs and plots for a selected run of the SHEBA forward CME.",0, 0, ,
"http://www.myexperiment.org/workflows/3262/versions/1.html","When do the Fastest type II CME should be detected throughout all the heliosphere?","2012-10-2119:00:36","2013-03-2012:21:55","http://www.myexperiment.org/workflows/3262/download/When_do_the_Fastest_type_II_CME_should_be_detected_throughout_all_the_heliosphere_-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723, /users/59168, /users/21398, /users/59183, /users/59185, /users/59198, /users/59169, /users/19798, /users/59186,","David PS, Eoincar, Gab, Baptiste Cecconi, Shanem, Jbyrne, Florian Mayer, Natasha, A lynnyk,","The fastest CME is found from an interval of time, and propagated to Earth, in two steps, first to obtain the Solar wind speed at Earth and then propagated again with a more reasonable CME speed.The output produces Min-Max ETAs for each object in the heliosphere and the plots of the final propagation model.This Workflow was produced as one of the challenges in the HELIO CDAW-IV hosted at TCD",0, 0, ,
"http://www.myexperiment.org/workflows/3262/versions/2.html","When do the Fastest type II CME should be detected throughout all the heliosphere?","2012-10-2119:00:36","2013-03-2012:21:55","http://www.myexperiment.org/workflows/3262/download/When_do_the_Fastest_type_II_CME_should_be_detected_throughout_all_the_heliosphere_-v2.t2flow?version=2","/users/14723","David PS","taverna 2","/users/14723, /users/59168, /users/21398, /users/59183, /users/59185, /users/59198, /users/59169, /users/19798, /users/59186,","David PS, Eoincar, Gab, Baptiste Cecconi, Shanem, Jbyrne, Florian Mayer, Natasha, A lynnyk,","The fastest CME is found from an interval of time, and propagated to Earth, in two steps, first to obtain the Solar wind speed at Earth and then propagated again with a more reasonable CME speed.The output produces Min-Max ETAs for each object in the heliosphere and the plots of the final propagation model.This Workflow was produced as one of the challenges in the HELIO CDAW-IV hosted at TCD",0, 0, ,
"http://www.myexperiment.org/workflows/3264/versions/1.html","Back CIR-CME propagation model","2012-10-2416:09:33","","http://www.myexperiment.org/workflows/3264/download/Back_CIR-CME_propagation_model-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723, /users/4706,","David PS, Anja Le Blanc,","With a observing time at an object and the type of PM that you want to run executes it and provides the plots and the time and longitude where it should be seen the origin of the event.",0, 0, ,
"http://www.myexperiment.org/workflows/3265/versions/1.html","Solar Wind properties and plot","2012-10-2507:48:20","","http://www.myexperiment.org/workflows/3265/download/Solar_Wind_properties_and_plot-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723,","David PS,","Using HELIO-MDES this workflow provides some properties of the solar wind from an input date and a mission and the plot +/-1 day for context.",0, 0, ,
"http://www.myexperiment.org/workflows/3268/versions/1.html","Extract average Solar wind speed from ACE data","2012-10-3011:42:20","","http://www.myexperiment.org/workflows/3268/download/Extract_average_Solar_wind_speed_from_ACE_data-v1.t2flow?version=1","/users/59168","Eoincar","taverna 2","/users/59168,","Eoincar,","It reads the data coming from a MDES (HELIO) query and calculates the average Solar Wind speed.  Notice that it just works for ACE as other missions could have the columns in different order.",0, 0, ,
"http://www.myexperiment.org/workflows/3269/versions/1.html","Number of bonds/atoms generator from Chemical name","2012-10-3014:37:41","2012-10-3014:38:00","http://www.myexperiment.org/workflows/3269/download/Number_of_bonds_atoms_generator_from_Chemical_name-v1.t2flow?version=1","/users/60147","Michael Smith","taverna 2","/users/60147,","Michael Smith,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3276/versions/1.html","Creation of a stage matrix model from demographic monitoring of individuals in an animal or plant population","2012-11-0112:59:45","2014-07-2507:35:24","http://www.myexperiment.org/workflows/3276/download/Creation_of_a_stage_matrix_model_from_demographic_monitoring_of_individuals_in_an_animal_or_plant_population-v1.t2flow?version=1","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3276/versions/2.html","Creation of a stage matrix model from demographic monitoring of individuals in an animal or plant population","2012-11-0112:59:45","2014-07-2507:35:24","http://www.myexperiment.org/workflows/3276/download/Creation_of_a_stage_matrix_model_from_demographic_monitoring_of_individuals_in_an_animal_or_plant_population-v2.t2flow?version=2","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3277/versions/1.html","Matching flare events to active regions","2012-11-0116:07:03","","http://www.myexperiment.org/workflows/3277/download/Matching_flare_events_to_active_regions-v1.t2flow?version=1","/users/4706","Anja Le Blanc","taverna 2","/users/4706,","Anja Le Blanc,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3278/versions/1.html","Matrix Population Model construction and analysis","2012-11-0210:34:45","2014-09-1710:44:44","http://www.myexperiment.org/workflows/3278/download/Matrix_Population_Model_construction_and_analysis-v1.t2flow?version=1","/users/62314","Biodiversity eLaboratory","taverna 2","/users/20379, /users/20423, /users/20384,","Jon Giddy, Gerard Oostermeijer, Maria Paula Balcazar-Vargas,",,0, 0, ,
"http://www.myexperiment.org/workflows/3278/versions/2.html","Matrix Population Model construction and analysis","2012-11-0210:34:45","2014-09-1710:44:44","http://www.myexperiment.org/workflows/3278/download/Matrix_Population_Model_construction_and_analysis-v2.t2flow?version=2","/users/62314","Biodiversity eLaboratory","taverna 2","/users/20379, /users/20423, /users/20384,","Jon Giddy, Gerard Oostermeijer, Maria Paula Balcazar-Vargas,","This workflow is deprecated. To obtain a more recent version of this workflow, please refer to:  <a href=http://www.myexperiment.org/packs/483.html rel=nofollow>http://www.myexperiment.org/packs/483.html</a> For historic access to this workflow, please view an earlier version.",0, 0, ,
"http://www.myexperiment.org/workflows/3278/versions/3.html","Matrix Population Model construction and analysis","2012-11-0210:34:45","2014-09-1710:44:44","http://www.myexperiment.org/workflows/3278/download/Matrix_Population_Model_construction_and_analysis-v3.t2flow?version=3","/users/62314","Biodiversity eLaboratory","taverna 2","/users/20379, /users/20423, /users/20384,","Jon Giddy, Gerard Oostermeijer, Maria Paula Balcazar-Vargas,","This workflow is deprecated. To obtain a more recent version of this workflow, please refer to:  <a href=http://www.myexperiment.org/packs/483.html rel=nofollow>http://www.myexperiment.org/packs/483.html</a> For historic access to this workflow, please view an earlier version.",0, 0, ,
"http://www.myexperiment.org/workflows/3282/versions/1.html","Matrix Population Model construction and analysis","2012-11-0211:48:53","2014-09-1710:42:43","http://www.myexperiment.org/workflows/3282/download/Matrix_Population_Model_construction_and_analysis-v1.t2flow?version=1","/users/62314","Biodiversity eLaboratory","taverna 2","/users/20379, /users/20384, /users/20423,","Jon Giddy, Maria Paula Balcazar-Vargas, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3282/versions/2.html","Matrix Population Model construction and analysis","2012-11-0211:48:53","2014-09-1710:42:43","http://www.myexperiment.org/workflows/3282/download/Matrix_Population_Model_construction_and_analysis-v2.t2flow?version=2","/users/62314","Biodiversity eLaboratory","taverna 2","/users/20379, /users/20384, /users/20423,","Jon Giddy, Maria Paula Balcazar-Vargas, Gerard Oostermeijer,","This workflow is deprecated. To obtain a more recent version of this workflow, please refer to:  <a href=http://www.myexperiment.org/packs/483.html rel=nofollow>http://www.myexperiment.org/packs/483.html</a> For historic access to this workflow, please view an earlier version.",0, 0, ,
"http://www.myexperiment.org/workflows/3284/versions/1.html","Eigen analysis","2012-11-0213:53:41","2014-07-2511:16:04","http://www.myexperiment.org/workflows/3284/download/Eigen_analysis-v1.t2flow?version=1","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3284/versions/2.html","Eigen analysis","2012-11-0213:53:41","2014-07-2511:16:04","http://www.myexperiment.org/workflows/3284/download/Eigen_analysis-v2.t2flow?version=2","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3284/versions/3.html","Eigen analysis","2012-11-0213:53:41","2014-07-2511:16:04","http://www.myexperiment.org/workflows/3284/download/Eigen_analysis-v3.t2flow?version=3","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,","The Eigen analysis results are a set of demographic statistics: 1) Lambda or dominant eigenvalue: The population will be stable, grow or decrease at a rate given by lambda: eg: ? = 1 (population is stable), ? &gt; 1 (population is growing) and finally ? &lt; 1 (populatiopn is decreasing) . 2) The stable stage distribution: It is the proportion of the number of individuals per stage and it is given by (w). Elasticity and Sensitivity: Sensitivity and elasticity analyses are prospective analyses. 3) The sensitivity matrix: The sensitivity gives the effect on ? of changes in any entry of the matrix, including those that may, an a given context, be regarded as fixed at zero or some other value. The derivative tells what would happened to ? if aij was to change, not whether, or in what direction, or how much, aij actually change. The hypothetical results of such impossible perturbations may or may not be of interest, but they are not zero. It is up to you to decide whether they are useful (Caswell 2001). When comparing the ?-sensitivity values for all matrix elements one can find out in what element a certain increase has the biggest impact on ?. However, a 0.01 increase in a survival matrix element is hard to compare to a 0.01 increase in a reproduction matrix element, because the latter is not bound between 0 and 1 and can sometimes take high values. Increasing matrix element a14 (number of S (seedlings) the next year produced by an G (Reproductive individuals)) with 0.01 from 7.666 to 7.676 does not have a noticeable effect on ?. For comparison between matrix elements it can therefore be more insightful to look at the impact of proportional changes in elements: by what percentage does ? change if a matrix element is changed by a certain percentage? This proportional sensitivity is termed elasticity (Description based on Oostermeijer data, based on Jongejans &amp; de Kroon 2012). 4) The Elasticity matrix: The elasticities sum to 1 across the whole matrix (Caswell 1986; de Kroon et al. 1986; Mesterton-Gibbons 1993) and can be interpreted as proportional contributions of the corresponding vital rates to the matrix (see van Groenendael et al. 1994). 5) Reproductive value (v): scaled so v[1]=1. To what extent  will a plant or animal of a determinate category or stage , contribute to the ancestry of future generation. 6) The damping ratio:  it can be considered as a measure of the intrinsic resilience of the population, describing how quickly transient dynamics decay following disturbance or perturbation regardless of population structure, the larger the p, the quicker the population converges. Those statistics are function of the vital rates, and througt them of biological and environmental variables. For further details see: Caswell, H. 1986. Life cycle models for plants. Lectures on Mathematics in the Life Sciences 18: 171-233.Caswell, H. 2001. Matrix population models: Construction, analysis and interpretation, 2nd Edition. Sinauer Associates, Sunderland, Massachusetts.Horvitz, C., D.W. Schemske, and Hal Caswell. 1997. The relative importance of life-history stages to population growth: Prospective and retrospective analyses. In S. Tuljapurkar and H. Caswell. Structured population models in  terrestrial and freshwater systems. Chapman and Hall, New York.Jongejans E. &amp; H. de Kroon. 2012. Matrix models. Chapter in Encyclopedia of Theoretical Ecology (eds. Hastings A &amp; Gross L) University of California, p415-423de Kroon, H. J., A. Plaiser, J. van Groenendael, and H. Caswell. 1986. Elasticity: The relative contribution of demographic parameters to population growth rate. Ecology 67: 1427-1431.Mesterton-Gibbons, M. 1993. Why demographic elasticities sum to one: A postscript to de Kroon et al. Ecology 74: 2467-2468.van Groenendael, J., H. de Kroon, S. Kalisz, and S. Tuljapurkar. 1994. Loop analysis: Evaluating life history pathways in population projection matrices. Ecology 75: 2410-2415.",0, 0, ,
"http://www.myexperiment.org/workflows/3286/versions/1.html","Age specific analysis","2012-11-0214:28:56","2014-07-2412:24:05","http://www.myexperiment.org/workflows/3286/download/Age_specific_analysis-v1.t2flow?version=1","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3286/versions/2.html","Age specific analysis","2012-11-0214:28:56","2014-07-2412:24:05","http://www.myexperiment.org/workflows/3286/download/Age_specific_analysis-v2.t2flow?version=2","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3286/versions/3.html","Age specific analysis","2012-11-0214:28:56","2014-07-2412:24:05","http://www.myexperiment.org/workflows/3286/download/Age_specific_analysis-v3.t2flow?version=3","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3288/versions/1.html","Transient Dynamics.","2012-11-0214:54:47","2014-07-3110:17:38","http://www.myexperiment.org/workflows/3288/download/Transient_Dynamics.-v1.t2flow?version=1","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3288/versions/2.html","Transient Dynamics.","2012-11-0214:54:47","2014-07-3110:17:38","http://www.myexperiment.org/workflows/3288/download/Transient_Dynamics.-v2.t2flow?version=2","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3288/versions/3.html","Transient Dynamics.","2012-11-0214:54:47","2014-07-3110:17:38","http://www.myexperiment.org/workflows/3288/download/Transient_Dynamics.-v3.t2flow?version=3","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3289/versions/1.html","Generation time (T)","2012-11-0215:04:47","2014-07-2508:40:21","http://www.myexperiment.org/workflows/3289/download/Generation_time__T_-v1.t2flow?version=1","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3289/versions/2.html","Generation time (T)","2012-11-0215:04:47","2014-07-2508:40:21","http://www.myexperiment.org/workflows/3289/download/Generation_time__T_-v2.t2flow?version=2","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3291/versions/1.html","Net reproductive rate (Ro)","2012-11-0215:58:58","2014-07-2508:59:08","http://www.myexperiment.org/workflows/3291/download/Net_reproductive_rate__Ro_-v1.t2flow?version=1","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3291/versions/2.html","Net reproductive rate (Ro)","2012-11-0215:58:58","2014-07-2508:59:08","http://www.myexperiment.org/workflows/3291/download/Net_reproductive_rate__Ro_-v2.t2flow?version=2","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3292/versions/1.html","Mp3 To Wav Migrate QA CLI List Test","2012-11-0511:43:51","2012-11-1310:54:26","http://www.myexperiment.org/workflows/3292/download/Mp3_To_Wav_Migrate_QA_CLI_List_Test-v1.t2flow?version=1","/users/19098","Bolette Jurik","taverna 2","/users/19098,","Bolette Jurik,","Migrates Mp3 files from input List to Wav files and performs QA. The QA steps include File Format Validation, Significant Property Comparison and migrationQA file content comparison (all CLI). As this is a Test workflow, the (very large) Wav files are deleted, and only the QA results and log files are saved for analysis.",0, 0, ,
"http://www.myexperiment.org/workflows/3292/versions/2.html","Mp3 To Wav Migrate QA CLI List Test","2012-11-0511:43:51","2012-11-1310:54:26","http://www.myexperiment.org/workflows/3292/download/Mp3_To_Wav_Migrate_QA_CLI_List_Test-v2.t2flow?version=2","/users/19098","Bolette Jurik","taverna 2","/users/19098,","Bolette Jurik,","This workflow migrates an mp3 file to wav using a SCAPE ffmpeg web service. It validates the migrated file using a jhove2 SCAPE web service. It extracts and compares simple characteristic using an ffprobe SCAPE web service. This workflow matches solution (most of) SO4 on the SCAPE opf wiki, see  <a href=http://wiki.opf-labs.org/display/SP/SO4+Audio+mp3+to+wav+Migration+and+QA+Workflow rel=nofollow>http://wiki.opf-labs.org/display/SP/SO4+Audio+mp3+to+wav+Migration+and+QA+Workflow</a> <br /> &nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/3292/versions/3.html","Mp3 To Wav Migrate QA CLI List Test","2012-11-0511:43:51","2012-11-1310:54:26","http://www.myexperiment.org/workflows/3292/download/Mp3_To_Wav_Migrate_QA_CLI_List_Test-v3.t2flow?version=3","/users/19098","Bolette Jurik","taverna 2","/users/19098,","Bolette Jurik,","Migrates Mp3 files from input List to Wav files and performs QA. The QA steps include File Format Validation, Significant Property Comparison and migrationQA file content comparison (all CLI). As this is a Test workflow, the (very large) Wav files are deleted, and only the QA results and log files are saved for analysis. This workflow matches solution SO4 on the SCAPE opf wiki, see  <a href=http://wiki.opf-labs.org/display/SP/SO4+Audio+mp3+to+wav+Migration+and+QA+Workflow rel=nofollow>http://wiki.opf-labs.org/display/SP/SO4+Audio+mp3+to+wav+Migration+and+QA+Workflow</a> <br /> &nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/3292/versions/4.html","Mp3 To Wav Migrate QA CLI List Test","2012-11-0511:43:51","2012-11-1310:54:26","http://www.myexperiment.org/workflows/3292/download/Mp3_To_Wav_Migrate_QA_CLI_List_Test-v4.t2flow?version=4","/users/19098","Bolette Jurik","taverna 2","/users/19098,","Bolette Jurik,","Migrates Mp3 files from input List to Wav files and performs QA. The QA steps include File Format Validation, Significant Property Comparison and migrationQA file content comparison (all CLI). As this is a Test workflow, the (very large) Wav files are deleted, and only the QA results and log files are saved for analysis. This workflow matches solution SO4 on the SCAPE opf wiki, see  <a href=http://wiki.opf-labs.org/display/SP/SO4+Audio+mp3+to+wav+Migration+and+QA+Workflow rel=nofollow>http://wiki.opf-labs.org/display/SP/SO4+Audio+mp3+to+wav+Migration+and+QA+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3293/versions/1.html","HFC Synoptic map from date","2012-11-0512:48:40","","http://www.myexperiment.org/workflows/3293/download/HFC_Synoptic_map_from_date-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723,","David PS,","query the HELIO Feature Catalogue, and retrieves the image with all the features catalgued for certain date.",0, 0, ,
"http://www.myexperiment.org/workflows/3294/versions/1.html","CDAW CME movie from date","2012-11-0512:54:59","","http://www.myexperiment.org/workflows/3294/download/CDAW_CME_movie_from_date-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723,","David PS,","generates the url for the input date to visualize CMEs and GOES xray light curve produced by CDAW at GSFC",0, 0, ,
"http://www.myexperiment.org/workflows/3295/versions/1.html","Bootstrap of  observed census transitions.","2012-11-0515:05:37","2014-07-2413:09:04","http://www.myexperiment.org/workflows/3295/download/Bootstrap_of__observed_census_transitions.-v1.t2flow?version=1","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3295/versions/2.html","Bootstrap of  observed census transitions.","2012-11-0515:05:37","2014-07-2413:09:04","http://www.myexperiment.org/workflows/3295/download/Bootstrap_of__observed_census_transitions.-v2.t2flow?version=2","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3295/versions/3.html","Bootstrap of  observed census transitions.","2012-11-0515:05:37","2014-07-2413:09:04","http://www.myexperiment.org/workflows/3295/download/Bootstrap_of__observed_census_transitions.-v3.t2flow?version=3","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3300/versions/1.html","ImportRefSeqtoKegg","2012-11-1214:31:05","2013-01-0809:25:20","http://www.myexperiment.org/workflows/3300/download/ImportRefSeqtoKegg-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow extracts a column of RefSeq gene IDs from a CSV file and then converts them to Kegg gene identifiers",0, 0, ,
"http://www.myexperiment.org/workflows/3300/versions/2.html","ImportRefSeqtoKegg","2012-11-1214:31:05","2013-01-0809:25:20","http://www.myexperiment.org/workflows/3300/download/ImportRefSeqtoKegg-v2.t2flow?version=2","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow extracts a column of RefSeq gene IDs from a CSV file and then converts them to Kegg gene identifiers. This workflow uses the new KEGG REST service, which replaces the old SOAP interface from 31st December 2012",0, 0, ,
"http://www.myexperiment.org/workflows/3300/versions/3.html","ImportRefSeqtoKegg","2012-11-1214:31:05","2013-01-0809:25:20","http://www.myexperiment.org/workflows/3300/download/ImportRefSeqtoKegg-v3.t2flow?version=3","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow extracts a column of RefSeq gene IDs from a CSV file and then converts them to Kegg gene identifiers. This workflow uses the new KEGG REST service, which replaces the old SOAP interface from 31st December 2012",0, 0, ,
"http://www.myexperiment.org/workflows/3301/versions/1.html","Finding the origins of Solar Wind events at Earth","2012-11-1612:51:59","2013-03-2112:26:41","http://www.myexperiment.org/workflows/3301/download/Finding_the_origins_of_Solar_Wind_events_at_Earth-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723,","David PS,","This gives a comprenhensive overview of high speed solar wind events (CME or CIR) seen at Eart, by obtaining the maximum in-situ measure velocity from the data evaluation service (DES), propagating the even backwards to Earth using the HELIO processing service (HPS) and SHEBA propagation model, and search whether halo CMEs or CHs were observed on that time, and retrieves, besides all the previous information, a context solar wind plot (+/- 1 day) and  a URL linking to a context movie for CMEs or map from the HELIO feature catalogue (HFC) for CHs.",0, 0, ,
"http://www.myexperiment.org/workflows/3301/versions/2.html","Finding the origins of Solar Wind events at Earth","2012-11-1612:51:59","2013-03-2112:26:41","http://www.myexperiment.org/workflows/3301/download/Finding_the_origins_of_Solar_Wind_events_at_Earth-v2.t2flow?version=2","/users/14723","David PS","taverna 2","/users/14723,","David PS,","This gives a comprenhensive overview of high speed solar wind events (CME or CIR) seen at Eart, by obtaining the maximum in-situ measure velocity from the data evaluation service (DES), propagating the even backwards to Earth using the HELIO processing service (HPS) and SHEBA propagation model, and search whether halo CMEs or CHs were observed on that time, and retrieves, besides all the previous information, a context solar wind plot (+/- 1 day) and  a URL linking to a context movie for CMEs or map from the HELIO feature catalogue (HFC) for CHs.",0, 0, ,
"http://www.myexperiment.org/workflows/3301/versions/3.html","Finding the origins of Solar Wind events at Earth","2012-11-1612:51:59","2013-03-2112:26:41","http://www.myexperiment.org/workflows/3301/download/Finding_the_origins_of_Solar_Wind_events_at_Earth-v3.t2flow?version=3","/users/14723","David PS","taverna 2","/users/14723,","David PS,","This gives a comprenhensive overview of high speed solar wind events (CME or CIR) seen at Eart, by obtaining the maximum in-situ measure velocity from the data evaluation service (DES), propagating the even backwards to Earth using the HELIO processing service (HPS) and SHEBA propagation model, and search whether halo CMEs or CHs were observed on that time, and retrieves, besides all the previous information, a context solar wind plot (+/- 1 day) and  a URL linking to a context movie for CMEs or map from the HELIO feature catalogue (HFC) for CHs.",0, 0, ,
"http://www.myexperiment.org/workflows/3301/versions/4.html","Finding the origins of Solar Wind events at Earth","2012-11-1612:51:59","2013-03-2112:26:41","http://www.myexperiment.org/workflows/3301/download/Finding_the_origins_of_Solar_Wind_events_at_Earth-v4.t2flow?version=4","/users/14723","David PS","taverna 2","/users/14723,","David PS,","This gives a comprenhensive overview of high speed solar wind events (CME or CIR) seen at Eart, by obtaining the maximum in-situ measure velocity from the data evaluation service (DES), propagating the even backwards to Earth using the HELIO processing service (HPS) and SHEBA propagation model, and search whether halo CMEs or CHs were observed on that time, and retrieves, besides all the previous information, a context solar wind plot (+/- 1 day) and  a URL linking to a context movie for CMEs or map from the HELIO feature catalogue (HFC) for CHs.",0, 0, ,
"http://www.myexperiment.org/workflows/3301/versions/5.html","Finding the origins of Solar Wind events at Earth","2012-11-1612:51:59","2013-03-2112:26:41","http://www.myexperiment.org/workflows/3301/download/Finding_the_origins_of_Solar_Wind_events_at_Earth-v5.t2flow?version=5","/users/14723","David PS","taverna 2","/users/14723,","David PS,","This gives a comprenhensive overview of high speed solar wind events (CME or CIR) seen at Eart, by obtaining the maximum in-situ measure velocity from the data evaluation service (DES), propagating the even backwards to Earth using the HELIO processing service (HPS) and SHEBA propagation model, and search whether halo CMEs or CHs were observed on that time, and retrieves, besides all the previous information, a context solar wind plot (+/- 1 day) and  a URL linking to a context movie for CMEs or map from the HELIO feature catalogue (HFC) for CHs.",0, 0, ,
"http://www.myexperiment.org/workflows/3301/versions/6.html","Finding the origins of Solar Wind events at Earth","2012-11-1612:51:59","2013-03-2112:26:41","http://www.myexperiment.org/workflows/3301/download/Finding_the_origins_of_Solar_Wind_events_at_Earth-v6.t2flow?version=6","/users/14723","David PS","taverna 2","/users/14723,","David PS,","This gives a comprenhensive overview of high speed solar wind events (CME or CIR) seen at Eart, by obtaining the maximum in-situ measure velocity from the data evaluation service (DES), propagating the even backwards to Earth using the HELIO processing service (HPS) and SHEBA propagation model, and search whether halo CMEs or CHs were observed on that time, and retrieves, besides all the previous information, a context solar wind plot (+/- 1 day) and  a URL linking to a context movie for CMEs or map from the HELIO feature catalogue (HFC) for CHs.",0, 0, ,
"http://www.myexperiment.org/workflows/3306/versions/1.html","AIT Matchbox Scenario All","2012-11-2422:39:18","2012-11-2422:39:19","http://www.myexperiment.org/workflows/3306/download/AIT_Matchbox_Scenario_All-v1.t2flow?version=1","/users/17168","Roman","taverna 2","/users/17168,","Roman,","In this scenario matchbox will find duplicates in passed digital collection. All matchbox workflow steps are executed automatically in one turn. User will get a list of duplicates in result. Matchbox in this scenario is installed on remote Linux VM. Digital collection is stored on Windows machine.",0, 0, ,
"http://www.myexperiment.org/workflows/3308/versions/1.html","AIT Matchbox Scenario Professional","2012-11-2422:47:17","2012-11-2422:56:24","http://www.myexperiment.org/workflows/3308/download/AIT_Matchbox_Scenario_Professional-v1.t2flow?version=1","/users/17168","Roman","taverna 2","/users/17168,","Roman,","In this scenario matchbox will find duplicates in passed digital collection. All matchbox workflow steps are executed automatically in one turn. User will get a list of duplicates in result. Matchbox in this scenario is installed on remote Linux VM. Digital collection is stored on Windows machine.",0, 0, ,
"http://www.myexperiment.org/workflows/3308/versions/2.html","AIT Matchbox Scenario Professional","2012-11-2422:47:17","2012-11-2422:56:24","http://www.myexperiment.org/workflows/3308/download/AIT_Matchbox_Scenario_Professional-v2.t2flow?version=2","/users/17168","Roman","taverna 2","/users/17168,","Roman,","In this scenario matchbox will find duplicates in passed digital collection. All matchbox workflow steps are executed automatically in one turn. User will get a list of duplicates in result. Matchbox in this scenario is installed on remote Linux VM. Digital collection is stored on Windows machine. This workflow starts duplicate finding process using the FindDuplicates python script of the matchbox tool. Matchbox tool support python in version 2.7. Execution starts from the directory where python scripts are located. If you use source code from Github, then it is a scape/pc-qa-matchbox/Python/ directory. The python script supports different parameter. Experienced user can apply extract, train, bowhist and compare parameters in order to execute associated step in the matchbox workflow for duplicate seach. The order of execution steps should not be changed, because each next step requires an output from a previous step. E.g. if you are going to repeat the comparison step you should have calculated required BOWHistogram files from bowhist step.",0, 0, ,
"http://www.myexperiment.org/workflows/3308/versions/3.html","AIT Matchbox Scenario Professional","2012-11-2422:47:17","2012-11-2422:56:24","http://www.myexperiment.org/workflows/3308/download/AIT_Matchbox_Scenario_Professional-v3.t2flow?version=3","/users/17168","Roman","taverna 2","/users/17168,","Roman,","In this scenario matchbox will find duplicates in passed digital collection. Each matchbox workflow step can be executed separately. User will get a list of duplicates in result. Matchbox in this scenario is installed on remote Linux VM. Digital collection is stored on Windows machine. This workflow starts duplicate finding process using the FindDuplicates python script of the matchbox tool. Matchbox tool support python in version 2.7. Execution starts from the directory where python scripts are located. If you use source code from Github, then it is a scape/pc-qa-matchbox/Python/ directory. The python script supports different parameter. Experienced user can apply extract, train, bowhist and compare parameters in order to execute associated step in the matchbox workflow for duplicate seach. The order of execution steps should not be changed, because each next step requires an output from a previous step. E.g. if you are going to repeat the comparison step you should have calculated required BOWHistogram files from bowhist step.",0, 0, ,
"http://www.myexperiment.org/workflows/3309/versions/1.html","AIT Matchbox Scenario Find Duplicates using Nested Commands","2012-11-2423:04:32","","http://www.myexperiment.org/workflows/3309/download/AIT_Matchbox_Scenario_Find_Duplicates_using_Nested_Commands-v1.t2flow?version=1","/users/17168","Roman","taverna 2","/users/17168,","Roman,","In this scenario matchbox will find duplicates in passed digital collection. All matchbox workflow steps are defined separately using input parameter sequence: clean, extract, train, bowhist and compare. User will get a list of duplicates in result. Matchbox in this scenario is installed on remote Linux VM. Digital collection is stored on Windows machine.",0, 0, ,
"http://www.myexperiment.org/workflows/3310/versions/1.html","AIT Matchbox Scenario Check Duplicate Pair using SSIM","2012-11-2423:13:53","","http://www.myexperiment.org/workflows/3310/download/AIT_Matchbox_Scenario_Check_Duplicate_Pair_using_SSIM-v1.t2flow?version=1","/users/17168","Roman","taverna 2","/users/17168,","Roman,","In this scenario matchbox will check duplicate pair of previously found duplicates in passed digital collection if output information was lost. The pair check does not require the time consumpting whole analysis and is very fast. Matchbox in this scenario is installed on remote Linux VM. Digital collection is stored on Windows machine.",0, 0, ,
"http://www.myexperiment.org/workflows/3311/versions/1.html","AIT Matchbox Scenario Compare Image Pair based on Profile","2012-11-2423:23:45","","http://www.myexperiment.org/workflows/3311/download/AIT_Matchbox_Scenario_Compare_Image_Pair_based_on_Profile-v1.t2flow?version=1","/users/17168","Roman","taverna 2","/users/17168,","Roman,","In this scenario matchbox will compare given image pair based on extracted profile information. User will get a histogram intersection distance value in result. Small value means high similarity, high value means different images. Matchbox in this scenario is installed on remote Linux VM. Digital collection is stored on Windows machine.",0, 0, ,
"http://www.myexperiment.org/workflows/3336/versions/1.html","Ingest.t2flow","2012-12-1914:07:08","","http://www.myexperiment.org/workflows/3336/download/Ingest.t2flow-v1.t2flow?version=1","/users/60916","Holly Zhen","taverna 2","/users/2790,","Arifshaon,","&nbsp;characterisation of NeXus files",-1, 0, ,
"http://www.myexperiment.org/workflows/3349/versions/1.html","Microbial Metagenomic Trait Statistical Analysis Workflow","2012-12-1923:11:08","2014-11-1209:45:08","http://www.myexperiment.org/workflows/3349/download/Microbial_Metagenomic_Trait_Statistical_Analysis_Workflow-v1.t2flow?version=1","/users/20367","Antonio Fernandez-Guerra","taverna 2","/users/20367, /users/18968, /users/60773,","Antonio Fernandez-Guerra, Renzo, Peliny,","The metagenomic traits statistics workflow computes the multivariate statistics related to the community traits outlined in Barberan et al. 2011 Exploration of community traits as ecological markers in microbial metagenomes. The traits included in the statistical analyses range from GC content to functional diversity, and deliver a valuable set of ecological markers in order discriminate between habitats or geographic locations. Furthermore, intertrait relationships can be used as habitat descriptors or indicators of artefacts during sample processing. Overall, these metagenomics community traits approach, here combined in a single workflow, helps to interpret metagenomics data to gain a full understanding of microbial community patterns in a rigorous ecological framework.",0, 0, ,
"http://www.myexperiment.org/workflows/3349/versions/2.html","Microbial Metagenomic Trait Statistical Analysis Workflow","2012-12-1923:11:08","2014-11-1209:45:08","http://www.myexperiment.org/workflows/3349/download/Microbial_Metagenomic_Trait_Statistical_Analysis_Workflow-v2.t2flow?version=2","/users/20367","Antonio Fernandez-Guerra","taverna 2","/users/20367, /users/18968, /users/60773,","Antonio Fernandez-Guerra, Renzo, Peliny,","The metagenomic traits statistics workflow computes the multivariate statistics related to the community traits outlined in Barberan et al. 2011 Exploration of community traits as ecological markers in microbial metagenomes. The traits included in the statistical analyses range from GC content to functional diversity, and deliver a valuable set of ecological markers in order discriminate between habitats or geographic locations. Furthermore, intertrait relationships can be used as habitat descriptors or indicators of artefacts during sample processing. Overall, these metagenomics community traits approach, here combined in a single workflow, helps to interpret metagenomics data to gain a full understanding of microbial community patterns in a rigorous ecological framework.",0, 0, ,
"http://www.myexperiment.org/workflows/3349/versions/3.html","Microbial Metagenomic Trait Statistical Analysis Workflow","2012-12-1923:11:08","2014-11-1209:45:08","http://www.myexperiment.org/workflows/3349/download/Microbial_Metagenomic_Trait_Statistical_Analysis_Workflow-v3.t2flow?version=3","/users/20367","Antonio Fernandez-Guerra","taverna 2","/users/20367, /users/18968, /users/60773,","Antonio Fernandez-Guerra, Renzo, Peliny,","The Metagenomic Traits Statistical Analysis workflow computes the multivariate statistics related to the community traits outlined in Barberan et al. 2012 Exploration of community traits as ecological markers in microbial metagenomes. The traits included in the statistical analyses range from GC content to functional diversity, and deliver a valuable set of ecological markers in order discriminate between habitats or geographic locations. Furthermore, intertrait relationships can be used as habitat descriptors or indicators of artefacts during sample processing. Overall, these metagenomics community traits approach, here combined in a single workflow, helps to interpret metagenomics data to gain a full understanding of microbial community patterns in a rigorous ecological framework.",0, 0, ,
"http://www.myexperiment.org/workflows/3349/versions/4.html","Microbial Metagenomic Trait Statistical Analysis Workflow","2012-12-1923:11:08","2014-11-1209:45:08","http://www.myexperiment.org/workflows/3349/download/Microbial_Metagenomic_Trait_Statistical_Analysis_Workflow-v4.t2flow?version=4","/users/20367","Antonio Fernandez-Guerra","taverna 2","/users/20367, /users/18968, /users/60773,","Antonio Fernandez-Guerra, Renzo, Peliny,","The Metagenomic Traits Statistical Analysis workflow computes the multivariate statistics related to the community traits outlined in Barberan et al. 2012 Exploration of community traits as ecological markers in microbial metagenomes. The traits included in the statistical analyses range from GC content to functional diversity, and deliver a valuable set of ecological markers in order discriminate between habitats or geographic locations. Furthermore, intertrait relationships can be used as habitat descriptors or indicators of artefacts during sample processing. Overall, these metagenomics community traits approach, here combined in a single workflow, helps to interpret metagenomics data to gain a full understanding of microbial community patterns in a rigorous ecological framework.",0, 0, ,
"http://www.myexperiment.org/workflows/3349/versions/5.html","Microbial Metagenomic Trait Statistical Analysis Workflow","2012-12-1923:11:08","2014-11-1209:45:08","http://www.myexperiment.org/workflows/3349/download/Microbial_Metagenomic_Trait_Statistical_Analysis_Workflow-v5.t2flow?version=5","/users/20367","Antonio Fernandez-Guerra","taverna 2","/users/20367, /users/18968, /users/60773,","Antonio Fernandez-Guerra, Renzo, Peliny,","The Metagenomic Traits Statistical Analysis workflow computes the multivariate statistics related to the community traits outlined in Barberan et al. 2012 Exploration of community traits as ecological markers in microbial metagenomes. The traits included in the statistical analyses range from GC content to functional diversity, and deliver a valuable set of ecological markers in order discriminate between habitats or geographic locations. Furthermore, intertrait relationships can be used as habitat descriptors or indicators of artefacts during sample processing. Overall, these metagenomics community traits approach, here combined in a single workflow, helps to interpret metagenomics data to gain a full understanding of microbial community patterns in a rigorous ecological framework.",0, 0, ,
"http://www.myexperiment.org/workflows/3349/versions/6.html","Microbial Metagenomic Trait Statistical Analysis Workflow","2012-12-1923:11:08","2014-11-1209:45:08","http://www.myexperiment.org/workflows/3349/download/Microbial_Metagenomic_Trait_Statistical_Analysis_Workflow-v6.t2flow?version=6","/users/20367","Antonio Fernandez-Guerra","taverna 2","/users/20367, /users/18968, /users/60773,","Antonio Fernandez-Guerra, Renzo, Peliny,","The Metagenomic Traits Statistical Analysis workflow computes the multivariate statistics related to the community traits outlined in Barberan et al. 2012 Exploration of community traits as ecological markers in microbial metagenomes. The traits included in the statistical analyses range from GC content to functional diversity, and deliver a valuable set of ecological markers in order discriminate between habitats or geographic locations. Furthermore, intertrait relationships can be used as habitat descriptors or indicators of artefacts during sample processing. Overall, these metagenomics community traits approach, here combined in a single workflow, helps to interpret metagenomics data to gain a full understanding of microbial community patterns in a rigorous ecological framework.",0, 0, ,
"http://www.myexperiment.org/workflows/3349/versions/7.html","Microbial Metagenomic Trait Statistical Analysis Workflow","2012-12-1923:11:08","2014-11-1209:45:08","http://www.myexperiment.org/workflows/3349/download/Microbial_Metagenomic_Trait_Statistical_Analysis_Workflow-v7.t2flow?version=7","/users/20367","Antonio Fernandez-Guerra","taverna 2","/users/20367, /users/18968, /users/60773,","Antonio Fernandez-Guerra, Renzo, Peliny,","The Metagenomic Traits Statistical Analysis workflow computes the multivariate statistics related to the community traits outlined in Barberan et al. 2012 Exploration of community traits as ecological markers in microbial metagenomes. The traits included in the statistical analyses range from GC content to functional diversity, and deliver a valuable set of ecological markers in order discriminate between habitats or geographic locations. Furthermore, intertrait relationships can be used as habitat descriptors or indicators of artefacts during sample processing. Overall, these metagenomics community traits approach, here combined in a single workflow, helps to interpret metagenomics data to gain a full understanding of microbial community patterns in a rigorous ecological framework.",0, 0, ,
"http://www.myexperiment.org/workflows/3349/versions/8.html","Microbial Metagenomic Trait Statistical Analysis Workflow","2012-12-1923:11:08","2014-11-1209:45:08","http://www.myexperiment.org/workflows/3349/download/Microbial_Metagenomic_Trait_Statistical_Analysis_Workflow-v8.t2flow?version=8","/users/20367","Antonio Fernandez-Guerra","taverna 2","/users/20367, /users/18968, /users/60773,","Antonio Fernandez-Guerra, Renzo, Peliny,","This workflow retrieves the following microbial metagenomic traits from the Microbial Metagenomic Trait Database: -GC content-Variance of GC content-Dinucleotides-Number of rRNA-Codon usage-Amino acid composition-Acidic to basic amino acids ratio-% of Transcriptional factors-% of classified reads-Functional content-Functional diversity-Taxonomic content-Taxonomic diversity After the retrieval performs the ecological analyses described in Barberan et al. 2012 ( <a href=http://dx.doi.org/10.1111/j.1365-294X.2011.05383.x rel=nofollow>http://dx.doi.org/10.1111/j.1365-294X.2011.05383.x</a> ) Please read:  <a href=https://wiki.biovel.eu/display/doc/Metagenomic+Workflows rel=nofollow>https://wiki.biovel.eu/display/doc/Metagenomic+Workflows</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3349/versions/9.html","Microbial Metagenomic Trait Statistical Analysis Workflow","2012-12-1923:11:08","2014-11-1209:45:08","http://www.myexperiment.org/workflows/3349/download/Microbial_Metagenomic_Trait_Statistical_Analysis_Workflow-v9.t2flow?version=9","/users/20367","Antonio Fernandez-Guerra","taverna 2","/users/20367, /users/18968, /users/60773,","Antonio Fernandez-Guerra, Renzo, Peliny,","This workflow retrieves the following microbial metagenomic traits from the Microbial Metagenomic Trait Database: -GC content-Variance of GC content-Dinucleotides-Number of rRNA-Codon usage-Amino acid composition-Acidic to basic amino acids ratio-% of Transcriptional factors-% of classified reads-Functional content-Functional diversity-Taxonomic content-Taxonomic diversity After the retrieval performs the ecological analyses described in Barberan et al. 2012 ( <a href=http://dx.doi.org/10.1111/j.1365-294X.2011.05383.x rel=nofollow>http://dx.doi.org/10.1111/j.1365-294X.2011.05383.x</a> ) Please read:  <a href=https://wiki.biovel.eu/display/doc/Metagenomic+Workflows rel=nofollow>https://wiki.biovel.eu/display/doc/Metagenomic+Workflows</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3351/versions/1.html","Intialize Sample","2013-01-0420:37:02","2013-01-0516:17:55","http://www.myexperiment.org/workflows/3351/download/Intialize_Sample-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","/users/21243, /users/23655,","Juandesant, Jsm,","&nbsp;This workflow takes as input the path of the tabular *.pckl Python pickle dataset created in the previous workflow, as well as the database connection settings and several criteria on how to filter the",0, 0, ,
"http://www.myexperiment.org/workflows/3351/versions/2.html","Intialize Sample","2013-01-0420:37:02","2013-01-0516:17:55","http://www.myexperiment.org/workflows/3351/download/Intialize_Sample-v2.t2flow?version=2","/users/14936","Jose Enrique Ruiz","taverna 2","/users/21243, /users/23655,","Juandesant, Jsm,","This workflow saves a tabular *.pckl Python pickle dataset in the local file system, containing values calculated on physical parameters associated to potential companions of a sample of target galaxies. These original physical parameters are extracted from a postgreSQL database, containing information of all galaxies covered by the SDSS spectroscopic survey. The workflow first access the external database located in the AMIGA server and selects the target galaxies from the sample (those having spectroscopic redshift between 0.03 and 0.1). It then creates a tabular gridded datacube with values associated to potentialneighbours. These values are calculates for each point of a 3D space defined by the axes: magnitude in r band, photometric redshift and sigma level of detection. The input default values to build the parameteriseddatacube are: - 14.5&lt;mr&gt;&lt;22.5&gt;&lt;z&gt;&lt;0.11&gt;&lt;sigma&gt;&lt;3.2&gt; Auxiliary function libraries and scripts are also copied in local file system, and the PYTHONPATH environmental variable is set to a value provided by the user as the Working Path of the digital experiment.Other user provided input values are the database connection settings: hostname, login and password. Execution environment The first requirement to run the workflows provided by both ROs is Taverna Workbench2 2.4 or higher. AstroTaverna (Taverna plugin) is also needed in order to get functionalities related with VirtualObservatory web services queries and management of standard VOTable data formats. In general, the execution environment is a Linux distribution including Python4 2.x and a bash shell, with psycopg and numpy Python packages. Access to a PostgreSQL database storing the physical parameters provided by SDSS is also needed; a dump file of database may be downloaded from the AMIGA web server and in order to be deployed and accessible from a local execution environment.",0, 0, ,
"http://www.myexperiment.org/workflows/3352/versions/1.html","Environment","2013-01-0420:41:31","2013-01-1409:39:40","http://www.myexperiment.org/workflows/3352/download/Environment-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","/users/21243, /users/23655,","Juandesant, Jsm,","This workflow takes as input the path of the tabular *.pckl Python pickle dataset created in the previous workflow, as well as the database connection settings and several criteria on how to filter thepotential companions of the target galaxies. It provides a file with the SDSS identifiers of each target galaxy of the sample, environmental estimators and radius where the 10th companion has been found. The workflow looks for potential companions in radius ranging from 3Mpc to 11Mpc, with a step of 1Mpc. The user may modify these numbers at the input stage, as well as several limits and ranges needed in the filtering process. As in the previous workflow other provided input values are the Working Path of the digital experiment and the database connection settings: hostname, login and password. Execution environmentThe first requirement to run the workflows provided by both ROs is Taverna Workbench2 2.4 or higher. AstroTaverna (Taverna plugin) is also needed in order to get functionalities related with VirtualObservatory web services queries and management of standard VOTable data formats. In general, the execution environment is a Linux distribution including Python4 2.x and a bash shell, with psycopg and numpy Python packages. Access to a PostgreSQL database storing the physical parameters provided by SDSS is also needed; a dump file of database may be downloaded from the AMIGA web server and in order to be deployed and accessible from a local execution environment.",0, 0, ,
"http://www.myexperiment.org/workflows/3352/versions/2.html","Environment","2013-01-0420:41:31","2013-01-1409:39:40","http://www.myexperiment.org/workflows/3352/download/Environment-v2.t2flow?version=2","/users/14936","Jose Enrique Ruiz","taverna 2","/users/21243, /users/23655,","Juandesant, Jsm,","From a previously selected cube of galaxies residing in a remote database, we provide extragalactic environment parameters for all galaxies sample. This workflow takes as input the path of the tabular *.pckl Python pickle dataset created in the previous workflow, as well as the database connection settings and several criteria on how to filter the potential companions of the target galaxies. It provides a file with the SDSS identifiers of each target galaxy of the sample, environmental estimators and radius where the 10th companion has been found. The workflow looks for potential companions in radius ranging from 3Mpc to 11Mpc, with a step of 1Mpc. The user may modify these numbers at the input stage, as well as several limits and ranges needed in the filtering process. As in the previous workflow other provided input values are the Working Path of the digital experiment and the database connection settings: hostname, login and password. Execution environment The first requirement to run the workflows provided by both ROs is Taverna Workbench2 2.4 or higher. AstroTaverna (Taverna plugin) is also needed in order to get functionalities related with Virtual Observatory web services queries and management of standard VOTable data formats. In general, the execution environment is a Linux distribution including Python4 2.x and a bash shell, with psycopg and numpy Python packages. Access to a PostgreSQL database storing the physical parameters provided by SDSS is also needed; a dump file of database may be downloaded from the AMIGA web server and in order to be deployed and accessible from a local execution environment.",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/1.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v1.t2flow?version=1","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with openModeller. The model is tested (internal test and external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, so it is important to make sure that the records refer to the same species, unless you are interested in some sort of multi-species model. Cross validation calculates the mean AUC. <br /> <br /> For more information about the input format, please look at the documentation for the corresponding parameter. <br /> <br /> NOTE: If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. <br /> <br /> IMPORTANT: When running on the workbench, this workflow requires the interaction plugin installed.",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/2.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v2.t2flow?version=2","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with openModeller. The model is tested (internal test and external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, so it is important to make sure that the records refer to the same species, unless you are interested in some sort of multi-species model. Cross validation calculates the mean AUC. For more information about the input format, please look at the documentation for the corresponding parameter. NOTE: If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. IMPORTANT: When running on the workbench, this workflow requires the interaction plugin installed.",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/3.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v3.t2flow?version=3","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with openModeller. The model is tested (internal test and external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, so it is important to make sure that the records refer to the same species, unless you are interested in some sort of multi-species model. Cross validation calculates the mean AUC. For more information about the input format, please look at the documentation for the corresponding parameter. NOTE: If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. IMPORTANT: When running on the workbench, this workflow requires the interaction plugin installed.",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/4.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v4.t2flow?version=4","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with openModeller. The model is tested (internal test and external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, so it is important to make sure that the records refer to the same species, unless you are interested in some sort of multi-species model. Cross validation calculates the mean AUC. For more information about the input format, please look at the documentation for the corresponding parameter. NOTE: If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. IMPORTANT: When running on the workbench, this workflow requires the interaction plugin installed.",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/5.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v5.t2flow?version=5","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with openModeller. The model is tested (internal test and external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, so it is important to make sure that the records refer to the same species, unless you are interested in some sort of multi-species model. Cross validation calculates the mean AUC. For more information about the input format, please look at the documentation for the corresponding parameter. NOTE: If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. IMPORTANT: When running on the workbench, this workflow requires the interaction plugin installed.",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/6.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v6.t2flow?version=6","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with openModeller. The model is tested (internal test and external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, so it is important to make sure that the records refer to the same species, unless you are interested in some sort of multi-species model. Cross validation calculates the mean AUC. For more information about the input format, please look at the documentation for the corresponding parameter. NOTE: If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. IMPORTANT: When running on the workbench, this workflow requires the interaction plugin installed.",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/7.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v7.t2flow?version=7","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with openModeller. The model is tested (internal test and external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, so it is important to make sure that the records refer to the same species, unless you are interested in some sort of multi-species model. Cross validation calculates the mean AUC. For more information about the input format, please look at the documentation for the corresponding parameter. NOTE: If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. IMPORTANT: When running on the workbench, this workflow requires the interaction plugin installed.",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/8.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v8.t2flow?version=8","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, so it is important to make sure that the records refer to the same species, unless you are interested in some sort of multi-species model. Cross validation calculates the mean AUC. For more information about the input file format, please look at the documentation for the corresponding parameter. If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed. More information and documentation about this workflow can be found here:  <a rel=nofollow href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/9.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v9.t2flow?version=9","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, so it is important to make sure that the records refer to the same species, unless you are interested in some sort of multi-species model. Cross validation calculates the mean AUC. For more information about the input file format, please look at the documentation for the corresponding parameter. If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed. More information and documentation about this workflow can be found here:  <a rel=nofollow href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/10.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v10.t2flow?version=10","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, so it is important to make sure that the records refer to the same species, unless you are interested in some sort of multi-species model. Cross validation calculates the mean AUC. For more information about the input file format, please look at the documentation for the corresponding parameter. If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed. More information and documentation about this workflow can be found here:  <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/11.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v11.t2flow?version=11","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, so it is important to make sure that the records refer to the same species, unless you are interested in some sort of multi-species model. Cross validation calculates the mean AUC. For more information about the input file format, please look at the documentation for the corresponding parameter. If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed. More information and documentation about this workflow can be found here:  <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/12.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v12.t2flow?version=12","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, so it is important to make sure that the records refer to the same species, unless you are interested in some sort of multi-species model. Cross validation calculates the mean AUC. For more information about the input file format, please look at the documentation for the corresponding parameter. If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed. More information and documentation about this workflow can be found here:  <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/13.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v13.t2flow?version=13","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, so it is important to make sure that the records refer to the same species, unless you are interested in some sort of multi-species model. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please look at the documentation for the corresponding parameter. If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed. More information and documentation about this workflow can be found here:  <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/14.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v14.t2flow?version=14","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, so it is important to make sure that the records refer to the same species, unless you are interested in some sort of multi-species model. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please look at the documentation for the corresponding parameter. If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed. More information and documentation about this workflow can be found here:  <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/15.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v15.t2flow?version=15","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, so it is important to make sure that the records refer to the same species, unless you are interested in some sort of multi-species model. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please look at the documentation for the corresponding parameter. If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed. More information and documentation about this workflow can be found here:  <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/16.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v16.t2flow?version=16","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, even if there are differences in the scientific names. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please check the documentation of the corresponding parameter. The default occurrence points are from a marine species called Gammarus tigrinus, so it is necessary to choose marine environmental layers during the modelling procedure to use it. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed. More information and documentation about this workflow can be found here:  <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/17.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v17.t2flow?version=17","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, even if there are differences in the scientific names. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please check the documentation of the corresponding parameter. The default occurrence points are from a marine species called Gammarus tigrinus, so it is necessary to choose marine environmental layers during the modelling procedure to use it. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed. More information and documentation about this workflow can be found here:  <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/18.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v18.t2flow?version=18","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, even if there are differences in the scientific names. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please check the documentation of the corresponding parameter. The default occurrence points are from a marine species called Gammarus tigrinus, so it is necessary to choose marine environmental layers during the modelling procedure to use it. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed. More information and documentation about this workflow can be found here:  <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/19.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v19.t2flow?version=19","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional external 10-fold cross validation) and projected one or more times. All points from the input file are used to create a single model, even if there are differences in the scientific names. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please check the documentation of the corresponding parameter. The default occurrence points are from a marine species called Gammarus tigrinus, so it is necessary to choose marine environmental layers during the modelling procedure to use it. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed. More information and documentation about this workflow can be found here:  <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/20.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v20.t2flow?version=20","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional cross validation external test) and then projected one or more times. All points from the input file are used to create a single model, even if there are differences in the scientific names. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please check the documentation of the corresponding parameter. The default occurrence points are from a marine species called Gammarus tigrinus, so it is necessary to choose marine environmental layers during the modelling procedure to use it. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed. Please note that ecological niche modelling experiments can take a long time to run depending on the parameters - sometimes several hours. This may happen with high resolution environmental layers, thousands of occurrence points and heavy algorithms, such as ANN and GARP BS. Cancelling a workflow run may not cancel the corresponding job on the server side, so if this procedure is repeated the server may get overloaded. More information and documentation about this workflow can be found here: <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/21.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v21.t2flow?version=21","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional cross validation external test) and then projected one or more times. All points from the input file are used to create a single model, even if there are differences in the scientific names. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please check the documentation of the corresponding parameter. The default occurrence points are from a marine species called Gammarus tigrinus, so it is necessary to choose marine environmental layers during the modelling procedure to use it. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed. Please note that ecological niche modelling experiments can take a long time to run depending on the parameters - sometimes several hours. This may happen with high resolution environmental layers, thousands of occurrence points and heavy algorithms, such as ANN and GARP BS. Cancelling a workflow run may not cancel the corresponding job on the server side, so if this procedure is repeated the server may get overloaded. More information and documentation about this workflow can be found here: <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/22.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v22.t2flow?version=22","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional cross validation external test) and then projected one or more times. All points from the input file are used to create a single model, even if there are differences in the scientific names. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please check the documentation of the corresponding parameter. The default occurrence points are from a marine species called Gammarus tigrinus, so it is necessary to choose marine environmental layers during the modelling procedure to use it. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed. Please note that ecological niche modelling experiments can take a long time to run depending on the parameters - sometimes several hours. This may happen with high resolution environmental layers, thousands of occurrence points and heavy algorithms, such as ANN and GARP BS. Cancelling a workflow run may not cancel the corresponding job on the server side, so if this procedure is repeated the server may get overloaded. More information and documentation about this workflow can be found here: <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/23.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v23.t2flow?version=23","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional cross validation external test) and then projected one or more times. All points from the input file are used to create a single model, even if there are differences in the scientific names. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please check the documentation of the corresponding parameter. The default occurrence points are from a marine species called Gammarus tigrinus, so it is necessary to choose marine environmental layers during the modelling procedure to use it. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed (for versions &lt; 2.5). Please note that ecological niche modelling experiments can take a long time to run depending on the parameters - sometimes several hours. This may happen with high resolution environmental layers, thousands of occurrence points and heavy algorithms, such as ANN and GARP BS. Cancelling a workflow run may not cancel the corresponding job on the server side, so if this procedure is repeated the server may get overloaded. More information and documentation about this workflow can be found here:https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/24.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v24.t2flow?version=24","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional cross validation external test) and then projected one or more times. All points from the input file are used to create a single model, even if there are differences in the scientific names. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please check the documentation of the corresponding parameter. The default occurrence points are from a marine species called Gammarus tigrinus, so it is necessary to choose marine environmental layers during the modelling procedure to use it. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and workbench  version &gt;= 2.5. Please note that ecological niche modelling experiments can take a long time to run depending on the parameters - sometimes several hours. This may happen with high resolution environmental layers, thousands of occurrence points and heavy algorithms, such as ANN and GARP BS. Cancelling a workflow run may not cancel the corresponding job on the server side, so if this procedure is repeated the server may get overloaded. More information and documentation about this workflow can be found here: <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/25.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v25.t2flow?version=25","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional cross validation external test) and then projected one or more times. All points from the input file are used to create a single model, even if there are differences in the scientific names. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please check the documentation of the corresponding parameter. The default occurrence points are from a marine species called Gammarus tigrinus, so it is necessary to choose marine environmental layers during the modelling procedure to use it. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and workbench  version &gt;= 2.5. Please note that ecological niche modelling experiments can take a long time to run depending on the parameters - sometimes several hours. This may happen with high resolution environmental layers, thousands of occurrence points and heavy algorithms, such as ANN and GARP BS. Cancelling a workflow run may not cancel the corresponding job on the server side, so if this procedure is repeated the server may get overloaded. More information and documentation about this workflow can be found here: <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/26.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v26.t2flow?version=26","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional cross validation external test) and then projected one or more times. All points from the input file are used to create a single model, even if there are differences in the scientific names. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please check the documentation of the corresponding parameter. The default occurrence points are from a marine species called Gammarus tigrinus, so it is necessary to choose marine environmental layers during the modelling procedure to use it. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and workbench  version &gt;= 2.5. Please note that ecological niche modelling experiments can take a long time to run depending on the parameters - sometimes several hours. This may happen with high resolution environmental layers, thousands of occurrence points and heavy algorithms, such as ANN and GARP BS. Cancelling a workflow run may not cancel the corresponding job on the server side, so if this procedure is repeated the server may get overloaded. More information and documentation about this workflow can be found here: <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/27.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v27.t2flow?version=27","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional cross validation external test) and then projected one or more times. All points from the input file are used to create a single model, even if there are differences in the scientific names. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please check the documentation of the corresponding parameter. The default occurrence points are from a marine species called Gammarus tigrinus, so it is necessary to choose marine environmental layers during the modelling procedure to use it. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and workbench  version &gt;= 2.5. Please note that ecological niche modelling experiments can take a long time to run depending on the parameters - sometimes several hours. This may happen with high resolution environmental layers, thousands of occurrence points and heavy algorithms, such as ANN and GARP BS. Cancelling a workflow run may not cancel the corresponding job on the server side, so if this procedure is repeated the server may get overloaded. More information and documentation about this workflow can be found here: <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3355/versions/28.html","Ecological niche modelling workflow","2013-01-0718:29:13","2015-06-1113:32:35","http://www.myexperiment.org/workflows/3355/download/Ecological_niche_modelling_workflow-v28.t2flow?version=28","/users/20358","Renato De Giovanni","taverna 2","/users/20358, /users/30, /users/20320, /users/61633, /users/20365,","Renato De Giovanni, Alan Williams, Robert Kulawik, Francisco Quevedo, Vhernand,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service. Algorithm, environmental layers and mask are selected during the workflow. The model is tested (internal test and optional cross validation external test) and then projected one or more times. All points from the input file are used to create a single model, even if there are differences in the scientific names. Cross validation calculates the mean AUC. Model projections can be downloaded from the links in the workflow output. They are geotiff files with suitability values ranging from 0 to 254 (nodata=255). For more information about the input file format, please check the documentation of the corresponding parameter. The default occurrence points are from a marine species called Gammarus tigrinus, so it is necessary to choose marine environmental layers during the modelling procedure to use it. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and workbench  version &gt;= 2.5. Please note that ecological niche modelling experiments can take a long time to run depending on the parameters - sometimes several hours. This may happen with high resolution environmental layers, thousands of occurrence points and heavy algorithms, such as ANN and GARP BS. Cancelling a workflow run may not cancel the corresponding job on the server side, so if this procedure is repeated the server may get overloaded. More information and documentation about this workflow can be found here: <a href=https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow rel=nofollow>https://wiki.biovel.eu/display/doc/Ecological+Niche+Modelling+%28ENM%29+Workflow</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3360/versions/1.html","workflow to test Rshell (for internal purposes)","2013-01-2116:46:25","2013-03-1113:50:13","http://www.myexperiment.org/workflows/3360/download/workflow_to_test_Rshell__for_internal_purposes_-v1.t2flow?version=1","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","&nbsp;This is a workflow to test if Rserve is working properly, for internal purposes.&nbsp; Takes as input two integers. output is the sum of integer 1 and integer 2 &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/3362/versions/1.html","GET statuses/home_timeline | Twitter","2013-01-2211:46:39","","http://www.myexperiment.org/workflows/3362/download/GET_statuses_home_timeline___Twitter-v1.t2flow?version=1","/users/10","Mark Borkum","taverna 2","/users/10,","Mark Borkum,","Returns a collection of the most recent tweets and retweets posted by the authenticating user and the users they follow.  Uses the  <a rel=nofollow href=http://build.mygrid.org.uk/taverna/internal/biovel/240/>OAuth plugin</a>  for Taverna Workbench.",-1, 0, ,
"http://www.myexperiment.org/workflows/3364/versions/1.html","Migration ffmpeg audio to wav pcm_s32le","2013-01-2414:42:24","","http://www.myexperiment.org/workflows/3364/download/Migration_ffmpeg_audio_to_wav_pcm_s32le-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","","","Converts audio to wav using ffmpeg with codec pcm_s32le",0, 0, ,
"http://www.myexperiment.org/workflows/3369/versions/1.html","Blast_Align_and_Tree","2013-01-2808:50:21","2013-01-3012:18:08","http://www.myexperiment.org/workflows/3369/download/Blast_Align_and_Tree-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/925,","Katy Wolstencroft, Hamish McWilliam,","This workflow accepts a protein sequence as input. This sequence is compared to others in the Uniprot database, using the NCBI BLAST Web Service from the EBI (WSDL), and the top 10 hits are returned (Nested workflow:EBI_NCBI_BLast).For each extracted hit, the Uniprot REST service returns the protein sequence in FASTA format. The workflow concatenates the 10 protein sequences and submits them as input to the EBI CLustalw service (Nested workflow EMBL_EBI_clustalw2_SOAP). These sequences are aligned and returned as results.Finally, the alignment is submitted to the EBI Clustalw_phylogeny service (Nested Workflow: clustalw_phylogeny), and a phylogenetic tree in phylip format is retuned.The workflow returned a list of protein sequences in FASTA format, a Clustalw alignment, and a phylogenetic tree.",0, 0, ,
"http://www.myexperiment.org/workflows/3369/versions/2.html","Blast_Align_and_Tree","2013-01-2808:50:21","2013-01-3012:18:08","http://www.myexperiment.org/workflows/3369/download/Blast_Align_and_Tree-v2.t2flow?version=2","/users/13","Katy Wolstencroft","taverna 2","/users/13, /users/925,","Katy Wolstencroft, Hamish McWilliam,","This workflow accepts a protein sequence as input. This sequence is compared to others in the Uniprot database, using the NCBI BLAST Web Service from the EBI (WSDL), and the top 10 hits are returned (Nested workflow:EBI_NCBI_BLast).For each extracted hit, the Uniprot REST service returns the protein sequence in FASTA format. The workflow concatenates the 10 protein sequences and submits them as input to the EBI CLustalw service (Nested workflow EMBL_EBI_clustalw2_SOAP). These sequences are aligned and returned as results.Finally, the alignment is submitted to the EBI Clustalw_phylogeny service (Nested Workflow: clustalw_phylogeny), and a phylogenetic tree in phylip format is retuned.The workflow returned a list of protein sequences in FASTA format, a Clustalw alignment, and a phylogenetic tree.",0, 0, ,
"http://www.myexperiment.org/workflows/3370/versions/1.html","clustal_phylogeny","2013-01-2809:02:03","2013-03-1115:26:43","http://www.myexperiment.org/workflows/3370/download/clustal_phylogeny-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow accepts a ClustalW protein sequence alignment and produces a phylogenetic tree, using the EBI clustalw_phylogeny web service, which implements phylip.",0, 0, ,
"http://www.myexperiment.org/workflows/3370/versions/2.html","clustal_phylogeny","2013-01-2809:02:03","2013-03-1115:26:43","http://www.myexperiment.org/workflows/3370/download/clustal_phylogeny-v2.t2flow?version=2","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow accepts a ClustalW protein sequence alignment and produces a phylogenetic tree, using the EBI clustalw_phylogeny web service, which implements phylip.",0, 0, ,
"http://www.myexperiment.org/workflows/3370/versions/3.html","clustal_phylogeny","2013-01-2809:02:03","2013-03-1115:26:43","http://www.myexperiment.org/workflows/3370/download/clustal_phylogeny-v3.t2flow?version=3","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow accepts a ClustalW protein sequence alignment and produces a phylogenetic tree, using the EBI clustalw_phylogeny web service, which implements phylip.",0, 0, ,
"http://www.myexperiment.org/workflows/3373/versions/1.html","Blast_and_Interproscan","2013-01-2810:07:16","2013-01-3012:45:33","http://www.myexperiment.org/workflows/3373/download/Blast_and_Interproscan-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow performs an NCBI blast at the EBI. It accepts a protein sequence as input. Default values have been set for the search database (Uniprot), the number of hits to return (10), and all scoring and matrix options. These can be changed in the workflow by altering the string constant values if required.The sequences for the top 10 hits are retrieved from the UniProt database and analysed using InterproScan (also from the EBI) to determine functional domains and motifs in each sequence. The results are shown in a graphical format.This workflow uses the new EBI services. They are asynchronous and so require looping over the nested workflows (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration.",0, 0, ,
"http://www.myexperiment.org/workflows/3373/versions/2.html","Blast_and_Interproscan","2013-01-2810:07:16","2013-01-3012:45:33","http://www.myexperiment.org/workflows/3373/download/Blast_and_Interproscan-v2.t2flow?version=2","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow performs an NCBI blast at the EBI. It accepts a protein sequence as input. Default values have been set for the search database (Uniprot), the number of hits to return (10), and all scoring and matrix options. These can be changed in the workflow by altering the string constant values if required.The sequences for the top 10 hits are retrieved from the UniProt database and analysed using InterproScan (also from the EBI) to determine functional domains and motifs in each sequence. The results are shown in a graphical format.This workflow uses the new EBI services. They are asynchronous and so require looping over the nested workflows (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration.",0, 0, ,
"http://www.myexperiment.org/workflows/3373/versions/3.html","Blast_and_Interproscan","2013-01-2810:07:16","2013-01-3012:45:33","http://www.myexperiment.org/workflows/3373/download/Blast_and_Interproscan-v3.t2flow?version=3","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow performs an NCBI blast at the EBI. It accepts a protein sequence as input. Default values have been set for the search database (Uniprot), the number of hits to return (10), and all scoring and matrix options. These can be changed in the workflow by altering the string constant values if required.The sequences for the top 10 hits are retrieved from the UniProt database and analysed using InterproScan (also from the EBI) to determine functional domains and motifs in each sequence. The results are shown in a graphical format.This workflow uses the new EBI services. They are asynchronous and so require looping over the nested workflows (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration.",0, 0, ,
"http://www.myexperiment.org/workflows/3373/versions/4.html","Blast_and_Interproscan","2013-01-2810:07:16","2013-01-3012:45:33","http://www.myexperiment.org/workflows/3373/download/Blast_and_Interproscan-v4.t2flow?version=4","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow performs an NCBI blast at the EBI. It accepts a protein sequence as input. Default values have been set for the search database (Uniprot), the number of hits to return (10), and all scoring and matrix options. These can be changed in the workflow by altering the string constant values if required.The sequences for the top 10 hits are retrieved from the UniProt database and analysed using InterproScan (also from the EBI) to determine functional domains and motifs in each sequence. The results are shown in a graphical format.This workflow uses the new EBI services. They are asynchronous and so require looping over the nested workflows (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration.",0, 0, ,
"http://www.myexperiment.org/workflows/3373/versions/5.html","Blast_and_Interproscan","2013-01-2810:07:16","2013-01-3012:45:33","http://www.myexperiment.org/workflows/3373/download/Blast_and_Interproscan-v5.t2flow?version=5","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow performs an NCBI blast at the EBI. It accepts a protein sequence as input. Default values have been set for the search database (Uniprot), the number of hits to return (10), and all scoring and matrix options. These can be changed in the workflow by altering the string constant values if required.The sequences for the top 10 hits are retrieved from the UniProt database and analysed using InterproScan (also from the EBI) to determine functional domains and motifs in each sequence. The results are shown in a graphical format.This workflow uses the new EBI services. They are asynchronous and so require looping over the nested workflows (Status) until the workflow has finished. Many of the EBI services now work in this way, so you can use this workflow as an example of the invocation pattern and looping configuration.",0, 0, ,
"http://www.myexperiment.org/workflows/3374/versions/1.html","InterproScan_Example","2013-01-2810:08:37","2013-01-3013:26:43","http://www.myexperiment.org/workflows/3374/download/InterproScan_Example-v1.t2flow?version=1","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow performs an interproscan at the EBI on sequences provided as input. The output is provided as text, xml or png.This workflow uses the new EBI services, which are asynchronous and require looping over the nested workflow (Status) until the workflow has finished.",0, 0, ,
"http://www.myexperiment.org/workflows/3374/versions/2.html","InterproScan_Example","2013-01-2810:08:37","2013-01-3013:26:43","http://www.myexperiment.org/workflows/3374/download/InterproScan_Example-v2.t2flow?version=2","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow performs an interproscan at the EBI on sequences provided as input. The output is provided as text, xml or png.This workflow uses the new EBI services, which are asynchronous and require looping over the nested workflow (Status) until the workflow has finished.",0, 0, ,
"http://www.myexperiment.org/workflows/3374/versions/3.html","InterproScan_Example","2013-01-2810:08:37","2013-01-3013:26:43","http://www.myexperiment.org/workflows/3374/download/InterproScan_Example-v3.t2flow?version=3","/users/13","Katy Wolstencroft","taverna 2","/users/13,","Katy Wolstencroft,","This workflow performs an interproscan at the EBI on sequences provided as input. The output is provided as text, xml or png.This workflow uses the new EBI services, which are asynchronous and require looping over the nested workflow (Status) until the workflow has finished.",0, 0, ,
"http://www.myexperiment.org/workflows/3376/versions/1.html","ROC_AUC_Workflow","2013-01-2812:52:28","","http://www.myexperiment.org/workflows/3376/download/ROC_AUC_Workflow-v1.t2flow?version=1","/users/23068","Magnus Palmblad","taverna 2","/users/23068,","Magnus Palmblad,","This small workflow extracts the area under the curve (AUC) from the receiver operating characteristic (ROC) curve for all charge states analyzed by PeptideProphet. This measure can be used to compare the sensitivity and specificity of different search engines for matching tandem mass spectra to peptides.",0, 0, ,
"http://www.myexperiment.org/workflows/3384/versions/1.html","Mining the Kegg pathway database with the top hits from a GWAS, thereby predicting which gene regulatory pathways may be altered as a result of genetic mutations in a subpopulation.","2013-01-3013:57:22","","http://www.myexperiment.org/workflows/3384/download/Mining_the_Kegg_pathway_database_with_the_top_hits_from_a_GWAS__thereby_predicting_which_gene_regulatory_pathways_may_be_altered_as_a_result_of_genetic_mutations_in_a_subpopulation.-v1.t2flow?version=1","/users/18","Marco Roos","taverna 2","/users/18,","Marco Roos,",,0, 0, ,
"http://www.myexperiment.org/workflows/3396/versions/1.html","Match concept profiles with predefined set","2013-02-0521:13:17","2014-07-1413:51:43","http://www.myexperiment.org/workflows/3396/download/Match_concept_profiles_with_predefined_set-v1.t2flow?version=1","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/18, /users/12548,","Kristina Hettne, Marco Roos, Reinout van Schouwen,","Purpose of workflow: The workflow can be used to match a set of concept profiles with another set of concept profiles. The result is a list of concepts ordered by their match to the query concept profiles. The workflow matches two sets of concept profiles. At the time of writing the concepts are derived from human, rat, and mouse terminologies, ontologies, and database identifiers. The profiles are lists of concepts ranked by their association with the identifying concept, as determined by co-location statistics computed from MedLine (up until 2009 at the time of writing). Author's comments: This workflow can be used together with other workflows in this pack:  <a rel=nofollow href=http://www.myexperiment.org/packs/282>http://www.myexperiment.org/packs/282</a>  for functional gene and SNP annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/3396/versions/2.html","Match concept profiles with predefined set","2013-02-0521:13:17","2014-07-1413:51:43","http://www.myexperiment.org/workflows/3396/download/Match_concept_profiles_with_predefined_set-v2.t2flow?version=2","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/18, /users/12548,","Kristina Hettne, Marco Roos, Reinout van Schouwen,","Purpose of workflow: The workflow can be used to match a set of concept profiles with predefined set of concept profiles. Result: A list of concepts ordered by their match to the query concept profiles.",0, 0, ,
"http://www.myexperiment.org/workflows/3397/versions/1.html","Annotate a gene list with disease concepts","2013-02-0620:02:24","","http://www.myexperiment.org/workflows/3397/download/Annotate_a_gene_list_with_disease_concepts-v1.t2flow?version=1","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/12548, /users/18,","Kristina Hettne, Reinout van Schouwen, Marco Roos,","Purpose: Currently, this workflow takes a list of genes and a concept set as input, calculates the matching score between these and finds the concept that contributes the most to the match. Author comments: The workflow is in Beta stage. It runs, but needs more testing with different parameter settings. This workflow can be used together with other workflows in this pack:  <a rel=nofollow href=http://www.myexperiment.org/packs/368>http://www.myexperiment.org/packs/368</a>  for functional gene annotation and knowledge discovery.",0, 0, ,
"http://www.myexperiment.org/workflows/3399/versions/1.html","JP2 to TIFF file format migration with quality assurance","2013-02-0714:00:18","","http://www.myexperiment.org/workflows/3399/download/JP2_to_TIFF_file_format_migration_with_quality_assurance-v1.t2flow?version=1","/users/4707","Sven","taverna 2","/users/4707,","Sven,","This workflow reads a textfile containing absolute paths to JP2 image files and converts them to TIFF image files using Kakadu's j2k_to_image command line application ( <a rel=nofollow href=http://www.kakadusoftware.com>http://www.kakadusoftware.com</a> ). Based on the input text file, the workflow creates a Taverna list to be processed file by file. A temporary directory is created (createtmpdir) where the migrated image files and some temporary tool outputs are stored. Before converting the files, the JP2 input files are validated using the SCAPE tool Jpylyzer ( <a rel=nofollow href=http://www.openplanetsfoundation.org/software/jpylyzer>http://www.openplanetsfoundation.org/software/jpylyzer</a> ). The TIFF files are validated using JHove2 ( <a rel=nofollow href=http://www.jhove2.org>http://www.jhove2.org</a> ) and the original JP2 file and the migrated TIFF file are compared using a direct SIFTComparison metric of the SCAPE Matchbox tool ( <a rel=nofollow href=https://github.com/openplanets/scape/tree/master/pc-qa-matchbox>https://github.com/openplanets/scape/tree/master/pc-qa-matchbox</a> ). If the SIFTComparison result is greater than a defined treshold (treshold_value), the migration is supposed to be successful.",0, 0, ,
"http://www.myexperiment.org/workflows/3400/versions/1.html","Taverna controlling a Hadoop migration","2013-02-0714:49:26","2013-02-0714:56:23","http://www.myexperiment.org/workflows/3400/download/Taverna_controlling_a_Hadoop_migration-v1.t2flow?version=1","/users/60182","willp-bl","taverna 2","/users/60182,","willp-bl,","This workflow uses Taverna to coordinate a series of Hadoop jobs.",0, 0, ,
"http://www.myexperiment.org/workflows/3401/versions/1.html","A workflow for a single migration of a TIFF to JP2","2013-02-0714:58:06","2013-10-0313:39:26","http://www.myexperiment.org/workflows/3401/download/A_workflow_for_a_single_migration_of_a_TIFF_to_JP2-v1.t2flow?version=1","/users/60182","willp-bl","taverna 2","/users/60182,","willp-bl,","This workflow is a full migration for TIFF-&gt;JP2 with validation.",0, 0, ,
"http://www.myexperiment.org/workflows/3401/versions/2.html","A workflow for a single migration of a TIFF to JP2","2013-02-0714:58:06","2013-10-0313:39:26","http://www.myexperiment.org/workflows/3401/download/A_workflow_for_a_single_migration_of_a_TIFF_to_JP2-v2.t2flow?version=2","/users/60182","willp-bl","taverna 2","/users/60182,","willp-bl,",,0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/1.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v1.t2flow?version=1","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinderand test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/2.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v2.t2flow?version=2","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinderand test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/3.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v3.t2flow?version=3","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/4.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v4.t2flow?version=4","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/5.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v5.t2flow?version=5","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/6.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v6.t2flow?version=6","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/7.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v7.t2flow?version=7","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/8.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v8.t2flow?version=8","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/9.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v9.t2flow?version=9","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/10.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v10.t2flow?version=10","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/11.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v11.t2flow?version=11","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/12.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v12.t2flow?version=12","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/13.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v13.t2flow?version=13","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/14.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v14.t2flow?version=14","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/15.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v15.t2flow?version=15","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/16.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v16.t2flow?version=16","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/17.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v17.t2flow?version=17","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/18.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v18.t2flow?version=18","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/19.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v19.t2flow?version=19","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/20.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v20.t2flow?version=20","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3404/versions/21.html","Select Model For Me with components","2013-02-2012:55:59","2014-01-3111:28:33","http://www.myexperiment.org/workflows/3404/download/Select_Model_For_Me_with_components-v21.t2flow?version=21","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of PartitionFinder, inference and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3406/versions/1.html","Input Ready","2013-02-2013:41:39","2014-04-1319:25:37","http://www.myexperiment.org/workflows/3406/download/Input_Ready-v1.t2flow?version=1","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. Perform inference  and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3406/versions/2.html","Input Ready","2013-02-2013:41:39","2014-04-1319:25:37","http://www.myexperiment.org/workflows/3406/download/Input_Ready-v2.t2flow?version=2","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. Perform inference  and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3406/versions/3.html","Input Ready","2013-02-2013:41:39","2014-04-1319:25:37","http://www.myexperiment.org/workflows/3406/download/Input_Ready-v3.t2flow?version=3","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. Perform inference  and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3406/versions/4.html","Input Ready","2013-02-2013:41:39","2014-04-1319:25:37","http://www.myexperiment.org/workflows/3406/download/Input_Ready-v4.t2flow?version=4","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. Perform inference  and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3406/versions/5.html","Input Ready","2013-02-2013:41:39","2014-04-1319:25:37","http://www.myexperiment.org/workflows/3406/download/Input_Ready-v5.t2flow?version=5","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. Perform inference  and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3406/versions/6.html","Input Ready","2013-02-2013:41:39","2014-04-1319:25:37","http://www.myexperiment.org/workflows/3406/download/Input_Ready-v6.t2flow?version=6","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. Perform inference  and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3406/versions/7.html","Input Ready","2013-02-2013:41:39","2014-04-1319:25:37","http://www.myexperiment.org/workflows/3406/download/Input_Ready-v7.t2flow?version=7","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes. Perform inference  and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3406/versions/8.html","Input Ready","2013-02-2013:41:39","2014-04-1319:25:37","http://www.myexperiment.org/workflows/3406/download/Input_Ready-v8.t2flow?version=8","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,",,0, 0, ,
"http://www.myexperiment.org/workflows/3407/versions/1.html","Bayesian Phylogenetic Infererence: Evaluate MrBayes Run","2013-02-2013:42:45","2015-06-1213:39:21","http://www.myexperiment.org/workflows/3407/download/Bayesian_Phylogenetic_Infererence__Evaluate_MrBayes_Run_-v1.t2flow?version=1","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3407/versions/2.html","Bayesian Phylogenetic Infererence: Evaluate MrBayes Run","2013-02-2013:42:45","2015-06-1213:39:21","http://www.myexperiment.org/workflows/3407/download/Bayesian_Phylogenetic_Infererence__Evaluate_MrBayes_Run_-v2.t2flow?version=2","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Retrieve Phylogenetic inference with MrBayes and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3407/versions/3.html","Bayesian Phylogenetic Infererence: Evaluate MrBayes Run","2013-02-2013:42:45","2015-06-1213:39:21","http://www.myexperiment.org/workflows/3407/download/Bayesian_Phylogenetic_Infererence__Evaluate_MrBayes_Run_-v3.t2flow?version=3","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Retrieve Phylogenetic inference with MrBayes and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3407/versions/4.html","Bayesian Phylogenetic Infererence: Evaluate MrBayes Run","2013-02-2013:42:45","2015-06-1213:39:21","http://www.myexperiment.org/workflows/3407/download/Bayesian_Phylogenetic_Infererence__Evaluate_MrBayes_Run_-v4.t2flow?version=4","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,",,0, 0, ,
"http://www.myexperiment.org/workflows/3407/versions/5.html","Bayesian Phylogenetic Infererence: Evaluate MrBayes Run","2013-02-2013:42:45","2015-06-1213:39:21","http://www.myexperiment.org/workflows/3407/download/Bayesian_Phylogenetic_Infererence__Evaluate_MrBayes_Run_-v5.t2flow?version=5","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,",,0, 0, ,
"http://www.myexperiment.org/workflows/3407/versions/6.html","Bayesian Phylogenetic Infererence: Evaluate MrBayes Run","2013-02-2013:42:45","2015-06-1213:39:21","http://www.myexperiment.org/workflows/3407/download/Bayesian_Phylogenetic_Infererence__Evaluate_MrBayes_Run_-v6.t2flow?version=6","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,",,0, 0, ,
"http://www.myexperiment.org/workflows/3407/versions/7.html","Bayesian Phylogenetic Infererence: Evaluate MrBayes Run","2013-02-2013:42:45","2015-06-1213:39:21","http://www.myexperiment.org/workflows/3407/download/Bayesian_Phylogenetic_Infererence__Evaluate_MrBayes_Run_-v7.t2flow?version=7","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,",,0, 0, ,
"http://www.myexperiment.org/workflows/3408/versions/1.html","Bayesian Phylogenetic Inference: Select Model -  Submission","2013-02-2013:47:05","2014-07-0409:53:04","http://www.myexperiment.org/workflows/3408/download/Bayesian_Phylogenetic_Inference__Select_Model_-__Submission-v1.t2flow?version=1","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3408/versions/2.html","Bayesian Phylogenetic Inference: Select Model -  Submission","2013-02-2013:47:05","2014-07-0409:53:04","http://www.myexperiment.org/workflows/3408/download/Bayesian_Phylogenetic_Inference__Select_Model_-__Submission-v2.t2flow?version=2","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes and GUI helping to define partitioned Model for MrBayes",0, 0, ,
"http://www.myexperiment.org/workflows/3408/versions/3.html","Bayesian Phylogenetic Inference: Select Model -  Submission","2013-02-2013:47:05","2014-07-0409:53:04","http://www.myexperiment.org/workflows/3408/download/Bayesian_Phylogenetic_Inference__Select_Model_-__Submission-v3.t2flow?version=3","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,",,0, 0, ,
"http://www.myexperiment.org/workflows/3408/versions/4.html","Bayesian Phylogenetic Inference: Select Model -  Submission","2013-02-2013:47:05","2014-07-0409:53:04","http://www.myexperiment.org/workflows/3408/download/Bayesian_Phylogenetic_Inference__Select_Model_-__Submission-v4.t2flow?version=4","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,",,0, 0, ,
"http://www.myexperiment.org/workflows/3409/versions/1.html","Select Model","2013-02-2014:16:25","2014-06-1313:54:56","http://www.myexperiment.org/workflows/3409/download/Select_Model-v1.t2flow?version=1","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/27680, /users/18953,","Saverio Vicario, Bachirb, Giacinto Donvito,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of Graphich User Interface (GUI) on the web page, while inference is validated with a test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3409/versions/2.html","Select Model","2013-02-2014:16:25","2014-06-1313:54:56","http://www.myexperiment.org/workflows/3409/download/Select_Model-v2.t2flow?version=2","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/27680, /users/18953,","Saverio Vicario, Bachirb, Giacinto Donvito,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of Graphich User Interface (GUI) on the web page, while inference is validated with a test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3409/versions/3.html","Select Model","2013-02-2014:16:25","2014-06-1313:54:56","http://www.myexperiment.org/workflows/3409/download/Select_Model-v3.t2flow?version=3","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/27680, /users/18953,","Saverio Vicario, Bachirb, Giacinto Donvito,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of Graphich User Interface (GUI) on the web page, while inference is validated with a test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3409/versions/4.html","Select Model","2013-02-2014:16:25","2014-06-1313:54:56","http://www.myexperiment.org/workflows/3409/download/Select_Model-v4.t2flow?version=4","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/27680, /users/18953,","Saverio Vicario, Bachirb, Giacinto Donvito,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of Graphich User Interface (GUI) on the web page, while inference is validated with a test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3409/versions/5.html","Select Model","2013-02-2014:16:25","2014-06-1313:54:56","http://www.myexperiment.org/workflows/3409/download/Select_Model-v5.t2flow?version=5","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/27680, /users/18953,","Saverio Vicario, Bachirb, Giacinto Donvito,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of Graphich User Interface (GUI) on the web page, while inference is validated with a test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3409/versions/6.html","Select Model","2013-02-2014:16:25","2014-06-1313:54:56","http://www.myexperiment.org/workflows/3409/download/Select_Model-v6.t2flow?version=6","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/27680, /users/18953,","Saverio Vicario, Bachirb, Giacinto Donvito,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of Graphich User Interface (GUI) on the web page, while inference is validated with a test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3409/versions/7.html","Select Model","2013-02-2014:16:25","2014-06-1313:54:56","http://www.myexperiment.org/workflows/3409/download/Select_Model-v7.t2flow?version=7","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/27680, /users/18953,","Saverio Vicario, Bachirb, Giacinto Donvito,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of Graphich User Interface (GUI) on the web page, while inference is validated with a test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3409/versions/8.html","Select Model","2013-02-2014:16:25","2014-06-1313:54:56","http://www.myexperiment.org/workflows/3409/download/Select_Model-v8.t2flow?version=8","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/27680, /users/18953,","Saverio Vicario, Bachirb, Giacinto Donvito,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of Graphich User Interface (GUI) on the web page, while inference is validated with a test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3409/versions/9.html","Select Model","2013-02-2014:16:25","2014-06-1313:54:56","http://www.myexperiment.org/workflows/3409/download/Select_Model-v9.t2flow?version=9","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/27680, /users/18953,","Saverio Vicario, Bachirb, Giacinto Donvito,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of Graphich User Interface (GUI) on the web page, while inference is validated with a test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3409/versions/10.html","Select Model","2013-02-2014:16:25","2014-06-1313:54:56","http://www.myexperiment.org/workflows/3409/download/Select_Model-v10.t2flow?version=10","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/27680, /users/18953,","Saverio Vicario, Bachirb, Giacinto Donvito,","Phylogenetic inference with MrBayes. The the model of evolution is defined with the help of Graphich User Interface (GUI) on the web page, while inference is validated with a test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3409/versions/11.html","Select Model","2013-02-2014:16:25","2014-06-1313:54:56","http://www.myexperiment.org/workflows/3409/download/Select_Model-v11.t2flow?version=11","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/27680, /users/18953,","Saverio Vicario, Bachirb, Giacinto Donvito,",,0, 0, ,
"http://www.myexperiment.org/workflows/3409/versions/12.html","Select Model","2013-02-2014:16:25","2014-06-1313:54:56","http://www.myexperiment.org/workflows/3409/download/Select_Model-v12.t2flow?version=12","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/27680, /users/18953,","Saverio Vicario, Bachirb, Giacinto Donvito,",,0, 0, ,
"http://www.myexperiment.org/workflows/3410/versions/1.html","Bayesian Phylogenetic Inference: Select Model For Me - Submission","2013-02-2014:43:49","2014-07-0409:32:44","http://www.myexperiment.org/workflows/3410/download/Bayesian_Phylogenetic_Inference__Select_Model_For_Me_-_Submission-v1.t2flow?version=1","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes and test of MCMC convergence (GEOKS) and fit of the model on the data (Posterior Predictive test)",0, 0, ,
"http://www.myexperiment.org/workflows/3410/versions/2.html","Bayesian Phylogenetic Inference: Select Model For Me - Submission","2013-02-2014:43:49","2014-07-0409:32:44","http://www.myexperiment.org/workflows/3410/download/Bayesian_Phylogenetic_Inference__Select_Model_For_Me_-_Submission-v2.t2flow?version=2","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Submit a Phylogenetic inference with MrBayes with PartitionFinder to define model of evolution",0, 0, ,
"http://www.myexperiment.org/workflows/3410/versions/3.html","Bayesian Phylogenetic Inference: Select Model For Me - Submission","2013-02-2014:43:49","2014-07-0409:32:44","http://www.myexperiment.org/workflows/3410/download/Bayesian_Phylogenetic_Inference__Select_Model_For_Me_-_Submission-v3.t2flow?version=3","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,",,0, 0, ,
"http://www.myexperiment.org/workflows/3411/versions/1.html","Bayesian Phylogenetic Infererence: Input Ready -  Submission","2013-02-2014:48:50","2015-06-1213:39:32","http://www.myexperiment.org/workflows/3411/download/Bayesian_Phylogenetic_Infererence__Input_Ready_-__Submission-v1.t2flow?version=1","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,","Phylogenetic inference with MrBayes",0, 0, ,
"http://www.myexperiment.org/workflows/3411/versions/2.html","Bayesian Phylogenetic Infererence: Input Ready -  Submission","2013-02-2014:48:50","2015-06-1213:39:32","http://www.myexperiment.org/workflows/3411/download/Bayesian_Phylogenetic_Infererence__Input_Ready_-__Submission-v2.t2flow?version=2","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,",,0, 0, ,
"http://www.myexperiment.org/workflows/3411/versions/3.html","Bayesian Phylogenetic Infererence: Input Ready -  Submission","2013-02-2014:48:50","2015-06-1213:39:32","http://www.myexperiment.org/workflows/3411/download/Bayesian_Phylogenetic_Infererence__Input_Ready_-__Submission-v3.t2flow?version=3","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953, /users/27680,","Saverio Vicario, Giacinto Donvito, Bachirb,",,0, 0, ,
"http://www.myexperiment.org/workflows/3417/versions/1.html","Migration Imagemagick convert no compression","2013-02-2513:31:11","2013-02-2609:20:02","http://www.myexperiment.org/workflows/3417/download/Migration_Imagemagick_convert_no_compression-v1.t2flow?version=1","/users/22146","Kraxner","taverna 2","","","Converts an image using imagemagick convert",0, 0, ,
"http://www.myexperiment.org/workflows/3417/versions/2.html","Migration Imagemagick convert no compression","2013-02-2513:31:11","2013-02-2609:20:02","http://www.myexperiment.org/workflows/3417/download/Migration_Imagemagick_convert_no_compression-v2.t2flow?version=2","/users/22146","Kraxner","taverna 2","","","Converts an image using imagemagick convert -compress None",0, 0, ,
"http://www.myexperiment.org/workflows/3418/versions/1.html","Test RShell","2013-02-2714:21:22","","http://www.myexperiment.org/workflows/3418/download/Test_RShell-v1.t2flow?version=1","/users/12548","Reinout van Schouwen","taverna 2","/users/12548, /users/17730,","Reinout van Schouwen, Eleni,","workflow hacked to include empty username and password elements",-1, 0, ,
"http://www.myexperiment.org/workflows/3423/versions/1.html","Calculate_Isotopic_Distribution","2013-03-0517:26:04","","http://www.myexperiment.org/workflows/3423/download/Calculate_Isotopic_Distribution-v1.t2flow?version=1","/users/23068","Magnus Palmblad","taverna 2","/users/23068,","Magnus Palmblad,","This small workflow takes as input a peptide sequence and calculates the elemental composition of the peptide (Calculate_Elemental_Composition). This is then transferred as a numerical vector to the Rshell Calculate_Isotopic_Distribution, that calculates the (integer mass) isotopic distribution using the FFT method. To shift to approximate real masses (or m/z values), transpose the distribution with the difference between the integer and real monoisotopic masses (both easily calculated using integer and exact isotopic masses). The building blocks can be used in any other workflows using the isotopic distribution of peptides or other molecules as measured by mass spectrometry. The workflow is tested and works in R 2.15.2 with Rserve 0.6.8 for R 2.15.",0, 0, ,
"http://www.myexperiment.org/workflows/3424/versions/1.html","Visualize PAV provenance as SVG","2013-03-0523:36:36","2013-04-0510:05:39","http://www.myexperiment.org/workflows/3424/download/Visualize_PAV_provenance_as_SVG-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","VoID descriptions are fetched as Turtle, cleaned up to be valid OWL ontology and include useful labels, processed through the OWL reasoner Pellet; this adds inferred PROV statements to the RDF, which is then fed to the PROV Toolbox, generating an SVG visualization of the provenance.",0, 0, ,
"http://www.myexperiment.org/workflows/3424/versions/2.html","Visualize PAV provenance as SVG","2013-03-0523:36:36","2013-04-0510:05:39","http://www.myexperiment.org/workflows/3424/download/Visualize_PAV_provenance_as_SVG-v2.t2flow?version=2","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","VoID descriptions are fetched as Turtle, cleaned up to be valid OWL ontology and include useful labels, processed through the OWL reasoner Pellet; this adds inferred PROV statements to the RDF, which is then fed to the PROV Toolbox, generating an SVG visualization of the provenance. Note that this workflow downloads CWM, Pellet and ProvToolbox on demand, and uses UNIX command line tools like wget and md5 which are unlikely to work in Windows. This workflow has been tested on Ubuntu 12.10 with Taverna 2.4.0.",0, 0, ,
"http://www.myexperiment.org/workflows/3425/versions/1.html","First Taverna workflow","2013-03-0606:56:24","","http://www.myexperiment.org/workflows/3425/download/First_Taverna_workflow-v1.t2flow?version=1","/users/61196","Prasund...","taverna 2","/users/61196,","Prasundutta87,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3426/versions/1.html","imagemagick-convert-tiff2tiff-compression","2013-03-0622:18:56","2013-03-0622:18:55","http://www.myexperiment.org/workflows/3426/download/imagemagick-convert-tiff2tiff-compression-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","","","Migration of tiff2tiff with compression action",0, 0, ,
"http://www.myexperiment.org/workflows/3427/versions/1.html","Three Microbase responders used for the Identification of Microorganisms present in  IonTorrent Data using SFF_Exctract MIRA or Ray and BLAST","2013-03-0723:00:44","","http://www.myexperiment.org/workflows/3427/download/Three_Microbase_responders_used_for_the_Identification_of_Microorganisms_present_in__IonTorrent_Data_using_SFF_Exctract_MIRA_or_Ray_and_BLAST-v1.t2flow?version=1","/users/61230","Team A","taverna 2","/users/61230,","Team A,","Three microbase responders are used to take .sff data from IonTorrent and report on the organisms present within the data. It also takes three JSON input messages. The first calls sff_extract python script, the next calls MIRA or Ray and the final responder calls BLAST. For more information including a user manual visit  <a rel=nofollow href=http://www.bioinformatix.co.uk>www.bioinformatix.co.uk</a>",-1, 0, ,
"http://www.myexperiment.org/workflows/3428/versions/1.html","Metabolic profiling from NCBI GIs","2013-03-0801:50:35","","http://www.myexperiment.org/workflows/3428/download/Metabolic_profiling_from_NCBI_GIs-v1.t2flow?version=1","/users/61230","Team A","taverna 2","/users/61230,","Team A,","This workflow will take NCBI GIs and produce the following output: KEGG identifier corresponding to the NCBI GI Information about the gene corresponding to the NCBI GI Pathway IDs corresponding to the the KEGG identifier Images of the pathways that the proteins defined by the NCBI GIs are involved in.",0, 0, ,
"http://www.myexperiment.org/workflows/3430/versions/1.html","Identification of Virulence Factors from a genome sequence in FASTA format","2013-03-0804:57:53","","http://www.myexperiment.org/workflows/3430/download/Identification_of_Virulence_Factors_from_a_genome_sequence_in_FASTA_format-v1.t2flow?version=1","/users/61230","Team A","taverna 2","/users/61230,","Team A,","&nbsp; <span>This workflow takes a user specified genomic sequence and, via BLAST, queries a database containing genomic sequences of virulence factors. The database and genome sequence must be held locally. A python script is associated with this workflow and should be downloaded from <a rel=nofollow href=http://www.bioinformatix.co.uk>www.bioinformatix.co.uk</a>. A user and maintenance manual relating to this workflow can be found at <a rel=nofollow href=http://www.bioinformatix.co.uk>www.bioinformatix.co.uk</a> and should be consulted before this workflow is utilised.</span>",-1, 0, ,
"http://www.myexperiment.org/workflows/3431/versions/1.html","Antibiotic resistance profiling","2013-03-0805:15:51","","http://www.myexperiment.org/workflows/3431/download/Antibiotic_resistance_profiling-v1.t2flow?version=1","/users/61230","Team A","taverna 2","/users/61230,","Team A,","<span>&nbsp;A workflow that takes a user defined genomic sequence and queries a third party database of genes encoding antibiotic resistance through a BLAST search for matching sequences. The accession IDs from the matches are extracted and the Entrez webservice is used to retrieve genbank records for the antibiotic resistance genes found. A python script is essential in the functioning of this workflow and this can be found at <a rel=nofollow href=http://www.bioinformatix.co.uk>www.bioinformatix.co.uk</a> along with a user and maintenance manual which should be consulted before this workflow is utilised.</span>  &lt;o:p&gt;&lt;/o:p&gt;",-1, 0, ,
"http://www.myexperiment.org/workflows/3432/versions/1.html","Microbase S3CMD and AWS Workflow to Analyse Next Gen Sequence Data","2013-03-0808:13:24","","http://www.myexperiment.org/workflows/3432/download/Microbase_S3CMD_and_AWS_Workflow_to_Analyse_Next_Gen_Sequence_Data-v1.t2flow?version=1","/users/61224","ROBSeq Tech. Ltd.","taverna 2","/users/61224,","ROBSeq Tech. Ltd.,","&nbsp;This workflow is designed to interact with the aws and a specific VM, to carry out commands and analsye next gen sequence data (SFF FASTQ)",-1, 0, ,
"http://www.myexperiment.org/workflows/3437/versions/1.html","Extract a column from a VOTable into a List","2013-03-0812:18:11","2013-04-2211:40:01","http://www.myexperiment.org/workflows/3437/download/Extract_a_column_from_a_VOTable_into_a_List-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617, /users/19173,","Julian Garrido, Susana,","It requires astrotaverna plugin",0, 0, ,
"http://www.myexperiment.org/workflows/3437/versions/2.html","Extract a column from a VOTable into a List","2013-03-0812:18:11","2013-04-2211:40:01","http://www.myexperiment.org/workflows/3437/download/Extract_a_column_from_a_VOTable_into_a_List-v2.t2flow?version=2","/users/22617","Julian Garrido","taverna 2","/users/22617, /users/19173,","Julian Garrido, Susana,","Snippet showing how to use AstroTaverna tool for extracting a column from a VOTable into a single List.",0, 0, ,
"http://www.myexperiment.org/workflows/3437/versions/3.html","Extract a column from a VOTable into a List","2013-03-0812:18:11","2013-04-2211:40:01","http://www.myexperiment.org/workflows/3437/download/Extract_a_column_from_a_VOTable_into_a_List-v3.t2flow?version=3","/users/22617","Julian Garrido","taverna 2","/users/22617, /users/19173,","Julian Garrido, Susana,","Snippet showing how to use AstroTaverna tool for extracting a column from a VOTable into a single List.",0, 0, ,
"http://www.myexperiment.org/workflows/3439/versions/1.html","Simulate_Mass_Spectrum","2013-03-1213:58:21","","http://www.myexperiment.org/workflows/3439/download/Simulate_Mass_Spectrum-v1.t2flow?version=1","/users/23068","Magnus Palmblad","taverna 2","/users/23068,","Magnus Palmblad,","This  workflow takes as input a peptide sequence and calculates the elemental composition of the peptide (Calculate_Elemental_Composition). This is then transferred as a numerical vector to the Rshell Simulate_Mass_Spectrum, that calculates the isotopic distribution using the FFT method and convolutes the theoretical (infinite resolution) distribution with a Gaussian peak shape. The building blocks can be used in any other workflows using the isotopic distribution of peptides or other molecules as measured by mass spectrometry. The workflow is tested and works in R 2.15.2 with Rserve 0.6.8 for R 2.15.",0, 0, ,
"http://www.myexperiment.org/workflows/3453/versions/1.html","Untitled","2013-03-1515:45:32","","http://www.myexperiment.org/workflows/3453/download/Untitled-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","Initial version",-1, 0, ,
"http://www.myexperiment.org/workflows/3456/versions/1.html","Untitled","2013-03-1516:53:33","","http://www.myexperiment.org/workflows/3456/download/Untitled-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","Initial version",-1, 0, ,
"http://www.myexperiment.org/workflows/3457/versions/1.html","Untitled","2013-03-1516:53:44","","http://www.myexperiment.org/workflows/3457/download/Untitled-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","2",-1, 0, ,
"http://www.myexperiment.org/workflows/3459/versions/1.html","Untitled","2013-03-1516:58:59","","http://www.myexperiment.org/workflows/3459/download/Untitled-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","v2",-1, 0, ,
"http://www.myexperiment.org/workflows/3466/versions/1.html","retrive dpas data for all ics instruments for HEC event data","2013-03-2017:25:32","2013-03-2116:06:49","http://www.myexperiment.org/workflows/3466/download/retrive_dpas_data_for_all_ics_instruments_for_HEC_event_data-v1.t2flow?version=1","/users/6902","Nadia Cerezo","taverna 2","/users/6902,","Nadia Cerezo,",,0, 0, ,
"http://www.myexperiment.org/workflows/3466/versions/2.html","retrive dpas data for all ics instruments for HEC event data","2013-03-2017:25:32","2013-03-2116:06:49","http://www.myexperiment.org/workflows/3466/download/retrive_dpas_data_for_all_ics_instruments_for_HEC_event_data-v2.t2flow?version=2","/users/6902","Nadia Cerezo","taverna 2","/users/6902,","Nadia Cerezo,",,0, 0, ,
"http://www.myexperiment.org/workflows/3467/versions/1.html","Find data from a list of instruments and a time range where flares of certain intensity have happened","2013-03-2017:33:38","","http://www.myexperiment.org/workflows/3467/download/Find_data_from_a_list_of_instruments_and_a_time_range_where_flares_of_certain_intensity_have_happened_-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723, /users/4706, /users/6902, /users/21398,","David PS, Anja Le Blanc, Nadia Cerezo, Gab,","For a certain time range, it looks for flares between a energy range (GOES x-ray flare class), and it provides the observations for such time range for the list of instruments asked.  It also provides the table of flares with its properties. Note: This workflow does not look whether the instrument was not looking to the right field of view (eg., CDS)",0, 0, ,
"http://www.myexperiment.org/workflows/3468/versions/1.html","Monthly counts for event occurences between beginning of year_start and end of year_end","2013-03-2110:39:32","","http://www.myexperiment.org/workflows/3468/download/Monthly_counts_for_event_occurences_between_beginning_of_year_start_and_end_of_year_end-v1.t2flow?version=1","/users/6902","Nadia Cerezo","taverna 2","/users/6902, /users/4706, /users/14723,","Nadia Cerezo, Anja Le Blanc, David PS,","This workflow provides monthly counts of events in HEC between the beginning of year_start and the end of year_end.Returns the result as comma separated file (csv) and as list of lists.",0, 0, ,
"http://www.myexperiment.org/workflows/3469/versions/1.html","When do the Fastest type II CME should be detected throughout all the heliosphere? (Returns single values, not a list)","2013-03-2116:44:44","","http://www.myexperiment.org/workflows/3469/download/When_do_the_Fastest_type_II_CME_should_be_detected_throughout_all_the_heliosphere___Returns_single_values__not_a_list_-v1.t2flow?version=1","/users/21398","Gab","taverna 2","/users/21398, /users/4706, /users/14723,","Gab, Anja Le Blanc, David PS,","The fastest CME is found from an interval of time, and propagated to Earth, in two steps, first to obtain the Solar wind speed at Earth and then propagated again with a more reasonable CME speed.The output produces Min-Max ETAs for each object in the heliosphere and the plots of the final propagation model.This Workflow was produced as one of the challenges in the HELIO CDAW-IV hosted at TCD",0, 0, ,
"http://www.myexperiment.org/workflows/3486/versions/1.html","Comparison of Peptide and Protein Fractionation Methods","2013-03-2710:04:23","","http://www.myexperiment.org/workflows/3486/download/Comparison_of_Peptide_and_Protein_Fractionation_Methods-v1.t2flow?version=1","/users/57863","Kate Mostovenko","taverna 2","/users/57863, /users/17146, /users/23068,","Kate Mostovenko, Yassene, Magnus Palmblad,","This workflow was used to analyze the data in a manuscript  by Mostovenko et al. (2013, submitted), comparing peptide and protein fractionation methods. The workflow identifies proteins by X!Tandem database search and validates the results using PeptideProphet. Additional information such as pI and fraction number is extracted and plotted for IEF and SCX data. For each protein identified in SDS-PAGE derived data sequences are downloaded from UniProt and plotted against the fraction number. Rshell script produces the figures essentially as they appear in the manuscript. Executing the workflow requires Rserve running and the Trans-Proteomic Pipeline ( <a href=http://tools.proteomecenter.org/wiki/index.php?title=Software:TPP rel=nofollow>http://tools.proteomecenter.org/wiki/index.php?title=Software:TPP</a> ) installed with default settings and in the default location. The Rshell script contains the location where the figures will be generated. All other output files are stored in the input data folders by default. The version of X!Tandem called from this workflow is separate from the one installed with the Trans-Proteomic Pipeline (the location specified in the Tandem components).",0, 0, ,
"http://www.myexperiment.org/workflows/3487/versions/1.html","EB-eye getAllResultIds and WSDbfetch fetchBatch","2013-03-2812:34:14","","http://www.myexperiment.org/workflows/3487/download/EB-eye_getAllResultIds_and_WSDbfetch_fetchBatch-v1.t2flow?version=1","/users/925","Hamish McWilliam","taverna 2","/users/925,","Hamish McWilliam,","Get database entries for a query using EB-eye to perform the initial query against the database to get entry identifiers and using the identifiers with WSDbfetch to retrieve the entry data in the desired format. Note: this particular implementation is not suitable for queries which return large numbers of results.",0, 0, ,
"http://www.myexperiment.org/workflows/3490/versions/1.html","ImageMagick: Convert JPG to TIFF","2013-04-0408:53:33","2013-04-0409:08:21","http://www.myexperiment.org/workflows/3490/download/ImageMagick__Convert_JPG_to_TIFF-v1.t2flow?version=1","/users/9056","Donal Fellows","taverna 2","","","Initial version",0, 0, ,
"http://www.myexperiment.org/workflows/3490/versions/2.html","ImageMagick: Convert JPG to TIFF","2013-04-0408:53:33","2013-04-0409:08:21","http://www.myexperiment.org/workflows/3490/download/ImageMagick__Convert_JPG_to_TIFF-v2.t2flow?version=2","/users/9056","Donal Fellows","taverna 2","","","More annotations",0, 0, ,
"http://www.myexperiment.org/workflows/3490/versions/3.html","ImageMagick: Convert JPG to TIFF","2013-04-0408:53:33","2013-04-0409:08:21","http://www.myexperiment.org/workflows/3490/download/ImageMagick__Convert_JPG_to_TIFF-v3.t2flow?version=3","/users/9056","Donal Fellows","taverna 2","","","Converts a JPG image to a TIFF image",0, 0, ,
"http://www.myexperiment.org/workflows/3491/versions/1.html","jpylyzer: Extract width and height","2013-04-0409:22:11","","http://www.myexperiment.org/workflows/3491/download/jpylyzer__Extract_width_and_height-v1.t2flow?version=1","/users/9056","Donal Fellows","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/3492/versions/1.html","Convert TIFF to JPEG-2000","2013-04-0410:57:05","2013-04-0813:23:41","http://www.myexperiment.org/workflows/3492/download/Convert_TIFF_to_JPEG-2000-v1.t2flow?version=1","/users/9056","Donal Fellows","taverna 2","","","Initial version",0, 0, ,
"http://www.myexperiment.org/workflows/3492/versions/2.html","Convert TIFF to JPEG-2000","2013-04-0410:57:05","2013-04-0813:23:41","http://www.myexperiment.org/workflows/3492/download/Convert_TIFF_to_JPEG-2000-v2.t2flow?version=2","/users/9056","Donal Fellows","taverna 2","","","Fix list handling",0, 0, ,
"http://www.myexperiment.org/workflows/3492/versions/3.html","Convert TIFF to JPEG-2000","2013-04-0410:57:05","2013-04-0813:23:41","http://www.myexperiment.org/workflows/3492/download/Convert_TIFF_to_JPEG-2000-v3.t2flow?version=3","/users/9056","Donal Fellows","taverna 2","","","Factor out the location of the binary.",0, 0, ,
"http://www.myexperiment.org/workflows/3492/versions/4.html","Convert TIFF to JPEG-2000","2013-04-0410:57:05","2013-04-0813:23:41","http://www.myexperiment.org/workflows/3492/download/Convert_TIFF_to_JPEG-2000-v4.t2flow?version=4","/users/9056","Donal Fellows","taverna 2","","","fix path for OSX ports",0, 0, ,
"http://www.myexperiment.org/workflows/3492/versions/5.html","Convert TIFF to JPEG-2000","2013-04-0410:57:05","2013-04-0813:23:41","http://www.myexperiment.org/workflows/3492/download/Convert_TIFF_to_JPEG-2000-v5.t2flow?version=5","/users/9056","Donal Fellows","taverna 2","","","A TIFF-&gt;JP2 converter.",0, 0, ,
"http://www.myexperiment.org/workflows/3493/versions/1.html","TIFF 2 JPEG-2000","2013-04-0412:08:51","2013-04-1710:07:44","http://www.myexperiment.org/workflows/3493/download/TIFF_2_JPEG-2000-v1.t2flow?version=1","/users/9056","Donal Fellows","taverna 2","","","Demonstration of SCAPE migration component in a workflow.",-1, 0, ,
"http://www.myexperiment.org/workflows/3493/versions/2.html","TIFF 2 JPEG-2000","2013-04-0412:08:51","2013-04-1710:07:44","http://www.myexperiment.org/workflows/3493/download/TIFF_2_JPEG-2000-v2.t2flow?version=2","/users/9056","Donal Fellows","taverna 2","","","Demonstration of SCAPE migration and characterisation components in a workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/3493/versions/3.html","TIFF 2 JPEG-2000","2013-04-0412:08:51","2013-04-1710:07:44","http://www.myexperiment.org/workflows/3493/download/TIFF_2_JPEG-2000-v3.t2flow?version=3","/users/9056","Donal Fellows","taverna 2","","","Demonstration of SCAPE migration and characterisation components in a workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/3493/versions/4.html","TIFF 2 JPEG-2000","2013-04-0412:08:51","2013-04-1710:07:44","http://www.myexperiment.org/workflows/3493/download/TIFF_2_JPEG-2000-v4.t2flow?version=4","/users/9056","Donal Fellows","taverna 2","","","Demonstration of SCAPE migration and characterisation components in a workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/3493/versions/5.html","TIFF 2 JPEG-2000","2013-04-0412:08:51","2013-04-1710:07:44","http://www.myexperiment.org/workflows/3493/download/TIFF_2_JPEG-2000-v5.t2flow?version=5","/users/9056","Donal Fellows","taverna 2","","","Demonstration of SCAPE migration and characterisation components in a workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/3493/versions/6.html","TIFF 2 JPEG-2000","2013-04-0412:08:51","2013-04-1710:07:44","http://www.myexperiment.org/workflows/3493/download/TIFF_2_JPEG-2000-v6.t2flow?version=6","/users/9056","Donal Fellows","taverna 2","","","Demonstration of SCAPE migration and characterisation components in a workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/3494/versions/1.html","Extract JPEG-2000 dimensions","2013-04-0412:52:24","2013-04-0814:38:21","http://www.myexperiment.org/workflows/3494/download/Extract_JPEG-2000_dimensions-v1.t2flow?version=1","/users/9056","Donal Fellows","taverna 2","","","Initial version",0, 0, ,
"http://www.myexperiment.org/workflows/3494/versions/2.html","Extract JPEG-2000 dimensions","2013-04-0412:52:24","2013-04-0814:38:21","http://www.myexperiment.org/workflows/3494/download/Extract_JPEG-2000_dimensions-v2.t2flow?version=2","/users/9056","Donal Fellows","taverna 2","","","Fixed depth handling",0, 0, ,
"http://www.myexperiment.org/workflows/3494/versions/3.html","Extract JPEG-2000 dimensions","2013-04-0412:52:24","2013-04-0814:38:21","http://www.myexperiment.org/workflows/3494/download/Extract_JPEG-2000_dimensions-v3.t2flow?version=3","/users/9056","Donal Fellows","taverna 2","","","Factor out location of executable",0, 0, ,
"http://www.myexperiment.org/workflows/3494/versions/4.html","Extract JPEG-2000 dimensions","2013-04-0412:52:24","2013-04-0814:38:21","http://www.myexperiment.org/workflows/3494/download/Extract_JPEG-2000_dimensions-v4.t2flow?version=4","/users/9056","Donal Fellows","taverna 2","","","Nicer titles on processors",0, 0, ,
"http://www.myexperiment.org/workflows/3494/versions/5.html","Extract JPEG-2000 dimensions","2013-04-0412:52:24","2013-04-0814:38:21","http://www.myexperiment.org/workflows/3494/download/Extract_JPEG-2000_dimensions-v5.t2flow?version=5","/users/9056","Donal Fellows","taverna 2","","","Corrected name",0, 0, ,
"http://www.myexperiment.org/workflows/3494/versions/6.html","Extract JPEG-2000 dimensions","2013-04-0412:52:24","2013-04-0814:38:21","http://www.myexperiment.org/workflows/3494/download/Extract_JPEG-2000_dimensions-v6.t2flow?version=6","/users/9056","Donal Fellows","taverna 2","","","First sample version of a characterisation component. This extracts the dimensions of a jp2k file.",0, 0, ,
"http://www.myexperiment.org/workflows/3497/versions/1.html","Venus: Compare VEX data with HYB model","2013-04-0713:35:04","","http://www.myexperiment.org/workflows/3497/download/Venus__Compare_VEX_data_with_HYB_model-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723, /users/19798,","David PS, Natasha,","It compares data from VEX from a certain date range with what HYB has modeled in the coordinates where VEX spacecraft is at that moment.",-1, 0, ,
"http://www.myexperiment.org/workflows/3498/versions/1.html","Extract TIFF dimensions","2013-04-0814:36:47","","http://www.myexperiment.org/workflows/3498/download/Extract_TIFF_dimensions-v1.t2flow?version=1","/users/9056","Donal Fellows","taverna 2","","","Component that extracts the dimensions of a TIFF image.",0, 0, ,
"http://www.myexperiment.org/workflows/3510/versions/1.html","Discovery of Brown Dwarfs mining the 2MASS and SDSS databases","2013-04-1216:37:41","","http://www.myexperiment.org/workflows/3510/download/Discovery_of_Brown_Dwarfs_mining_the_2MASS_and_SDSS_databases-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","Brown dwarfs are objects occupying the gap between the least massive stars and the most massive planets. They are intrinsically faint objects so their detection is not straighforward and, in fact, was almost impossible until the advent of global surveys at deep optical and near-infrared bands like SDSS, 2MASS or DENIS among others. Here we propose to mine the SDSS and 2MASS databases to identify T-type brown dwarfs through an appropriate combination of colours in the optical and the infra-red. Ref:  <a href=http://www.euro-vo.org/fc/workflows/BDs.html rel=nofollow>http://www.euro-vo.org/fc/workflows/BDs.html</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3511/versions/1.html","Crossmatching VOTables","2013-04-1216:44:46","2013-04-2211:37:25","http://www.myexperiment.org/workflows/3511/download/Crossmatching_VOTables-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","Snippet showing how to use AstroTaverna tool for crossmatching two VOTables VOTable samples may be downloaded from MyExperiment <a href=http://www.myexperiment.org/files/911/versions/1/download/SDSS7.vot rel=nofollow>http://www.myexperiment.org/files/911/versions/1/download/SDSS7.vot</a> <a href=http://www.myexperiment.org/files/910/versions/1/download/2MASS.vot rel=nofollow>http://www.myexperiment.org/files/910/versions/1/download/2MASS.vot</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3511/versions/2.html","Crossmatching VOTables","2013-04-1216:44:46","2013-04-2211:37:25","http://www.myexperiment.org/workflows/3511/download/Crossmatching_VOTables-v2.t2flow?version=2","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","Snippet showing how to use AstroTaverna tool for crossmatching two VOTables VOTable samples may be downloaded from MyExperiment <a href=http://www.myexperiment.org/files/911/versions/1/download/SDSS7.vot rel=nofollow>http://www.myexperiment.org/files/911/versions/1/download/SDSS7.vot</a> <a href=http://www.myexperiment.org/files/910/versions/1/download/2MASS.vot rel=nofollow>http://www.myexperiment.org/files/910/versions/1/download/2MASS.vot</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3512/versions/1.html","Retrieving information from HST ConeSearch and Image VO Services","2013-04-1217:18:58","","http://www.myexperiment.org/workflows/3512/download/Retrieving_information_from_HST_ConeSearch_and_Image_VO_Services-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","This workflow retieves information from Hubble Space Telescope VO Services in the form of VOTables. The input of the workflow is an ASCII file with a list of source names. This file is converted to a VOTable, and coordinates added with an extra-column needed to query SIAP Image service. The final result are two different VOTables issued as the response of both VO Services, Images VOTable has been previously filtered.",0, 0, ,
"http://www.myexperiment.org/workflows/3513/versions/1.html","Table format coversion: ASCII to VOTable","2013-04-1217:29:56","2013-04-1217:33:02","http://www.myexperiment.org/workflows/3513/download/Table_format_coversion__ASCII_to_VOTable-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool for table format conversion",0, 0, ,
"http://www.myexperiment.org/workflows/3513/versions/2.html","Table format coversion: ASCII to VOTable","2013-04-1217:29:56","2013-04-1217:33:02","http://www.myexperiment.org/workflows/3513/download/Table_format_coversion__ASCII_to_VOTable-v2.t2flow?version=2","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool for table format conversion",0, 0, ,
"http://www.myexperiment.org/workflows/3514/versions/1.html","Resolving coordinates from a source names list","2013-04-1217:43:18","2013-04-2211:38:17","http://www.myexperiment.org/workflows/3514/download/Resolving_coordinates_from_a_source_names_list-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool for coordinates resolving. The input is a list of source names and the output is a VOTable with three columns: SourceName, RAJ2000, DECJ2000.",0, 0, ,
"http://www.myexperiment.org/workflows/3514/versions/2.html","Resolving coordinates from a source names list","2013-04-1217:43:18","2013-04-2211:38:17","http://www.myexperiment.org/workflows/3514/download/Resolving_coordinates_from_a_source_names_list-v2.t2flow?version=2","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool for coordinates resolving. The input is a list of source names and the output is a VOTable with three columns: SourceName, RAJ2000, DECJ2000.",0, 0, ,
"http://www.myexperiment.org/workflows/3515/versions/1.html","Coordinate units conversion","2013-04-1218:12:58","2013-04-2212:11:41","http://www.myexperiment.org/workflows/3515/download/Coordinate_units_conversion-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool for coordinate units conversion. The input is a VOTable with three columns: SourceName, RA_J2000, DEC_J2000 in units degrees. Two conversions are performed on the coordinates for Right Ascension, first from degrees to radians, and a second one from radians to RA hours:minutes:seconds. Choices on the units to convert from and to may be set up in service configuration: right click on box Coordinate units conversion.",0, 0, ,
"http://www.myexperiment.org/workflows/3515/versions/2.html","Coordinate units conversion","2013-04-1218:12:58","2013-04-2212:11:41","http://www.myexperiment.org/workflows/3515/download/Coordinate_units_conversion-v2.t2flow?version=2","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool Coordinates_units_conversion_in_VOTable for coordinates resolving. The input is a list of source names and the output is a VOTable with three columns: SourceName, RAJ2000, DECJ2000.",0, 0, ,
"http://www.myexperiment.org/workflows/3515/versions/3.html","Coordinate units conversion","2013-04-1218:12:58","2013-04-2212:11:41","http://www.myexperiment.org/workflows/3515/download/Coordinate_units_conversion-v3.t2flow?version=3","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool for coordinate units conversion Coordinates_units_conversion_in_VOTable. The input is a VOTable with three columns: SourceName, RA_J2000, DEC_J2000 in units degrees. Two conversions are performed on the coordinates for Right Ascension, first from degrees to radians, and a second one from radians to RA hours:minutes:seconds. Choices on the units to convert from and to may be set up in service configuration: right click on box Coordinate units conversion.",0, 0, ,
"http://www.myexperiment.org/workflows/3516/versions/1.html","Adding a column to a VOTable using a mathematical expression","2013-04-1219:07:10","","http://www.myexperiment.org/workflows/3516/download/Adding_a_column_to_a_VOTable_using_a_mathematical_expression-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool for adding columns based on expressions of existing columns. The input is a VOTable with five columns. A new column is added considering the maximum value of the three last columns. All functions provided by STILTS Library may be used. <a href=http://www.star.bris.ac.uk/~mbt/stilts/sun256/sun256.html#staticMethods rel=nofollow>http://www.star.bris.ac.uk/~mbt/stilts/sun256/sun256.html#staticMethods</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3517/versions/1.html","Concatenates two VOTables with the same numer of columns into a single one","2013-04-1219:15:04","2013-04-1219:19:10","http://www.myexperiment.org/workflows/3517/download/Concatenates_two_VOTables_with_the_same_numer_of_columns_into_a_single_one_-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool for cocatenating two VOTables. The input is two VOTables with with the same number of columns. The result if using sample values provided will be a duplicated VOTable.",0, 0, ,
"http://www.myexperiment.org/workflows/3517/versions/2.html","Concatenates two VOTables with the same numer of columns into a single one","2013-04-1219:15:04","2013-04-1219:19:10","http://www.myexperiment.org/workflows/3517/download/Concatenates_two_VOTables_with_the_same_numer_of_columns_into_a_single_one_-v2.t2flow?version=2","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool for concatenating two VOTables. The input is two VOTables with the same number of columns. The result if using sample values provided will be a vertically duplicated VOTable.",0, 0, ,
"http://www.myexperiment.org/workflows/3518/versions/1.html","Joins two VOTables with the same numer of rows into a single one","2013-04-1219:20:26","","http://www.myexperiment.org/workflows/3518/download/Joins_two_VOTables_with_the_same_numer_of_rows_into_a_single_one_-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool for joining two VOTables. The input is two VOTables with the same number of rows. The result if using sample values provided will be an horizontally duplicated VOTable.",0, 0, ,
"http://www.myexperiment.org/workflows/3519/versions/1.html","Select rows from VOTable","2013-04-1222:47:40","","http://www.myexperiment.org/workflows/3519/download/Select_rows_from_VOTable-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool for selecting/filtering rows from a VOTable. Functions provided by STILTS Library may be used. <a href=http://www.star.bris.ac.uk/~mbt/stilts/sun256/sun256.html#staticMethods rel=nofollow>http://www.star.bris.ac.uk/~mbt/stilts/sun256/sun256.html#staticMethods</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3520/versions/1.html","Select columns from VOTable","2013-04-1222:51:48","2013-04-1222:55:54","http://www.myexperiment.org/workflows/3520/download/Select_columns_from_VOTable-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool for selecting/filtering columns from a VOTable.",0, 0, ,
"http://www.myexperiment.org/workflows/3520/versions/2.html","Select columns from VOTable","2013-04-1222:51:48","2013-04-1222:55:54","http://www.myexperiment.org/workflows/3520/download/Select_columns_from_VOTable-v2.t2flow?version=2","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool for selecting/filtering columns from a VOTable.",0, 0, ,
"http://www.myexperiment.org/workflows/3521/versions/1.html","Validate_Compare_Compare_List","2013-04-1509:45:54","","http://www.myexperiment.org/workflows/3521/download/Validate_Compare_Compare_List-v1.t2flow?version=1","/users/19098","Bolette Jurik","taverna 2","/users/19098,","Bolette Jurik,","QA for file migrated to wav. The QA steps include File Format Validation, Significant Property Comparison and xcorrSound waveform-compare file content comparison (all CLI). Input the migrated wav and a compare-to-wav file.",0, 0, ,
"http://www.myexperiment.org/workflows/3522/versions/1.html","GWAS to biomedical concept","2013-04-1512:35:44","2014-07-1414:17:16","http://www.myexperiment.org/workflows/3522/download/GWAS_to_biomedical_concept-v1.t2flow?version=1","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/17633, /users/18, /users/12548,","Kristina Hettne, Harish Dharuri, Marco Roos, Reinout van Schouwen,",,0, 0, ,
"http://www.myexperiment.org/workflows/3522/versions/2.html","GWAS to biomedical concept","2013-04-1512:35:44","2014-07-1414:17:16","http://www.myexperiment.org/workflows/3522/download/GWAS_to_biomedical_concept-v2.t2flow?version=2","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/17633, /users/18, /users/12548,","Kristina Hettne, Harish Dharuri, Marco Roos, Reinout van Schouwen,",,0, 0, ,
"http://www.myexperiment.org/workflows/3522/versions/3.html","GWAS to biomedical concept","2013-04-1512:35:44","2014-07-1414:17:16","http://www.myexperiment.org/workflows/3522/download/GWAS_to_biomedical_concept-v3.t2flow?version=3","/users/2642","Kristina Hettne","taverna 2","/users/2642, /users/17633, /users/18, /users/12548,","Kristina Hettne, Harish Dharuri, Marco Roos, Reinout van Schouwen,",,0, 0, ,
"http://www.myexperiment.org/workflows/3547/versions/1.html","Text-mining using OSCAR to obtain a list of Chemical names and Identifiers","2013-04-1813:01:50","","http://www.myexperiment.org/workflows/3547/download/Text-mining_using_OSCAR_to_obtain_a_list_of_Chemical_names_and_Identifiers-v1.t2flow?version=1","/users/60147","Michael Smith","taverna 2","/users/60147, /users/10,","Michael Smith, Mark Borkum,","This service extracts chemical names from text and obtains identifiers for these names. It outputs a HTML string that can be opened in a browser providing a table of information and links to ChemSpider. <br /> Known issues <br /> &nbsp;- Character limit ~3000 <br /> &nbsp;- Unable to produce InChIs or CSID for some names <br /> &nbsp;- Error sometimes encountered when a trivial and systematic name for the same compound are used <br /> &nbsp;- Some issues with identifiers being recognised but not able to be processed <br /> <br /> requires access to an OSCAR3 service and ChemSpider <br /> more information is contained within the text constant &quot;Instructions&quot; &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/3551/versions/1.html","Transformation of reference coordinate system","2013-04-2214:45:45","","http://www.myexperiment.org/workflows/3551/download/Transformation_of_reference_coordinate_system-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool for reference coordinate system transformation. The input is a list of source names and coordiantes and the output is a VOTable with two added columns for Galactic Latitude and Galactic Longitude.",0, 0, ,
"http://www.myexperiment.org/workflows/3552/versions/1.html","Add a common row to a VOTable","2013-04-2215:14:35","","http://www.myexperiment.org/workflows/3552/download/Add_a_common_row_to_a_VOTable-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool for adding a common row to a whole VOTable. The input are two VOTable, the main one has a lis of sources and coordinates, to which is appended a common row Object Type with common values Messier Object. Right click on tool may change configuration to append the common row to left or right side of main VOTable.",0, 0, ,
"http://www.myexperiment.org/workflows/3553/versions/1.html","Use of temporary files to execute local tool and/or create report of execution","2013-04-2216:37:28","","http://www.myexperiment.org/workflows/3553/download/Use_of_temporary_files_to_execute_local_tool_and_or_create_report_of_execution-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna tool Fill template from VOTable for creating temporary files filling a template provided by the user. The input is two templates a one VOTable with information on where to store files created from filling the templates. The VOTable also contains data values to fill the templates. This snippet is particularly useful when a local tool needs different configuration files when looping through different executions.",0, 0, ,
"http://www.myexperiment.org/workflows/3554/versions/1.html","Perform a ConeSearch query to a VO Service","2013-04-2219:14:48","2013-04-2219:16:20","http://www.myexperiment.org/workflows/3554/download/Perform_a_ConeSearch_query_to_a_VO_Service-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna VO service perspective for performing ConeSearch queries on VO Services. The result is a VOTable that may be renderized properly in the perspective Results, coosing Value Type as VOTable.",0, 0, ,
"http://www.myexperiment.org/workflows/3554/versions/2.html","Perform a ConeSearch query to a VO Service","2013-04-2219:14:48","2013-04-2219:16:20","http://www.myexperiment.org/workflows/3554/download/Perform_a_ConeSearch_query_to_a_VO_Service-v2.t2flow?version=2","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna VO service perspective for performing ConeSearch queries on VO Services. The result is a VOTable that may be renderized properly in the perspective Results, coosing Value Type as VOTable.",0, 0, ,
"http://www.myexperiment.org/workflows/3555/versions/1.html","Perform Multi-ConeSearch queries to a VO Service","2013-04-2219:43:39","","http://www.myexperiment.org/workflows/3555/download/Perform_Multi-ConeSearch_queries_to_a_VO_Service-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna VO service perspective and other tools for performing Multi-ConeSearch queries to a VO Services. The input is a VOTable with a list of source names and coordinates to perform the multi-query. Please *note how the AMIGACS block list handling is cofigured* with right click -&gt; Configure running -&gt; List Handling.  Add_n_concat_tables tool is used to concatenate the list of responses issued from the multiquery.  The result is a VOTable that may be renderized properly in the perspective Results, coosing Value Type as VOTable.",0, 0, ,
"http://www.myexperiment.org/workflows/3556/versions/1.html","Retrieve Bibliography from NED","2013-04-2308:19:13","","http://www.myexperiment.org/workflows/3556/download/Retrieve_Bibliography_from_NED-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","This is a smal workflow that retrieves bibliography from Literature NED Web Service  <a href=http://ned.ipac.caltech.edu/forms/SearchRefsByObjectName.html rel=nofollow>http://ned.ipac.caltech.edu/forms/SearchRefsByObjectName.html</a> The input is a list of source names and the output is a VOTable with the info provided by NED, plus an extra column with the link pointing to the bliography in the NED website. This VOTable may be sent to Topcat via SAMP and the content of the Link column used as an action to display the website content in a browser when clicked. Note that the output VOTable is produced in a way all bibliographic references are packed with their correspondent source.",0, 0, ,
"http://www.myexperiment.org/workflows/3557/versions/1.html","Perform a SIA query to an Image VO Service","2013-04-2308:55:04","","http://www.myexperiment.org/workflows/3557/download/Perform_a_SIA_query_to_an_Image_VO_Service-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","Snippet showing how to use AstroTaverna VO service perspective for performing SIA queries on Image VO Services. The result is a VOTable that may be renderized properly in the perspective Results, choosing Value Type as VOTable. In this particular case the Image Service queried is the Infrared Space Observatory (ISO) Data Archive SIAP Service, with coordinates RA, DEC of 30, 30 and 10 degrees in size.",0, 0, ,
"http://www.myexperiment.org/workflows/3558/versions/1.html","Perform Multi-SIA queries to an Image VO Service","2013-04-2309:13:44","2013-04-2309:33:12","http://www.myexperiment.org/workflows/3558/download/Perform_Multi-SIA_queries_to_an_Image_VO_Service-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","Snippet showing how to use AstroTaverna VO service perspective and other tools for performing Multi-SIA queries to Image VO Services. The input is a VOTable with a list of source names and coordinates to perform the multi-query. Add_n_concat_tables tool is used to concatenate the list of responses issued from the multiquery.  The result is a VOTable that may be renderized properly in the perspective Results, choosing Value Type as VOTable. It may also be sent via SAMP to other VO soft implementing SAMP. In this particular case, the Image Service queried is the The Hubble Space Telecope Legacy Archive (HLA)",0, 0, ,
"http://www.myexperiment.org/workflows/3558/versions/2.html","Perform Multi-SIA queries to an Image VO Service","2013-04-2309:13:44","2013-04-2309:33:12","http://www.myexperiment.org/workflows/3558/download/Perform_Multi-SIA_queries_to_an_Image_VO_Service-v2.t2flow?version=2","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","Snippet showing how to use AstroTaverna VO service perspective and other tools for performing Multi-SIA queries to Image VO Services. The input is a VOTable with a list of source names and coordinates to perform the multi-query. Add_n_concat_tables tool is used to concatenate the list of responses issued from the multiquery.  The result is a VOTable that may be renderized properly in the perspective Results, choosing Value Type as VOTable. It may also be sent via SAMP to other VO soft implementing SAMP. In this particular case, the Image Service queried is the The Hubble Space Telecope Legacy Archive (HLA)",0, 0, ,
"http://www.myexperiment.org/workflows/3559/versions/1.html","Perform a SSA query to a Spectral VO Service","2013-04-2309:28:31","","http://www.myexperiment.org/workflows/3559/download/Perform_a_SSA_query_to_a_Spectral_VO_Service-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","Snippet showing how to use AstroTaverna VO service perspective for performing SSA queries on Spectral VO Services. The result is a VOTable that may be renderized properly in the perspective Results, choosing Value Type as VOTable. In this particular case the Spectral Service queried is the Galexy Evolution Explorer (GALEX) SSA Service, with coordinates RA, DEC of 25, 22 and 1 degree in size.",0, 0, ,
"http://www.myexperiment.org/workflows/3560/versions/1.html","Retrieve the best position from an object calling NED_basic_posn REST Service","2013-04-2312:19:17","2013-04-2312:21:20","http://www.myexperiment.org/workflows/3560/download/Retrieve_the_best_position_from_an_object_calling_NED_basic_posn_REST_Service-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","Snippet showing how to use Taverna REST Service tool for performing a query to a standard REST Service. In this particular case, the query is performed against NED_basic_posn REST Service from NASA Extragalactic Database (NED) Archive for the object M51. The result is a VOTable that may be renderized properly in the perspective Results, choosing Value Type as VOTable.",0, 0, ,
"http://www.myexperiment.org/workflows/3560/versions/2.html","Retrieve the best position from an object calling NED_basic_posn REST Service","2013-04-2312:19:17","2013-04-2312:21:20","http://www.myexperiment.org/workflows/3560/download/Retrieve_the_best_position_from_an_object_calling_NED_basic_posn_REST_Service-v2.t2flow?version=2","/users/14936","Jose Enrique Ruiz","taverna 2","/users/14936,","Jose Enrique Ruiz,","Snippet showing how to use Taverna REST Service tool for performing a query to a standard REST Service. In this particular case, the query is performed against NED_basic_posn REST Service from NASA Extragalactic Database (NED) Archive for the object M51. The result is a VOTable that may be renderized properly in the perspective Results, choosing Value Type as VOTable. More info on NED Web Serces:  <a href=http://adsabs.harvard.edu/abs/2007ASPC..382..165M rel=nofollow>http://adsabs.harvard.edu/abs/2007ASPC..382..165M</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3562/versions/1.html","Perform Multi-SSA queries to an Spectral VO Service","2013-04-2317:38:49","2013-04-2317:43:17","http://www.myexperiment.org/workflows/3562/download/Perform_Multi-SSA_queries_to_an_Spectral_VO_Service-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna VO service perspective and other tools for performing Multi-SSA queries to Spectral VO Services. The input is a VOTable with a list of source names and coordinates to perform the multi-query. Add_n_concat_tables tool is used to concatenate the list of responses issued from the multiquery.  The result is a VOTable that may be renderized properly in the perspective Results, choosing Value Type as VOTable. It may also be sent via SAMP to other VO soft implementing SAMP. In this particular case, the Spectral Service queried is the The Hubble Space Telecope Legacy Archive (HLA)",0, 0, ,
"http://www.myexperiment.org/workflows/3562/versions/2.html","Perform Multi-SSA queries to an Spectral VO Service","2013-04-2317:38:49","2013-04-2317:43:17","http://www.myexperiment.org/workflows/3562/download/Perform_Multi-SSA_queries_to_an_Spectral_VO_Service-v2.t2flow?version=2","/users/14936","Jose Enrique Ruiz","taverna 2","","","Snippet showing how to use AstroTaverna VO service perspective and other tools for performing Multi-SSA queries to Spectral VO Services. The input is a VOTable with a list of source names and coordinates to perform the multi-query. Add_n_concat_tables tool is used to concatenate the list of responses issued from the multiquery.  The result is a VOTable that may be renderized properly in the perspective Results, choosing Value Type as VOTable. It may also be sent via SAMP to other VO soft implementing SAMP. In this particular case, the Spectral Service queried is the NASA/IPAC Extragalactic Database SED Data Discovery Service",0, 0, ,
"http://www.myexperiment.org/workflows/3566/versions/1.html","Retrieve object properties from NED and VO Archives, and calculate distance for a list of galaxies.","2013-04-2512:05:02","2013-06-2717:35:25","http://www.myexperiment.org/workflows/3566/download/Retrieve_object_properties_from_NED_and_VO_Archives__and_calculate_distance_for_a_list_of_galaxies.-v1.t2flow?version=1","/users/14936","Jose Enrique Ruiz","taverna 2","","","From an initial list of galaxy names, retrieve their physical properties from Virtual Observatory archives and services (NASA Extragalactic Database NED), and calculate others like Distance, based on the ones previously obtained (e.g. recession velocity, equatorial and galactic coordinates). The sample is filtered in a later step with criteria related to the angular size of the object and its declination. The goal is to build a sample of objects and their properties with up-to-date physical information in order to use it as the basis for a potential observational proposal. From a list of source names in one ASCII file, the workflow will build up three different VOTables that could be inspected via SAMP with VO-compliant software like Topcat. Result VOtables are Literature, External Links and Physical Properties.",0, 0, ,
"http://www.myexperiment.org/workflows/3566/versions/2.html","Retrieve object properties from NED and VO Archives, and calculate distance for a list of galaxies.","2013-04-2512:05:02","2013-06-2717:35:25","http://www.myexperiment.org/workflows/3566/download/Retrieve_object_properties_from_NED_and_VO_Archives__and_calculate_distance_for_a_list_of_galaxies.-v2.t2flow?version=2","/users/14936","Jose Enrique Ruiz","taverna 2","","","From an initial list of galaxy names, retrieve their physical properties from Virtual Observatory archives and services (NASA Extragalactic Database NED), and calculate others like Distance, based on the ones previously obtained (e.g. recession velocity, equatorial and galactic coordinates). The sample is filtered in a later step with criteria related to the angular size of the object and its declination. The goal is to build a sample of objects and their properties with up-to-date physical information in order to use it as the basis for a potential observational proposal. From a list of source names in one ASCII file, the workflow will build up three different VOTables that could be inspected via SAMP with VO-compliant software like Topcat. Result VOtables are Literature, External Links and Physical Properties.",0, 0, ,
"http://www.myexperiment.org/workflows/3566/versions/3.html","Retrieve object properties from NED and VO Archives, and calculate distance for a list of galaxies.","2013-04-2512:05:02","2013-06-2717:35:25","http://www.myexperiment.org/workflows/3566/download/Retrieve_object_properties_from_NED_and_VO_Archives__and_calculate_distance_for_a_list_of_galaxies.-v3.t2flow?version=3","/users/14936","Jose Enrique Ruiz","taverna 2","","","From an initial list of galaxy names, retrieve their physical properties from Virtual Observatory archives and services (NASA Extragalactic Database NED), and calculate others like Distance, based on the ones previously obtained (e.g. recession velocity, equatorial and galactic coordinates). The sample is filtered in a later step with criteria related to the angular size of the object and its declination. The goal is to build a sample of objects and their properties with up-to-date physical information in order to use it as the basis for a potential observational proposal. From a list of source names in one ASCII file, the workflow will build up three different VOTables that could be inspected via SAMP with VO-compliant software like Topcat. Result VOtables are Literature, External Links and Physical Properties.",0, 0, ,
"http://www.myexperiment.org/workflows/3566/versions/4.html","Retrieve object properties from NED and VO Archives, and calculate distance for a list of galaxies.","2013-04-2512:05:02","2013-06-2717:35:25","http://www.myexperiment.org/workflows/3566/download/Retrieve_object_properties_from_NED_and_VO_Archives__and_calculate_distance_for_a_list_of_galaxies.-v4.t2flow?version=4","/users/14936","Jose Enrique Ruiz","taverna 2","","","From an initial list of galaxy names, retrieve some of their properties from Virtual Observatory archives and services (NASA Extragalactic Database NED), and calculate others like Distance, based on the ones previously obtained (e.g. recession velocity, equatorial and galactic coordinates). The sample is filtered in a later step with criteria related to the angular size of the object and its declination. The goal is to build a sample of objects and their properties with up-to-date physical information in order to use it as the basis for a potential observational proposal. From a list of source names in one ASCII file, the workflow will build up three different VOTables that could be inspected via SAMP with VO-compliant software like Topcat. Result VOTables are Bibliography, ExternalLinks and ObjectProperties.",0, 0, ,
"http://www.myexperiment.org/workflows/3569/versions/1.html","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH with parsing Qiime","2013-05-0709:05:19","2015-06-1213:39:35","http://www.myexperiment.org/workflows/3569/download/Partitioning_environmental_sequencing_data_using_categorical_and_phylogenetic_information_using_PhyloH_with_parsing_Qiime-v1.t2flow?version=1","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953,","Saverio Vicario, Giacinto Donvito,","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH .The WF need a tree in newick format, a samplefile that show the where the leaf of the tree are found in the different sample and how many time, and a grouping file where the different sample are grouped using a categorical variable. The WF gives back a tabular and graphical representation of an entropy based partitioning of the information present in the sequence across the groupings, and a graphical and tabular representation of the contribution of each branch of the tree to the differentiation across groups of sample.Further as side results the WF gives the tree annotated with the per branch contribution to the differentiation across groups of sample in nexml or phyloxml format and all files necessary to produce ex.novo the annotated tree on itol, giving the possibility to the user to add taxonomic information.",0, 0, ,
"http://www.myexperiment.org/workflows/3569/versions/2.html","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH with parsing Qiime","2013-05-0709:05:19","2015-06-1213:39:35","http://www.myexperiment.org/workflows/3569/download/Partitioning_environmental_sequencing_data_using_categorical_and_phylogenetic_information_using_PhyloH_with_parsing_Qiime-v2.t2flow?version=2","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953,","Saverio Vicario, Giacinto Donvito,","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH .The WF need a tree in newick format, a samplefile that show the where the leaf of the tree are found in the different sample and how many time, and a grouping file where the different sample are grouped using a categorical variable. The WF gives back a tabular and graphical representation of an entropy based partitioning of the information present in the sequence across the groupings, and a graphical and tabular representation of the contribution of each branch of the tree to the differentiation across groups of sample.Further as side results the WF gives the tree annotated with the per branch contribution to the differentiation across groups of sample in nexml or phyloxml format and all files necessary to produce ex.novo the annotated tree on itol, giving the possibility to the user to add taxonomic information.",0, 0, ,
"http://www.myexperiment.org/workflows/3569/versions/3.html","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH with parsing Qiime","2013-05-0709:05:19","2015-06-1213:39:35","http://www.myexperiment.org/workflows/3569/download/Partitioning_environmental_sequencing_data_using_categorical_and_phylogenetic_information_using_PhyloH_with_parsing_Qiime-v3.t2flow?version=3","/users/20342","Saverio Vicario","taverna 2","/users/20342, /users/18953,","Saverio Vicario, Giacinto Donvito,","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH .The WF need a tree in newick format, a samplefile that show the where the leaf of the tree are found in the different sample and how many time, and a grouping file where the different sample are grouped using a categorical variable. The WF gives back a tabular and graphical representation of an entropy based partitioning of the information present in the sequence across the groupings, and a graphical and tabular representation of the contribution of each branch of the tree to the differentiation across groups of sample.Further as side results the WF gives the tree annotated with the per branch contribution to the differentiation across groups of sample in nexml or phyloxml format and all files necessary to produce ex.novo the annotated tree on itol, giving the possibility to the user to add taxonomic information.",0, 0, ,
"http://www.myexperiment.org/workflows/3570/versions/1.html","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH with parsing Qiime","2013-05-0712:13:37","2015-06-1213:39:38","http://www.myexperiment.org/workflows/3570/download/Partitioning_environmental_sequencing_data_using_categorical_and_phylogenetic_information_using_PhyloH_with_parsing_Qiime-v1.t2flow?version=1","/users/20342","Saverio Vicario","taverna 2","/users/20342,","Saverio Vicario,","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH .The WF need a tree in newick format, a samplefile that show the where the leaf of the tree are found in the different sample and how many time, and a grouping file where the different sample are grouped using a categorical variable. The WF gives back a tabular and graphical representation of an entropy based partitioning of the information present in the sequence across the groupings, and a graphical and tabular representation of the contribution of each branch of the tree to the differentiation across groups of sample.Further as side results the WF gives the tree annotated with the per branch contribution to the differentiation across groups of sample in nexml or phyloxml format and all files necessary to produce ex.novo the annotated tree on itol, giving the possibility to the user to add taxonomic information.",0, 0, ,
"http://www.myexperiment.org/workflows/3570/versions/2.html","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH with parsing Qiime","2013-05-0712:13:37","2015-06-1213:39:38","http://www.myexperiment.org/workflows/3570/download/Partitioning_environmental_sequencing_data_using_categorical_and_phylogenetic_information_using_PhyloH_with_parsing_Qiime-v2.t2flow?version=2","/users/20342","Saverio Vicario","taverna 2","/users/20342,","Saverio Vicario,","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH .The WF need a tree in newick format, a samplefile that show the where the leaf of the tree are found in the different sample and how many time, and a grouping file where the different sample are grouped using a categorical variable. The WF gives back a tabular and graphical representation of an entropy based partitioning of the information present in the sequence across the groupings, and a graphical and tabular representation of the contribution of each branch of the tree to the differentiation across groups of sample.Further as side results the WF gives the tree annotated with the per branch contribution to the differentiation across groups of sample in nexml or phyloxml format and all files necessary to produce ex.novo the annotated tree on itol, giving the possibility to the user to add taxonomic information.",0, 0, ,
"http://www.myexperiment.org/workflows/3570/versions/3.html","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH with parsing Qiime","2013-05-0712:13:37","2015-06-1213:39:38","http://www.myexperiment.org/workflows/3570/download/Partitioning_environmental_sequencing_data_using_categorical_and_phylogenetic_information_using_PhyloH_with_parsing_Qiime-v3.t2flow?version=3","/users/20342","Saverio Vicario","taverna 2","/users/20342,","Saverio Vicario,","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH .The WF need a tree in newick format, a samplefile that show the where the leaf of the tree are found in the different sample and how many time, and a grouping file where the different sample are grouped using a categorical variable. The WF gives back a tabular and graphical representation of an entropy based partitioning of the information present in the sequence across the groupings, and a graphical and tabular representation of the contribution of each branch of the tree to the differentiation across groups of sample.Further as side results the WF gives the tree annotated with the per branch contribution to the differentiation across groups of sample in nexml or phyloxml format and all files necessary to produce ex.novo the annotated tree on itol, giving the possibility to the user to add taxonomic information.",0, 0, ,
"http://www.myexperiment.org/workflows/3570/versions/4.html","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH with parsing Qiime","2013-05-0712:13:37","2015-06-1213:39:38","http://www.myexperiment.org/workflows/3570/download/Partitioning_environmental_sequencing_data_using_categorical_and_phylogenetic_information_using_PhyloH_with_parsing_Qiime-v4.t2flow?version=4","/users/20342","Saverio Vicario","taverna 2","/users/20342,","Saverio Vicario,","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH .The WF need a tree in newick format, a samplefile that show the where the leaf of the tree are found in the different sample and how many time, and a grouping file where the different sample are grouped using a categorical variable. The WF gives back a tabular and graphical representation of an entropy based partitioning of the information present in the sequence across the groupings, and a graphical and tabular representation of the contribution of each branch of the tree to the differentiation across groups of sample.Further as side results the WF gives the tree annotated with the per branch contribution to the differentiation across groups of sample in nexml or phyloxml format and all files necessary to produce ex.novo the annotated tree on itol, giving the possibility to the user to add taxonomic information.",0, 0, ,
"http://www.myexperiment.org/workflows/3570/versions/5.html","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH with parsing Qiime","2013-05-0712:13:37","2015-06-1213:39:38","http://www.myexperiment.org/workflows/3570/download/Partitioning_environmental_sequencing_data_using_categorical_and_phylogenetic_information_using_PhyloH_with_parsing_Qiime-v5.t2flow?version=5","/users/20342","Saverio Vicario","taverna 2","/users/20342,","Saverio Vicario,","Partitioning environmental sequencing data using categorical and phylogenetic information using PhyloH .The WF need a tree in newick format, a samplefile that show the where the leaf of the tree are found in the different sample and how many time, and a grouping file where the different sample are grouped using a categorical variable. The WF gives back a tabular and graphical representation of an entropy based partitioning of the information present in the sequence across the groupings, and a graphical and tabular representation of the contribution of each branch of the tree to the differentiation across groups of sample.Further as side results the WF gives the tree annotated with the per branch contribution to the differentiation across groups of sample in nexml or phyloxml format and all files necessary to produce ex.novo the annotated tree on itol, giving the possibility to the user to add taxonomic information.",0, 0, ,
"http://www.myexperiment.org/workflows/3571/versions/1.html","BioSTIF Interaction Rastermask","2013-05-1309:03:02","2014-09-1711:33:57","http://www.myexperiment.org/workflows/3571/download/BioSTIF_Interaction_Rastermask-v1.t2flow?version=1","/users/62314","Biodiversity eLaboratory","taverna 2","/users/20320,","Robert Kulawik,","The Rastermask interaction allows to create a mask from a geiven extent and resolution and store it to the Geoserver for futher computations",-1, 0, ,
"http://www.myexperiment.org/workflows/3571/versions/2.html","BioSTIF Interaction Rastermask","2013-05-1309:03:02","2014-09-1711:33:57","http://www.myexperiment.org/workflows/3571/download/BioSTIF_Interaction_Rastermask-v2.t2flow?version=2","/users/62314","Biodiversity eLaboratory","taverna 2","/users/20320,","Robert Kulawik,","The Rastermask interaction allows to create a mask from a geiven extent and resolution and store it to the Geoserver for futher computations. This version includes a check if the mask is created when the &quot;continue&quot; button is pushed. The task=createmask parameter must be set to get the check.",-1, 0, ,
"http://www.myexperiment.org/workflows/3603/versions/1.html","From molecule name to SMILE and InchI using ChemSpider","2013-05-2113:42:45","2013-05-2113:51:06","http://www.myexperiment.org/workflows/3603/download/From_molecule_name_to_SMILE_and_InchI_using_ChemSpider-v1.t2flow?version=1","/users/61598","Luna De Ferrari","taverna 3","/users/61598,","Luna De Ferrari,","Takes as input a list of molecule common names, converts them to ChemSpider identifiers and then gets their SMILES and InchI. Outputs the results as tab separated file. Please note you will need to register with ChemSpider to get your own security key.",
"http://www.myexperiment.org/workflows/3603/versions/2.html","From molecule name to SMILE and InchI using ChemSpider","2013-05-2113:42:45","2013-05-2113:51:06","http://www.myexperiment.org/workflows/3603/download/From_molecule_name_to_SMILE_and_InchI_using_ChemSpider-v2.t2flow?version=2","/users/61598","Luna De Ferrari","taverna 3","/users/61598,","Luna De Ferrari,","From molecule name to smile and inchi using chemspider. If the name cannot be matched to a chemspider identifier, the molecule name will appear in the results with an empty line. The output is a tab separated file.",
"http://www.myexperiment.org/workflows/3606/versions/1.html","ref","2013-05-2809:51:37","2013-05-2809:52:15","http://www.myexperiment.org/workflows/3606/download/ref-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","Initial version",-1, 0, ,
"http://www.myexperiment.org/workflows/3606/versions/2.html","ref","2013-05-2809:51:37","2013-05-2809:52:15","http://www.myexperiment.org/workflows/3606/download/ref-v2.t2flow?version=2","/users/30","Alan Williams","taverna 2","","","ref",-1, 0, ,
"http://www.myexperiment.org/workflows/3607/versions/1.html","Fundamental matrix","2013-05-2810:46:42","","http://www.myexperiment.org/workflows/3607/download/Fundamental_matrix-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","This component calculates the fundamental matrix from a stage matrix",-1, 0, ,
"http://www.myexperiment.org/workflows/3608/versions/1.html","Convert TIFF to PNG","2013-05-2811:13:24","2013-05-2812:41:43","http://www.myexperiment.org/workflows/3608/download/Convert_TIFF_to_PNG-v1.t2flow?version=1","/users/9056","Donal Fellows","taverna 2","","","Initial version",0, 0, ,
"http://www.myexperiment.org/workflows/3608/versions/2.html","Convert TIFF to PNG","2013-05-2811:13:24","2013-05-2812:41:43","http://www.myexperiment.org/workflows/3608/download/Convert_TIFF_to_PNG-v2.t2flow?version=2","/users/9056","Donal Fellows","taverna 2","","","Use SIPS instead of ImageMagick",0, 0, ,
"http://www.myexperiment.org/workflows/3608/versions/3.html","Convert TIFF to PNG","2013-05-2811:13:24","2013-05-2812:41:43","http://www.myexperiment.org/workflows/3608/download/Convert_TIFF_to_PNG-v3.t2flow?version=3","/users/9056","Donal Fellows","taverna 2","","","Convert a TIFF to a PNG.Note that the semantic description is currently wrong due to a bug in the component plugin.",0, 0, ,
"http://www.myexperiment.org/workflows/3609/versions/1.html","Extract PNG dimensions","2013-05-2811:37:16","2013-05-2811:59:11","http://www.myexperiment.org/workflows/3609/download/Extract_PNG_dimensions-v1.t2flow?version=1","/users/9056","Donal Fellows","taverna 2","","","Initial version",0, 0, ,
"http://www.myexperiment.org/workflows/3609/versions/2.html","Extract PNG dimensions","2013-05-2811:37:16","2013-05-2811:59:11","http://www.myexperiment.org/workflows/3609/download/Extract_PNG_dimensions-v2.t2flow?version=2","/users/9056","Donal Fellows","taverna 2","","","First version of a simple PNG characterizer",0, 0, ,
"http://www.myexperiment.org/workflows/3610/versions/1.html","Extract Image Dimensions with SIPS","2013-05-2812:07:27","2013-05-2812:32:35","http://www.myexperiment.org/workflows/3610/download/Extract_Image_Dimensions_with_SIPS-v1.t2flow?version=1","/users/9056","Donal Fellows","taverna 2","","","Initial version",0, 0, ,
"http://www.myexperiment.org/workflows/3610/versions/2.html","Extract Image Dimensions with SIPS","2013-05-2812:07:27","2013-05-2812:32:35","http://www.myexperiment.org/workflows/3610/download/Extract_Image_Dimensions_with_SIPS-v2.t2flow?version=2","/users/9056","Donal Fellows","taverna 2","","","Extract the dimensions of an image with SIPS (OSX only)",0, 0, ,
"http://www.myexperiment.org/workflows/3611/versions/1.html","Clustering of Molecular Compounds with BioDICE Clustering Visualization Tool","2013-05-2913:09:50","2014-01-0911:22:28","http://www.myexperiment.org/workflows/3611/download/Clustering_of_Molecular_Compounds_with_BioDICE_Clustering_Visualization_Tool-v1.t2flow?version=1","/users/60189","Antonino Fiannaca","taverna 2","/users/60189, /users/59917,","Antonino Fiannaca, Massimo La Rosa,","This workflow downloads an input set of molecular compounds in SMILES format, using Chemspider service. The most frequent molecular fragments are extracted by means of MoSS tool (see  <a href=http://www.borgelt.net/moss.html rel=nofollow>http://www.borgelt.net/moss.html</a> ) , in order to obtain a set of features for each compound. Then a clustering and a visual exploration of the input dataset is performed by BioDICE service (see  <a href=http://biolab.pa.icar.cnr.it/biodice.html rel=nofollow>http://biolab.pa.icar.cnr.it/biodice.html</a> ), implementing Fast Learning Self-Organized Map (FLSOM) algorithm. Finally the output is a list of compounds for each cluster.The workflow requires as input a text file with a list of compounds names (or Chemspider IDs) and a file with a list of MoSS minimal support focus values (see MoSS docuemntation  <a href=http://www.borgelt.net/doc/moss/moss.html rel=nofollow>http://www.borgelt.net/doc/moss/moss.html</a>  for a detailed description).",0, 0, ,
"http://www.myexperiment.org/workflows/3611/versions/2.html","Clustering of Molecular Compounds with BioDICE Clustering Visualization Tool","2013-05-2913:09:50","2014-01-0911:22:28","http://www.myexperiment.org/workflows/3611/download/Clustering_of_Molecular_Compounds_with_BioDICE_Clustering_Visualization_Tool-v2.t2flow?version=2","/users/60189","Antonino Fiannaca","taverna 2","/users/60189, /users/59917,","Antonino Fiannaca, Massimo La Rosa,","This workflow downloads an input set of molecular compounds in SMILES format, using Chemspider service. The most frequent molecular fragments are extracted by means of MoSS tool (see  <a href=http://www.borgelt.net/moss.html rel=nofollow>http://www.borgelt.net/moss.html</a> ) , in order to obtain a set of features for each compound. Then a clustering and a visual exploration of the input dataset is performed by BioDICE service (see  <a href=http://biolab.pa.icar.cnr.it/biodice.html rel=nofollow>http://biolab.pa.icar.cnr.it/biodice.html</a> ), implementing Fast Learning Self-Organized Map (FLSOM) algorithm. Finally the output is a list of compounds for each cluster.The workflow requires as input a text file with a list of compounds names (or Chemspider IDs) and a file with a list of MoSS minimal support focus values (see MoSS docuemntation  <a href=http://www.borgelt.net/doc/moss/moss.html rel=nofollow>http://www.borgelt.net/doc/moss/moss.html</a>  for a detailed description).",0, 0, ,
"http://www.myexperiment.org/workflows/3611/versions/3.html","Clustering of Molecular Compounds with BioDICE Clustering Visualization Tool","2013-05-2913:09:50","2014-01-0911:22:28","http://www.myexperiment.org/workflows/3611/download/Clustering_of_Molecular_Compounds_with_BioDICE_Clustering_Visualization_Tool-v3.t2flow?version=3","/users/60189","Antonino Fiannaca","taverna 2","/users/60189, /users/59917,","Antonino Fiannaca, Massimo La Rosa,","This workflow downloads an input set of molecular compounds in SMILES format, using Chemspider service. The most frequent molecular fragments are extracted by means of MoSS tool (see  <a href=http://www.borgelt.net/moss.html rel=nofollow>http://www.borgelt.net/moss.html</a> ) , in order to obtain a set of features for each compound. Then a clustering and a visual exploration of the input dataset is performed by BioDICE service (see  <a href=http://biolab.pa.icar.cnr.it/biodice.html rel=nofollow>http://biolab.pa.icar.cnr.it/biodice.html</a> ), implementing Fast Learning Self-Organized Map (FLSOM) algorithm. Finally the output is a list of compounds for each cluster.The workflow requires as input a text file with a list of compounds names (or Chemspider IDs) and a file with a list of MoSS minimal support focus values (see MoSS docuemntation  <a href=http://www.borgelt.net/doc/moss/moss.html rel=nofollow>http://www.borgelt.net/doc/moss/moss.html</a>  for a detailed description).",0, 0, ,
"http://www.myexperiment.org/workflows/3611/versions/4.html","Clustering of Molecular Compounds with BioDICE Clustering Visualization Tool","2013-05-2913:09:50","2014-01-0911:22:28","http://www.myexperiment.org/workflows/3611/download/Clustering_of_Molecular_Compounds_with_BioDICE_Clustering_Visualization_Tool-v4.t2flow?version=4","/users/60189","Antonino Fiannaca","taverna 2","/users/60189, /users/59917,","Antonino Fiannaca, Massimo La Rosa,","This workflow downloads an input set of molecular compounds in SMILES format, using Chemspider service. The most frequent molecular fragments are extracted by means of MoSS tool (see  <a href=http://www.borgelt.net/moss.html rel=nofollow>http://www.borgelt.net/moss.html</a> ) , in order to obtain a set of features for each compound. Then a clustering and a visual exploration of the input dataset is performed by BioDICE service (see  <a href=http://biolab.pa.icar.cnr.it/biodice.html rel=nofollow>http://biolab.pa.icar.cnr.it/biodice.html</a> ), implementing Fast Learning Self-Organized Map (FLSOM) algorithm. Finally the output is a list of compounds for each cluster. The workflow requires as input a text file with a list of compounds names (or Chemspider IDs) and a file with a list of MoSS minimal support focus values (see MoSS docuemntation  <a href=http://www.borgelt.net/doc/moss/moss.html rel=nofollow>http://www.borgelt.net/doc/moss/moss.html</a>  for a detailed description).",0, 0, ,
"http://www.myexperiment.org/workflows/3618/versions/1.html","Biome-BGC CARBON 1.2","2013-06-0410:32:37","2015-06-1212:12:18","http://www.myexperiment.org/workflows/3618/download/Biome-BGC_CARBON_1.2-v1.t2flow?version=1","/users/11655","Ferenc HORVATH","taverna 2","/users/11655, /users/21374, /users/21964, /users/19743,","Ferenc HORVATH, Dora Krasser, Peter Ittzes, Zoltan BARCZA,","",0, 0, ,
"http://www.myexperiment.org/workflows/3618/versions/2.html","Biome-BGC CARBON 1.2","2013-06-0410:32:37","2015-06-1212:12:18","http://www.myexperiment.org/workflows/3618/download/Biome-BGC_CARBON_1.2-v2.t2flow?version=2","/users/11655","Ferenc HORVATH","taverna 2","/users/11655, /users/21374, /users/21964, /users/19743,","Ferenc HORVATH, Dora Krasser, Peter Ittzes, Zoltan BARCZA,","",0, 0, ,
"http://www.myexperiment.org/workflows/3618/versions/3.html","Biome-BGC CARBON 1.2","2013-06-0410:32:37","2015-06-1212:12:18","http://www.myexperiment.org/workflows/3618/download/Biome-BGC_CARBON_1.2-v3.t2flow?version=3","/users/11655","Ferenc HORVATH","taverna 2","/users/11655, /users/21374, /users/21964, /users/19743,","Ferenc HORVATH, Dora Krasser, Peter Ittzes, Zoltan BARCZA,","Biome-BGC is a process-based biogeochemical model that can be used to simulate carbon, nitrogen and water fluxes of different terrestrial ecosystems. A new version of the model, called Biome-BGC MuSo was developed to perform more realistic simulations in terms of soil hydrology, and improved ecosystem management options essentially (Hidy et al. 2012; Hidy &amp; Barcza 2014). The Biome-BGC CARBON service executes a single simulation run at a given geographic location under that distinctive environmental circumstances, and for a specified time-span of years, past and/or future climate scenarios and management options. The simulations require specific inputs like: - local daily meteorology input dataset- a number of general ecophysiological constants as essential parameters- local site/soil parameters- annual atmospheric CO2 concentration (optional)- annual nitrogen deposition (optional)- output control settings of Biome-BGC variables- spinup and normal initialization settings The Biome-BGC Project Database &amp; Management System (BBGCDB) was developed to support users to manage various Biome-BGC ecosystem modelling investigations, and to share related input, parameter, initialisation and output files. It provides interaction to the Taverna workflows in a user friendly environment of the BioVeL Portal. The interaction page provides a user friendly interface to select model version and all the other predefined parameter settings and inputs. Two model versions are implemented: Biome-BGC 4.1.1 MPI (Trusilova et al. 2009) and Biome-BGC MuSo 3.0 (Hidy &amp; Barcza 2014).",0, 0, ,
"http://www.myexperiment.org/workflows/3618/versions/4.html","Biome-BGC CARBON 1.2","2013-06-0410:32:37","2015-06-1212:12:18","http://www.myexperiment.org/workflows/3618/download/Biome-BGC_CARBON_1.2-v4.t2flow?version=4","/users/11655","Ferenc HORVATH","taverna 2","/users/11655, /users/21374, /users/21964, /users/19743,","Ferenc HORVATH, Dora Krasser, Peter Ittzes, Zoltan BARCZA,","Biome-BGC is a process-based biogeochemical model that can be used to simulate carbon, nitrogen and water fluxes of different terrestrial ecosystems. A new version of the model, called Biome-BGC MuSo was developed to perform more realistic simulations in terms of soil hydrology, and improved ecosystem management options essentially (Hidy et al. 2012; Hidy &amp; Barcza 2014). The Biome-BGC CARBON service executes a single simulation run at a given geographic location under that distinctive environmental circumstances, and for a specified time-span of years, past and/or future climate scenarios and management options. The simulations require specific inputs like: - local daily meteorology input dataset- a number of general ecophysiological constants as essential parameters- local site/soil parameters- annual atmospheric CO2 concentration (optional)- annual nitrogen deposition (optional)- output control settings of Biome-BGC variables- spinup and normal initialization settings The Biome-BGC Project Database &amp; Management System (BBGCDB) was developed to support users to manage various Biome-BGC ecosystem modelling investigations, and to share related input, parameter, initialisation and output files. It provides interaction to the Taverna workflows in a user friendly environment of the BioVeL Portal. The interaction page provides a user friendly interface to select model version and all the other predefined parameter settings and inputs. Two model versions were implemented: Biome-BGC 4.1.1 MPI (Trusilova et al. 2009) and Biome-BGC MuSo 3.0 (Hidy &amp; Barcza 2014).",0, 0, ,
"http://www.myexperiment.org/workflows/3619/versions/1.html","Fraunhofer IAIS mydec","2013-06-0415:41:57","2014-02-0712:53:49","","/users/6731","cneudecker","taverna 2","/users/6731,","cneudecker,","<a href=http://www.iais.fraunhofer.de/mydec.html rel=nofollow>http://www.iais.fraunhofer.de/mydec.html</a>",
"http://www.myexperiment.org/workflows/3619/versions/2.html","Fraunhofer IAIS mydec","2013-06-0415:41:57","2014-02-0712:53:49","","/users/6731","cneudecker","taverna 2","/users/6731,","cneudecker,","For more information please visit  <a href=http://www.iais.fraunhofer.de/mydec.html rel=nofollow>http://www.iais.fraunhofer.de/mydec.html</a>",
"http://www.myexperiment.org/workflows/3619/versions/3.html","Fraunhofer IAIS mydec","2013-06-0415:41:57","2014-02-0712:53:49","","/users/6731","cneudecker","taverna 2","/users/6731,","cneudecker,","For more information please visit  <a href=http://www.iais.fraunhofer.de/mydec.html rel=nofollow>http://www.iais.fraunhofer.de/mydec.html</a>",
"http://www.myexperiment.org/workflows/3619/versions/4.html","Fraunhofer IAIS mydec","2013-06-0415:41:57","2014-02-0712:53:49","","/users/6731","cneudecker","taverna 2","/users/6731,","cneudecker,","This workflow is provided by the Succeed EU project. For more information about Succeed, please visit  <a href=http://succeed-project.eu/ rel=nofollow>http://succeed-project.eu/</a> . For more information about mydec, please visit  <a href=http://www.iais.fraunhofer.de/mydec.html rel=nofollow>http://www.iais.fraunhofer.de/mydec.html</a>",
"http://www.myexperiment.org/workflows/3620/versions/1.html","Biome-BGC MCE 1.4.1","2013-06-0416:59:31","2014-10-0415:48:25","http://www.myexperiment.org/workflows/3620/download/Biome-BGC_MCE_1.4.1-v1.t2flow?version=1","/users/11655","Ferenc HORVATH","taverna 2","/users/11655, /users/19743, /users/21374, /users/21964,","Ferenc HORVATH, Zoltan BARCZA, Dora Krasser, Peter Ittzes,","",0, 0, ,
"http://www.myexperiment.org/workflows/3620/versions/2.html","Biome-BGC MCE 1.4.1","2013-06-0416:59:31","2014-10-0415:48:25","http://www.myexperiment.org/workflows/3620/download/Biome-BGC_MCE_1.4.1-v2.t2flow?version=2","/users/11655","Ferenc HORVATH","taverna 2","/users/11655, /users/19743, /users/21374, /users/21964,","Ferenc HORVATH, Zoltan BARCZA, Dora Krasser, Peter Ittzes,","",0, 0, ,
"http://www.myexperiment.org/workflows/3620/versions/3.html","Biome-BGC MCE 1.4.1","2013-06-0416:59:31","2014-10-0415:48:25","http://www.myexperiment.org/workflows/3620/download/Biome-BGC_MCE_1.4.1-v3.t2flow?version=3","/users/11655","Ferenc HORVATH","taverna 2","/users/11655, /users/19743, /users/21374, /users/21964,","Ferenc HORVATH, Zoltan BARCZA, Dora Krasser, Peter Ittzes,",,0, 0, ,
"http://www.myexperiment.org/workflows/3620/versions/4.html","Biome-BGC MCE 1.4.1","2013-06-0416:59:31","2014-10-0415:48:25","http://www.myexperiment.org/workflows/3620/download/Biome-BGC_MCE_1.4.1-v4.t2flow?version=4","/users/11655","Ferenc HORVATH","taverna 2","/users/11655, /users/19743, /users/21374, /users/21964,","Ferenc HORVATH, Zoltan BARCZA, Dora Krasser, Peter Ittzes,",,0, 0, ,
"http://www.myexperiment.org/workflows/3625/versions/1.html","OPS_FreetextToTargetInfo","2013-06-1818:40:28","","http://www.myexperiment.org/workflows/3625/download/OPS_FreetextToTargetInfo-v1.t2flow?version=1","/users/18","Marco Roos","taverna 2","/users/18, /users/13, /users/287,","Marco Roos, Katy Wolstencroft, paul groth,","Workflow to retrieve target information for the concepts as refered to by humans (the input). Known issues: It produces error values for the concepts returned by ConceptWiki that are apparently not present in OPS (e.g. for ezh2 and limit=10, it gives 7/10 error values vs ezh2 (homo sapiens) giving 2 valid values).",0, 0, ,
"http://www.myexperiment.org/workflows/3626/versions/1.html","MusicClassificationExperiment","2013-06-2010:35:24","","http://www.myexperiment.org/workflows/3626/download/MusicClassificationExperiment-v1.t2flow?version=1","/users/61708","Rudolf Mayer","taverna 2","/users/61708,","Rudolf Mayer,","Performs a scientific experiment of classifying music into genres",0, 0, ,
"http://www.myexperiment.org/workflows/3628/versions/1.html","Free text search to Concept Wiki URI","2013-06-2415:04:27","2013-06-2415:29:10","http://www.myexperiment.org/workflows/3628/download/Free_text_search_to_Concept_Wiki_URI-v1.t2flow?version=1","/users/474","Ian Dunlop","taverna 2","/users/474, /users/13, /users/18, /users/287,","Ian Dunlop, Katy Wolstencroft, Marco Roos, paul groth,","Workflow to retrieve target information for the concepts as refered to by humans (the input). PLEASE DO NOT DISTRIBUTE Known issues: It produces error values for the concepts returned by ConceptWiki that are apparently not present in OPS (e.g. for ezh2 and limit=10, it gives 7/10 error values vs ezh2 (homo sapiens) giving 2 valid values).",0, 0, ,
"http://www.myexperiment.org/workflows/3628/versions/2.html","Free text search to Concept Wiki URI","2013-06-2415:04:27","2013-06-2415:29:10","http://www.myexperiment.org/workflows/3628/download/Free_text_search_to_Concept_Wiki_URI-v2.t2flow?version=2","/users/474","Ian Dunlop","taverna 2","/users/474, /users/13, /users/18, /users/287,","Ian Dunlop, Katy Wolstencroft, Marco Roos, paul groth,","Workflow to retrieve information for either compounds or targets",0, 0, ,
"http://www.myexperiment.org/workflows/3628/versions/3.html","Free text search to Concept Wiki URI","2013-06-2415:04:27","2013-06-2415:29:10","http://www.myexperiment.org/workflows/3628/download/Free_text_search_to_Concept_Wiki_URI-v3.t2flow?version=3","/users/474","Ian Dunlop","taverna 2","/users/474, /users/13, /users/18, /users/287,","Ian Dunlop, Katy Wolstencroft, Marco Roos, paul groth,","Free text search of concept wiki using the Openphacts Map free text to a concept url based on semantic tag ie /search/byTag. Search for either compounds or targets depending on the input uuid for searchType and filter by source authority with the branch input",0, 0, ,
"http://www.myexperiment.org/workflows/3628/versions/4.html","Free text search to Concept Wiki URI","2013-06-2415:04:27","2013-06-2415:29:10","http://www.myexperiment.org/workflows/3628/download/Free_text_search_to_Concept_Wiki_URI-v4.t2flow?version=4","/users/474","Ian Dunlop","taverna 2","/users/474, /users/13, /users/18, /users/287,","Ian Dunlop, Katy Wolstencroft, Marco Roos, paul groth,","Free text search of concept wiki using the Openphacts Map free text to a concept url based on semantic tag ie /search/byTag. Search for either compounds or targets depending on the input uuid for searchType and filter by source authority with the branch input",0, 0, ,
"http://www.myexperiment.org/workflows/3629/versions/1.html","Test for Taverna Server + multiple R components","2013-06-2713:14:13","","http://www.myexperiment.org/workflows/3629/download/Test_for_Taverna_Server___multiple_R_components-v1.t2flow?version=1","/users/61138","Eelke van der Horst","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/3630/versions/1.html","Test Taverna Server with coupled R components","2013-06-2714:09:17","","http://www.myexperiment.org/workflows/3630/download/Test_Taverna_Server_with_coupled_R_components-v1.t2flow?version=1","/users/61138","Eelke van der Horst","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/3631/versions/1.html","maps genes to chromosomal location with constants","2013-06-2714:42:49","","http://www.myexperiment.org/workflows/3631/download/maps_genes_to_chromosomal_location_with_constants-v1.t2flow?version=1","/users/61138","Eelke van der Horst","taverna 2","","",,0, 0, ,
"http://www.myexperiment.org/workflows/3632/versions/1.html","Simple WikiPathways SPARQL query","2013-06-2805:15:50","2013-06-2807:43:31","http://www.myexperiment.org/workflows/3632/download/Simple_WikiPathways_SPARQL_query-v1.t2flow?version=1","/users/61138","Eelke van der Horst","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/3636/versions/1.html","Find pathways in which two genes co-occur (in WikiPathways)","2013-06-2813:45:23","2013-06-2814:14:23","http://www.myexperiment.org/workflows/3636/download/Find_pathways_in_which_two_genes_co-occur__in_WikiPathways_-v1.t2flow?version=1","/users/61138","Eelke van der Horst","taverna 2","","","This workflow finds all pathways in which two gene symbols co-occur. This workflow was created as an exercise for the Managing and Integrating Information in the Life Sciences course 2013 at the LUMC, which is organized by the Netherlands Bioinformatics Center (NBIC).",0, 0, ,
"http://www.myexperiment.org/workflows/3644/versions/1.html","OPS REST services","2013-07-0607:49:19","","http://www.myexperiment.org/workflows/3644/download/OPS_REST_services-v1.t2flow?version=1","/users/18","Marco Roos","taverna 2","/users/18,","Marco Roos,","Library of REST services developed for the Open Pharmacological Space (OPS) by the OpenPHACTS project. Usage: <ol><li value=1>Copy-paste a service into your workflow</li><li value=2>Add an output to responseBody</li><li value=3>Run the workflow (this will produce output in XML)</li><li value=4>Copy the XML output</li><li value=5>Go back to the design window and add the XPath widget to the canvas</li><li value=6>Link the responseBody output to the XPath widget input</li><li value=7>Paste the XML output to the example window in the XPath configure window</li><li value=8>Select the desired elements from the example XML</li><li value=9>Generate the XPath query and test it</li><li value=10>Add a workflow output and link it to the XPath output.</li></ol>",0, 0, ,
"http://www.myexperiment.org/workflows/3646/versions/1.html","Imagemagick convert - tiff2tiff - compression","2013-07-0814:50:13","2013-07-0814:55:35","http://www.myexperiment.org/workflows/3646/download/Imagemagick_convert_-_tiff2tiff_-_compression-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Converts tiff to tiff using imagemagick convert with the provided compression",0, 0, ,
"http://www.myexperiment.org/workflows/3646/versions/2.html","Imagemagick convert - tiff2tiff - compression","2013-07-0814:50:13","2013-07-0814:55:35","http://www.myexperiment.org/workflows/3646/download/Imagemagick_convert_-_tiff2tiff_-_compression-v2.t2flow?version=2","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Converts tiff to tiff using imagemagick convert with the provided compression",0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/1.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v1.t2flow?version=1","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,","The postanalytical statistic workflow (PSW) allows the computation of the extent and intensity of change in species potential distribution through computation of the differences between two raster layers using the R statistical environment (R Core Team 2013). The difference file is computed from two input files (in this case present projection and 2050 projection). The difference between each corresponding raster cell value is computed and stored in the difference file, regardless of the input files&rsquo; geographical extent and origin. If the files have a different geographical extent and/or origin the raster-diff workflow automatically crops them to the same extent and resamples the values using the &ldquo;nearest neighbour&rdquo; method, resulting in a perfect cell match between the two rasters. The resulting value in the difference file ranges from the negative and positive maximum values of the input files to represent the maximum possible change in both directions. The diff result values are classified into six positive and negative classes. The predicted differences are presented for each species as a heat map, where cells with colors from green to red indicate an increase and from green to blue a decrease of predicted potential for a species. The workflow enables the computation of overall coverage, overall intensity and the difference in intensity or coverage between two raster layers. Overall coverage is computed as the percentage of raster cells with values &gt;0, and overall intensity is computed as the sum of all valued cells divided by the number of raster cells. Summary statistics for the raster layers are also provided: number of raster cells, mean intensity, median, CV, SD, Min value, Max value and number of cells outside the mask. <br /> This workflow store the computed difference image to the BioVeL Geoserver and create PNG overwiews contains the input and output files. The difference result image could be shown in the BioSTIF web visualisation client The PNG overview will be created with these values (corresponding to the Geoserver style) <br /> ERDASImagine file: <br /> breakpoints = c(0,1,25,50,75,100) <br /> GeoTIFF file <br /> breakpoints = c(0,2,63,127,190,254) <br /> colors =&nbsp; c(rgb(1.0,1.0,1.0),rgb(0.996,0.898,0.851),rgb(0.988,0.682,0.569),rgb(0.984,0.416,0.290), <br /> &nbsp;&nbsp; rgb(0.871,0.176,0.149),rgb(0.647,0.059,0.082)) Expected as input files are raster images as a URL from openModeller created by an ENM workflow. A file upload is not possible! Supported formats are: <br /> - ERDASImagine (.img) files with a value range 0 - 100, noData value 101 <br /> - GeoTIFF (.tif) files with a value range 0- 254, noData Value 255 Input files with a different extent will be intersected to a common extent and the current layer (inputfile 1) will be resampled to the prediction layer (inputfile 2) using the &quot;nearest neighbor&quot; sampling method. The difference layer will be computed as inputfile_2 - inputfile_1 For working with the PSW in a own localhost an R instance should by installed on a own machine ( <a href=http://cran.r-project.org/ rel=nofollow>http://cran.r-project.org/</a> ). For the computation the followed extensions must be installed: rgdal, raster and rserve. Rserve must be started before the computation. -------------------- This workflow has been created by the Biodiversity Virtual e-Laboratory (BioVeL  <a href=http://www.biovel.eu/ rel=nofollow>http://www.biovel.eu/</a> ) project. BioVeL is funded by the EU&rsquo;s Seventh Framework Program, grant no. 283359.",0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/2.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v2.t2flow?version=2","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/3.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v3.t2flow?version=3","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/4.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v4.t2flow?version=4","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/5.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v5.t2flow?version=5","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/6.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v6.t2flow?version=6","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/7.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v7.t2flow?version=7","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/8.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v8.t2flow?version=8","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/9.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v9.t2flow?version=9","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/10.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v10.t2flow?version=10","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/11.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v11.t2flow?version=11","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/12.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v12.t2flow?version=12","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/13.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v13.t2flow?version=13","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/14.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v14.t2flow?version=14","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/15.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v15.t2flow?version=15","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3647/versions/16.html","BioVeL ESW DIFF - ENM Statistical Workflow with raster difference computation","2013-07-0815:06:00","2016-06-2214:45:16","http://www.myexperiment.org/workflows/3647/download/BioVeL_ESW_DIFF_-_ENM_Statistical_Workflow_with_raster_difference_computation-v16.t2flow?version=16","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3653/versions/1.html","Find asteroids in images from CAHA observatory","2013-07-1712:09:27","","http://www.myexperiment.org/workflows/3653/download/Find_asteroids_in_images_from_CAHA_observatory-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","It analyzes images from CAFOS instrument in Calar Alto Observatory. It uses SkyBot catalog in order to identify objects in the Solar System. It includes a double check to avoid objets that are not asteroids (comparing  with USNO and 2MASS catalogs). The result is a VOTable of asteroids",0, 0, ,
"http://www.myexperiment.org/workflows/3656/versions/1.html","wf4ever_PDF2TXT2Solr_Database","2013-07-2413:12:54","","http://www.myexperiment.org/workflows/3656/download/wf4ever_PDF2TXT2Solr_Database-v1.t2flow?version=1","/users/61765","Sander van boom","taverna 2","","","This workflow extracts the text of a .pdf file and stores it in a .txt file. Then it stores the .txt file in a Solr database.",0, 0, ,
"http://www.myexperiment.org/workflows/3657/versions/1.html","wf4ever_document_extraction_and_storage","2013-07-2414:48:38","2013-08-2910:50:46","http://www.myexperiment.org/workflows/3657/download/wf4ever_document_extraction_and_storage-v1.t2flow?version=1","/users/61765","Sander van boom","taverna 2","","","The workflow uses parts of the existing BioAid workflow by Marco Roos ( <a href=http://www.myexperiment.org/workflows/74.html rel=nofollow>http://www.myexperiment.org/workflows/74.html</a> )The workflow stores found articles in a Solr database.Make sure that Solr is running in the correct directory (stored in the Solr_directory value).",0, 0, ,
"http://www.myexperiment.org/workflows/3659/versions/1.html","PubMed Search and Solr storage","2013-07-2514:38:20","2013-08-2614:13:59","http://www.myexperiment.org/workflows/3659/download/PubMed_Search_and_Solr_storage-v1.t2flow?version=1","/users/61765","Sander van boom","taverna 2","/users/61765,","Sander van boom,","Based on the work of Fisher: This workflow takes in a search term, are passed to the eSearch function and searched for in PubMed. I extended by removing outputs and text extraction and addded an automatic Solr storage process using a post.jar, specified by the user.Before running this workflow, make sure that a solr server is up and running and the variable attached to the SolrImport process contains the correct path. Dependencies: - Solr",0, 0, ,
"http://www.myexperiment.org/workflows/3659/versions/2.html","PubMed Search and Solr storage","2013-07-2514:38:20","2013-08-2614:13:59","http://www.myexperiment.org/workflows/3659/download/PubMed_Search_and_Solr_storage-v2.t2flow?version=2","/users/61765","Sander van boom","taverna 2","/users/61765,","Sander van boom,","Based on the work of Fisher: This workflow takes in a search term, are passed to the eSearch function and searched for in PubMed. I extended by removing outputs and text extraction and addded an automatic Solr storage process using a post.jar, specified by the user.Before running this workflow, make sure that a solr server is up and running and the variable attached to the SolrImport process contains the correct path. Dependencies: - Solr",0, 0, ,
"http://www.myexperiment.org/workflows/3659/versions/3.html","PubMed Search and Solr storage","2013-07-2514:38:20","2013-08-2614:13:59","http://www.myexperiment.org/workflows/3659/download/PubMed_Search_and_Solr_storage-v3.t2flow?version=3","/users/61765","Sander van boom","taverna 2","/users/61765,","Sander van boom,","Based on the work of Fisher: This workflow takes in a search term, are passed to the eSearch function and searched for in PubMed. I extended by removing outputs and text extraction and addded an automatic Solr storage process using a post.jar, specified by the user.Before running this workflow, make sure that a solr server is up and running and the variable attached to the SolrImport process contains the correct path. Dependencies: - Solr",0, 0, ,
"http://www.myexperiment.org/workflows/3659/versions/4.html","PubMed Search and Solr storage","2013-07-2514:38:20","2013-08-2614:13:59","http://www.myexperiment.org/workflows/3659/download/PubMed_Search_and_Solr_storage-v4.t2flow?version=4","/users/61765","Sander van boom","taverna 2","/users/61765,","Sander van boom,","Based on the work of Fisher: This workflow takes in a search term, are passed to the eSearch function and searched for in PubMed. I extended by removing outputs and text extraction and addded an automatic Solr storage process using a post.jar, specified by the user.Before running this workflow, make sure that a solr server is up and running and the variable attached to the SolrImport process contains the correct path. Dependencies: - Solr",0, 0, ,
"http://www.myexperiment.org/workflows/3659/versions/5.html","PubMed Search and Solr storage","2013-07-2514:38:20","2013-08-2614:13:59","http://www.myexperiment.org/workflows/3659/download/PubMed_Search_and_Solr_storage-v5.t2flow?version=5","/users/61765","Sander van boom","taverna 2","/users/61765,","Sander van boom,","Based on the work of Fisher: This workflow takes in a search term, are passed to the eSearch function and searched for in PubMed. I extended by removing outputs and text extraction and addded an automatic Solr storage process using a post.jar, specified by the user.Before running this workflow, make sure that a solr server is up and running and the variable attached to the SolrImport process contains the correct path. Dependencies: - Solr",0, 0, ,
"http://www.myexperiment.org/workflows/3661/versions/1.html","Query EVS by chromosomal position","2013-07-2610:42:18","2013-07-2610:44:00","http://www.myexperiment.org/workflows/3661/download/Query_EVS_by_chromosomal_position-v1.t2flow?version=1","/users/61816","Sirisha Hesketh","taverna 2","/users/61816,","Sirisha Hesketh,","The workflow takes a list of chromosomal positions (in the format chr:pos e.g. 2:139574) and returns a selection of data in the Exome Variant Server ( <a href=http://evs.gs.washington.edu/EVS/ rel=nofollow>http://evs.gs.washington.edu/EVS/</a> ).",0, 0, ,
"http://www.myexperiment.org/workflows/3674/versions/1.html","CSV to VOTable importer","2013-07-2917:33:49","2013-07-2917:37:10","http://www.myexperiment.org/workflows/3674/download/CSV_to_VOTable_importer-v1.t2flow?version=1","/users/21243","Juandesant","taverna 2","/users/21243,","Juandesant,","This module provides a VOTable representation of the CSV file being pointed by the csv_file_path, either as a POSIX local file path, or a URL.",0, 0, ,
"http://www.myexperiment.org/workflows/3674/versions/2.html","CSV to VOTable importer","2013-07-2917:33:49","2013-07-2917:37:10","http://www.myexperiment.org/workflows/3674/download/CSV_to_VOTable_importer-v2.t2flow?version=2","/users/21243","Juandesant","taverna 2","/users/21243,","Juandesant,","This module provides a VOTable representation of the CSV file being pointed by the csv_file_path, either as a POSIX local file path, or a URL.",0, 0, ,
"http://www.myexperiment.org/workflows/3679/versions/1.html","ENM Maxent workflow used for optimization","2013-08-0915:59:47","2013-09-0407:19:51","http://www.myexperiment.org/workflows/3679/download/ENM_Maxent_workflow_used_for_optimization-v1.t2flow?version=1","/users/8596","Sonja Holl","taverna 2","/users/8596, /users/20358,","Sonja Holl, Renato De Giovanni,","This workflow was used for the optimization of the Maxent algorithm from the openModeller toolbox ( <a href=http://openmodeller.sourceforge.net/ rel=nofollow>http://openmodeller.sourceforge.net/</a> ). The workflow uses 10-fold cross-validation and then calculates theaverage AUC, which can be used as fitness value during parameteroptimization.",0, 0, ,
"http://www.myexperiment.org/workflows/3680/versions/1.html","ENM SVM workflow used for optimization","2013-08-0916:01:50","2013-09-0407:20:28","http://www.myexperiment.org/workflows/3680/download/ENM_SVM_workflow_used_for_optimization-v1.t2flow?version=1","/users/8596","Sonja Holl","taverna 2","/users/8596, /users/20358,","Sonja Holl, Renato De Giovanni,","This workflow was used for the optimization of the SVM algorithm from the openModeller toolbox ( <a href=http://openmodeller.sourceforge.net rel=nofollow>http://openmodeller.sourceforge.net</a> ). The workflow uses 10-fold cross-validation and then calculates theaverage AUC, which can be used as fitness value during parameteroptimization.",0, 0, ,
"http://www.myexperiment.org/workflows/3682/versions/1.html","Biome-BGC ESI version 1.4.1","2013-08-1212:20:48","2014-10-0415:07:16","http://www.myexperiment.org/workflows/3682/download/Biome-BGC_ESI_version_1.4.1-v1.t2flow?version=1","/users/11655","Ferenc HORVATH","taverna 2","/users/11655, /users/21374, /users/21964,","Ferenc HORVATH, Dora Krasser, Peter Ittzes,","",0, 0, ,
"http://www.myexperiment.org/workflows/3682/versions/2.html","Biome-BGC ESI version 1.4.1","2013-08-1212:20:48","2014-10-0415:07:16","http://www.myexperiment.org/workflows/3682/download/Biome-BGC_ESI_version_1.4.1-v2.t2flow?version=2","/users/11655","Ferenc HORVATH","taverna 2","/users/11655, /users/21374, /users/21964,","Ferenc HORVATH, Dora Krasser, Peter Ittzes,","Biome-BGC is a process-based biogeochemical model that can be used to simulate carbon, nitrogen and water fluxes of different terrestrial ecosystems. The model can help us to quantify a broad range of ecosystem service indicators. These newly developed measures include: annual wood increment, yearly production of grasslands or croplands, total average carbon stock, annual evapotranspiration, damping of ecosystem daily water outflow, living and dead biomass protecting the soil against erosion, litter and coarse woody debris decomposition rate, and humification rate in the soil. They are unrealistic or even impossible to measure in the field and so they have to be calculated. The Biome-BGC ESI - Ecosystem Service Indicators service executes a single simulation run at a given geographic location under that distinctive environmental circumstances, and for a specified time-span of years, past and/or future climate scenarios and management options. The simulations require specific inputs like: - local daily meteorology input dataset- a number of general ecophysiological constants as essential parameters- local site/soil parameters- annual atmospheric CO2 concentration (optional)- annual nitrogen deposition (optional)- output control settings of Biome-BGC variables- spinup and normal initialization settings The Biome-BGC Project Database &amp; Management System (BBGCDB) was developed to support users to manage various Biome-BGC ecosystem modelling investigations, and to share related input, parameter, initialisation and output files. It provides also interaction to the Taverna workflows within the environment of the BioVeL Portal. It provides a user friendly interface to select model version and all the other predefined parameter settings and inputs. Two model versions were implemented: Biome-BGC 4.1.1 MPI (Trusilova et al. 2009) and Biome-BGC MuSo 3.0 (Hidy &amp; Barcza 2014).",0, 0, ,
"http://www.myexperiment.org/workflows/3682/versions/3.html","Biome-BGC ESI version 1.4.1","2013-08-1212:20:48","2014-10-0415:07:16","http://www.myexperiment.org/workflows/3682/download/Biome-BGC_ESI_version_1.4.1-v3.t2flow?version=3","/users/11655","Ferenc HORVATH","taverna 2","/users/11655, /users/21374, /users/21964,","Ferenc HORVATH, Dora Krasser, Peter Ittzes,","Biome-BGC is a process-based biogeochemical model that can be used to simulate carbon, nitrogen and water fluxes of different terrestrial ecosystems. The model can help us to quantify a broad range of ecosystem service indicators. These newly developed measures include: annual wood increment, yearly production of grasslands or croplands, total average carbon stock, annual evapotranspiration, damping of ecosystem daily water outflow, living and dead biomass protecting the soil against erosion, litter and coarse woody debris decomposition rate, and humification rate in the soil. They are unrealistic or even impossible to measure in the field and so they have to be calculated. The Biome-BGC ESI - Ecosystem Service Indicators service executes a single simulation run at a given geographic location under that distinctive environmental circumstances, and for a specified time-span of years, past and/or future climate scenarios and management options. The simulations require specific inputs like: - local daily meteorology input dataset- a number of general ecophysiological constants as essential parameters- local site/soil parameters- annual atmospheric CO2 concentration (optional)- annual nitrogen deposition (optional)- output control settings of Biome-BGC variables- spinup and normal initialization settings The Biome-BGC Project Database &amp; Management System (BBGCDB) was developed to support users to manage various Biome-BGC ecosystem modelling investigations, and to share related input, parameter, initialisation and output files. It provides also interaction to the Taverna workflows within the environment of the BioVeL Portal. It provides a user friendly interface to select model version and all the other predefined parameter settings and inputs. Two model versions were implemented: Biome-BGC 4.1.1 MPI (Trusilova et al. 2009) and Biome-BGC MuSo 3.0 (Hidy &amp; Barcza 2014).",0, 0, ,
"http://www.myexperiment.org/workflows/3684/versions/1.html","Matrix Population Model construction and analysis v20","2013-08-1308:31:07","2014-07-0412:57:14","http://www.myexperiment.org/workflows/3684/download/Matrix_Population_Model_construction_and_analysis_v20-v1.t2flow?version=1","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3684/versions/2.html","Matrix Population Model construction and analysis v20","2013-08-1308:31:07","2014-07-0412:57:14","http://www.myexperiment.org/workflows/3684/download/Matrix_Population_Model_construction_and_analysis_v20-v2.t2flow?version=2","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3684/versions/3.html","Matrix Population Model construction and analysis v20","2013-08-1308:31:07","2014-07-0412:57:14","http://www.myexperiment.org/workflows/3684/download/Matrix_Population_Model_construction_and_analysis_v20-v3.t2flow?version=3","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3686/versions/1.html","Matrix Population Model analysis v12","2013-08-1309:18:08","2014-07-0912:32:27","http://www.myexperiment.org/workflows/3686/download/Matrix_Population_Model_analysis_v12-v1.t2flow?version=1","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3686/versions/2.html","Matrix Population Model analysis v12","2013-08-1309:18:08","2014-07-0912:32:27","http://www.myexperiment.org/workflows/3686/download/Matrix_Population_Model_analysis_v12-v2.t2flow?version=2","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3687/versions/1.html","Integral Projection Model for Demographic Modelling v34","2013-08-1309:37:22","","http://www.myexperiment.org/workflows/3687/download/Integral_Projection_Model_for_Demographic_Modelling_v34-v1.t2flow?version=1","/users/20384","Maria Paula Balcazar-Vargas","taverna 2","/users/20384, /users/20379, /users/20423,","Maria Paula Balcazar-Vargas, Jon Giddy, Gerard Oostermeijer,",,0, 0, ,
"http://www.myexperiment.org/workflows/3691/versions/1.html","Optimization of retention time prediction","2013-08-1316:39:50","2013-09-0407:20:45","http://www.myexperiment.org/workflows/3691/download/Optimization_of_retention_time_prediction-v1.t2flow?version=1","/users/8596","Sonja Holl","taverna 2","/users/8596, /users/17146, /users/23068,","Sonja Holl, Yassene, Magnus Palmblad,","The workflow uses RTCalc from the TPP toolbox to perform two different retention time predictions. The third branch uses a linear retention time predictor (Palmblad et al., 2002). The workflow has a flag that switches on a specific branch.",-1, 0, ,
"http://www.myexperiment.org/workflows/3693/versions/1.html","X!Tandem and PeptideProphet on the Grid","2013-08-1317:12:48","2013-09-0407:21:10","http://www.myexperiment.org/workflows/3693/download/X_Tandem_and_PeptideProphet_on_the_Grid-v1.t2flow?version=1","/users/8596","Sonja Holl","taverna 2","/users/8596, /users/17146, /users/23068,","Sonja Holl, Yassene, Magnus Palmblad,","The workflow performs the execution of X!Tandem and PeptideProphet from the TPP toolbox on the Grid. The execution is performed by the UNICORE Plugin for Taverna. mzXMLDecomposer/Composer is used to run the execution of X!Tandem in parallel. extract_values extract relevant information from thetandem.interact.pep.xml File. The file can then remain on the remote storage.",0, 0, ,
"http://www.myexperiment.org/workflows/3694/versions/1.html","Biomarker Identification via RFE on the Grid","2013-08-1317:18:58","2013-09-2408:17:01","http://www.myexperiment.org/workflows/3694/download/Biomarker_Identification_via_RFE_on_the_Grid-v1.t2flow?version=1","/users/8596","Sonja Holl","taverna 2","/users/8596,","Sonja Holl,","The first two components split the original data set into several sub-sampling sets. The RFE component performs the machine learning approach by executing several instances of a SVM, each of which consuming one sub-sample data set. The execution of the SVM takes place in a distributed computing environment. The calc_objFunc component calculates the F-measure of the ranked gene list compared to a 'gold standard'.",-1, 0, ,
"http://www.myexperiment.org/workflows/3694/versions/2.html","Biomarker Identification via RFE on the Grid","2013-08-1317:18:58","2013-09-2408:17:01","http://www.myexperiment.org/workflows/3694/download/Biomarker_Identification_via_RFE_on_the_Grid-v2.t2flow?version=2","/users/8596","Sonja Holl","taverna 2","/users/8596,","Sonja Holl,","The first two components split the original data set into several sub-sampling sets. The RFE component performs the machine learning approach by executing several instances of a SVM, each of which consuming one sub-sample data set. The execution of the SVM takes place in a distributed computing environment, using the UNICORE-Taverna Plugin. The calc_objFunc component calculates the F-measure of the ranked gene list compared to a 'gold standard'.",-1, 0, ,
"http://www.myexperiment.org/workflows/3695/versions/1.html","Biomarker Identification via EFS on the Grid","2013-08-1317:23:30","2013-09-2408:18:53","http://www.myexperiment.org/workflows/3695/download/Biomarker_Identification_via_EFS_on_the_Grid-v1.t2flow?version=1","/users/8596","Sonja Holl","taverna 2","/users/8596,","Sonja Holl,","The workflow splits the data set into several sub-sampling sets, which are then used as input forEnsemble Feature Selection (support vector machine) . The objective function is calculated by taking a 'gold standard' into account. The execution of the EFS is performed on the Grid by using the Taverna UNICORE Plugin.",-1, 0, ,
"http://www.myexperiment.org/workflows/3695/versions/2.html","Biomarker Identification via EFS on the Grid","2013-08-1317:23:30","2013-09-2408:18:53","http://www.myexperiment.org/workflows/3695/download/Biomarker_Identification_via_EFS_on_the_Grid-v2.t2flow?version=2","/users/8596","Sonja Holl","taverna 2","/users/8596,","Sonja Holl,","The first two components split the original data set into several sub-sampling sets. The EFS component performs the machine learning approach by executing several instances of a SVM, each of which consuming one sub-sample data set. Another level of SVM execution is added by taking bootstapping into account. The execution of all SVMs takes place in a distributed computing environment using the UNICORE-Taverna plugin.  The calc_objFunc component calculates the F-measure of the ranked gene list compared to a 'gold standard'",-1, 0, ,
"http://www.myexperiment.org/workflows/3697/versions/1.html","Imagemagick convert - tiff2tiff - compression","2013-08-1511:22:24","","http://www.myexperiment.org/workflows/3697/download/Imagemagick_convert_-_tiff2tiff_-_compression-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Converts tiff to tiff using imagemagick convert with the provided compression",0, 0, ,
"http://www.myexperiment.org/workflows/3699/versions/1.html","Generate Spectral Library","2013-08-1613:47:47","","http://www.myexperiment.org/workflows/3699/download/Generate_Spectral_Library_-v1.t2flow?version=1","/users/17146","Yassene","taverna 2","/users/17146, /users/23068,","Yassene, Magnus Palmblad,",,0, 0, ,
"http://www.myexperiment.org/workflows/3704/versions/1.html","SCAPE Assess Metrics","2013-08-2212:49:54","2013-08-2212:53:21","http://www.myexperiment.org/workflows/3704/download/SCAPE_Assess_Metrics-v1.t2flow?version=1","/users/9056","Donal Fellows","taverna 2","","","Assesses whether a set of metrics satisfy some provided Quality Level Definition (QLD).The QLD is given as a Schematron schema, and is evaluated by the Java tool library Jing.Jing ( <a href=http://www.thaiopensource.com/relaxng/jing.html rel=nofollow>http://www.thaiopensource.com/relaxng/jing.html</a> ) is assumed to be installed in the current directory.",0, 0, ,
"http://www.myexperiment.org/workflows/3706/versions/1.html","EBI NCBI BLAST filter e-value and length","2013-08-2310:24:02","2014-02-0614:44:58","http://www.myexperiment.org/workflows/3706/download/EBI_NCBI_BLAST_filter_e-value_and_length-v1.t2flow?version=1","/users/8596","Sonja Holl","taverna 2","/users/8596,","Sonja Holl,","The workflow queries the NCBI BLAST web service and extracts the e-values and length of the results. One of the sub-workflows filters the length first and afterwards the e-value and the other sub-workflow filters first the e-value and then the length. As the result may be different, this workflow was used for optimization purposes to find the sub-workflow performing best.",-1, 0, ,
"http://www.myexperiment.org/workflows/3722/versions/1.html","Get concept suggestions from term","2013-08-3114:46:07","","http://www.myexperiment.org/workflows/3722/download/Get_concept_suggestions_from_term-v1.t2flow?version=1","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","This workflow suggests concept ids that match the query term. The user can run this workflowwith any term of interest as for example human, htt, Transcription etc, and will get suggestions forconcept ids together with descriptions. Then can choose the concept id that matches the best to her/his needs and use it to the rest of the CPA workflows.",0, 0, ,
"http://www.myexperiment.org/workflows/3725/versions/1.html","Bioclim workflow","2013-09-0213:44:59","2015-04-0420:57:28","http://www.myexperiment.org/workflows/3725/download/Bioclim_workflow-v1.t2flow?version=1","/users/20358","Renato De Giovanni","taverna 2","/users/20358,","Renato De Giovanni,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service using the Bioclim algorithm. Environmental layers and mask are selected during the workflow. Points are filtered so that only environmentally unique points are used to create the model. For more information about the input file format, please look at the documentation for the corresponding parameter. If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed.",0, 0, ,
"http://www.myexperiment.org/workflows/3725/versions/2.html","Bioclim workflow","2013-09-0213:44:59","2015-04-0420:57:28","http://www.myexperiment.org/workflows/3725/download/Bioclim_workflow-v2.t2flow?version=2","/users/20358","Renato De Giovanni","taverna 2","/users/20358,","Renato De Giovanni,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service using the Bioclim algorithm. Environmental layers and mask are selected during the workflow. Points are filtered so that only environmentally unique points are used to create the model. You can use this workflow to either filter a set of species occurrence points excluding redundant points with the same environmental conditions (you can get the result in the output selected_csv_points) or to know the environmental ranges for each variable considering all input points. In the later case, you can inspect the model_xml to find this information in the Maximum and MInimum attributes of the Bioclim element. Values are separated by a space in the same order of the layers. Please note that there are no model tests or projections in this workflow. For more information about the input file format, please look at the documentation for the corresponding parameter. If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed.",0, 0, ,
"http://www.myexperiment.org/workflows/3725/versions/3.html","Bioclim workflow","2013-09-0213:44:59","2015-04-0420:57:28","http://www.myexperiment.org/workflows/3725/download/Bioclim_workflow-v3.t2flow?version=3","/users/20358","Renato De Giovanni","taverna 2","/users/20358,","Renato De Giovanni,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service using the Bioclim algorithm. Environmental layers and mask are selected during the workflow. Points are filtered so that only environmentally unique points are used to create the model. You can use this workflow to either filter a set of species occurrence points excluding redundant points with the same environmental conditions (you can get the result in the output selected_csv_points) or to know the environmental ranges for each variable considering all input points. In the later case, you can inspect the model_xml to find this information in the Maximum and MInimum attributes of the Bioclim element. Values are separated by a space in the same order of the layers. Please note that there are no model tests or projections in this workflow. For more information about the input file format, please look at the documentation for the corresponding parameter. If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed.",0, 0, ,
"http://www.myexperiment.org/workflows/3725/versions/4.html","Bioclim workflow","2013-09-0213:44:59","2015-04-0420:57:28","http://www.myexperiment.org/workflows/3725/download/Bioclim_workflow-v4.t2flow?version=4","/users/20358","Renato De Giovanni","taverna 2","/users/20358,","Renato De Giovanni,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service using the Bioclim algorithm. Environmental layers and mask are selected during the workflow. Points are filtered so that only environmentally unique points are used to create the model. You can use this workflow to either filter a set of species occurrence points excluding redundant points with the same environmental conditions (you can get the result in the output selected_csv_points) or to know the environmental ranges for each variable considering all input points. In the later case, you can inspect the model_xml to find this information in the Maximum and MInimum attributes of the Bioclim element. Values are separated by a space in the same order of the layers. Please note that there are no model tests or projections in this workflow. For more information about the input file format, please look at the documentation for the corresponding parameter. If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed.",0, 0, ,
"http://www.myexperiment.org/workflows/3725/versions/5.html","Bioclim workflow","2013-09-0213:44:59","2015-04-0420:57:28","http://www.myexperiment.org/workflows/3725/download/Bioclim_workflow-v5.t2flow?version=5","/users/20358","Renato De Giovanni","taverna 2","/users/20358,","Renato De Giovanni,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service using the Bioclim algorithm. Environmental layers and mask are selected during the workflow. Points are filtered so that only environmentally unique points are used to create the model. You can use this workflow to either filter a set of species occurrence points excluding redundant points with the same environmental conditions (you can get the result in the output selected_csv_points) or to know the environmental ranges for each variable considering all input points. In the later case, you can inspect the model_xml to find this information in the Maximum and MInimum attributes of the Bioclim element. Values are separated by a space in the same order of the layers. Please note that there are no model tests or projections in this workflow. For more information about the input file format, please look at the documentation for the corresponding parameter. If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed.",0, 0, ,
"http://www.myexperiment.org/workflows/3725/versions/6.html","Bioclim workflow","2013-09-0213:44:59","2015-04-0420:57:28","http://www.myexperiment.org/workflows/3725/download/Bioclim_workflow-v6.t2flow?version=6","/users/20358","Renato De Giovanni","taverna 2","/users/20358,","Renato De Giovanni,","This workflow takes as input a file containing species occurrence points to create a model with the openModeller Web Service using the Bioclim algorithm. Environmental layers and mask are selected during the workflow. Points are filtered so that only environmentally unique points are used to create the model. You can use this workflow to either filter a set of species occurrence points excluding redundant points with the same environmental conditions (you can get the result in the output selected_csv_points) or to know the environmental ranges for each variable considering all input points. In the later case, you can inspect the model_xml to find this information in the Maximum and MInimum attributes of the Bioclim element. Values are separated by a space in the same order of the layers. Please note that there are no model tests or projections in this workflow. For more information about the input file format, please look at the documentation for the corresponding parameter. If you use the default occurrence points you should know that Gammarus tigrinus is an aquatic species, so you need to choose marine environmental layers during the modelling procedure. Workflow requirements: When running on Taverna workbench, this workflow requires Internet connection and the Taverna interaction plugin installed.",0, 0, ,
"http://www.myexperiment.org/workflows/3726/versions/1.html","UnigeneID to KEGG Pathways","2013-09-0321:22:42","","http://www.myexperiment.org/workflows/3726/download/UnigeneID_to_KEGG_Pathways-v1.t2flow?version=1","/users/61510","Aleksandra Pawlik","taverna 2","/users/13, /users/30, /users/43,","Katy Wolstencroft, Alan Williams, Paul Fisher,","This workflow accepts a list of Unigene gene identifiers and returns descriptions of gene functions and a list of all pathways each gene is involved in (plus pathway image) from the KEGG database.This workflow replaces the earlier SOAP version with the new KEGG REST services",0, 0, ,
"http://www.myexperiment.org/workflows/3727/versions/1.html","Pathway to Pubmed","2013-09-0322:25:15","","http://www.myexperiment.org/workflows/3727/download/Pathway_to_Pubmed-v1.t2flow?version=1","/users/61510","Aleksandra Pawlik","taverna 2","/users/30, /users/43,","Alan Williams, Paul Fisher,","This workflow takes in a list of KEGG pathway descriptions and searches the PubMed database for corresponding articles. Any matches to the pathways are then retrieved (abstracts only). These abstracts are then returned to the user.",0, 0, ,
"http://www.myexperiment.org/workflows/3729/versions/1.html","v2 Retry-Example","2013-09-0322:37:51","","http://www.myexperiment.org/workflows/3729/download/v2_Retry-Example-v1.t2flow?version=1","/users/61510","Aleksandra Pawlik","taverna 2","/users/61510,","Aleksandra Pawlik,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3731/versions/1.html","Hello World","2013-09-0411:05:51","","http://www.myexperiment.org/workflows/3731/download/Hello_World-v1.t2flow?version=1","/users/20929","Raul Palma","taverna 2","/users/20929,","Raul Palma,","One of the simplest workflows possible, outputting the String Constant Hello world! <hr /> One of the simplest workflows possible. No workflow input ports, a single workflow output port greeting,  outputting Hello, world! as produced by the String Constant hello.",0, 0, ,
"http://www.myexperiment.org/workflows/3732/versions/1.html","Convert Taverna list of RExpr to R list - v2","2013-09-0415:37:15","2013-10-1415:41:25","http://www.myexperiment.org/workflows/3732/download/Convert_Taverna_list_of_RExpr_to_R_list_-_v2-v1.t2flow?version=1","/users/20379","Jon Giddy","taverna 2","/users/20379,","Jon Giddy,","This workflow accepts a Taverna list of arbitrary R expressions and returns a single R expression representing an R list containing the original expressions. This workflow relies on the current Taverna behaviour of an R expression being represented by a list of strings containing the deparsed expression. If this changes, this workflow will likely break. The fix would be to replace the first Merge with an RShell code to call deparse(). The first Merge converts each R expression (actually a list of strings) to a single string. This uses implicit iteration to do this for each R expression, so the input depth is 1 but the input port depth is 2. The second Merge creates a comma-separated list of the deparsed R expressions. The wrap_in_list component wraps the string with the R list() function. So now we have a single string s that can be turned into an R list using eval(parse(text=s)). But RShell already does that parsing for us, so we just need to ensure the string looks like an R expression by turning it into a list of strings. So wrap_in_list actually outputs a 1-element list containing the string.",0, 0, ,
"http://www.myexperiment.org/workflows/3732/versions/2.html","Convert Taverna list of RExpr to R list - v2","2013-09-0415:37:15","2013-10-1415:41:25","http://www.myexperiment.org/workflows/3732/download/Convert_Taverna_list_of_RExpr_to_R_list_-_v2-v2.t2flow?version=2","/users/20379","Jon Giddy","taverna 2","/users/20379,","Jon Giddy,","This workflow accepts a Taverna list of arbitrary R expressions and returns a single R expression representing an R list containing the original expressions. This workflow relies on the current Taverna behaviour of an R expression being represented by a list of strings containing the deparsed expression. If this changes, this workflow will likely break. The first BeanShell converts each R expression (actually a list of strings) to a single string. This uses implicit iteration to do this for each R expression, so input port depth is 2 but the BeanShell input depth is 1. The second Beanshell creates a comma-separated list of the deparsed R expressions and wraps the string with the R list() function. So now we have a single string s that can be turned into an R list using eval(parse(text=s)). But RShell already does that parsing for us, so we just need to ensure the string looks like an R expression by turning it into a list of strings. So we actually output a 1-element list containing the string. Version 1: initial implementationVersion 2: reduce number of BeanShells",0, 0, ,
"http://www.myexperiment.org/workflows/3733/versions/1.html","BioVeL workshop reduced full workflow","2013-09-0416:03:01","","http://www.myexperiment.org/workflows/3733/download/BioVeL_workshop_reduced_full_workflow-v1.t2flow?version=1","/users/61510","Aleksandra Pawlik","taverna 2","/users/13, /users/30,","Katy Wolstencroft, Alan Williams,","The workflow is a reduced version of the main workflow. It can be used to call web services to support biodiversity research. It fetches data from GBIF. The occurrences are then used to create a model using OpenModeller, test the model and to project the model. The projection of the model is currently a native projection i.e. it uses the same layers as those used to create the model. The services within the workflow will allow non-native projections",0, 0, ,
"http://www.myexperiment.org/workflows/3734/versions/1.html","Print R expression","2013-09-0510:03:29","2013-10-1615:56:16","http://www.myexperiment.org/workflows/3734/download/Print_R_expression-v1.t2flow?version=1","/users/20379","Jon Giddy","taverna 2","/users/20379,","Jon Giddy,","This is a very small nested workflow to convert an R expression to the same textual representation that you see displayed when using the R command line.",0, 0, ,
"http://www.myexperiment.org/workflows/3734/versions/2.html","Print R expression","2013-09-0510:03:29","2013-10-1615:56:16","http://www.myexperiment.org/workflows/3734/download/Print_R_expression-v2.t2flow?version=2","/users/20379","Jon Giddy","taverna 2","/users/20379,","Jon Giddy,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3734/versions/3.html","Print R expression","2013-09-0510:03:29","2013-10-1615:56:16","http://www.myexperiment.org/workflows/3734/download/Print_R_expression-v3.t2flow?version=3","/users/20379","Jon Giddy","taverna 2","/users/20379,","Jon Giddy,","This is a very small nested workflow to convert an R expression to the same textual representation that you see displayed when using the R command line.",0, 0, ,
"http://www.myexperiment.org/workflows/3743/versions/1.html","BioCyc:Pathway Scheme","2013-09-0613:24:35","","http://www.myexperiment.org/workflows/3743/download/BioCyc_Pathway_Scheme-v1.t2flow?version=1","/users/17633","Harish Dharuri","taverna 2","/users/17633,","Harish Dharuri,","The purpose of the workflow is to determine all the genes operating in BioCyc pathways that the input metabolite participates in. The overall idea is to generate a set of genes that potentially influence the levels of a metabolite due to the common pathways that they share.",0, 0, ,
"http://www.myexperiment.org/workflows/3744/versions/1.html","BioCyc:Reaction Scheme","2013-09-0613:26:45","","http://www.myexperiment.org/workflows/3744/download/BioCyc_Reaction_Scheme-v1.t2flow?version=1","/users/17633","Harish Dharuri","taverna 2","/users/17633,","Harish Dharuri,","The purpose of this workflow is to determine all the enzymes/genes that participate in a radius of 2 reaction steps around a given metabolite. Broadly, the scheme involves the following steps: <ol><li value=1>determine all the reactions that the given metabolite participates in</li><li value=2>determine all the compounds that participate in these reactions</li><li value=3>filter certain compounds like H2O, ATP etc to avoid non-specific connections</li><li value=4>determine all the reactions that the compounds passing through step 3 participate in</li><li value=5>determine the enzymes that drive the reactions from step 4</li><li value=6>determine genes corresponding to the enzymes in step 5</li><li value=7>store the entrez gene ids as a text file</li></ol>",0, 0, ,
"http://www.myexperiment.org/workflows/3748/versions/1.html","VOTable on the net maker for IMPEx","2013-09-1008:23:05","","http://www.myexperiment.org/workflows/3748/download/VOTable_on_the_net_maker_for_IMPEx-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723,","David PS,","This simple workflow is a way to create a simple votable that uses the standards from IMPEx and provides an URL for the created VOTable enabling re-use of it through the IMPEx services",0, 0, ,
"http://www.myexperiment.org/workflows/3749/versions/1.html","Interpolate values on planetary models provided under IMPEx","2013-09-1008:26:09","","http://www.myexperiment.org/workflows/3749/download/Interpolate_values_on_planetary_models_provided_under_IMPEx-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723,","David PS,","This is a simple workflow using one of the webservice provided by IMPEx.  It calculates the value of different variables, at the cordinates provided, for a particular planetary model.",0, 0, ,
"http://www.myexperiment.org/workflows/3750/versions/1.html","Interpolate values on planetary models provided under IMPEx for Spacecraft orbits.","2013-09-1008:28:11","2013-09-1016:46:31","http://www.myexperiment.org/workflows/3750/download/Interpolate_values_on_planetary_models_provided_under_IMPEx_for_Spacecraft_orbits.-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723,","David PS,","This is a simple workflow using one of the webservice provided by IMPEx.  It calculates the value of different variables, at the cordinates that a spacecraft pass through for the time range provided, for a particular planetary model.The orbital values of the spacecraft are obtained by AMDA.",0, 0, ,
"http://www.myexperiment.org/workflows/3750/versions/2.html","Interpolate values on planetary models provided under IMPEx for Spacecraft orbits.","2013-09-1008:28:11","2013-09-1016:46:31","http://www.myexperiment.org/workflows/3750/download/Interpolate_values_on_planetary_models_provided_under_IMPEx_for_Spacecraft_orbits.-v2.t2flow?version=2","/users/14723","David PS","taverna 2","/users/14723,","David PS,","This is a simple workflow using one of the webservice provided by IMPEx.  It calculates the value of different variables, at the cordinates that a spacecraft pass through for the time range provided, for a particular planetary model.The orbital values of the spacecraft are obtained by AMDA.",0, 0, ,
"http://www.myexperiment.org/workflows/3751/versions/1.html","Particle trajectories in the planetary models provided under IMPEx","2013-09-1008:29:58","","http://www.myexperiment.org/workflows/3751/download/Particle_trajectories_in_the_planetary_models_provided_under_IMPEx-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723,","David PS,","This is a simple workflow using one of the webservice provided by IMPEx.  It calculates the particle trajectories for the defined particle (initial position, velocity, mass and charge) for a particular planetary model.",0, 0, ,
"http://www.myexperiment.org/workflows/3752/versions/1.html","Vector field lines in the planetary models provided under IMPEx","2013-09-1008:30:55","","http://www.myexperiment.org/workflows/3752/download/Vector_field_lines_in_the_planetary_models_provided_under_IMPEx-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723,","David PS,","This is a simple workflow using one of the webservice provided by IMPEx.  It calculates the field lines for the vector field requested for the starting points provided for a particular planetary model.",0, 0, ,
"http://www.myexperiment.org/workflows/3753/versions/1.html","Sphere lan-lot random points","2013-09-1008:32:31","","http://www.myexperiment.org/workflows/3753/download/Sphere_lan-lot_random_points-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723,","David PS,","It gest n lat-lon coordinates pairs as comma separated values.It uses a a random generator from  <a href=http://www.random.org rel=nofollow>http://www.random.org</a>",0, 0, ,
"http://www.myexperiment.org/workflows/3754/versions/1.html","Interpolate n-randon points in a sphere on a planetary models provided under IMPEx","2013-09-1008:40:22","","http://www.myexperiment.org/workflows/3754/download/Interpolate_n-randon_points_in_a_sphere_on_a_planetary_models_provided_under_IMPEx-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723,","David PS,","This is a workflow that uses 2 different services from IMPEx to calculate different variables at a certain radius for a particular planetary model.",0, 0, ,
"http://www.myexperiment.org/workflows/3755/versions/1.html","Get Particle trajectories from starting points in a sphere on a planetary models provided under IMPEx","2013-09-1012:42:31","","http://www.myexperiment.org/workflows/3755/download/Get_Particle_trajectories_from_starting_points_in_a_sphere_on_a_planetary_models_provided_under_IMPEx-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723,","David PS,","This is a workflow that uses 2 different services from IMPEx to calculate different variables at a certain radius for a particular planetary model.",0, 0, ,
"http://www.myexperiment.org/workflows/3756/versions/1.html","Refresh SPI after plugin installation","2013-09-1014:06:30","","http://www.myexperiment.org/workflows/3756/download/Refresh_SPI_after_plugin_installation-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","This workflow hacks into Taverna's plugin system to force update the net.sf.taverna.t2.workbench.views.results.saveactions.SaveAllResultsSPIRegistry SPI, which means it is possible to install/update the Taverna PROV plugin without restarting. This is needed to enable live update of this plugin, because there is a bug in Taverna 2.4 and below where the SPI registries are not updated correctly after installation of a plugin.",0, 0, ,
"http://www.myexperiment.org/workflows/3758/versions/1.html","Plane cut on planetary models provided under IMPEx","2013-09-1112:32:58","","http://www.myexperiment.org/workflows/3758/download/Plane_cut_on_planetary_models_provided_under_IMPEx-v1.t2flow?version=1","/users/14723","David PS","taverna 2","/users/14723,","David PS,","This is a simple workflow using one of the webservice provided by IMPEx.  It calculates the value of a plane for different variables for a particular planetary model.",0, 0, ,
"http://www.myexperiment.org/workflows/3759/versions/1.html","PDL workflow for a VAMDC collision service","2013-09-1118:01:41","2013-10-3110:07:47","http://www.myexperiment.org/workflows/3759/download/PDL_workflow_for_a_VAMDC_collision_service-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","Example to show how to use a PDL description file implementation of a VAMDC collision service. It calls the service, waits until status is finished (a complete implementation should handle also errors), it downloads the resulting jar, untar the jar and read the files in the jar.",0, 0, ,
"http://www.myexperiment.org/workflows/3759/versions/2.html","PDL workflow for a VAMDC collision service","2013-09-1118:01:41","2013-10-3110:07:47","http://www.myexperiment.org/workflows/3759/download/PDL_workflow_for_a_VAMDC_collision_service-v2.t2flow?version=2","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","Example to show how to use a PDL description file implementation of a VAMDC collision asynchronous service",0, 0, ,
"http://www.myexperiment.org/workflows/3760/versions/1.html","Using PDL description and PDL smart description for rest services","2013-09-1118:38:55","","http://www.myexperiment.org/workflows/3760/download/Using_PDL_description_and_PDL_smart_description_for_rest_services-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","This workflow call the same service using two different PDL descriptions.In the first case, the PDL_service artifact is set up to work with a rest service.In the second case, the PDL_service artifact is set up to work with a rest service but a votable is expected and processed according to the PDL description. It allows providing columns from the votable as output ports.",0, 0, ,
"http://www.myexperiment.org/workflows/3788/versions/1.html","Example Workflow","2013-09-1314:48:35","","http://www.myexperiment.org/workflows/3788/download/Example_Workflow-v1.t2flow?version=1","/users/9056","Donal Fellows","taverna 2","","","This is an example workflow",-1, 0, ,
"http://www.myexperiment.org/workflows/3812/versions/1.html","String upload","2013-09-1613:51:13","2014-02-0313:54:26","http://www.myexperiment.org/workflows/3812/download/String_upload-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","The component uploads the string within the InputBody tothe File_name within the fixed WebDAV",-1, 0, ,
"http://www.myexperiment.org/workflows/3814/versions/1.html","SCAPE Workshop demo workflow","2013-09-1615:15:34","2013-09-1912:45:46","","/users/9056","Donal Fellows","taverna 2","/users/9056, /users/4707,","Donal Fellows, Sven,",,
"http://www.myexperiment.org/workflows/3814/versions/2.html","SCAPE Workshop demo workflow","2013-09-1615:15:34","2013-09-1912:45:46","","/users/9056","Donal Fellows","taverna 2","/users/9056, /users/4707,","Donal Fellows, Sven,","This is an updated version of the SCAPE workshow demonstrator workflow, based on the workflow defined by Sven Schlarb at  <a href=http://wiki.opf-labs.org/display/SP/Workflows+Exercise+Worksheet rel=nofollow>http://wiki.opf-labs.org/display/SP/Workflows+Exercise+Worksheet</a>",
"http://www.myexperiment.org/workflows/3821/versions/1.html","In2Out","2013-09-1914:05:54","","http://www.myexperiment.org/workflows/3821/download/In2Out-v1.t2flow?version=1","/users/61138","Eelke van der Horst","taverna 2","","",,-1, 0, ,
"http://www.myexperiment.org/workflows/3826/versions/1.html","Use of rest services described with PDL","2013-09-2008:08:02","","http://www.myexperiment.org/workflows/3826/download/Use_of_rest_services_described_with_PDL-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","Workflow that exemplifies the use of PDL (parameter description language) descriptions for rest services.There are two cases.- the artifact provides as output the response from the service (rest config).- the web service provides a VOTable that is processed according to the PDL description. Some of the columns in the votable are provided as output in the artifacts (smartVOrest config).",0, 0, ,
"http://www.myexperiment.org/workflows/3827/versions/1.html","Example of interoperability validation on real time with PDL services","2013-09-2008:09:40","2013-10-3110:15:43","http://www.myexperiment.org/workflows/3827/download/Example_of_interoperability_validation_on_real_time_with_PDL_services-v1.t2flow?version=1","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","Workflow that exemplifies the use of PDL (parameter description language) descriptions for rest services.This workflow is using two types of PDL descriptions.- the artifact provides as output the response from the service (rest config).- the web service provides a VOTable that is processed according to the PDL description. Some of the columns in the votable are provided as output in the artifacts (smartVORest config).To check interoperability we have to validatate the connections between outputs and inputs of the artifacts.The tests for the connections between the smart pdl cone search services are passed because they have the same metadata.However, dec output is connected to ra input and ra output is connected to dec input for the last two artifacts in the workflow. As they have different metadata, the validation report shows warnings for these connections (a mismatch in the metadata).",0, 0, ,
"http://www.myexperiment.org/workflows/3827/versions/2.html","Example of interoperability validation on real time with PDL services","2013-09-2008:09:40","2013-10-3110:15:43","http://www.myexperiment.org/workflows/3827/download/Example_of_interoperability_validation_on_real_time_with_PDL_services-v2.t2flow?version=2","/users/22617","Julian Garrido","taverna 2","/users/22617,","Julian Garrido,","Workflow that exemplifies the use of PDL (parameter description language) descriptions for rest services.The web service provides a VOTable that is processed according to the PDL description. Some of the columns in the votable are provided as output in the artifacts (smartVORest config).To check interoperability we have to validatate the connections between outputs and inputs of the artifacts. In this case,  there is an error in the connections. dec output is connected to dec input but dec output is also connected to ra input. As they have different metadata, the validation report shows warnings for these connections (a mismatch in the metadata).",0, 0, ,
"http://www.myexperiment.org/workflows/3843/versions/1.html","Building a knowledge base for data mining algorithms","2013-10-0310:56:54","2017-06-0619:31:47","http://www.myexperiment.org/workflows/3843/download/Building_a_knowledge_base_for_data_mining_algorithms-v1.t2flow?version=1","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,","The main objective of this this workflow is to allow users data mining experts enrich a knowledge base that will be used by a recommender to assist non-expert users to apply mining techniques",-1, 0, ,
"http://www.myexperiment.org/workflows/3843/versions/2.html","Building a knowledge base for data mining algorithms","2013-10-0310:56:54","2017-06-0619:31:47","http://www.myexperiment.org/workflows/3843/download/Building_a_knowledge_base_for_data_mining_algorithms-v2.t2flow?version=2","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3843/versions/3.html","Building a knowledge base for data mining algorithms","2013-10-0310:56:54","2017-06-0619:31:47","http://www.myexperiment.org/workflows/3843/download/Building_a_knowledge_base_for_data_mining_algorithms-v3.t2flow?version=3","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3843/versions/4.html","Building a knowledge base for data mining algorithms","2013-10-0310:56:54","2017-06-0619:31:47","http://www.myexperiment.org/workflows/3843/download/Building_a_knowledge_base_for_data_mining_algorithms-v4.t2flow?version=4","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3843/versions/5.html","Building a knowledge base for data mining algorithms","2013-10-0310:56:54","2017-06-0619:31:47","http://www.myexperiment.org/workflows/3843/download/Building_a_knowledge_base_for_data_mining_algorithms-v5.t2flow?version=5","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3844/versions/1.html","Measuring data quality criteria in arff files","2013-10-0311:50:08","2014-11-1717:59:01","http://www.myexperiment.org/workflows/3844/download/Measuring_data_quality_criteria_in_arff_files-v1.t2flow?version=1","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,","This workflow measuring data quality criterias in arff files",-1, 0, ,
"http://www.myexperiment.org/workflows/3844/versions/2.html","Measuring data quality criteria in arff files","2013-10-0311:50:08","2014-11-1717:59:01","http://www.myexperiment.org/workflows/3844/download/Measuring_data_quality_criteria_in_arff_files-v2.t2flow?version=2","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3844/versions/3.html","Measuring data quality criteria in arff files","2013-10-0311:50:08","2014-11-1717:59:01","http://www.myexperiment.org/workflows/3844/download/Measuring_data_quality_criteria_in_arff_files-v3.t2flow?version=3","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3844/versions/4.html","Measuring data quality criteria in arff files","2013-10-0311:50:08","2014-11-1717:59:01","http://www.myexperiment.org/workflows/3844/download/Measuring_data_quality_criteria_in_arff_files-v4.t2flow?version=4","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3845/versions/1.html","Data Mining Algorithms","2013-10-0312:04:21","2014-11-1717:58:22","http://www.myexperiment.org/workflows/3845/download/Data_Mining_Algorithms-v1.t2flow?version=1","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,","This workflow allow the application of data mining algorithms.",-1, 0, ,
"http://www.myexperiment.org/workflows/3845/versions/2.html","Data Mining Algorithms","2013-10-0312:04:21","2014-11-1717:58:22","http://www.myexperiment.org/workflows/3845/download/Data_Mining_Algorithms-v2.t2flow?version=2","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3845/versions/3.html","Data Mining Algorithms","2013-10-0312:04:21","2014-11-1717:58:22","http://www.myexperiment.org/workflows/3845/download/Data_Mining_Algorithms-v3.t2flow?version=3","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3845/versions/4.html","Data Mining Algorithms","2013-10-0312:04:21","2014-11-1717:58:22","http://www.myexperiment.org/workflows/3845/download/Data_Mining_Algorithms-v4.t2flow?version=4","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3845/versions/5.html","Data Mining Algorithms","2013-10-0312:04:21","2014-11-1717:58:22","http://www.myexperiment.org/workflows/3845/download/Data_Mining_Algorithms-v5.t2flow?version=5","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3845/versions/6.html","Data Mining Algorithms","2013-10-0312:04:21","2014-11-1717:58:22","http://www.myexperiment.org/workflows/3845/download/Data_Mining_Algorithms-v6.t2flow?version=6","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3845/versions/7.html","Data Mining Algorithms","2013-10-0312:04:21","2014-11-1717:58:22","http://www.myexperiment.org/workflows/3845/download/Data_Mining_Algorithms-v7.t2flow?version=7","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3846/versions/1.html","User friendly data mining","2013-10-0313:14:54","2017-06-1221:01:42","http://www.myexperiment.org/workflows/3846/download/User_friendly_data_mining-v1.t2flow?version=1","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,","This workflow pretend apply user friendly data mining in order to help non-expert users to find knowledge using a recommender system.",-1, 0, ,
"http://www.myexperiment.org/workflows/3846/versions/2.html","User friendly data mining","2013-10-0313:14:54","2017-06-1221:01:42","http://www.myexperiment.org/workflows/3846/download/User_friendly_data_mining-v2.t2flow?version=2","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3846/versions/3.html","User friendly data mining","2013-10-0313:14:54","2017-06-1221:01:42","http://www.myexperiment.org/workflows/3846/download/User_friendly_data_mining-v3.t2flow?version=3","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3846/versions/4.html","User friendly data mining","2013-10-0313:14:54","2017-06-1221:01:42","http://www.myexperiment.org/workflows/3846/download/User_friendly_data_mining-v4.t2flow?version=4","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3846/versions/5.html","User friendly data mining","2013-10-0313:14:54","2017-06-1221:01:42","http://www.myexperiment.org/workflows/3846/download/User_friendly_data_mining-v5.t2flow?version=5","/users/16696","respinosa","taverna 2","/users/16696,","respinosa,",,-1, 0, ,
"http://www.myexperiment.org/workflows/3848/versions/1.html","get promoter region + operate on genomic intervals for T2WEB","2013-10-0415:44:11","2013-11-0419:38:14","http://www.myexperiment.org/workflows/3848/download/get_promoter_region___operate_on_genomic_intervals_for_T2WEB-v1.t2flow?version=1","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","<span>This workflow computes a promoter region for each gene that we provide as input</span> <br /> carrying the genomic information. Then it computes the overlap between&nbsp; <br /> the two datasets that contain genomic information. <br /> Returns rows of file_1 which overlap with the second file. <br /> <span>Uses the R package GenomicRanges.</span> <br /> &nbsp;",0, 0, ,
"http://www.myexperiment.org/workflows/3848/versions/2.html","get promoter region + operate on genomic intervals for T2WEB","2013-10-0415:44:11","2013-11-0419:38:14","http://www.myexperiment.org/workflows/3848/download/get_promoter_region___operate_on_genomic_intervals_for_T2WEB-v2.t2flow?version=2","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","This workflow computes a promoter region for each gene that we provide as inputcarrying the genomic information. Then it computes the overlap betweenthe two datasets that contain genomic information plus some statistics.Returns rows of file_1 which overlap with the second file.A kolmogorov smirnov test is applied betweenthe list that overlaps and the one that does not.Uses the R package GenomicRanges.",0, 0, ,
"http://www.myexperiment.org/workflows/3848/versions/3.html","get promoter region + operate on genomic intervals for T2WEB","2013-10-0415:44:11","2013-11-0419:38:14","http://www.myexperiment.org/workflows/3848/download/get_promoter_region___operate_on_genomic_intervals_for_T2WEB-v3.t2flow?version=3","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","This workflow computes a promoter region for each gene that we provide as inputcarrying the genomic information. Then it computes the overlap betweenthe two datasets that contain genomic information plus some statistics.Returns rows of file_1 which overlap with the second file.A kolmogorov smirnov test is applied betweenthe list that overlaps and the one that does not.Uses the R package GenomicRanges.",0, 0, ,
"http://www.myexperiment.org/workflows/3848/versions/4.html","get promoter region + operate on genomic intervals for T2WEB","2013-10-0415:44:11","2013-11-0419:38:14","http://www.myexperiment.org/workflows/3848/download/get_promoter_region___operate_on_genomic_intervals_for_T2WEB-v4.t2flow?version=4","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","This workflow computes a promoter region for each gene that we provide as inputcarrying the genomic information. Then it computes the overlap betweenthe two datasets that contain genomic information plus some statistics.Returns rows of file_1 which overlap with the second file.A kolmogorov smirnov test is applied betweenthe list that overlaps and the one that does not.Uses the R package GenomicRanges.",0, 0, ,
"http://www.myexperiment.org/workflows/3848/versions/5.html","get promoter region + operate on genomic intervals for T2WEB","2013-10-0415:44:11","2013-11-0419:38:14","http://www.myexperiment.org/workflows/3848/download/get_promoter_region___operate_on_genomic_intervals_for_T2WEB-v5.t2flow?version=5","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","This workflow computes a promoter region for each gene that we provide as inputcarrying the genomic information. Then it computes the overlap betweenthe two datasets that contain genomic information plus some statistics.Returns rows of file_1 which overlap with the second file.A kolmogorov smirnov test is applied betweenthe list that overlaps and the one that does not.Uses the R package GenomicRanges.",0, 0, ,
"http://www.myexperiment.org/workflows/3850/versions/1.html","plotGenomic","2013-10-0715:02:26","","http://www.myexperiment.org/workflows/3850/download/plotGenomic-v1.t2flow?version=1","/users/61908","mdabr","taverna 2","/users/61908,","mdabr,",,0, 0, ,
"http://www.myexperiment.org/workflows/3851/versions/1.html","showDatasetsGenomic","2013-10-0715:37:03","","http://www.myexperiment.org/workflows/3851/download/showDatasetsGenomic-v1.t2flow?version=1","/users/61908","mdabr","taverna 2","/users/61908,","mdabr,","Shows all the datasets available in the Nencki Genomics Database ( <a href=http://www.nencki-genomics.org rel=nofollow>www.nencki-genomics.org</a> ).Click 'Use examples' to see all the datasets, separated into datasets of TFBS motifs, and all the remaining datasets (areas), the latter including data from Ensembl funcgen and (thus) Encode. Publication doi: 10.1093/database/bat069",0, 0, ,
"http://www.myexperiment.org/workflows/3852/versions/1.html","loadData","2013-10-0812:11:59","","http://www.myexperiment.org/workflows/3852/download/loadData-v1.t2flow?version=1","/users/61908","mdabr","taverna 2","/users/61908,","mdabr,","Permits loading data to Nencki Genomics Database.",0, 0, ,
"http://www.myexperiment.org/workflows/3855/versions/1.html","concatTwoStrings","2013-10-1015:06:05","2013-10-1015:06:25","http://www.myexperiment.org/workflows/3855/download/concatTwoStrings-v1.t2flow?version=1","/users/61908","mdabr","taverna 2","/users/61908,","mdabr,","for tests of TavernaServer",0, 0, ,
"http://www.myexperiment.org/workflows/3856/versions/1.html","BioVeL ESW STACK - ENM Statistical Workflow with raster stack computation","2013-10-1312:27:09","2016-06-2214:45:58","http://www.myexperiment.org/workflows/3856/download/BioVeL_ESW_STACK_-_ENM_Statistical_Workflow_with_raster_stack_computation-v1.t2flow?version=1","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,","The ENM Statistical Stack Workflow (ESW STACK) allows the computation of the extent, intensity and a cummulated potential species dictribution through computation of a average sum layer from the input raster layers using the R statistical environment (R Core Team 2013). The sum layer is computed from all input files. e.g from different distribution of species as a mean value from each corresponding raster cell values, coming from the Ecological Niche Modelling (ENM) Workflow ( <a href=http://www.myexperiment.org/workflows/3355 rel=nofollow>http://www.myexperiment.org/workflows/3355</a> ). The average sum layer computed from each corresponding raster cell values is stored together with all input layers in a multilayer stack file, regardless of the input files&rsquo; geographical extent and origin. If the files have a different geographical extent and/or origin, the raster-diff workflow automatically crop them to the same extent and resample the values using the &ldquo;nearest neighbour&rdquo; method, resulting in a perfect cell match between the two rasters. The resulting values in the average sum file depends of the value range of the input files and will be normalized to their value range. The values of the input layers and the average sum layer are classified into six positive classes. The predicted differences are presented for each species as a heat map, where cells with colors from green to red indicate an increase and from green to blue a decrease of predicted potential for a species. The workflow enables the computation of overall coverage, overall intensity and the difference in intensity or coverage between two raster layers. Overall coverage is computed as the percentage of raster cells with values &gt;0, and overall intensity is computed as the sum of all valued cells divided by the number of raster cells. Summary statistics for the raster layers are also provided: number of raster cells, mean intensity, median, CV, SD, Min value, Max value and number of cells outside the mask. The workflow contains the computation methods: - Computation of the average sum layer: <br /> sum_layer = sum(layerstack, na.rm=FALSE) <br /> average_sum_layer = (sum_layer /(nlayers(layerstack)*maxValue)) * maxValue. - Computation of the overall coverage and intensity <br /> overall_coverage = ((ncell(x)-cellStats(x, &#39;countNA&#39;)-count(x,0))/ncell(x))*100 <br /> overall_intensity = cellStats(x, sum)/(ncell(x)-cellStats(x, &#39;countNA&#39;)) - Computation of the covariance and pearson matrix: <br /> The covariance (the measure of how much two random variables change together) and pearson correlation coefficient (measure of the linear correlation (dependence) between two variables) matrix will be computed using&nbsp; standard functions in R: layerStats(layerstack,&quot;cov&quot;,na.rm=TRUE) and layerStats(layerstack,&quot;person&quot;,na.rm=TRUE) with excusion of noData values. - Used standard R functions: <br /> cellStats:  <a href=https://r-forge.r-project.org/scm/viewvc.php/pkg/raster/R/cellStats.R?view=markup&amp;root=raster rel=nofollow>https://r-forge.r-project.org/scm/viewvc.php/pkg/raster/R/cellStats.R?view=markup&amp;amp;root=raster</a> <br /> layerStats:  <a href=https://r-forge.r-project.org/scm/viewvc.php/pkg/raster/R/layerStats.R?view=markup&amp;root=raster rel=nofollow>https://r-forge.r-project.org/scm/viewvc.php/pkg/raster/R/layerStats.R?view=markup&amp;amp;root=raster</a> This workflow create a multilayer stack file as output and create PNG thumbnais and PNG overwiews from the input files and the average sum layer The PNG overview will be created with these values (corresponding to the Geoserver style) <br /> ERDASImagine file: <br /> breakpoints = c(0,1,25,50,75,100) <br /> GeoTIFF file <br /> breakpoints = c(0,2,63,127,190,254) <br /> colors =&nbsp; c(rgb(1.0,1.0,1.0), rgb(0.996,0.898,0.851), rgb(0.988,0.682,0.569), rgb(0.984,0.416,0.290), rgb(0.871,0.176,0.149), rgb(0.647,0.059,0.082)) Expected as input files are those raster images as a URL reference e.g. output files from openModeller created by an ENM workflow. <br /> *A file upload into the workflow is not possible, only a reference to the input file as URL* Supported formats are: <br /> - ERDASImagine (.img) files with a value range 0 - 100, noData value 101 <br /> - GeoTIFF (.tif) files with a value range 0- 254, noData Value 255 Input files with a different extent will be intersected to a common extent and resampled to each other using the &quot;nearest neighbor&quot; sampling method. For working with the ESW in a own localhost an R instance should by installed on a own machine ( <a href=http://cran.r-project.org/ rel=nofollow>http://cran.r-project.org/</a> ). For the computation the followed extensions must be installed: rgdal, raster and rserve. Rserve must be started before the computation. -------------------- This workflow has been created by the Biodiversity Virtual e-Laboratory (BioVeL  <a href=http://www.biovel.eu/ rel=nofollow>http://www.biovel.eu/</a> ) project. BioVeL is funded by the EU&rsquo;s Seventh Framework Program, grant no. 283359.",0, 0, ,
"http://www.myexperiment.org/workflows/3856/versions/2.html","BioVeL ESW STACK - ENM Statistical Workflow with raster stack computation","2013-10-1312:27:09","2016-06-2214:45:58","http://www.myexperiment.org/workflows/3856/download/BioVeL_ESW_STACK_-_ENM_Statistical_Workflow_with_raster_stack_computation-v2.t2flow?version=2","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3856/versions/3.html","BioVeL ESW STACK - ENM Statistical Workflow with raster stack computation","2013-10-1312:27:09","2016-06-2214:45:58","http://www.myexperiment.org/workflows/3856/download/BioVeL_ESW_STACK_-_ENM_Statistical_Workflow_with_raster_stack_computation-v3.t2flow?version=3","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3856/versions/4.html","BioVeL ESW STACK - ENM Statistical Workflow with raster stack computation","2013-10-1312:27:09","2016-06-2214:45:58","http://www.myexperiment.org/workflows/3856/download/BioVeL_ESW_STACK_-_ENM_Statistical_Workflow_with_raster_stack_computation-v4.t2flow?version=4","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3856/versions/5.html","BioVeL ESW STACK - ENM Statistical Workflow with raster stack computation","2013-10-1312:27:09","2016-06-2214:45:58","http://www.myexperiment.org/workflows/3856/download/BioVeL_ESW_STACK_-_ENM_Statistical_Workflow_with_raster_stack_computation-v5.t2flow?version=5","/users/20320","Robert Kulawik","taverna 2","/users/20320,","Robert Kulawik,",,0, 0, ,
"http://www.myexperiment.org/workflows/3857/versions/1.html","Hello World","2013-10-1511:23:36","","http://www.myexperiment.org/workflows/3857/download/Hello_World-v1.t2flow?version=1","/users/62066","Stian Soiland-Reyes","taverna 2","/users/62066,","Stian Soiland-Reyes,","One of the simplest workflows possible. No workflow input ports, a single workflow output port greeting,  outputting Hello, world! as produced by the String Constant hello.",0, 0, ,
"http://www.myexperiment.org/workflows/3858/versions/1.html","Hello Anyone","2013-10-1511:23:52","","http://www.myexperiment.org/workflows/3858/download/Hello_Anyone-v1.t2flow?version=1","/users/62066","Stian Soiland-Reyes","taverna 2","/users/62066,","Stian Soiland-Reyes,","An extension to helloworld.t2flow - this workflow takes a workflow input name which is combined with the string constant Hello,  using the local worker Concatenate two strings, and outputs the produced string to the workflow output greeting.",0, 0, ,
"http://www.myexperiment.org/workflows/3859/versions/1.html","Fetch today&#39;s xkcd comic","2013-10-1511:24:02","","http://www.myexperiment.org/workflows/3859/download/Fetch_today_s_xkcd_comic-v1.t2flow?version=1","/users/62066","Stian Soiland-Reyes","taverna 2","/users/62066,","Stian Soiland-Reyes,","Use the local services and some filtering operations to fetch the comic strip image from  <a href=http://xkcd.com/ rel=nofollow>http://xkcd.com/</a> Based on the FetchDailyDilbert workflow.",0, 0, ,
"http://www.myexperiment.org/workflows/3860/versions/1.html","Find compounds pharmacology and align against  target sequences","2013-10-1614:12:06","","http://www.myexperiment.org/workflows/3860/download/Find_compounds_pharmacology_and_align_against__target_sequences-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5, /users/13,","Stian Soiland-Reyes, Katy Wolstencroft,","Look up concept URI from freetext, e.g. aspirin, find compound pharmacology and their target info. For each target, blast+tree on its sequence - if any. Uses the Open PHACTs API  <a href=https://dev.openphacts.org/docs/alpha rel=nofollow>https://dev.openphacts.org/docs/alpha</a>  and the myExperiment workflow 3369 Blast_Align_and_Tree  <a href=http://www.myexperiment.org/workflows/3369 rel=nofollow>http://www.myexperiment.org/workflows/3369</a> . Notice that in tihs workflow, most concepts won't have compounds, and most compounds won't have targets, and most targets won't have a sequence - Open PHACT API wise this means this workflow would be propagating 404 Not Found errors. Until there is a Local worker to filter out Errors, the best way to view only the results is to manually select View results for each output port - after the workflow run has finished. Note that some of the ports have XML outputs.",0, 0, ,
"http://www.myexperiment.org/workflows/3862/versions/1.html","Find compounds pharmacology targets in Open PHACTS","2013-10-1614:18:06","2015-11-1911:44:45","http://www.myexperiment.org/workflows/3862/download/Find_compounds_pharmacology_targets_in_Open_PHACTS-v1.t2flow?version=1","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","Look up concept URI from freetext, e.g. aspirin, find compound pharmacology and their target info. For each target, blast+tree on its sequence - if any. Uses the Open PHACTs API  <a href=https://dev.openphacts.org/docs/alpha rel=nofollow>https://dev.openphacts.org/docs/alpha</a> . Notice that in tihs workflow, most concepts won't have compounds, and most compounds won't have targets, and most targets won't have a sequence - Open PHACT API wise this means this workflow would be propagating 404 Not Found errors. Until there is a Local worker to filter out Errors, the best way to view only the results is to manually select View results for each output port - after the workflow run has finished. Note that some of the ports have XML outputs.",0, 0, ,
"http://www.myexperiment.org/workflows/3862/versions/2.html","Find compounds pharmacology targets in Open PHACTS","2013-10-1614:18:06","2015-11-1911:44:45","http://www.myexperiment.org/workflows/3862/download/Find_compounds_pharmacology_targets_in_Open_PHACTS-v2.t2flow?version=2","/users/5","Stian Soiland-Reyes","taverna 2","/users/5,","Stian Soiland-Reyes,","Look up concept URI from freetext, e.g. aspirin, find compound pharmacology and their target info. For each target, blast+tree on its sequence - if any. Uses the Open PHACTS API  <a href=https://dev.openphacts.org/docs/1.5 rel=nofollow>https://dev.openphacts.org/docs/1.5</a> . Notice that in tihs workflow, most concepts won't have compounds, and most compounds won't have targets, and most targets won't have a sequence - Open PHACT API wise this means this workflow would be propagating 404 Not Found errors. Until there is a Local worker to filter out Errors, the best way to view only the results is to manually select View results for each output port - after the workflow run has finished. Note that some of the ports have XML outputs.",0, 0, ,
"http://www.myexperiment.org/workflows/3874/versions/1.html","echoer","2013-10-2513:45:09","2014-05-0711:22:08","http://www.myexperiment.org/workflows/3874/download/echoer-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","Initial version",-1, 0, ,
"http://www.myexperiment.org/workflows/3874/versions/2.html","echoer","2013-10-2513:45:09","2014-05-0711:22:08","http://www.myexperiment.org/workflows/3874/download/echoer-v2.t2flow?version=2","/users/30","Alan Williams","taverna 2","","","Small change",-1, 0, ,
"http://www.myexperiment.org/workflows/3874/versions/3.html","echoer","2013-10-2513:45:09","2014-05-0711:22:08","http://www.myexperiment.org/workflows/3874/download/echoer-v3.t2flow?version=3","/users/30","Alan Williams","taverna 2","","","Echo the input to the output",-1, 0, ,
"http://www.myexperiment.org/workflows/3874/versions/4.html","echoer","2013-10-2513:45:09","2014-05-0711:22:08","http://www.myexperiment.org/workflows/3874/download/echoer-v4.t2flow?version=4","/users/30","Alan Williams","taverna 2","","","This is a small change to check that version descriptionsare updated correctly",-1, 0, ,
"http://www.myexperiment.org/workflows/3874/versions/5.html","echoer","2013-10-2513:45:09","2014-05-0711:22:08","http://www.myexperiment.org/workflows/3874/download/echoer-v5.t2flow?version=5","/users/30","Alan Williams","taverna 2","","","Updated beanshell",-1, 0, ,
"http://www.myexperiment.org/workflows/3874/versions/6.html","echoer","2013-10-2513:45:09","2014-05-0711:22:08","http://www.myexperiment.org/workflows/3874/download/echoer-v6.t2flow?version=6","/users/30","Alan Williams","taverna 2","","","Renamed beanshell",-1, 0, ,
"http://www.myexperiment.org/workflows/3876/versions/1.html","MeasuresDocBuilder","2013-10-2815:34:44","2014-07-2308:52:57","http://www.myexperiment.org/workflows/3876/download/MeasuresDocBuilder-v1.t2flow?version=1","/users/9056","Donal Fellows","taverna 2","","","Initial version",0, 0, ,
"http://www.myexperiment.org/workflows/3876/versions/2.html","MeasuresDocBuilder","2013-10-2815:34:44","2014-07-2308:52:57","http://www.myexperiment.org/workflows/3876/download/MeasuresDocBuilder-v2.t2flow?version=2","/users/9056","Donal Fellows","taverna 2","","","Move the type list splitting into the component.",0, 0, ,
"http://www.myexperiment.org/workflows/3876/versions/3.html","MeasuresDocBuilder","2013-10-2815:34:44","2014-07-2308:52:57","http://www.myexperiment.org/workflows/3876/download/MeasuresDocBuilder-v3.t2flow?version=3","/users/9056","Donal Fellows","taverna 2","","","Creates a SCAPE measures document from individual atomic measures of a single subject entity.",0, 0, ,
"http://www.myexperiment.org/workflows/3876/versions/4.html","MeasuresDocBuilder","2013-10-2815:34:44","2014-07-2308:52:57","http://www.myexperiment.org/workflows/3876/download/MeasuresDocBuilder-v4.t2flow?version=4","/users/9056","Donal Fellows","taverna 2","","","Added namespace",0, 0, ,
"http://www.myexperiment.org/workflows/3877/versions/1.html","MeasuresDocCombiner","2013-10-2815:36:58","2014-07-2308:52:39","http://www.myexperiment.org/workflows/3877/download/MeasuresDocCombiner-v1.t2flow?version=1","/users/9056","Donal Fellows","taverna 2","","","Combined two SCAPE measures documents. These measures documents can be about the same or different subjects.",0, 0, ,
"http://www.myexperiment.org/workflows/3877/versions/2.html","MeasuresDocCombiner","2013-10-2815:36:58","2014-07-2308:52:39","http://www.myexperiment.org/workflows/3877/download/MeasuresDocCombiner-v2.t2flow?version=2","/users/9056","Donal Fellows","taverna 2","","","Added namespace",0, 0, ,
"http://www.myexperiment.org/workflows/3881/versions/1.html","nested_echo","2013-10-3017:29:50","2013-10-3017:43:14","http://www.myexperiment.org/workflows/3881/download/nested_echo-v1.t2flow?version=1","/users/30","Alan Williams","taverna 2","","","Initial version",-1, 0, ,
"http://www.myexperiment.org/workflows/3881/versions/2.html","nested_echo","2013-10-3017:29:50","2013-10-3017:43:14","http://www.myexperiment.org/workflows/3881/download/nested_echo-v2.t2flow?version=2","/users/30","Alan Williams","taverna 2","","","Just calls the echoer",-1, 0, ,
"http://www.myexperiment.org/workflows/3882/versions/1.html","Download data from array express + create expressionset object","2013-11-0419:18:54","","http://www.myexperiment.org/workflows/3882/download/Download_data_from_array_express___create_expressionset_object-v1.t2flow?version=1","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","This workflow uses the array express library to download data from the array express repositoryand creates two separate files. The gene expression and the phenotype files. The files are saved in the directory that the user has to specify in the input.NOTE: The library(ArrayExpress) is a prerequisite for this workflow",0, 0, ,
"http://www.myexperiment.org/workflows/3883/versions/1.html","Get differentially expressed genes for Array A (one brain region)","2013-11-0419:21:38","","http://www.myexperiment.org/workflows/3883/download/Get_differentially_expressed_genes_for_Array_A__one_brain_region_-v1.t2flow?version=1","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,",,0, 0, ,
"http://www.myexperiment.org/workflows/3884/versions/1.html","Get differentially expressed genes for Array B (one brain region)","2013-11-0419:23:42","","http://www.myexperiment.org/workflows/3884/download/Get_differentially_expressed_genes_for_Array_B__one_brain_region__-v1.t2flow?version=1","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,",,0, 0, ,
"http://www.myexperiment.org/workflows/3885/versions/1.html","Map genes to chromosomal location","2013-11-0419:25:50","","http://www.myexperiment.org/workflows/3885/download/Map_genes_to_chromosomal_location_-v1.t2flow?version=1","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","This workflow maps a gene list to the genome using the biomart service, and afterwardscomputes a promoter region for each gene. The user needs to define the promoterregion to be computed. The direction that a gene is transcribed is being taken into account in thecompute_promoter_region_with_strand component. The variable strand is responsible for that.NOTE: The library(biomaRt) is a prerequisite for this workflow",0, 0, ,
"http://www.myexperiment.org/workflows/3886/versions/1.html","get promoter region + operate on genomic intervals","2013-11-0419:28:07","","http://www.myexperiment.org/workflows/3886/download/get_promoter_region___operate_on_genomic_intervals-v1.t2flow?version=1","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","Finds the overlap between two datasets which contain genomic information (e.g. [gene id], chromosome name, gene start, gene end), plus some statistics. Returns rows of file_1 which overlap with the second file. A kolmogorov smirnov test is applied between the list that overlaps and the one that does not.NOTE: The library(GenomicRanges) is a prerequisite for this workflow",0, 0, ,
"http://www.myexperiment.org/workflows/3887/versions/1.html","Map genes to chromosomal location for T2WEB","2013-11-0419:39:38","","http://www.myexperiment.org/workflows/3887/download/Map_genes_to_chromosomal_location_for_T2WEB-v1.t2flow?version=1","/users/17730","Eleni","taverna 2","/users/17730,","Eleni,","This workflow maps a gene list on the genome using the biomart service.IMPORTANT NOTE: Keep in mind that for uploading files on t2web, you need to wait few minutes before executing the workflow. That's essential because the file needs first to be uploaded on the server.",0, 0, ,
"http://www.myexperiment.org/workflows/3892/versions/1.html","MatchboxHadoopAPI","2013-11-0510:21:56","","http://www.myexperiment.org/workflows/3892/download/MatchboxHadoopAPI-v1.t2flow?version=1","/users/17168","Roman","taverna 2","/users/17168,","Roman,","The workflow MatchboxHadoopApi.t2flow enables using of matchbox tool on Hadoop with Taverna. This workflow is based on Python scripts and Hadoop Streaming API included in <br /> &quot;pythonwf&quot; folder of pc-qa-matchbox project on github ( <a href=https://github.com/openplanets/scape/tree/master/pc-qa-matchbox/hadoop/pythonwf rel=nofollow>https://github.com/openplanets/scape/tree/master/pc-qa-matchbox/hadoop/pythonwf</a> ). For this workflow we assume that digital collection is located on HDFS and we have a list of input files in format &quot; <a rel=nofollow>hdfs:///user/training/collection/00000032.jp2&amp;quot</a> ; - one row per file entry. <br /> This list can be also generated in scripts. Changing python scripts user can customize the workflow and adjust it to the institutional needs. This workflow does not apply pt-mapred JAR and uses directly Hadoop Streaming API to avoid additional dependencies. The workflow has four input paramters but could be also used with default parameters. <br /> These parameters are: <br /> 1. homepath is a path to the scripts on a local machine e.g. &quot;/home/training/pythonwf&quot; <br /> 2. hdfspath is a path to the home directory on HDFS e.g. &quot;/user/training&quot; <br /> 3. collectionpath is a name of the folder that comprises digital collection on HDFS e.g. &quot;collection&quot; <br /> 4. summarypath is a name of the folder that comprises calculation results (list of possible duplicates) on HDFS e.g. &quot;compare&quot;. The list of possible duplicates can be found in file benchmark_result_list.csv in summary path. <br /> The main script in a workflow is a PythonMatchboxWF.sh that comprises all other scripts. Experienced user could execute each workflow step in a separate module in order to <br /> better manage script parameters. 1. The first step in the workflow is a preparation of input files list and is performed by CreateInputFiles.sh. Result of this step is a file with paths to collection files stored on HDFS <br /> in inputfiles folder. <br /> 2. The second step is a SIFT features extraction calculated using &quot;binary&quot; parameter in order to improve performance. Result of this step are feature files for each input file like <br /> &quot;00000031.jp2.SIFTComparison.descriptors.dat&quot;, &quot;00000031.jp2.SIFTComparison.keypoints.dat&quot; and &quot;00000031.jp2.SIFTComparison.feat.xml.gz&quot; stored in matchbox folder on HDFS. <br /> 3. The third step is a calculation of Bag of Words (visual dictionary) performed by CmdCalculateBoW.sh. Result is stored in bow folder in bow.xml file on HDFS. <br /> 4. Then we extract visual histograms using CmdExtractHistogram.sh for each input file. Result is stored in folder histogram on HDFS e.g. &quot;00000031.jp2.BOWHistogram.feat.xml.gz&quot;. <br /> 5. The final step is to perform actual comparison using CmdCompare.sh. Results are stored in compare folder on HDFS and comprise file benchmardk_result_list.csv that <br /> presents possible duplicates - one pair per row e.g. img1;img2;similarity between 0 (low) and 1 (high) &nbsp;",-1, 0, ,
"http://www.myexperiment.org/workflows/3894/versions/1.html","Imagemagick convert - tiff2tiff - compression","2013-11-0814:04:40","","http://www.myexperiment.org/workflows/3894/download/Imagemagick_convert_-_tiff2tiff_-_compression-v1.t2flow?version=1","/users/20122","Markus Plangg","taverna 2","/users/20122,","Markus Plangg,","Converts tiff to tiff using imagemagick convert with the provided compression",0, 0, ,
