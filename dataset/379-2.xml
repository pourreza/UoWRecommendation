<?xml version="1.0" encoding="UTF-8"?>
<s:scufl xmlns:s="http://org.embl.ebi.escience/xscufl/0.1alpha" version="0.2" log="0">
  <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:00d3cce3-2ad3-4c81-af98-a61f6f312cec" author="Marco Roos (workflow) and the AID team (services)" title="BioAID_ProteinDiscovery_HomoSapiens">This workflow extracts proteins and protein relations from from a subset of Medline that is about Homo Sapiens according to mesh annotation. Protein names (symbols of at least 3 characters) are validated against human UniProt symbols.

This workflow follows the following basic steps:
1. it retrieves documents relevant for the query string (documents tagged with mesh term 'Humans' only)
2. it discovers proteins in those documents, considered relevant to the query string (colocation in text mining terms)
3. it extract protein-protein relations (slightly stronger than colocation)

Protein discoveries are filtered on their presence in UniProt (human only)

Acknowledgements:
Synonyms and Uniprot services: Martijn Scheumie, BioSemantics Group, University of Rotterdam, The Netherlands (BioRange project)</s:workflowdescription>
  <s:processor name="false" boring="true">
    <s:stringconstant>false</s:stringconstant>
  </s:processor>
  <s:processor name="true" boring="true">
    <s:stringconstant>true</s:stringconstant>
  </s:processor>
  <s:processor name="Timestamp">
    <s:beanshell>
      <s:scriptvalue>/*
provides current date and time in various formats
no inputs
output:
now_RFC822
now_short
now_ISO8601
*/
import java.util.Date;
import java.text.DateFormat;
import java.text.SimpleDateFormat;

DateFormat dateFormatRFC822 = new SimpleDateFormat("EEE', 'dd' 'MMM' 'yyyy' 'HH':'mm':'ss' 'z");
DateFormat dateFormatISO8601 = new SimpleDateFormat("yyyy'-'MM'-'dd'T'HH':'mm':'ssZ");
DateFormat dateFormatShort = new SimpleDateFormat("yyMMdd_HHmmss");

Date date = new Date();

now_RFC822=dateFormatRFC822.format(date);
now_ISO8601=dateFormatISO8601.format(date);
now_short=dateFormatShort.format(date);</s:scriptvalue>
      <s:beanshellinputlist />
      <s:beanshelloutputlist>
        <s:beanshelloutput s:syntactictype="'text/plain'">now_RFC822</s:beanshelloutput>
        <s:beanshelloutput s:syntactictype="'text/plain'">now_short</s:beanshelloutput>
        <s:beanshelloutput s:syntactictype="'text/plain'">now_ISO8601</s:beanshelloutput>
      </s:beanshelloutputlist>
      <s:dependencies s:classloader="iteration" />
    </s:beanshell>
  </s:processor>
  <s:processor name="s06_AddProteinRelationToSemanticModel">
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:d58ca285-c662-4a60-a085-e7a58f65f65b" author="" title="AddProteinRelationToSemanticModel" />
        <s:link source="interaction_term" sink="interaction_instance" />
        <s:source name="protein_name1" />
        <s:source name="protein_name2" />
        <s:source name="interaction_term" />
        <s:source name="uniprot_id1" />
        <s:source name="uniprot_id2" />
        <s:source name="doc_instance" />
        <s:sink name="interaction_instance" />
      </s:scufl>
    </s:workflow>
    <s:iterationstrategy>
      <i:cross xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
        <i:dot>
          <i:iterator name="interaction_term" />
          <i:iterator name="protein_name1" />
          <i:iterator name="protein_name2" />
          <i:iterator name="uniprot_id1" />
          <i:iterator name="uniprot_id2" />
        </i:dot>
        <i:iterator name="doc_instance" />
      </i:cross>
    </s:iterationstrategy>
  </s:processor>
  <s:processor name="s07_AddScoreToSemanticModel">
    <s:description>Add RDF cf:
@prefix mybio: &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/BiologicalModel.owl#&gt; .
@prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .
@prefix pub: &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/Publication.owl#&gt; .
@prefix dsc: &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/DiscoveredEntities.owl#&gt; .
@prefix owl: &lt;http://www.w3.org/2002/07/owl#&gt; .
@prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt; .

&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/BiologicalDiscoveries.owl#ExampleInstance_DiscoveredEnzyme&gt; a &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/BiologicalDiscoveries.owl#DiscoveredEnzyme&gt; ;
	dsc:hasLikelihoodScore "1.0"^^&lt;http://www.w3.org/2001/XMLSchema#float&gt; .</s:description>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:f642ee66-0236-4222-820b-e45b4f33b923" author="Marco Roos (workfllow), Willem R. van Hage (services)" title="AddScoreToSemanticModel">Add Likelihood Score  to Semantic model with Sesame service cf example Score</s:workflowdescription>
        <s:source name="score" />
        <s:source name="protein_instance" />
      </s:scufl>
    </s:workflow>
    <s:iterationstrategy>
      <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
        <i:iterator name="score" />
        <i:iterator name="protein_instance" />
      </i:dot>
    </s:iterationstrategy>
  </s:processor>
  <s:processor name="s04_AddDocToSemanticModel">
    <s:description>Add Document to Semantic model with Sesame service cf example discovered document</s:description>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:c5beeaee-ff9a-4f34-af41-a33a0c19c141" author="Marco Roos (workflow), Willem R. van Hage (service)" title="AddDocumentToSemanticModel">Add Document to Semantic model with Sesame service cf example discovered document</s:workflowdescription>
        <s:processor name="InstantiateSemanticType">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: Instance of Type including label and comment
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/BioModel.owl#Enzyme&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/2000/01/rdf-schema#label&gt; "an enzyme"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/2000/01/rdf-schema#comment&gt; "e.g. the enzyme referred to by as 'EZH2'"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_BioModel&gt; &lt;http://purl.org/dc/elements/1.1/date&gt; "1999-05-31T13:20:00-05:00"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; .
*/

/*
input:
instance_ontology_url
instance_name
type_uri
label_string
comment_string
datetime

output:
NTriple_InstanceOf_statement
instance_uri
*/

instance_uri = instance_ontology_url + "#" + instance_name;

NTriple_InstanceOf_statement = "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;" + type_uri + "&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/2000/01/rdf-schema#label&gt; \"" + label_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/2000/01/rdf-schema#comment&gt; \"" + comment_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://purl.org/dc/elements/1.1#date&gt; \"" + datetime + "\"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_ontology_url</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_name</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">type_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">label_string</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">comment_string</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">datetime</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_InstanceOf_statement</s:beanshelloutput>
              <s:beanshelloutput s:syntactictype="'text/plain'">instance_uri</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="DefineSemanticRelation_has_output">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: RelationByURI
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_InteractionTerm&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#discovered_by&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_RelationDiscoveryProcess&gt; .
*/

/*
variables, 
input:
domain_instance_uri
relation_uri
range_instance_uri

output:
NTriple_Relation_statement
*/

NTriple_Relation_statement = "&lt;" + domain_instance_uri + "&gt; &lt;" + relation_uri + "&gt; &lt;" + range_instance_uri + "&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">domain_instance_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">relation_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">range_instance_uri</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_Relation_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="DefineSemanticRelation_discovered_by">
          <s:defaults>
            <s:default name="domain_instance_uri">domain_instance_uri</s:default>
            <s:default name="range_instance_uri">range_instance_uri</s:default>
          </s:defaults>
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: RelationByURI
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_InteractionTerm&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#discovered_by&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_RelationDiscoveryProcess&gt; .
*/

/*
variables, input:
domain_instance_uri
relation_uri
range_instance_uri

output:
NTriple_Relation_statement
*/

NTriple_Relation_statement = "&lt;" + domain_instance_uri + "&gt; &lt;" + relation_uri + "&gt; &lt;" + range_instance_uri + "&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">domain_instance_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">relation_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">range_instance_uri</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_Relation_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="ConcatDocComment">
          <s:local>org.embl.ebi.escience.scuflworkers.java.StringConcat</s:local>
        </s:processor>
        <s:processor name="NTriple_WorkflowRelation_stmnt">
          <s:defaults>
            <s:default name="domain_instance_uri">domain_instance_uri</s:default>
            <s:default name="range_instance_uri">range_instance_uri</s:default>
          </s:defaults>
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: RelationByURI
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_InteractionTerm&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#discovered_by&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_RelationDiscoveryProcess&gt; .
*/

/*
variables, input:
domain_instance_uri
relation_uri
range_instance_uri

output:
NTriple_Relation_statement
*/

NTriple_Relation_statement = "&lt;" + domain_instance_uri + "&gt; &lt;" + relation_uri + "&gt; &lt;" + range_instance_uri + "&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">domain_instance_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">relation_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">range_instance_uri</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_Relation_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="ConcatenateStringList">
          <s:defaults>
            <s:default name="delimiter" />
          </s:defaults>
          <s:beanshell>
            <s:scriptvalue>/* 
Concatenates List of Strings.
Use 'merge all data' on its input to concatenate different inputs.
*/
String s;
Iterator iter = (Iterator) stringlist.iterator();

if (iter.hasNext()) s = iter.next();

while (iter.hasNext()) {
	s = s + delimiter + iter.next();
}

output = s;</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="l('text/plain')">stringlist</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">delimiter</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">output</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
          <s:mergemode input="stringlist" mode="merge" />
        </s:processor>
        <s:processor name="Inst_080814_114703__Protoontology_AIDA_Instances__AIDA_LuceneBasedMedLineDocumentRetrievalProcess" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/AIDA_Instances.owl#AIDA_LuceneBasedMedLineDocumentRetrievalProcess</s:stringconstant>
        </s:processor>
        <s:processor name="ConcatDocLabel">
          <s:local>org.embl.ebi.escience.scuflworkers.java.StringConcat</s:local>
        </s:processor>
        <s:processor name="Inst_080814_114703__Protoontology_AIDA_Instances__AIDA_DocumentRetrievalService" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/AIDA_Instances.owl#AIDA_DocumentRetrievalService</s:stringconstant>
        </s:processor>
        <s:processor name="cls_080813_161743__Protoontology_Text__Document" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/Text.owl#Document</s:stringconstant>
        </s:processor>
        <s:processor name="DocLabel" boring="true">
          <s:stringconstant>Retrieved PubMed Document</s:stringconstant>
        </s:processor>
        <s:processor name="DocComment" boring="true">
          <s:stringconstant>Retrieved document, PubMed URL:</s:stringconstant>
        </s:processor>
        <s:processor name="ObjProp_080813_161743__Protoontology_Workflow__has_output" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/Workflow.owl#has_output</s:stringconstant>
        </s:processor>
        <s:processor name="Append" boring="true">
          <s:stringconstant>yes</s:stringconstant>
        </s:processor>
        <s:processor name="Inst_080814_114703__Protoontology_AIDA_Instances__BioAID_BioModellingSupportByProteinExtractionWorkflow" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/AIDA_Instances.owl#BioAID_BioModellingSupportByProteinExtractionWorkflow</s:stringconstant>
        </s:processor>
        <s:processor name="ObjProp_080813_161743__Protoontology_TextMining__discovered_by" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#discovered_by</s:stringconstant>
        </s:processor>
        <s:processor name="save_as">
          <s:arbitrarywsdl>
            <s:wsdl>http://aida.science.uva.nl:8888/axis/AidaFiler.jws?wsdl</s:wsdl>
            <s:operation>save_as</s:operation>
          </s:arbitrarywsdl>
        </s:processor>
        <s:link source="pubmed_id" sink="ConcatDocLabel:string2" />
        <s:link source="ConcatDocComment:output" sink="InstantiateSemanticType:comment_string" />
        <s:link source="ConcatDocLabel:output" sink="InstantiateSemanticType:label_string" />
        <s:link source="DocComment:value" sink="ConcatDocComment:string1" />
        <s:link source="DocLabel:value" sink="ConcatDocLabel:string1" />
        <s:link source="instance_ontology_url" sink="InstantiateSemanticType:instance_ontology_url" />
        <s:link source="pubmed_URL" sink="ConcatDocComment:string2" />
        <s:link source="ObjProp_080813_161743__Protoontology_TextMining__discovered_by:value" sink="DefineSemanticRelation_discovered_by:relation_uri" />
        <s:link source="ObjProp_080813_161743__Protoontology_Workflow__has_output:value" sink="NTriple_WorkflowRelation_stmnt:relation_uri" />
        <s:link source="pubmed_URL" sink="InstantiateSemanticType:instance_name" />
        <s:link source="rdf_output_doc_url" sink="save_as:filename" />
        <s:link source="Append:value" sink="save_as:append" />
        <s:link source="ConcatenateStringList:output" sink="save_as:content" />
        <s:link source="DefineSemanticRelation_discovered_by:NTriple_Relation_statement" sink="ConcatenateStringList:stringlist" />
        <s:link source="DefineSemanticRelation_has_output:NTriple_Relation_statement" sink="ConcatenateStringList:stringlist" />
        <s:link source="Inst_080814_114703__Protoontology_AIDA_Instances__AIDA_DocumentRetrievalService:value" sink="DefineSemanticRelation_has_output:domain_instance_uri" />
        <s:link source="Inst_080814_114703__Protoontology_AIDA_Instances__AIDA_LuceneBasedMedLineDocumentRetrievalProcess:value" sink="DefineSemanticRelation_discovered_by:range_instance_uri" />
        <s:link source="Inst_080814_114703__Protoontology_AIDA_Instances__BioAID_BioModellingSupportByProteinExtractionWorkflow:value" sink="NTriple_WorkflowRelation_stmnt:domain_instance_uri" />
        <s:link source="InstantiateSemanticType:instance_uri" sink="DefineSemanticRelation_discovered_by:domain_instance_uri" />
        <s:link source="InstantiateSemanticType:instance_uri" sink="DefineSemanticRelation_has_output:range_instance_uri" />
        <s:link source="NTriple_WorkflowRelation_stmnt:NTriple_Relation_statement" sink="ConcatenateStringList:stringlist" />
        <s:link source="ObjProp_080813_161743__Protoontology_Workflow__has_output:value" sink="DefineSemanticRelation_has_output:relation_uri" />
        <s:link source="cls_080813_161743__Protoontology_Text__Document:value" sink="InstantiateSemanticType:type_uri" />
        <s:link source="datetime" sink="InstantiateSemanticType:datetime" />
        <s:link source="InstantiateSemanticType:NTriple_InstanceOf_statement" sink="ConcatenateStringList:stringlist" />
        <s:link source="InstantiateSemanticType:instance_uri" sink="NTriple_WorkflowRelation_stmnt:range_instance_uri" />
        <s:link source="InstantiateSemanticType:instance_uri" sink="doc_instance_uri" />
        <s:link source="save_as:save_asReturn" sink="RDFdoc_ref" />
        <s:source name="pubmed_id" />
        <s:source name="pubmed_URL" />
        <s:source name="instance_ontology_url">
          <s:metadata>
            <s:description>e.g. http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/BioAID_Instances.owl</s:description>
          </s:metadata>
        </s:source>
        <s:source name="rdf_output_doc_url">
          <s:metadata>
            <s:description>e.g.
http://aida.science.uva.nl:9999/aida_public/rdf-output/tmp-rdf-out.rdf</s:description>
          </s:metadata>
        </s:source>
        <s:source name="datetime">
          <s:metadata>
            <s:description>conform
2008-08-14T14:19:00+02:00</s:description>
          </s:metadata>
        </s:source>
        <s:sink name="doc_instance_uri" />
        <s:sink name="RDFdoc_ref" />
      </s:scufl>
    </s:workflow>
    <s:iterationstrategy>
      <i:cross xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
        <i:dot>
          <i:iterator name="pubmed_id" />
          <i:iterator name="pubmed_URL" />
        </i:dot>
        <i:iterator name="query_instance" />
      </i:cross>
    </s:iterationstrategy>
  </s:processor>
  <s:processor name="s05_AddProteinToSemanticModel">
    <s:description>Add Protein to Semantic model with Sesame service cf example Discovered Proteins</s:description>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:fd7d0d06-932c-45cc-af4a-3d301b0a5a9f" author="Marco Roos (workflow), Willem R. van Hage (services)" title="AddProteinToSemanticModel">Add Protein to Semantic model with Sesame service cf example Discovered Proteins</s:workflowdescription>
        <s:processor name="DefineSemanticRelation_hasParticipant">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: RelationByURI
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_InteractionTerm&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#discovered_by&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_RelationDiscoveryProcess&gt; .
*/

/*
variables, 
input:
domain_instance_uri
relation_uri
range_instance_uri

output:
NTriple_Relation_statement
*/

NTriple_Relation_statement = "&lt;" + domain_instance_uri + "&gt; &lt;" + relation_uri + "&gt; &lt;" + range_instance_uri + "&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">domain_instance_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">relation_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">range_instance_uri</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_Relation_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="DefineSemanticRelation_discovered_by">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: RelationByURI
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_InteractionTerm&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#discovered_by&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_RelationDiscoveryProcess&gt; .
*/

/*
variables, 
input:
domain_instance_uri
relation_uri
range_instance_uri

output:
NTriple_Relation_statement
*/

NTriple_Relation_statement = "&lt;" + domain_instance_uri + "&gt; &lt;" + relation_uri + "&gt; &lt;" + range_instance_uri + "&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">domain_instance_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">relation_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">range_instance_uri</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_Relation_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="DefineSemanticRelation_references">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: RelationByURI
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_InteractionTerm&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#discovered_by&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_RelationDiscoveryProcess&gt; .
*/

/*
variables, 
input:
domain_instance_uri
relation_uri
range_instance_uri

output:
NTriple_Relation_statement
*/

NTriple_Relation_statement = "&lt;" + domain_instance_uri + "&gt; &lt;" + relation_uri + "&gt; &lt;" + range_instance_uri + "&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">domain_instance_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">relation_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">range_instance_uri</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_Relation_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="InstantiateSemanticType_Protein">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: Instance of Type including label and comment
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/BioModel.owl#Enzyme&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/2000/01/rdf-schema#label&gt; "an enzyme"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/2000/01/rdf-schema#comment&gt; "e.g. the enzyme referred to by as 'EZH2'"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_BioModel&gt; &lt;http://purl.org/dc/elements/1.1/date&gt; "1999-05-31T13:20:00-05:00"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; .
*/

/*
input:
instance_ontology_url
instance_name
type_uri
label_string
comment_string
datetime

output:
NTriple_InstanceOf_statement
instance_uri
*/

instance_uri = instance_ontology_url + "#" + instance_name;

NTriple_InstanceOf_statement = "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;" + type_uri + "&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/2000/01/rdf-schema#label&gt; \"" + label_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/2000/01/rdf-schema#comment&gt; \"" + comment_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://purl.org/dc/elements/1.1#date&gt; \"" + datetime + "\"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_ontology_url</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_name</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">type_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">label_string</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">comment_string</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">datetime</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_InstanceOf_statement</s:beanshelloutput>
              <s:beanshelloutput s:syntactictype="'text/plain'">instance_uri</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="InstantiateSemanticType_ProteinTerm">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: Instance of Type including label and comment
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/BioModel.owl#Enzyme&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/2000/01/rdf-schema#label&gt; "an enzyme"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/2000/01/rdf-schema#comment&gt; "e.g. the enzyme referred to by as 'EZH2'"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_BioModel&gt; &lt;http://purl.org/dc/elements/1.1/date&gt; "1999-05-31T13:20:00-05:00"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; .
*/

/*
input:
instance_ontology_url
instance_name
type_uri
label_string
comment_string
datetime

output:
NTriple_InstanceOf_statement
instance_uri
*/

instance_uri = instance_ontology_url + "#" + instance_name;

NTriple_InstanceOf_statement = "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;" + type_uri + "&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/2000/01/rdf-schema#label&gt; \"" + label_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/2000/01/rdf-schema#comment&gt; \"" + comment_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://purl.org/dc/elements/1.1#date&gt; \"" + datetime + "\"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_ontology_url</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_name</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">type_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">label_string</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">comment_string</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">datetime</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_InstanceOf_statement</s:beanshelloutput>
              <s:beanshelloutput s:syntactictype="'text/plain'">instance_uri</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="cls_080814_114703__Protoontology_BioModel__Protein" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/BioModel.owl#Protein</s:stringconstant>
        </s:processor>
        <s:processor name="cls_080814_114703__Protoontology_Text__ProteinTerm" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/Text.owl#ProteinTerm</s:stringconstant>
        </s:processor>
        <s:processor name="ProteinTermAnnotations">
          <s:beanshell>
            <s:scriptvalue>/*
input:
protein_name
uniprot_id

output:
protein_label
protein_comment
protein_term_label
protein_term_comment
*/

if(uniprot_id.length()&gt;0) {
	protein_label = protein_name + "_" + uniprot_id;
	protein_comment = "protein referred to by as " + protein_name + " and UniProt ID: " + uniprot_id;
	protein_term_comment = "protein term " + protein_name + ", identified as name of protein with UniProt ID: " + uniprot_id;
} else {
	protein_label = protein_name; // flawed assumption that proteins without a uniprot id can be identified by their name
	protein_comment = "protein referred to by as " + protein_name + " without a rat, mouse, or human UniProt ID";
	protein_term_comment = "protein term " + protein_name + " as name of protein without rat, mouse, or human UniProt identifier";
}

protein_term_label = protein_label;</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">protein_name</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">uniprot_id</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">protein_label</s:beanshelloutput>
              <s:beanshelloutput s:syntactictype="'text/plain'">protein_comment</s:beanshelloutput>
              <s:beanshelloutput s:syntactictype="'text/plain'">protein_term_label</s:beanshelloutput>
              <s:beanshelloutput s:syntactictype="'text/plain'">protein_term_comment</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="ObjProp_080814_114703__Protoontology_BioModel__hasParticipant" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/BioModel.owl#hasParticipant</s:stringconstant>
        </s:processor>
        <s:processor name="Inst_080814_114703__Protoontology_AIDA_Instances__AIDA_CombinedProteinTermExtractionProcess" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/AIDA_Instances.owl#AIDA_CombinedProteinTermExtractionProcess</s:stringconstant>
        </s:processor>
        <s:processor name="ObjProp_080814_114703__Protoontology_TextMining__discovered_by" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#discovered_by</s:stringconstant>
        </s:processor>
        <s:processor name="ObjProp_080814_114703__Protoontology_MappingBioTextMining__references" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/MappingBioTextMining.owl#references</s:stringconstant>
        </s:processor>
        <s:processor name="ConcatenateStringList">
          <s:defaults>
            <s:default name="delimiter" />
          </s:defaults>
          <s:beanshell>
            <s:scriptvalue>/* 
Concatenates List of Strings.
Use 'merge all data' on its input to concatenate different inputs.
*/
String s;
Iterator iter = (Iterator) stringlist.iterator();

if (iter.hasNext()) s = iter.next();

while (iter.hasNext()) {
	s = s + delimiter + iter.next();
}

output = s;</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="l('text/plain')">stringlist</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">delimiter</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">output</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
          <s:mergemode input="stringlist" mode="merge" />
        </s:processor>
        <s:processor name="Append" boring="true">
          <s:stringconstant>no</s:stringconstant>
        </s:processor>
        <s:processor name="save_as">
          <s:arbitrarywsdl>
            <s:wsdl>http://aida.science.uva.nl:9999/axis/AidaFiler.jws?wsdl</s:wsdl>
            <s:operation>save_as</s:operation>
          </s:arbitrarywsdl>
        </s:processor>
        <s:link source="model_instance_uri" sink="DefineSemanticRelation_hasParticipant:domain_instance_uri" />
        <s:link source="protein_name" sink="InstantiateSemanticType_ProteinTerm:instance_name" />
        <s:link source="uniprot_id" sink="InstantiateSemanticType_Protein:instance_name" />
        <s:link source="uniprot_id" sink="protein_instance" />
        <s:link source="InstantiateSemanticType_Protein:instance_uri" sink="DefineSemanticRelation_hasParticipant:range_instance_uri" />
        <s:link source="cls_080814_114703__Protoontology_BioModel__Protein:value" sink="InstantiateSemanticType_Protein:type_uri" />
        <s:link source="cls_080814_114703__Protoontology_Text__ProteinTerm:value" sink="InstantiateSemanticType_ProteinTerm:type_uri" />
        <s:link source="protein_name" sink="ProteinTermAnnotations:protein_name" />
        <s:link source="uniprot_id" sink="ProteinTermAnnotations:uniprot_id" />
        <s:link source="ProteinTermAnnotations:protein_comment" sink="InstantiateSemanticType_Protein:comment_string" />
        <s:link source="ProteinTermAnnotations:protein_label" sink="InstantiateSemanticType_Protein:label_string" />
        <s:link source="ProteinTermAnnotations:protein_term_comment" sink="InstantiateSemanticType_ProteinTerm:comment_string" />
        <s:link source="ProteinTermAnnotations:protein_term_label" sink="InstantiateSemanticType_ProteinTerm:label_string" />
        <s:link source="datetime" sink="InstantiateSemanticType_Protein:datetime" />
        <s:link source="datetime" sink="InstantiateSemanticType_ProteinTerm:datetime" />
        <s:link source="instance_ontology_url" sink="InstantiateSemanticType_Protein:instance_ontology_url" />
        <s:link source="instance_ontology_url" sink="InstantiateSemanticType_ProteinTerm:instance_ontology_url" />
        <s:link source="Append:value" sink="save_as:append" />
        <s:link source="ConcatenateStringList:output" sink="save_as:content" />
        <s:link source="DefineSemanticRelation_discovered_by:NTriple_Relation_statement" sink="ConcatenateStringList:stringlist" />
        <s:link source="DefineSemanticRelation_hasParticipant:NTriple_Relation_statement" sink="ConcatenateStringList:stringlist" />
        <s:link source="DefineSemanticRelation_references:NTriple_Relation_statement" sink="ConcatenateStringList:stringlist" />
        <s:link source="Inst_080814_114703__Protoontology_AIDA_Instances__AIDA_CombinedProteinTermExtractionProcess:value" sink="DefineSemanticRelation_discovered_by:range_instance_uri" />
        <s:link source="InstantiateSemanticType_Protein:NTriple_InstanceOf_statement" sink="ConcatenateStringList:stringlist" />
        <s:link source="InstantiateSemanticType_Protein:instance_uri" sink="DefineSemanticRelation_references:range_instance_uri" />
        <s:link source="InstantiateSemanticType_ProteinTerm:NTriple_InstanceOf_statement" sink="ConcatenateStringList:stringlist" />
        <s:link source="InstantiateSemanticType_ProteinTerm:instance_uri" sink="DefineSemanticRelation_discovered_by:domain_instance_uri" />
        <s:link source="InstantiateSemanticType_ProteinTerm:instance_uri" sink="DefineSemanticRelation_references:domain_instance_uri" />
        <s:link source="ObjProp_080814_114703__Protoontology_BioModel__hasParticipant:value" sink="DefineSemanticRelation_hasParticipant:relation_uri" />
        <s:link source="ObjProp_080814_114703__Protoontology_MappingBioTextMining__references:value" sink="DefineSemanticRelation_references:relation_uri" />
        <s:link source="ObjProp_080814_114703__Protoontology_TextMining__discovered_by:value" sink="DefineSemanticRelation_discovered_by:relation_uri" />
        <s:link source="tmp_rdf_output_fileref" sink="save_as:filename" />
        <s:link source="save_as:save_asReturn" sink="output_doc_ref" />
        <s:source name="protein_name">
          <s:metadata>
            <s:description>E.g.
EZH2</s:description>
          </s:metadata>
        </s:source>
        <s:source name="uniprot_id">
          <s:metadata>
            <s:description>e.g.
Q15910</s:description>
          </s:metadata>
        </s:source>
        <s:source name="doc_instance_uri" />
        <s:source name="entrez_pubmed_URL">
          <s:metadata>
            <s:description>http://www.ncbi.nlm.nih.gov/pubmed/</s:description>
          </s:metadata>
        </s:source>
        <s:source name="expasy_URL">
          <s:metadata>
            <s:description>http://www.expasy.ch/</s:description>
          </s:metadata>
        </s:source>
        <s:source name="iHop_sentence_URL" />
        <s:source name="iHop_search_URL" />
        <s:source name="instance_ontology_url">
          <s:metadata>
            <s:description>E.g.
http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/BioAID_Instances.owl</s:description>
          </s:metadata>
        </s:source>
        <s:source name="model_instance_uri" />
        <s:source name="datetime">
          <s:metadata>
            <s:description>E.g.
2008-08-14T14:37:29+02:00</s:description>
          </s:metadata>
        </s:source>
        <s:source name="tmp_rdf_output_fileref">
          <s:metadata>
            <s:description>E.g.
http://aida.science.uva.nl:9999/aida_public/rdf-output/tmp-rdf-out.rdf</s:description>
          </s:metadata>
        </s:source>
        <s:sink name="protein_instance" />
        <s:sink name="output_doc_ref" />
      </s:scufl>
    </s:workflow>
    <s:iterationstrategy>
      <i:cross xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
        <i:dot>
          <i:iterator name="protein_name" />
          <i:iterator name="uniprot_id" />
          <i:iterator name="entrez_pubmed_URL" />
          <i:iterator name="expasy_URL" />
          <i:iterator name="iHop_sentence_URL" />
          <i:iterator name="iHop_search_URL" />
        </i:dot>
        <i:iterator name="doc_instance" />
      </i:cross>
    </s:iterationstrategy>
  </s:processor>
  <s:processor name="s03_AddExpandedQueryToSemanticModel">
    <s:description>Add autamotically expanded query to Semantic model.</s:description>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:2ca45a93-0d4d-4e5c-b305-240df4ae1d18" author="Marco Roos (workflow), Willem R. van Hage (service)" title="AddExpandedQueryToSemanticModel">Add autamotically expanded query to Semantic model.</s:workflowdescription>
        <s:processor name="InstantiateQueryInstance">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: Instance of Type including label, comment, and date
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/BioModel.owl#Enzyme&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/2000/01/rdf-schema#label&gt; "an enzyme"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/2000/01/rdf-schema#comment&gt; "e.g. the enzyme referred to by as 'EZH2'"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_BioModel&gt; &lt;http://purl.org/dc/elements/1.1/date&gt; "2008-08-14T14:37:29+02:00"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; .
*/

/*
input:
instance_ontology_url
instance_name
type_uri
label_string
comment_string
datetime // must be in the right format, cf. 2008-08-14T14:37:29+02:00 (yyyy-MM-ddTHH:mm:ssZ); NB 'Z' for timezone with Java's SimpleDateFormat omits the last colon which is required.

output:
NTriple_InstanceOf_statement
instance_uri
*/

instance_uri = instance_ontology_url + "#" + instance_name;

NTriple_InstanceOf_statement = "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;" + type_uri + "&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/2000/01/rdf-schema#label&gt; \"" + label_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/2000/01/rdf-schema#comment&gt; \"" + comment_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://purl.org/dc/elements/1.1/date&gt; \"" + datetime + "\"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_ontology_url</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_name</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">type_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">label_string</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">comment_string</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">datetime</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_InstanceOf_statement</s:beanshelloutput>
              <s:beanshelloutput s:syntactictype="'text/plain'">instance_uri</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="DefineSemanticRelation_expansion_of">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: RelationByURI
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_InteractionTerm&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#discovered_by&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_RelationDiscoveryProcess&gt; .
*/

/*
variables, 
input:
domain_instance_uri
relation_uri
range_instance_uri

output:
NTriple_Relation_statement
*/

NTriple_Relation_statement = "&lt;" + domain_instance_uri + "&gt; &lt;" + relation_uri + "&gt; &lt;" + range_instance_uri + "&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">domain_instance_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">relation_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">range_instance_uri</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_Relation_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="ReplaceCharsForQueryID">
          <s:beanshell>
            <s:scriptvalue>/*
replace characters that Protg does not like for names
*/

import java.util.regex.*;

String tmpstring = input;

Pattern p = Pattern.compile("#");
Matcher m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;hash;");

p = Pattern.compile("\\^");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;caret;");

p = Pattern.compile("&lt;");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;lt;");

p = Pattern.compile("&gt;");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;gt;");

p = Pattern.compile("\\{");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;lcurly;");

p = Pattern.compile("\\}");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;rcurly;");

p = Pattern.compile("%");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;perc;");

p = Pattern.compile("_");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;ndash;");

p = Pattern.compile("\"");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;quot;");

p = Pattern.compile("\\s");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("_");

output = tmpstring;</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">input</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">output</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="DefineBooleanPropertyOfInstance">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: Property of Instance
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_DocumentSearchQuery&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#has_lucene_query&gt; "\"EZH2\" AND chromatin"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
*/

/*
variables, input:
instance_uri
property_uri
property_string

output:
NTriple_PropertyOfInstance_statement
*/

NTriple_PropertyOfInstance_statement = "&lt;" + instance_uri + "&gt; &lt;"+ property_uri + "&gt; \"" + property_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#boolean&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">property_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">property_string</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_PropertyOfInstance_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="ConcatenateRDFstatements">
          <s:defaults>
            <s:default name="delimiter" />
          </s:defaults>
          <s:beanshell>
            <s:scriptvalue>/* 
Concatenates List of Strings.
Use 'merge all data' on its input to concatenate different inputs.
*/
String s;
Iterator iter = (Iterator) stringlist.iterator();

if (iter.hasNext()) s = iter.next();

while (iter.hasNext()) {
	s = s + delimiter + iter.next();
}

output = s;</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="l('text/plain')">stringlist</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">delimiter</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">output</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
          <s:mergemode input="stringlist" mode="merge" />
        </s:processor>
        <s:processor name="Concat">
          <s:local>org.embl.ebi.escience.scuflworkers.java.StringConcat</s:local>
        </s:processor>
        <s:processor name="DefinePropertyOfInstance">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: Property of Instance
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_DocumentSearchQuery&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#has_lucene_query&gt; "\"EZH2\" AND chromatin"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
*/

/*
variables, input:
instance_uri
property_uri
property_string

output:
NTriple_PropertyOfInstance_statement
*/

NTriple_PropertyOfInstance_statement = "&lt;" + instance_uri + "&gt; &lt;"+ property_uri + "&gt; \"" + property_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">property_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">property_string</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_uri</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_PropertyOfInstance_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="DefineSemanticRelation_references">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: RelationByURI
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_InteractionTerm&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#discovered_by&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_RelationDiscoveryProcess&gt; .
*/

/*
variables, 
input:
domain_instance_uri
relation_uri
range_instance_uri

output:
NTriple_Relation_statement
*/

NTriple_Relation_statement = "&lt;" + domain_instance_uri + "&gt; &lt;" + relation_uri + "&gt; &lt;" + range_instance_uri + "&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">domain_instance_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">relation_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">range_instance_uri</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_Relation_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="SlashDoubleQuotes">
          <s:defaults>
            <s:default name="findstring">"</s:default>
            <s:default name="replacestring">\\\"</s:default>
          </s:defaults>
          <s:beanshell>
            <s:scriptvalue>import java.util.regex.*;

Pattern p = Pattern.compile(findstring);
Matcher m = p.matcher(input);

output = (String) m.replaceAll(replacestring);</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">input</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">findstring</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">replacestring</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">output</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="QueryInstanceComment" boring="true">
          <s:stringconstant>input query for document retrieval</s:stringconstant>
        </s:processor>
        <s:processor name="QueryInstanceLabel" boring="true">
          <s:stringconstant>expanded query</s:stringconstant>
        </s:processor>
        <s:processor name="DocumentSearchQuery_id_part1" boring="true">
          <s:stringconstant>DocQry:</s:stringconstant>
        </s:processor>
        <s:processor name="cls_080814_114703__Protoontology_TextMining__DocumentSearchQuery" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#DocumentSearchQuery</s:stringconstant>
        </s:processor>
        <s:processor name="ObjProp_080814_114703__Protoontology_MappingBioTextMining__partially_represents" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/MappingBioTextMining.owl#partially_represents</s:stringconstant>
        </s:processor>
        <s:processor name="is_user_provided_original" boring="true">
          <s:stringconstant>false</s:stringconstant>
        </s:processor>
        <s:processor name="Append" boring="true">
          <s:stringconstant>yes</s:stringconstant>
        </s:processor>
        <s:processor name="Data_080814_114703__Protoontology_TextMining__is_user_original" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#is_user_original</s:stringconstant>
        </s:processor>
        <s:processor name="Data_080814_114703__Protoontology_TextMining__has_lucene_query" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#has_lucene_query</s:stringconstant>
        </s:processor>
        <s:processor name="ObjProp_080814_114703__Protoontology_TextMining__expanded_query_of" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#expanded_query_of</s:stringconstant>
        </s:processor>
        <s:processor name="save_as">
          <s:defaults>
            <s:default name="append">no</s:default>
          </s:defaults>
          <s:arbitrarywsdl>
            <s:wsdl>http://aida.science.uva.nl:9999/axis/AidaFiler.jws?wsdl</s:wsdl>
            <s:operation>save_as</s:operation>
          </s:arbitrarywsdl>
        </s:processor>
        <s:link source="ConcatenateRDFstatements:output" sink="save_as:content" />
        <s:link source="Data_080814_114703__Protoontology_TextMining__has_lucene_query:value" sink="DefinePropertyOfInstance:property_uri" />
        <s:link source="Data_080814_114703__Protoontology_TextMining__is_user_original:value" sink="DefineBooleanPropertyOfInstance:property_uri" />
        <s:link source="DefineBooleanPropertyOfInstance:NTriple_PropertyOfInstance_statement" sink="ConcatenateRDFstatements:stringlist" />
        <s:link source="DefinePropertyOfInstance:NTriple_PropertyOfInstance_statement" sink="ConcatenateRDFstatements:stringlist" />
        <s:link source="DefineSemanticRelation_references:NTriple_Relation_statement" sink="ConcatenateRDFstatements:stringlist" />
        <s:link source="DocumentSearchQuery_id_part1:value" sink="Concat:string1" />
        <s:link source="InstanceOntologyURL" sink="InstantiateQueryInstance:instance_ontology_url" />
        <s:link source="RDF_doc_filename" sink="save_as:filename" />
        <s:link source="query" sink="ReplaceCharsForQueryID:input" />
        <s:link source="query" sink="SlashDoubleQuotes:input" />
        <s:link source="Append:value" sink="save_as:append" />
        <s:link source="Concat:output" sink="InstantiateQueryInstance:instance_name" />
        <s:link source="InstantiateQueryInstance:instance_uri" sink="DefineBooleanPropertyOfInstance:instance_uri" />
        <s:link source="InstantiateQueryInstance:instance_uri" sink="DefinePropertyOfInstance:instance_uri" />
        <s:link source="InstantiateQueryInstance:instance_uri" sink="DefineSemanticRelation_references:domain_instance_uri" />
        <s:link source="ObjProp_080814_114703__Protoontology_MappingBioTextMining__partially_represents:value" sink="DefineSemanticRelation_references:relation_uri" />
        <s:link source="QueryInstanceComment:value" sink="InstantiateQueryInstance:comment_string" />
        <s:link source="QueryInstanceLabel:value" sink="InstantiateQueryInstance:label_string" />
        <s:link source="ReplaceCharsForQueryID:output" sink="Concat:string2" />
        <s:link source="SlashDoubleQuotes:output" sink="DefinePropertyOfInstance:property_string" />
        <s:link source="cls_080814_114703__Protoontology_TextMining__DocumentSearchQuery:value" sink="InstantiateQueryInstance:type_uri" />
        <s:link source="datetime" sink="InstantiateQueryInstance:datetime" />
        <s:link source="model_instance_uri" sink="DefineSemanticRelation_references:range_instance_uri" />
        <s:link source="InstantiateQueryInstance:NTriple_InstanceOf_statement" sink="ConcatenateRDFstatements:stringlist" />
        <s:link source="original_query_instance_uri" sink="DefineSemanticRelation_expansion_of:range_instance_uri" />
        <s:link source="DefineSemanticRelation_expansion_of:NTriple_Relation_statement" sink="ConcatenateRDFstatements:stringlist" />
        <s:link source="InstantiateQueryInstance:instance_uri" sink="DefineSemanticRelation_expansion_of:domain_instance_uri" />
        <s:link source="ObjProp_080814_114703__Protoontology_TextMining__expanded_query_of:value" sink="DefineSemanticRelation_expansion_of:relation_uri" />
        <s:link source="is_user_provided_original:value" sink="DefineBooleanPropertyOfInstance:property_string" />
        <s:link source="InstantiateQueryInstance:instance_uri" sink="query_instance" />
        <s:link source="save_as:save_asReturn" sink="QueryRDFdoc_url" />
        <s:source name="query" />
        <s:source name="RDF_doc_filename">
          <s:metadata>
            <s:description>Reference to  file for RDF output.

E.g.
http://aida.science.uva.nl:9999/aida_public/rdf-output/tmp-rdf-out.rdf</s:description>
          </s:metadata>
        </s:source>
        <s:source name="InstanceOntologyURL">
          <s:metadata>
            <s:description>Instance ontology URL. E.g. http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/BioAID_Instances.owl</s:description>
          </s:metadata>
        </s:source>
        <s:source name="model_instance_uri">
          <s:metadata>
            <s:description>e.g.
http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_BioModel</s:description>
          </s:metadata>
        </s:source>
        <s:source name="datetime">
          <s:metadata>
            <s:description>conform this format
2008-08-14T14:37:29+02:00</s:description>
          </s:metadata>
        </s:source>
        <s:source name="original_query_instance_uri" />
        <s:sink name="query_instance" />
        <s:sink name="QueryRDFdoc_url" />
      </s:scufl>
    </s:workflow>
  </s:processor>
  <s:processor name="s02_AddOriginalQueryToSemanticModel">
    <s:description>Add Query to Semantic model with Sesame service cf example Biological Query</s:description>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:2ca45a93-0d4d-4e5c-b305-240df4ae1d18" author="Marco Roos (workflow), Willem R. van Hage (service)" title="AddOriginalQueryToSemanticModel">Add original (user provided) query to Semantic model.</s:workflowdescription>
        <s:processor name="DefineSemanticRelation">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: RelationByURI
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_InteractionTerm&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#discovered_by&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_RelationDiscoveryProcess&gt; .
*/

/*
variables, 
input:
domain_instance_uri
relation_uri
range_instance_uri

output:
NTriple_Relation_statement
*/

NTriple_Relation_statement = "&lt;" + domain_instance_uri + "&gt; &lt;" + relation_uri + "&gt; &lt;" + range_instance_uri + "&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">domain_instance_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">relation_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">range_instance_uri</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_Relation_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="DefinePropertyOfInstance">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: Property of Instance
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_DocumentSearchQuery&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#has_lucene_query&gt; "\"EZH2\" AND chromatin"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
*/

/*
variables, input:
instance_uri
property_uri
property_string

output:
NTriple_PropertyOfInstance_statement
*/

NTriple_PropertyOfInstance_statement = "&lt;" + instance_uri + "&gt; &lt;"+ property_uri + "&gt; \"" + property_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">property_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">property_string</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_uri</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_PropertyOfInstance_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="ConcatenateRDFstatements">
          <s:defaults>
            <s:default name="delimiter" />
          </s:defaults>
          <s:beanshell>
            <s:scriptvalue>/* 
Concatenates List of Strings.
Use 'merge all data' on its input to concatenate different inputs.
*/
String s;
Iterator iter = (Iterator) stringlist.iterator();

if (iter.hasNext()) s = iter.next();

while (iter.hasNext()) {
	s = s + delimiter + iter.next();
}

output = s;</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="l('text/plain')">stringlist</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">delimiter</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">output</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
          <s:mergemode input="stringlist" mode="merge" />
        </s:processor>
        <s:processor name="ReplaceCharsForQueryID">
          <s:beanshell>
            <s:scriptvalue>/*
replace characters that Protg does not like for names
*/

import java.util.regex.*;

String tmpstring = input;

Pattern p = Pattern.compile("#");
Matcher m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;hash;");

p = Pattern.compile("\\^");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;caret;");

p = Pattern.compile("&lt;");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;lt;");

p = Pattern.compile("&gt;");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;gt;");

p = Pattern.compile("\\{");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;lcurly;");

p = Pattern.compile("\\}");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;rcurly;");

p = Pattern.compile("%");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;perc;");

p = Pattern.compile("_");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;ndash;");

p = Pattern.compile("\"");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;quot;");

p = Pattern.compile("\\s");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("_");

output = tmpstring;</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">input</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">output</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="Concat">
          <s:local>org.embl.ebi.escience.scuflworkers.java.StringConcat</s:local>
        </s:processor>
        <s:processor name="InstantiateQueryInstance">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: Instance of Type including label, comment, and date
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/BioModel.owl#Enzyme&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/2000/01/rdf-schema#label&gt; "an enzyme"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/2000/01/rdf-schema#comment&gt; "e.g. the enzyme referred to by as 'EZH2'"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_BioModel&gt; &lt;http://purl.org/dc/elements/1.1/date&gt; "2008-08-14T14:37:29+02:00"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; .
*/

/*
input:
instance_ontology_url
instance_name
type_uri
label_string
comment_string
datetime // must be in the right format, cf. 2008-08-14T14:37:29+02:00 (yyyy-MM-ddTHH:mm:ssZ); NB 'Z' for timezone with Java's SimpleDateFormat omits the last colon which is required.

output:
NTriple_InstanceOf_statement
instance_uri
*/

instance_uri = instance_ontology_url + "#" + instance_name;

NTriple_InstanceOf_statement = "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;" + type_uri + "&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/2000/01/rdf-schema#label&gt; \"" + label_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/2000/01/rdf-schema#comment&gt; \"" + comment_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://purl.org/dc/elements/1.1/date&gt; \"" + datetime + "\"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_ontology_url</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_name</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">type_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">label_string</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">comment_string</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">datetime</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_InstanceOf_statement</s:beanshelloutput>
              <s:beanshelloutput s:syntactictype="'text/plain'">instance_uri</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="SlashDoubleQuotes">
          <s:defaults>
            <s:default name="findstring">"</s:default>
            <s:default name="replacestring">\\\"</s:default>
          </s:defaults>
          <s:beanshell>
            <s:scriptvalue>import java.util.regex.*;

Pattern p = Pattern.compile(findstring);
Matcher m = p.matcher(input);

output = (String) m.replaceAll(replacestring);</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">input</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">findstring</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">replacestring</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">output</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="DefineBooleanPropertyOfInstance">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: Property of Instance
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_DocumentSearchQuery&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#has_lucene_query&gt; "\"EZH2\" AND chromatin"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
*/

/*
variables, input:
instance_uri
property_uri
property_string

output:
NTriple_PropertyOfInstance_statement
*/

NTriple_PropertyOfInstance_statement = "&lt;" + instance_uri + "&gt; &lt;"+ property_uri + "&gt; \"" + property_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#boolean&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">property_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">property_string</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_PropertyOfInstance_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="DocumentSearchQuery_id_part1" boring="true">
          <s:stringconstant>DocQry:</s:stringconstant>
        </s:processor>
        <s:processor name="cls_080814_114703__Protoontology_TextMining__DocumentSearchQuery" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#DocumentSearchQuery</s:stringconstant>
        </s:processor>
        <s:processor name="is_user_provided_original" boring="true">
          <s:stringconstant>true</s:stringconstant>
        </s:processor>
        <s:processor name="QueryInstanceComment" boring="true">
          <s:stringconstant>input query for document retrieval</s:stringconstant>
        </s:processor>
        <s:processor name="Data_080814_114703__Protoontology_TextMining__has_lucene_query" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#has_lucene_query</s:stringconstant>
        </s:processor>
        <s:processor name="ObjProp_080814_114703__Protoontology_MappingBioTextMining__partially_represents" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/MappingBioTextMining.owl#partially_represents</s:stringconstant>
        </s:processor>
        <s:processor name="Append" boring="true">
          <s:stringconstant>yes</s:stringconstant>
        </s:processor>
        <s:processor name="Data_080814_114703__Protoontology_TextMining__is_user_original" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#is_user_original</s:stringconstant>
        </s:processor>
        <s:processor name="QueryInstanceLabel" boring="true">
          <s:stringconstant>original query</s:stringconstant>
        </s:processor>
        <s:processor name="save_as">
          <s:defaults>
            <s:default name="append">no</s:default>
          </s:defaults>
          <s:arbitrarywsdl>
            <s:wsdl>http://aida.science.uva.nl:9999/axis/AidaFiler.jws?wsdl</s:wsdl>
            <s:operation>save_as</s:operation>
          </s:arbitrarywsdl>
        </s:processor>
        <s:link source="ConcatenateRDFstatements:output" sink="save_as:content" />
        <s:link source="Data_080814_114703__Protoontology_TextMining__has_lucene_query:value" sink="DefinePropertyOfInstance:property_uri" />
        <s:link source="Data_080814_114703__Protoontology_TextMining__is_user_original:value" sink="DefineBooleanPropertyOfInstance:property_uri" />
        <s:link source="DefineBooleanPropertyOfInstance:NTriple_PropertyOfInstance_statement" sink="ConcatenateRDFstatements:stringlist" />
        <s:link source="DefinePropertyOfInstance:NTriple_PropertyOfInstance_statement" sink="ConcatenateRDFstatements:stringlist" />
        <s:link source="DefineSemanticRelation:NTriple_Relation_statement" sink="ConcatenateRDFstatements:stringlist" />
        <s:link source="DocumentSearchQuery_id_part1:value" sink="Concat:string1" />
        <s:link source="InstanceOntologyURL" sink="InstantiateQueryInstance:instance_ontology_url" />
        <s:link source="RDF_doc_filename" sink="save_as:filename" />
        <s:link source="query" sink="ReplaceCharsForQueryID:input" />
        <s:link source="query" sink="SlashDoubleQuotes:input" />
        <s:link source="Append:value" sink="save_as:append" />
        <s:link source="Concat:output" sink="InstantiateQueryInstance:instance_name" />
        <s:link source="InstantiateQueryInstance:instance_uri" sink="DefineBooleanPropertyOfInstance:instance_uri" />
        <s:link source="InstantiateQueryInstance:instance_uri" sink="DefinePropertyOfInstance:instance_uri" />
        <s:link source="InstantiateQueryInstance:instance_uri" sink="DefineSemanticRelation:domain_instance_uri" />
        <s:link source="ObjProp_080814_114703__Protoontology_MappingBioTextMining__partially_represents:value" sink="DefineSemanticRelation:relation_uri" />
        <s:link source="QueryInstanceComment:value" sink="InstantiateQueryInstance:comment_string" />
        <s:link source="QueryInstanceLabel:value" sink="InstantiateQueryInstance:label_string" />
        <s:link source="ReplaceCharsForQueryID:output" sink="Concat:string2" />
        <s:link source="SlashDoubleQuotes:output" sink="DefinePropertyOfInstance:property_string" />
        <s:link source="cls_080814_114703__Protoontology_TextMining__DocumentSearchQuery:value" sink="InstantiateQueryInstance:type_uri" />
        <s:link source="datetime" sink="InstantiateQueryInstance:datetime" />
        <s:link source="model_instance_uri" sink="DefineSemanticRelation:range_instance_uri" />
        <s:link source="InstantiateQueryInstance:NTriple_InstanceOf_statement" sink="ConcatenateRDFstatements:stringlist" />
        <s:link source="is_user_provided_original:value" sink="DefineBooleanPropertyOfInstance:property_string" />
        <s:link source="InstantiateQueryInstance:instance_uri" sink="query_instance" />
        <s:link source="save_as:save_asReturn" sink="QueryRDFdoc_url" />
        <s:source name="query" />
        <s:source name="RDF_doc_filename">
          <s:metadata>
            <s:description>Reference to  file for RDF output.

E.g.
http://aida.science.uva.nl:9999/aida_public/rdf-output/tmp-rdf-out.rdf</s:description>
          </s:metadata>
        </s:source>
        <s:source name="InstanceOntologyURL">
          <s:metadata>
            <s:description>Instance ontology URL. E.g. http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/BioAID_Instances.owl</s:description>
          </s:metadata>
        </s:source>
        <s:source name="model_instance_uri">
          <s:metadata>
            <s:description>e.g.
http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_BioModel</s:description>
          </s:metadata>
        </s:source>
        <s:source name="datetime">
          <s:metadata>
            <s:description>conform this format
2008-08-14T14:37:29+02:00</s:description>
          </s:metadata>
        </s:source>
        <s:sink name="query_instance" />
        <s:sink name="QueryRDFdoc_url" />
      </s:scufl>
    </s:workflow>
  </s:processor>
  <s:processor name="06_UniProtXrefURLs">
    <s:description>Adds URL cross references to various protein information resources.</s:description>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:c0a963bc-2343-4d31-aa8c-304bfe3a6289" author="Marco Roos (workflow)" title="XrefUniprot_HomoSapiens">Adds URL cross references to various protein information resources.</s:workflowdescription>
        <s:processor name="Concatenate_iHopURL_preStub">
          <s:defaults>
            <s:default name="string1">http&amp;#58;//www.ihop-net.org/UniPub/iHOP/gismo/</s:default>
          </s:defaults>
          <s:local>org.embl.ebi.escience.scuflworkers.java.StringConcat</s:local>
        </s:processor>
        <s:processor name="Concatenate_iHopURL">
          <s:local>org.embl.ebi.escience.scuflworkers.java.StringConcat</s:local>
        </s:processor>
        <s:processor name="ConcatenateExpasyURL">
          <s:local>org.embl.ebi.escience.scuflworkers.java.StringConcat</s:local>
        </s:processor>
        <s:processor name="ConcatenateEntrezURL">
          <s:local>org.embl.ebi.escience.scuflworkers.java.StringConcat</s:local>
        </s:processor>
        <s:processor name="ExtractiHopRefByRegexp">
          <s:defaults>
            <s:default name="regex">&lt;iHOPguessedSymbolId query=\".+\" xmlns=\"http://www.pdg.cnb.uam.es/UniPub/iHOP/xml\"&gt;(.+)&lt;/iHOPguessedSymbolId&gt;</s:default>
            <s:default name="group">1</s:default>
          </s:defaults>
          <s:local>org.embl.ebi.escience.scuflworkers.java.RegularExpressionStringList</s:local>
        </s:processor>
        <s:processor name="Concatenate_iHopURL_postStub">
          <s:defaults>
            <s:default name="string2">.html?ORGANISM_ID=1</s:default>
          </s:defaults>
          <s:local>org.embl.ebi.escience.scuflworkers.java.StringConcat</s:local>
        </s:processor>
        <s:processor name="iHopSearchURL_stub" boring="true">
          <s:stringconstant>http&amp;#58;//www.ihop-net.org/UniPub/iHOP/?field=UNIPROT__AC&amp;ncbi_tax_id=9606&amp;organism_syn=&amp;search=</s:stringconstant>
        </s:processor>
        <s:processor name="iHopSentenceURL_prestub" boring="true">
          <s:stringconstant>http&amp;#58;//www.ihop-net.org/UniPub/iHOP/gismo/</s:stringconstant>
        </s:processor>
        <s:processor name="ExpasyUniProtURL_stub" boring="true">
          <s:stringconstant>http&amp;#58;//expasy.org/uniprot/</s:stringconstant>
        </s:processor>
        <s:processor name="EntrezPubMedUniProtURL_stub" boring="true">
          <s:stringconstant>http&amp;#58;//www.ncbi.nlm.nih.gov/entrez/viewer.fcgi?db=protein&amp;val=</s:stringconstant>
        </s:processor>
        <s:processor name="iHopSentenceURL_poststub" boring="true">
          <s:stringconstant>.html?ORGANISM_ID=1</s:stringconstant>
        </s:processor>
        <s:processor name="guessSymbolIdFromReference">
          <s:description>It takes a biological database reference as input. It guess the iHOP Id which best matches with the input.</s:description>
          <s:arbitrarywsdl>
            <s:wsdl>http://ubio.bioinfo.cnio.es/biotools/iHOP/iHOP-SOAP.wsdl</s:wsdl>
            <s:operation>guessSymbolIdFromReference</s:operation>
          </s:arbitrarywsdl>
        </s:processor>
        <s:link source="UniProtID" sink="ConcatenateEntrezURL:string2" />
        <s:link source="UniProtID" sink="ConcatenateExpasyURL:string2" />
        <s:link source="UniProtID" sink="Concatenate_iHopURL:string2" />
        <s:link source="UniProtID" sink="guessSymbolIdFromReference:reference" />
        <s:link source="Concatenate_iHopURL_preStub:output" sink="Concatenate_iHopURL_postStub:string1" />
        <s:link source="EntrezPubMedUniProtURL_stub:value" sink="ConcatenateEntrezURL:string1" />
        <s:link source="ConcatenateEntrezURL:output" sink="EntrezUniProtURL" />
        <s:link source="ConcatenateExpasyURL:output" sink="ExpasyUniProtURL" />
        <s:link source="Concatenate_iHopURL:output" sink="iHopSearchURL" />
        <s:link source="Concatenate_iHopURL_postStub:output" sink="iHopSentencesURL" />
        <s:link source="ExpasyUniProtURL_stub:value" sink="ConcatenateExpasyURL:string1" />
        <s:link source="ExtractiHopRefByRegexp:filteredlist" sink="Concatenate_iHopURL_preStub:string2" />
        <s:link source="guessSymbolIdFromReference:result" sink="ExtractiHopRefByRegexp:stringlist" />
        <s:link source="iHopSearchURL_stub:value" sink="Concatenate_iHopURL:string1" />
        <s:link source="iHopSentenceURL_poststub:value" sink="Concatenate_iHopURL_postStub:string2" />
        <s:link source="iHopSentenceURL_prestub:value" sink="Concatenate_iHopURL_preStub:string1" />
        <s:source name="UniProtID">
          <s:metadata>
            <s:description>UniProt ID (for iHop a Human protein is expected)
E.g. Q15190</s:description>
          </s:metadata>
        </s:source>
        <s:sink name="ExpasyUniProtURL" />
        <s:sink name="EntrezUniProtURL" />
        <s:sink name="iHopSearchURL">
          <s:metadata>
            <s:mimeTypes>
              <s:mimeType>text/xml</s:mimeType>
            </s:mimeTypes>
          </s:metadata>
        </s:sink>
        <s:sink name="iHopSentencesURL" />
      </s:scufl>
    </s:workflow>
  </s:processor>
  <s:processor name="s03_AddExpandedQueryToSemanticModel_Obsolete">
    <s:description>Add Query to Semantic model with Sesame service cf example Biological Query</s:description>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:2ca45a93-0d4d-4e5c-b305-240df4ae1d18" author="Marco Roos (workflow), Willem R. van Hage (service)" title="AddExpandedQueryToSemanticModel">Add Query to Semantic model with Sesame service cf example Biological Query

NB This workflow was built without a SemanticTypes workflow (it predates the SemanticTypes creating workflow).</s:workflowdescription>
        <s:processor name="NTriple_AnnotationsOfInstance_statement">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: Label of Instance by URI
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/2000/01/rdf-schema#label&gt; "an enzyme"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
*/

/*
variables, input:
instance_uri
label_string
comment_string

output:
NTriple_LabelCommentOfInstance_statement
*/

NTriple_LabelCommentOfInstance_statement = "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/2000/01/rdf-schema#label&gt; \"" + label_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; ." + " \n &lt;" + instance_uri + "&gt; &lt;http://www.w3.org/2000/01/rdf-schema#comment&gt; \"" + comment_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">label_string</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">comment_string</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_LabelCommentOfInstance_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="NTriple_QueryRelation_stmnt">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: RelationByURI
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_ExpandedDocumentSearchQuery&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#expanded_query_of&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_OriginalDocumentSearchQuery&gt; .
*/

/*
variables, input:
domain_instance_uri
// relation_uri =
relation_ontology_url
relation_name
range_instance_uri

output:
NTriple_Relation_statement
*/

relation_uri = relation_ontology_url + "#" + relation_name;

NTriple_Relation_statement = "&lt;" + domain_instance_uri + "&gt; &lt;" + relation_uri + "&gt; &lt;" + range_instance_uri + "&gt; .";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">domain_instance_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">range_instance_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">relation_ontology_url</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">relation_name</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_Relation_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="SlashDoubleQuotes">
          <s:defaults>
            <s:default name="findstring">"</s:default>
            <s:default name="replacestring">\\\"</s:default>
          </s:defaults>
          <s:beanshell>
            <s:scriptvalue>import java.util.regex.*;

Pattern p = Pattern.compile(findstring);
Matcher m = p.matcher(input);

output = (String) m.replaceAll(replacestring);</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">input</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">findstring</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">replacestring</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">output</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="NTriple_QueryPropertyOfInstance_statement">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: Property of Instance
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_DocumentSearchQuery&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl#has_lucene_query&gt; "\"EZH2\" AND chromatin"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
*/

/*
variables, input:
instance_uri
property_ontology_url
property_name
property_string

output:
NTriple_PropertyOfInstance_statement
*/

NTriple_PropertyOfInstance_statement = "&lt;" + instance_uri + "&gt; &lt;"+ property_ontology_url + "#" + property_name + "&gt; \"" + property_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">property_ontology_url</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">property_name</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">property_string</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_PropertyOfInstance_statement</s:beanshelloutput>
              <s:beanshelloutput s:syntactictype="'text/plain'">property_uri</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="ConcatenateRDFdoc">
          <s:beanshell>
            <s:scriptvalue>RDFdoc = NTripleInstanceStatement + " \n" + NTripleAnnotationsStatement + " \n" + NTriplePropertyStatement + " \n" + NTripleRelationStatement + " \n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">NTripleInstanceStatement</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">NTripleAnnotationsStatement</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">NTriplePropertyStatement</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">NTripleRelationStatement</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">RDFdoc</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="ReplaceCharsForQueryID">
          <s:beanshell>
            <s:scriptvalue>/*
replace characters that Protg does not like for names
*/

import java.util.regex.*;

String tmpstring = input;

Pattern p = Pattern.compile("#");
Matcher m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;hash;");

p = Pattern.compile("\\^");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;caret;");

p = Pattern.compile("&lt;");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;lt;");

p = Pattern.compile("&gt;");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;gt;");

p = Pattern.compile("\\{");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;lcurly;");

p = Pattern.compile("\\}");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;rcurly;");

p = Pattern.compile("%");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;perc;");

p = Pattern.compile("_");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;ndash;");

p = Pattern.compile("\"");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;quot;");

p = Pattern.compile("\\s");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("_");

output = tmpstring;</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">input</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">output</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="NTriple_InstanceOf_statement">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: Instance of Type
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/BioModel.owl#Enzyme&gt; .
*/

/*
variables, input:
instance_ontology_url
type_ontology_url
instance_name
type_name

output:
instance_uri
NTriple_InstanceOf_statement
*/

instance_uri = instance_ontology_url + "#" + instance_name;
NTriple_InstanceOf_statement = "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;" + type_ontology_url + "#" + type_name + "&gt; .";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_ontology_url</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">type_ontology_url</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_name</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">type_name</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">instance_uri</s:beanshelloutput>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_InstanceOf_statement</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="Concat">
          <s:local>org.embl.ebi.escience.scuflworkers.java.StringConcat</s:local>
        </s:processor>
        <s:processor name="QueryInstanceComment" boring="true">
          <s:stringconstant>input query for document retrieval</s:stringconstant>
        </s:processor>
        <s:processor name="InstanceType" boring="true">
          <s:stringconstant>DocumentSearchQuery</s:stringconstant>
        </s:processor>
        <s:processor name="Append" boring="true">
          <s:stringconstant>yes</s:stringconstant>
        </s:processor>
        <s:processor name="lucene_query_property" boring="true">
          <s:stringconstant>has_lucene_query</s:stringconstant>
        </s:processor>
        <s:processor name="DocumentSearchQuery_id_part1" boring="true">
          <s:stringconstant>DocQry:</s:stringconstant>
        </s:processor>
        <s:processor name="QueryInstanceLabel" boring="true">
          <s:stringconstant>expanded query</s:stringconstant>
        </s:processor>
        <s:processor name="expanded_query_relation_uri" boring="true">
          <s:stringconstant>expanded_query_of</s:stringconstant>
        </s:processor>
        <s:processor name="save_as">
          <s:defaults>
            <s:default name="append">no</s:default>
          </s:defaults>
          <s:arbitrarywsdl>
            <s:wsdl>http://aida.science.uva.nl:9999/axis/AidaFiler.jws?wsdl</s:wsdl>
            <s:operation>save_as</s:operation>
          </s:arbitrarywsdl>
        </s:processor>
        <s:link source="Concat:output" sink="NTriple_InstanceOf_statement:instance_name" />
        <s:link source="ConcatenateRDFdoc:RDFdoc" sink="save_as:content" />
        <s:link source="DocumentSearchQuery_id_part1:value" sink="Concat:string1" />
        <s:link source="InstanceOntologyURL" sink="NTriple_InstanceOf_statement:instance_ontology_url" />
        <s:link source="InstanceType:value" sink="NTriple_InstanceOf_statement:type_name" />
        <s:link source="NTriple_AnnotationsOfInstance_statement:NTriple_LabelCommentOfInstance_statement" sink="ConcatenateRDFdoc:NTripleAnnotationsStatement" />
        <s:link source="NTriple_InstanceOf_statement:NTriple_InstanceOf_statement" sink="ConcatenateRDFdoc:NTripleInstanceStatement" />
        <s:link source="NTriple_InstanceOf_statement:instance_uri" sink="NTriple_AnnotationsOfInstance_statement:instance_uri" />
        <s:link source="NTriple_InstanceOf_statement:instance_uri" sink="NTriple_QueryPropertyOfInstance_statement:instance_uri" />
        <s:link source="NTriple_QueryPropertyOfInstance_statement:NTriple_PropertyOfInstance_statement" sink="ConcatenateRDFdoc:NTriplePropertyStatement" />
        <s:link source="QueryInstanceComment:value" sink="NTriple_AnnotationsOfInstance_statement:comment_string" />
        <s:link source="QueryInstanceLabel:value" sink="NTriple_AnnotationsOfInstance_statement:label_string" />
        <s:link source="RDF_doc_filename" sink="save_as:filename" />
        <s:link source="expanded_query" sink="SlashDoubleQuotes:input" />
        <s:link source="Append:value" sink="save_as:append" />
        <s:link source="NTriple_InstanceOf_statement:instance_uri" sink="NTriple_QueryRelation_stmnt:domain_instance_uri" />
        <s:link source="SlashDoubleQuotes:output" sink="NTriple_QueryPropertyOfInstance_statement:property_string" />
        <s:link source="TextMiningOntologyURL" sink="NTriple_InstanceOf_statement:type_ontology_url" />
        <s:link source="TextMiningOntologyURL" sink="NTriple_QueryPropertyOfInstance_statement:property_ontology_url" />
        <s:link source="TextMiningOntologyURL" sink="NTriple_QueryRelation_stmnt:relation_ontology_url" />
        <s:link source="expanded_query" sink="ReplaceCharsForQueryID:input" />
        <s:link source="ReplaceCharsForQueryID:output" sink="Concat:string2" />
        <s:link source="expanded_query_relation_uri:value" sink="NTriple_QueryRelation_stmnt:relation_name" />
        <s:link source="lucene_query_property:value" sink="NTriple_QueryPropertyOfInstance_statement:property_name" />
        <s:link source="original_query_instance_uri" sink="NTriple_QueryRelation_stmnt:range_instance_uri" />
        <s:link source="NTriple_InstanceOf_statement:instance_uri" sink="expanded_query_instance" />
        <s:link source="NTriple_QueryRelation_stmnt:NTriple_Relation_statement" sink="ConcatenateRDFdoc:NTripleRelationStatement" />
        <s:link source="save_as:save_asReturn" sink="QueryRDFdoc_url" />
        <s:source name="expanded_query" />
        <s:source name="RDF_doc_filename">
          <s:metadata>
            <s:description>Reference to  file for RDF output.

E.g.
http://aida.science.uva.nl:9999/aida_public/rdf-output/tmp-rdf-out.rdf</s:description>
          </s:metadata>
        </s:source>
        <s:source name="original_query_instance_uri" />
        <s:source name="TextMiningOntologyURL">
          <s:metadata>
            <s:description>Text mining ontology url. E.g. http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl</s:description>
          </s:metadata>
        </s:source>
        <s:source name="InstanceOntologyURL">
          <s:metadata>
            <s:description>Instance ontology URL. E.g. http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/BioAID_Instances.owl</s:description>
          </s:metadata>
        </s:source>
        <s:sink name="expanded_query_instance" />
        <s:sink name="QueryRDFdoc_url" />
      </s:scufl>
    </s:workflow>
  </s:processor>
  <s:processor name="s01_AddBiologicalModelToSemanticModel">
    <s:description>Add Query to Semantic model with Sesame service cf example Biological Query</s:description>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:2ca45a93-0d4d-4e5c-b305-240df4ae1d18" author="Marco Roos (workflow), Willem R. van Hage (service)" title="InstantiateBiologicalModel">Add Query to Semantic model with Sesame service cf example Biological Query</s:workflowdescription>
        <s:processor name="InstantiateSemanticType">
          <s:beanshell>
            <s:scriptvalue>/*
N-triple beanshell: Instance of Type including label and comment
*/

/*
conform:
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/BioModel.owl#Enzyme&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/2000/01/rdf-schema#label&gt; "an enzyme"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
&lt;http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl#ExampleInstance_Enzyme&gt; &lt;http://www.w3.org/2000/01/rdf-schema#comment&gt; "e.g. the enzyme referred to by as 'EZH2'"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .
*/

/*
input:
instance_ontology_url
instance_name
type_uri
label_string
comment_string

output:
NTriple_InstanceOf_statement
instance_uri
*/

instance_uri = instance_ontology_url + "#" + instance_name;

NTriple_InstanceOf_statement = "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;" + type_uri + "&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/2000/01/rdf-schema#label&gt; \"" + label_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .\n";
NTriple_InstanceOf_statement = NTriple_InstanceOf_statement + "&lt;" + instance_uri + "&gt; &lt;http://www.w3.org/2000/01/rdf-schema#comment&gt; \"" + comment_string + "\"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt; .\n";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_ontology_url</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">instance_name</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">type_uri</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">label_string</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">comment_string</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">NTriple_InstanceOf_statement</s:beanshelloutput>
              <s:beanshelloutput s:syntactictype="'text/plain'">instance_uri</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="ReplaceCharsForID">
          <s:beanshell>
            <s:scriptvalue>/*
replace characters that Protg does not like for names
*/

import java.util.regex.*;

String tmpstring = input;

Pattern p = Pattern.compile("#");
Matcher m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;hash;");

p = Pattern.compile("\\^");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;caret;");

p = Pattern.compile("&lt;");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;lt;");

p = Pattern.compile("&gt;");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;gt;");

p = Pattern.compile("\\{");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;lcurly;");

p = Pattern.compile("\\}");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;rcurly;");

p = Pattern.compile("%");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;perc;");

p = Pattern.compile("_");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;ndash;");

p = Pattern.compile("\"");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("&amp;quot;");

p = Pattern.compile("\\s");
m = p.matcher(tmpstring);
tmpstring = (String) m.replaceAll("_");

output = tmpstring;</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">input</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">output</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="Class_080813_112057__Protoontology_BioModel__BiologicalModel" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/BioModel.owl#BiologicalModel</s:stringconstant>
        </s:processor>
        <s:processor name="Append" boring="true">
          <s:stringconstant>yes</s:stringconstant>
        </s:processor>
        <s:processor name="save_as">
          <s:defaults>
            <s:default name="append">no</s:default>
          </s:defaults>
          <s:arbitrarywsdl>
            <s:wsdl>http://aida.science.uva.nl:9999/axis/AidaFiler.jws?wsdl</s:wsdl>
            <s:operation>save_as</s:operation>
          </s:arbitrarywsdl>
        </s:processor>
        <s:link source="BioModelComment" sink="InstantiateSemanticType:comment_string" />
        <s:link source="InstanceOntologyURL" sink="InstantiateSemanticType:instance_ontology_url" />
        <s:link source="ModelIdentifyingName" sink="ReplaceCharsForID:input" />
        <s:link source="RDF_doc_filename" sink="save_as:filename" />
        <s:link source="Append:value" sink="save_as:append" />
        <s:link source="Class_080813_112057__Protoontology_BioModel__BiologicalModel:value" sink="InstantiateSemanticType:type_uri" />
        <s:link source="InstantiateSemanticType:NTriple_InstanceOf_statement" sink="save_as:content" />
        <s:link source="InstantiateSemanticType:instance_uri" sink="biomodel_instance_uri" />
        <s:link source="ReplaceCharsForID:output" sink="InstantiateSemanticType:instance_name" />
        <s:link source="save_as:save_asReturn" sink="QueryRDFdoc_url" />
        <s:source name="ModelIdentifyingName" />
        <s:source name="RDF_doc_filename">
          <s:metadata>
            <s:description>Reference to  file for RDF output.

E.g.
http://aida.science.uva.nl:9999/aida_public/rdf-output/tmp-rdf-out.rdf</s:description>
          </s:metadata>
        </s:source>
        <s:source name="InstanceOntologyURL">
          <s:metadata>
            <s:description>Instance ontology URL. E.g. http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/BioAID_Instances.owl</s:description>
          </s:metadata>
        </s:source>
        <s:source name="BioModelComment" />
        <s:sink name="biomodel_instance_uri" />
        <s:sink name="QueryRDFdoc_url" />
      </s:scufl>
    </s:workflow>
  </s:processor>
  <s:processor name="s00_InitializeSemanticStorage">
    <s:defaults>
      <s:default name="do_not_clear_repository">false</s:default>
      <s:default name="do_not_add_to_repository">false</s:default>
      <s:default name="do_not_clear_tmp_rdf_file">false</s:default>
    </s:defaults>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:4426fbe2-64df-43c2-8005-bc49d575508d" author="" title="Reload_BioAID_ProteinDiscovery_Ontologies" />
        <s:processor name="aida_semantic_server_url" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/sesame</s:stringconstant>
        </s:processor>
        <s:processor name="BioAnnotations_ontology_url" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/BioAnnotations.owl</s:stringconstant>
        </s:processor>
        <s:processor name="Workflow_ontology_url" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/Workflow.owl</s:stringconstant>
        </s:processor>
        <s:processor name="rdf_format" boring="true">
          <s:stringconstant>rdfxml</s:stringconstant>
        </s:processor>
        <s:processor name="Text_ontology_url" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/Text.owl</s:stringconstant>
        </s:processor>
        <s:processor name="rdf_Ntriple_format" boring="true">
          <s:description>'rdfxml' or 'turtle' or 'n3'</s:description>
          <s:stringconstant>n3</s:stringconstant>
        </s:processor>
        <s:processor name="Append_no" boring="true">
          <s:stringconstant>no</s:stringconstant>
        </s:processor>
        <s:processor name="BioModel_ontology_url" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/BioModel.owl</s:stringconstant>
        </s:processor>
        <s:processor name="ExampleInstances_ontology_url" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/ExampleInstances.owl</s:stringconstant>
        </s:processor>
        <s:processor name="BioAIDinstances_ontology_url" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Enriched-ontology/BioAID_Instances.owl</s:stringconstant>
        </s:processor>
        <s:processor name="Fail_if_true_Prevent_init">
          <s:local>org.embl.ebi.escience.scuflworkers.java.FailIfTrue</s:local>
        </s:processor>
        <s:processor name="Fail_if_true_Prevent_clear">
          <s:defaults>
            <s:default name="test">false</s:default>
          </s:defaults>
          <s:local>org.embl.ebi.escience.scuflworkers.java.FailIfTrue</s:local>
        </s:processor>
        <s:processor name="RepositoryRef">
          <s:beanshell>
            <s:scriptvalue>bioaid_repository_url = sesame_url + "/actionFrameset.jsp?repository=" + repository;</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">sesame_url</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">repository</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">bioaid_repository_url</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="TextMining_ontology_url" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/TextMining.owl</s:stringconstant>
        </s:processor>
        <s:processor name="Fail_if_true_Prevent_add">
          <s:defaults>
            <s:default name="test">false</s:default>
          </s:defaults>
          <s:local>org.embl.ebi.escience.scuflworkers.java.FailIfTrue</s:local>
        </s:processor>
        <s:processor name="Mapping_ontology_url" boring="true">
          <s:stringconstant>http://rdf.adaptivedisclosure.org/owl/BioAID/myModel/Proto-ontology/MappingBioTextMining.owl</s:stringconstant>
        </s:processor>
        <s:processor name="repository_bioaid">
          <s:arbitrarywsdl>
            <s:wsdl>http://aida.science.uva.nl:8888/axis/AidaSemanticStorage.jws?wsdl</s:wsdl>
            <s:operation>repository_bioaid</s:operation>
          </s:arbitrarywsdl>
        </s:processor>
        <s:processor name="username_bioaid">
          <s:arbitrarywsdl>
            <s:wsdl>http://aida.science.uva.nl:8888/axis/AidaSemanticStorage.jws?wsdl</s:wsdl>
            <s:operation>username_bioaid</s:operation>
          </s:arbitrarywsdl>
        </s:processor>
        <s:processor name="addRdfFile">
          <s:arbitrarywsdl>
            <s:wsdl>http://ws.adaptivedisclosure.org/axis/services/RepositoryWS?wsdl</s:wsdl>
            <s:operation>addRdfFile</s:operation>
          </s:arbitrarywsdl>
          <s:mergemode input="data_uri" mode="merge" />
          <s:iterationstrategy>
            <i:cross xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
              <i:dot>
                <i:iterator name="server_url" />
                <i:iterator name="repository" />
                <i:iterator name="username" />
                <i:iterator name="password" />
                <i:iterator name="rdf_format" />
              </i:dot>
              <i:iterator name="data_uri" />
            </i:cross>
          </s:iterationstrategy>
        </s:processor>
        <s:processor name="save_as">
          <s:defaults>
            <s:default name="content" />
          </s:defaults>
          <s:arbitrarywsdl>
            <s:wsdl>http://aida.science.uva.nl:8888/axis/AidaFiler.jws?wsdl</s:wsdl>
            <s:operation>save_as</s:operation>
          </s:arbitrarywsdl>
        </s:processor>
        <s:processor name="password_bioaid">
          <s:arbitrarywsdl>
            <s:wsdl>http://aida.science.uva.nl:8888/axis/AidaSemanticStorage.jws?wsdl</s:wsdl>
            <s:operation>password_bioaid</s:operation>
          </s:arbitrarywsdl>
        </s:processor>
        <s:processor name="def_rdf_output_doc_url">
          <s:arbitrarywsdl>
            <s:wsdl>http://aida.science.uva.nl:9999/axis/AidaSemanticStorage.jws?wsdl</s:wsdl>
            <s:operation>def_rdf_output_doc_url</s:operation>
          </s:arbitrarywsdl>
        </s:processor>
        <s:processor name="clear">
          <s:arbitrarywsdl>
            <s:wsdl>http://ws.adaptivedisclosure.org/axis/services/RepositoryWS?wsdl</s:wsdl>
            <s:operation>clear</s:operation>
          </s:arbitrarywsdl>
        </s:processor>
        <s:link source="aida_magic_word" sink="password_bioaid:magic_word" />
        <s:link source="aida_magic_word" sink="username_bioaid:magic_word" />
        <s:link source="BioAIDinstances_ontology_url:value" sink="BioAIDinstances_ontology_url" />
        <s:link source="BioAIDinstances_ontology_url:value" sink="addRdfFile:data_uri" />
        <s:link source="BioAnnotations_ontology_url:value" sink="BioAnnotations_ontology_url" />
        <s:link source="BioAnnotations_ontology_url:value" sink="addRdfFile:data_uri" />
        <s:link source="BioModel_ontology_url:value" sink="BioModel_ontology_url" />
        <s:link source="BioModel_ontology_url:value" sink="addRdfFile:data_uri" />
        <s:link source="ExampleInstances_ontology_url:value" sink="ExampleInstances_ontology_url" />
        <s:link source="ExampleInstances_ontology_url:value" sink="addRdfFile:data_uri" />
        <s:link source="Mapping_ontology_url:value" sink="Mapping_ontology_url" />
        <s:link source="Mapping_ontology_url:value" sink="addRdfFile:data_uri" />
        <s:link source="RepositoryRef:bioaid_repository_url" sink="BioAID_Repository_url" />
        <s:link source="TextMining_ontology_url:value" sink="TextMining_ontology_url" />
        <s:link source="TextMining_ontology_url:value" sink="addRdfFile:data_uri" />
        <s:link source="Text_ontology_url:value" sink="Text_ontology_url" />
        <s:link source="Text_ontology_url:value" sink="addRdfFile:data_uri" />
        <s:link source="Workflow_ontology_url:value" sink="Workflow_ontology_url" />
        <s:link source="Workflow_ontology_url:value" sink="addRdfFile:data_uri" />
        <s:link source="aida_semantic_server_url:value" sink="RepositoryRef:sesame_url" />
        <s:link source="aida_semantic_server_url:value" sink="addRdfFile:server_url" />
        <s:link source="aida_semantic_server_url:value" sink="clear:server_url" />
        <s:link source="do_not_add_to_repository" sink="Fail_if_true_Prevent_add:test" />
        <s:link source="do_not_clear_repository" sink="Fail_if_true_Prevent_clear:test" />
        <s:link source="do_not_clear_tmp_rdf_file" sink="Fail_if_true_Prevent_init:test" />
        <s:link source="Append_no:value" sink="save_as:append" />
        <s:link source="def_rdf_output_doc_url:def_rdf_output_doc_urlReturn" sink="RDFoutput_doc_url" />
        <s:link source="def_rdf_output_doc_url:def_rdf_output_doc_urlReturn" sink="save_as:filename" />
        <s:link source="password_bioaid:password_bioaidReturn" sink="addRdfFile:password" />
        <s:link source="password_bioaid:password_bioaidReturn" sink="clear:password" />
        <s:link source="rdf_Ntriple_format:value" sink="Rdf_NTriple_format" />
        <s:link source="rdf_format:value" sink="addRdfFile:rdf_format" />
        <s:link source="repository_bioaid:repository_bioaidReturn" sink="RepositoryRef:repository" />
        <s:link source="repository_bioaid:repository_bioaidReturn" sink="addRdfFile:repository" />
        <s:link source="repository_bioaid:repository_bioaidReturn" sink="clear:repository" />
        <s:link source="username_bioaid:username_bioaidReturn" sink="addRdfFile:username" />
        <s:link source="username_bioaid:username_bioaidReturn" sink="clear:username" />
        <s:source name="aida_magic_word" />
        <s:source name="do_not_clear_repository">
          <s:metadata>
            <s:description>true to prevent the repository from being cleared before adding semantic models</s:description>
          </s:metadata>
        </s:source>
        <s:source name="do_not_add_to_repository">
          <s:metadata>
            <s:description>true to prevent adding the ontologies to the repository</s:description>
          </s:metadata>
        </s:source>
        <s:source name="do_not_clear_tmp_rdf_file">
          <s:metadata>
            <s:description>true to prevent the temporary rdf output file for intermediate rdf output to be overwritten with an empty document.</s:description>
          </s:metadata>
        </s:source>
        <s:sink name="BioAID_Repository_url" />
        <s:sink name="Workflow_ontology_url" />
        <s:sink name="BioAIDinstances_ontology_url" />
        <s:sink name="Text_ontology_url" />
        <s:sink name="BioModel_ontology_url" />
        <s:sink name="TextMining_ontology_url" />
        <s:sink name="Mapping_ontology_url" />
        <s:sink name="BioAnnotations_ontology_url" />
        <s:sink name="ExampleInstances_ontology_url" />
        <s:sink name="Rdf_NTriple_format" />
        <s:sink name="RDFoutput_doc_url" />
        <s:coordination name="addRdfFile_BLOCKON_clear">
          <s:condition>
            <s:state>Completed</s:state>
            <s:target>clear</s:target>
          </s:condition>
          <s:action>
            <s:target>addRdfFile</s:target>
            <s:statechange>
              <s:from>Scheduled</s:from>
              <s:to>Running</s:to>
            </s:statechange>
          </s:action>
        </s:coordination>
        <s:coordination name="clear_BLOCKON_Fail_if_true">
          <s:condition>
            <s:state>Completed</s:state>
            <s:target>Fail_if_true_Prevent_clear</s:target>
          </s:condition>
          <s:action>
            <s:target>clear</s:target>
            <s:statechange>
              <s:from>Scheduled</s:from>
              <s:to>Running</s:to>
            </s:statechange>
          </s:action>
        </s:coordination>
        <s:coordination name="addRdfFile_BLOCKON_Fail_if_true_Precent_add">
          <s:condition>
            <s:state>Completed</s:state>
            <s:target>Fail_if_true_Prevent_add</s:target>
          </s:condition>
          <s:action>
            <s:target>addRdfFile</s:target>
            <s:statechange>
              <s:from>Scheduled</s:from>
              <s:to>Running</s:to>
            </s:statechange>
          </s:action>
        </s:coordination>
        <s:coordination name="save_as_BLOCKON_Fail_if_true_Prevent_init">
          <s:condition>
            <s:state>Completed</s:state>
            <s:target>Fail_if_true_Prevent_init</s:target>
          </s:condition>
          <s:action>
            <s:target>save_as</s:target>
            <s:statechange>
              <s:from>Scheduled</s:from>
              <s:to>Running</s:to>
            </s:statechange>
          </s:action>
        </s:coordination>
      </s:scufl>
    </s:workflow>
  </s:processor>
  <s:processor name="02_RetrieveDocumentsFromMedline">
    <s:description>This workflow applies the search web service from the AIDA toolbox.

Comments:
This search service is based on lucene defaults; it may be necessary to optimize the querystring to adopt the behaviour to what is most relevant in a particular domain (e.g. for medline prioritizing based on publication date is useful). Lucene favours shorter sentences, which may be bad for subsequent information extraction.</s:description>
    <s:defaults>
      <s:default name="document_index">MedLine</s:default>
      <s:default name="search_field">content</s:default>
    </s:defaults>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:858efe24-26c0-4090-be46-c9a5b4f21cad" author="Marco Roos (workflow), Edgard Meij (service)" title="AIDA_Retrieve_documents_in_parts">This workflow applies the search web service from the AIDA toolbox.

Comments:
This search service is based on lucene defaults; it may be necessary to optimize the querystring to adopt the behaviour to what is most relevant in a particular domain (e.g. for medline prioritizing based on publication date is useful). Lucene favours shorter sentences, which may be bad for subsequent information extraction.</s:workflowdescription>
        <s:processor name="XPath_PMID">
          <s:local>net.sourceforge.taverna.scuflworkers.xml.XPathTextWorker</s:local>
        </s:processor>
        <s:processor name="Concatenate1">
          <s:local>org.embl.ebi.escience.scuflworkers.java.StringConcat</s:local>
        </s:processor>
        <s:processor name="XPath_Abstract">
          <s:local>net.sourceforge.taverna.scuflworkers.xml.XPathTextWorker</s:local>
        </s:processor>
        <s:processor name="XPath_Title">
          <s:local>net.sourceforge.taverna.scuflworkers.xml.XPathTextWorker</s:local>
        </s:processor>
        <s:processor name="Concatenate2">
          <s:local>org.embl.ebi.escience.scuflworkers.java.StringConcat</s:local>
          <s:iterationstrategy>
            <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
              <i:iterator name="string1" />
              <i:iterator name="string2" />
            </i:dot>
          </s:iterationstrategy>
        </s:processor>
        <s:processor name="PubMedURL_stub" boring="true">
          <s:stringconstant>http&amp;#58;//www.ncbi.nlm.nih.gov/sites/entrez?cmd=Retrieve&amp;amp;db=PubMed&amp;amp;list_uids=</s:stringconstant>
        </s:processor>
        <s:processor name="pubmedID_xpath" boring="true">
          <s:stringconstant>/aid:result/doc/field[@name='PMID']/value</s:stringconstant>
        </s:processor>
        <s:processor name="abstract_xpath" boring="true">
          <s:stringconstant>/aid:result/doc/field[@name='content']/value</s:stringconstant>
        </s:processor>
        <s:processor name="title_xpath" boring="true">
          <s:stringconstant>/aid:result/doc/field[@name='title']/value</s:stringconstant>
        </s:processor>
        <s:processor name="search">
          <s:arbitrarywsdl>
            <s:wsdl>http://aida.science.uva.nl:8888/axis/services/SearcherWS?wsdl</s:wsdl>
            <s:operation>search</s:operation>
          </s:arbitrarywsdl>
        </s:processor>
        <s:link source="document_index" sink="search:index" />
        <s:link source="maxHits" sink="search:maxHits" />
        <s:link source="queryString" sink="search:queryString" />
        <s:link source="search_field" sink="search:defaultField" />
        <s:link source="XPath_PMID:nodelist" sink="Concatenate1:string2" />
        <s:link source="XPath_Title:nodelist" sink="Concatenate2:string1" />
        <s:link source="abstract_xpath:value" sink="XPath_Abstract:xpath" />
        <s:link source="pubmedID_xpath:value" sink="XPath_PMID:xpath" />
        <s:link source="search:searchReturn" sink="XPath_Abstract:xml-text" />
        <s:link source="search:searchReturn" sink="XPath_PMID:xml-text" />
        <s:link source="search:searchReturn" sink="XPath_Title:xml-text" />
        <s:link source="title_xpath:value" sink="XPath_Title:xpath" />
        <s:link source="Concatenate1:output" sink="pubmed_URL" />
        <s:link source="Concatenate2:output" sink="title_abstract" />
        <s:link source="PubMedURL_stub:value" sink="Concatenate1:string1" />
        <s:link source="XPath_Abstract:nodelist" sink="Concatenate2:string2" />
        <s:link source="XPath_Abstract:nodelist" sink="abstract" />
        <s:link source="XPath_PMID:nodelist" sink="pubmed_id" />
        <s:link source="XPath_Title:nodelist" sink="title" />
        <s:source name="queryString">
          <s:metadata>
            <s:description>Lucene query for search. Simple AND and OR queries will work. For advanced queries see http://lucene.apache.org for more information.</s:description>
          </s:metadata>
        </s:source>
        <s:source name="document_index">
          <s:metadata>
            <s:description>e.g. MedLine will give access to a weekly update index of the medline corpus.</s:description>
          </s:metadata>
        </s:source>
        <s:source name="search_field">
          <s:metadata>
            <s:description>e.g.' content' will search abstract and title; abstract just the abstract, title just the title.</s:description>
          </s:metadata>
        </s:source>
        <s:source name="maxHits">
          <s:metadata>
            <s:description>limits the maximum number of hits search will produce. In Taverna 1 '100' works well while a 1000 and above is likely to halt Taverna 1 due to memory problems. This also depends on the memory setting for the java virtual machine by the client (usually your local Taverna).</s:description>
          </s:metadata>
        </s:source>
        <s:sink name="pubmed_id" />
        <s:sink name="pubmed_URL" />
        <s:sink name="abstract" />
        <s:sink name="title" />
        <s:sink name="title_abstract" />
      </s:scufl>
    </s:workflow>
  </s:processor>
  <s:processor name="04_ExtractProteinRelations_HomoSapiens">
    <s:description>Workflow to extract protein protein interactions from text, followed by filtering protein names known as human protein names. The protein protein interaction service takes the output in 'IOB' format from applyCRF, which annotates proteins as such in text.</s:description>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:c0a963bc-2343-4d31-aa8c-304bfe3a6289" author="Marco Roos (workflow), Sophia Katrenko (extraction service), Martijn Schuemie (validation service)" title="ExtractProteinProteinInteractionsFromText_HomoSapiens">Workflow to extract protein protein interactions from text, followed by filtering protein names known as human protein names. The protein protein interaction service takes the output in 'IOB' format from applyCRF, which annotates proteins as such in text.

ToDo:
Add Relation extraction subworkflow for real.</s:workflowdescription>
        <s:processor name="FlattenProteinlist1">
          <s:local>
            org.embl.ebi.escience.scuflworkers.java.FlattenList
            <s:extensions>
              <s:flattenlist s:depth="2" />
            </s:extensions>
          </s:local>
        </s:processor>
        <s:processor name="FlattenUniProtlist2">
          <s:local>
            org.embl.ebi.escience.scuflworkers.java.FlattenList
            <s:extensions>
              <s:flattenlist s:depth="2" />
            </s:extensions>
          </s:local>
        </s:processor>
        <s:processor name="FlattenProteinlist2">
          <s:local>
            org.embl.ebi.escience.scuflworkers.java.FlattenList
            <s:extensions>
              <s:flattenlist s:depth="2" />
            </s:extensions>
          </s:local>
        </s:processor>
        <s:processor name="FlattenUniprotlist1">
          <s:local>
            org.embl.ebi.escience.scuflworkers.java.FlattenList
            <s:extensions>
              <s:flattenlist s:depth="2" />
            </s:extensions>
          </s:local>
        </s:processor>
        <s:processor name="example_interaction_doc">
          <s:beanshell>
            <s:scriptvalue>interaction_doc = "P300 TP53\r\nIRF3 CITED1\r\nCITED1 STAT5A\r\nTP73 P300\r\nP300 ZAC1\r\nP300 mSRC-1\r\nSigK T4\r\nGerE ykvP\r\nSpoIIE sigma(F)\r\nrsfA sigma(F)\r\nsigma(K) cwlH\r\nsigma(K) gerE\r\ncwlH gerE\r\nphrC sigmaH\r\nphrC CSF\r\nsigmaH CSF\r\nyfhS E_sigma_E\r\nsigmaK Spo0A\r\nsigmaK sigE\r\nSpo0A sigE\r\nGerE sigK\r\nGerE sigmaK\r\nsigK sigmaK\r\nsigmaK gerE\r\nsigmaK GerE\r\nsigmaK sigmaK\r\ngerE GerE\r\ngerE sigmaK\r\nGerE sigmaK\r\nGerE cotD\r\nGerE sigmaK\r\nGerE GerE\r\nGerE cotD\r\ncotD sigmaK\r\ncotD GerE\r\ncotD cotD\r\nsigmaK GerE\r\nsigmaK cotD\r\nGerE cotD\r\n";</s:scriptvalue>
            <s:beanshellinputlist />
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">interaction_doc</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="Filter_protein2">
          <s:defaults>
            <s:default name="group">2</s:default>
          </s:defaults>
          <s:local>org.embl.ebi.escience.scuflworkers.java.RegularExpressionStringList</s:local>
        </s:processor>
        <s:processor name="Filter_protein1">
          <s:defaults>
            <s:default name="group">1</s:default>
          </s:defaults>
          <s:local>org.embl.ebi.escience.scuflworkers.java.RegularExpressionStringList</s:local>
        </s:processor>
        <s:processor name="split_interactionlist">
          <s:local>org.embl.ebi.escience.scuflworkers.java.SplitByRegex</s:local>
        </s:processor>
        <s:processor name="ConcatenateRelation">
          <s:defaults>
            <s:default name="interaction_term">unspecified relation</s:default>
          </s:defaults>
          <s:beanshell>
            <s:scriptvalue>relation = protein_name1 + " - " + interaction_term + " - " + protein_name2;
id_relation = uniprot_id1 + ", " + interaction_term + ", " + uniprot_id2;</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">protein_name1</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">protein_name2</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">interaction_term</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">uniprot_id1</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">uniprot_id2</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">relation</s:beanshelloutput>
              <s:beanshelloutput s:syntactictype="'text/plain'">id_relation</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
          <s:iterationstrategy>
            <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
              <i:iterator name="protein_name1" />
              <i:iterator name="protein_name2" />
              <i:iterator name="uniprot_id1" />
              <i:iterator name="uniprot_id2" />
            </i:dot>
          </s:iterationstrategy>
        </s:processor>
        <s:processor name="IOB_output_from_NER_example" boring="true">
          <s:stringconstant>We	O have	O identified	O a	O transcriptional	O repressor,	O Nrg1,	O in	O a	O genetic	O screen	O designed	O to	O reveal	O negative	O factors	O involved	O in	O the	O expression	O of	O STA1,	B-PROTEIN which	O encodes	O a	O glucoamylase.	O The	O NRG1	B-PROTEIN gene	I-PROTEIN encodes	O a	O 25-kDa	O C2H2	B-PROTEIN zinc	I-PROTEIN finger	I-PROTEIN protein	I-PROTEIN which	O specifically	O binds	O to	O two	O regions	O in	O the	O upstream	O activation	O sequence	O of	O the	O STA1	B-PROTEIN gene,	O as	O judged	O by	O gel	O retardation	O and	O DNase	B-PROTEIN I	I-PROTEIN footprinting	O analyses.	O Disruption	O of	O the	O NRG1	B-PROTEIN gene	I-PROTEIN causes	O a	O fivefold	O increase	O in	O the	O level	O of	O the	O STA1	B-PROTEIN transcript	O in	O the	O presence	O of	O glucose.	O</s:stringconstant>
        </s:processor>
        <s:processor name="split_interaction_regexp" boring="true">
          <s:stringconstant>(.+)\s+(.+)</s:stringconstant>
        </s:processor>
        <s:processor name="split_interactions_regexp" boring="true">
          <s:stringconstant>(\r\n)|(\n)</s:stringconstant>
        </s:processor>
        <s:processor name="FilterHumanProteinPairs">
          <s:description>This workflow filters protein_molecule-labeled term pairs from two input strings(list). The result is a pair of tagged lists of proteins. It uses a UniProt service by Martijn Schuemie (BioSemantics group Rotterdam) that know about human proteins.</s:description>
          <s:workflow retrydelay="10" retrybackoff="10.0">
            <s:scufl version="0.2" log="0">
              <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:df6063f9-b469-4d56-aecc-a62db4bcb3ad" author="Marco Roos (AID)" title="FilterHumanProteinsPairsByUniprot">This workflow filters protein_molecule-labeled terms from an input string(list). The result is a tagged list of proteins (disregarding false positives in the input).

Internal information:
This workflow is a copy of 'filter_protein_molecule_MR3' used for the NBIC poster (now in Archive).</s:workflowdescription>
              <s:processor name="Filter_uniprot1">
                <s:defaults>
                  <s:default name="regex">.+</s:default>
                </s:defaults>
                <s:local>org.embl.ebi.escience.scuflworkers.java.FilterStringList</s:local>
              </s:processor>
              <s:processor name="UniProtOrNot2">
                <s:beanshell>
                  <s:scriptvalue>if (uniprotIDlist.isEmpty() ) {
	uniprotID_or_False = "False";
} else {
	uniprotID_or_False = (String) uniprotIDlist.iterator().next().toString();
}</s:scriptvalue>
                  <s:beanshellinputlist>
                    <s:beanshellinput s:syntactictype="l('text/plain')">uniprotIDlist</s:beanshellinput>
                  </s:beanshellinputlist>
                  <s:beanshelloutputlist>
                    <s:beanshelloutput s:syntactictype="l('text/plain')">uniprotID_or_False</s:beanshelloutput>
                  </s:beanshelloutputlist>
                  <s:dependencies s:classloader="iteration" />
                </s:beanshell>
              </s:processor>
              <s:processor name="UniProtOrNot1">
                <s:beanshell>
                  <s:scriptvalue>if (uniprotIDlist.isEmpty() ) {
	uniprotID_or_False = "False";
} else {
	uniprotID_or_False = (String) uniprotIDlist.iterator().next().toString();
}</s:scriptvalue>
                  <s:beanshellinputlist>
                    <s:beanshellinput s:syntactictype="l('text/plain')">uniprotIDlist</s:beanshellinput>
                  </s:beanshellinputlist>
                  <s:beanshelloutputlist>
                    <s:beanshelloutput s:syntactictype="l('text/plain')">uniprotID_or_False</s:beanshelloutput>
                  </s:beanshelloutputlist>
                  <s:dependencies s:classloader="iteration" />
                </s:beanshell>
              </s:processor>
              <s:processor name="Filter_uniprot2">
                <s:local>org.embl.ebi.escience.scuflworkers.java.FilterStringList</s:local>
              </s:processor>
              <s:processor name="Filter_protein2">
                <s:local>org.embl.ebi.escience.scuflworkers.java.FilterStringList</s:local>
              </s:processor>
              <s:processor name="filter_regexp" boring="true">
                <s:stringconstant>.+</s:stringconstant>
              </s:processor>
              <s:processor name="Filter_protein1">
                <s:defaults>
                  <s:default name="regex">.+</s:default>
                </s:defaults>
                <s:local>org.embl.ebi.escience.scuflworkers.java.FilterStringList</s:local>
              </s:processor>
              <s:processor name="FilterTrueProteinPairsByUniProtID">
                <s:beanshell>
                  <s:scriptvalue>if (uniprot1 != "False" &amp;&amp; uniprot2 != "False") {
	true_protein1=protein1;
	true_uniprot1=uniprot1;
	true_protein2=protein2;
	true_uniprot2=uniprot2;
}</s:scriptvalue>
                  <s:beanshellinputlist>
                    <s:beanshellinput s:syntactictype="'text/plain'">protein1</s:beanshellinput>
                    <s:beanshellinput s:syntactictype="'text/plain'">uniprot1</s:beanshellinput>
                    <s:beanshellinput s:syntactictype="'text/plain'">protein2</s:beanshellinput>
                    <s:beanshellinput s:syntactictype="'text/plain'">uniprot2</s:beanshellinput>
                  </s:beanshellinputlist>
                  <s:beanshelloutputlist>
                    <s:beanshelloutput s:syntactictype="'text/plain'">true_protein1</s:beanshelloutput>
                    <s:beanshelloutput s:syntactictype="'text/plain'">true_uniprot1</s:beanshelloutput>
                    <s:beanshelloutput s:syntactictype="'text/plain'">true_protein2</s:beanshelloutput>
                    <s:beanshelloutput s:syntactictype="'text/plain'">true_uniprot2</s:beanshelloutput>
                  </s:beanshelloutputlist>
                  <s:dependencies s:classloader="iteration" />
                </s:beanshell>
                <s:iterationstrategy>
                  <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
                    <i:iterator name="protein1" />
                    <i:iterator name="uniprot1" />
                    <i:iterator name="protein2" />
                    <i:iterator name="uniprot2" />
                  </i:dot>
                </s:iterationstrategy>
              </s:processor>
              <s:processor name="getUniprotID1">
                <s:arbitrarywsdl retrydelay="1">
                  <s:wsdl>http://bubbles.biosemantics.org:8180/axis/services/SynsetServer/SynsetServer.jws?wsdl</s:wsdl>
                  <s:operation>getUniprotID</s:operation>
                </s:arbitrarywsdl>
              </s:processor>
              <s:processor name="getUniprotID2">
                <s:arbitrarywsdl>
                  <s:wsdl>http://bubbles.biosemantics.org:8180/axis/services/SynsetServer/SynsetServer.jws?wsdl</s:wsdl>
                  <s:operation>getUniprotID</s:operation>
                </s:arbitrarywsdl>
              </s:processor>
              <s:link source="candidate1" sink="getUniprotID1:term" />
              <s:link source="candidate2" sink="getUniprotID2:term" />
              <s:link source="UniProtOrNot1:uniprotID_or_False" sink="FilterTrueProteinPairsByUniProtID:uniprot1" />
              <s:link source="UniProtOrNot2:uniprotID_or_False" sink="FilterTrueProteinPairsByUniProtID:uniprot2" />
              <s:link source="candidate1" sink="FilterTrueProteinPairsByUniProtID:protein1" />
              <s:link source="candidate2" sink="FilterTrueProteinPairsByUniProtID:protein2" />
              <s:link source="FilterTrueProteinPairsByUniProtID:true_protein1" sink="Filter_protein1:stringlist" />
              <s:link source="FilterTrueProteinPairsByUniProtID:true_protein2" sink="Filter_protein2:stringlist" />
              <s:link source="FilterTrueProteinPairsByUniProtID:true_uniprot1" sink="Filter_uniprot1:stringlist" />
              <s:link source="FilterTrueProteinPairsByUniProtID:true_uniprot2" sink="Filter_uniprot2:stringlist" />
              <s:link source="Filter_protein2:filteredlist" sink="protein_molecule2" />
              <s:link source="Filter_uniprot2:filteredlist" sink="uniprotID2" />
              <s:link source="filter_regexp:value" sink="Filter_protein1:regex" />
              <s:link source="filter_regexp:value" sink="Filter_protein2:regex" />
              <s:link source="filter_regexp:value" sink="Filter_uniprot1:regex" />
              <s:link source="filter_regexp:value" sink="Filter_uniprot2:regex" />
              <s:link source="getUniprotID1:getUniprotIDReturn" sink="UniProtOrNot1:uniprotIDlist" />
              <s:link source="getUniprotID2:getUniprotIDReturn" sink="UniProtOrNot2:uniprotIDlist" />
              <s:link source="Filter_protein1:filteredlist" sink="protein_molecule1" />
              <s:link source="Filter_uniprot1:filteredlist" sink="uniprotID1" />
              <s:source name="candidate1" />
              <s:source name="candidate2" />
              <s:sink name="protein_molecule1" />
              <s:sink name="uniprotID1" />
              <s:sink name="protein_molecule2" />
              <s:sink name="uniprotID2" />
            </s:scufl>
          </s:workflow>
          <s:iterationstrategy>
            <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
              <i:iterator name="candidate1" />
              <i:iterator name="candidate2" />
            </i:dot>
          </s:iterationstrategy>
        </s:processor>
        <s:link source="FilterHumanProteinPairs:protein_molecule1" sink="FlattenProteinlist1:inputlist" />
        <s:link source="FilterHumanProteinPairs:protein_molecule2" sink="FlattenProteinlist2:inputlist" />
        <s:link source="FilterHumanProteinPairs:uniprotID1" sink="FlattenUniprotlist1:inputlist" />
        <s:link source="FilterHumanProteinPairs:uniprotID2" sink="FlattenUniProtlist2:inputlist" />
        <s:link source="Filter_protein1:filteredlist" sink="FilterHumanProteinPairs:candidate1" />
        <s:link source="Filter_protein2:filteredlist" sink="FilterHumanProteinPairs:candidate2" />
        <s:link source="FlattenProteinlist1:outputlist" sink="ConcatenateRelation:protein_name1" />
        <s:link source="FlattenProteinlist2:outputlist" sink="ConcatenateRelation:protein_name2" />
        <s:link source="FlattenUniProtlist2:outputlist" sink="ConcatenateRelation:uniprot_id2" />
        <s:link source="FlattenUniprotlist1:outputlist" sink="ConcatenateRelation:uniprot_id1" />
        <s:link source="ConcatenateRelation:id_relation" sink="relation_ids" />
        <s:link source="ConcatenateRelation:relation" sink="relation" />
        <s:link source="ConcatenateRelation:relation" sink="relation_term" />
        <s:link source="FlattenProteinlist1:outputlist" sink="protein1" />
        <s:link source="FlattenProteinlist2:outputlist" sink="protein2" />
        <s:link source="FlattenUniProtlist2:outputlist" sink="uniprot_id2" />
        <s:link source="FlattenUniprotlist1:outputlist" sink="uniprot_id1" />
        <s:link source="example_interaction_doc:interaction_doc" sink="split_interactionlist:string" />
        <s:link source="split_interaction_regexp:value" sink="Filter_protein1:regex" />
        <s:link source="split_interaction_regexp:value" sink="Filter_protein2:regex" />
        <s:link source="split_interactionlist:split" sink="Filter_protein1:stringlist" />
        <s:link source="split_interactionlist:split" sink="Filter_protein2:stringlist" />
        <s:link source="split_interactions_regexp:value" sink="split_interactionlist:regex" />
        <s:source name="input_text">
          <s:metadata>
            <s:mimeTypes>
              <s:mimeType>text/plain</s:mimeType>
            </s:mimeTypes>
            <s:description>Plain text to extract proteins from.
e.g.
We have identified a transcriptional repressor, Nrg1, in a genetic screen designed to reveal negative factors involved in the expression of STA1, which encodes a glucoamylase. The NRG1 gene encodes a 25-kDa C2H2 zinc finger protein which specifically binds to two regions in the upstream activation sequence of the STA1 gene, as judged by gel retardation and DNase I footprinting analyses. Disruption of the NRG1 gene causes a fivefold increase in the level of the STA1 transcript in the presence of glucose.</s:description>
          </s:metadata>
        </s:source>
        <s:sink name="protein1" />
        <s:sink name="protein2" />
        <s:sink name="uniprot_id1" />
        <s:sink name="uniprot_id2" />
        <s:sink name="relation" />
        <s:sink name="relation_ids" />
        <s:sink name="relation_term" />
      </s:scufl>
    </s:workflow>
  </s:processor>
  <s:processor name="05_ScoreExtractedProteins">
    <s:description>This workflow calculates a min log likelihood score for the combination of a discoverd protein and a protein of interest (the query protein). Note that at the moment the total count of medline papers, which is part of the formula, is hard coded and not exact. Given its size this should not matter that much, and certainly not in comparison with other likelihoods calculated using the same value.</s:description>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:abc3350b-e618-4fdd-8317-cbf5c298804d" author="Marco Roos (for AID)" title="LiteratureLikelihoodScoreProteinDiscovery">This workflow calculates a min log likelihood score for the combination of a discoverd protein and a protein of interest (the query protein). Note that at the moment the total count of medline papers, which is part of the formula, is hard coded and not exact. Given its size this should not matter that much, and certainly not in comparison with other likelihoods calculated using the same value.</s:workflowdescription>
        <s:processor name="Flatten_query_frequency_list">
          <s:local>
            org.embl.ebi.escience.scuflworkers.java.FlattenList
            <s:extensions>
              <s:flattenlist s:depth="2" />
            </s:extensions>
          </s:local>
        </s:processor>
        <s:processor name="Flatten_querydiscoveredfrequency">
          <s:local>
            org.embl.ebi.escience.scuflworkers.java.FlattenList
            <s:extensions>
              <s:flattenlist s:depth="2" />
            </s:extensions>
          </s:local>
        </s:processor>
        <s:processor name="Flatten_query_list">
          <s:local>
            org.embl.ebi.escience.scuflworkers.java.FlattenList
            <s:extensions>
              <s:flattenlist s:depth="2" />
            </s:extensions>
          </s:local>
        </s:processor>
        <s:processor name="Flatten_query_discovered_list">
          <s:local>
            org.embl.ebi.escience.scuflworkers.java.FlattenList
            <s:extensions>
              <s:flattenlist s:depth="2" />
            </s:extensions>
          </s:local>
        </s:processor>
        <s:processor name="Flatten_discovered_frequency_list">
          <s:local>
            org.embl.ebi.escience.scuflworkers.java.FlattenList
            <s:extensions>
              <s:flattenlist s:depth="2" />
            </s:extensions>
          </s:local>
        </s:processor>
        <s:processor name="Flatten_discovery_list">
          <s:local>
            org.embl.ebi.escience.scuflworkers.java.FlattenList
            <s:extensions>
              <s:flattenlist s:depth="2" />
            </s:extensions>
          </s:local>
        </s:processor>
        <s:processor name="Flatten_mll">
          <s:local>
            org.embl.ebi.escience.scuflworkers.java.FlattenList
            <s:extensions>
              <s:flattenlist s:depth="2" />
            </s:extensions>
          </s:local>
        </s:processor>
        <s:processor name="CountListElements">
          <s:beanshell>
            <s:scriptvalue>count = list.size();</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="l('text/xml')">list</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="l('text/plain')">count</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="CloneQueries">
          <s:beanshell>
            <s:scriptvalue>import java.util.*;

List newlist = new ArrayList();

for (int i=0; i&lt;((int) Integer.parseInt(copy_number.toString())); i++) {
	newlist.add(input);
}

clones=newlist;</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">copy_number</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">input</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">clones</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
          <s:iterationstrategy>
            <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
              <i:iterator name="input" />
              <i:iterator name="copy_number" />
            </i:dot>
          </s:iterationstrategy>
        </s:processor>
        <s:processor name="MinLogLikelihood">
          <s:beanshell>
            <s:scriptvalue>/*
Mijn voorstel is een -log likelihood ratio:
-log ( (#QD_expected / #N) / (#QD / #N) )
waarbij
#QD : het gevonden aantal documenten met het Query eiwit Q, en het discovered eiwit D
#QD_expected = (#Q*#D)/#N : het verwachte aantal documenten met Q en D, gebaseerd op de gevonden aantallen #Q en #D

Edgar: De maat die je beschrijft lijkt erg veel op PMI (point-wise mutual information), wellicht dat je daar wat aan hebt. 
*/

/* variables
	query_frequency (#Q)
	discovered_frequency (#D)
	query_discovered_frequency (#QD)
	total_frequency (#N)
return
	minloglikelihood
*/
import java.lang.Math;
// import edu.uah.math.distributions;

double q = (double) Integer.parseInt( query_frequency );
double d = (double) Integer.parseInt( discovered_frequency );
double qd = (double) Integer.parseInt( query_discovered_frequency );
double n = (double) Integer.parseInt( total_frequency );

double qd_expected = (double) ((q*d)/n);

Double mll = (Double) new Double((double) -( ((double) Math.log(qd_expected/n)) - ((double) Math.log(qd/n))));

minloglikelihood = mll.toString();

// minloglikelihood = (String) "test";</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">query_frequency</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">discovered_frequency</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">query_discovered_frequency</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">total_frequency</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">minloglikelihood</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
          <s:iterationstrategy>
            <i:cross xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
              <i:dot>
                <i:iterator name="discovered_frequency" />
                <i:iterator name="query_discovered_frequency" />
                <i:iterator name="query_frequency" />
              </i:dot>
              <i:iterator name="total_frequency" />
            </i:cross>
          </s:iterationstrategy>
        </s:processor>
        <s:processor name="PubMedTotal" boring="true">
          <s:stringconstant>17000000</s:stringconstant>
        </s:processor>
        <s:processor name="Ready" boring="true">
          <s:stringconstant>edit me!</s:stringconstant>
        </s:processor>
        <s:processor name="CloneFrequencies">
          <s:beanshell>
            <s:scriptvalue>import java.util.*;

List newlist = new ArrayList();

for (int i=0; i&lt;((int) Integer.parseInt(copy_number.toString())); i++) {
	newlist.add(input);
}

clones=newlist;</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">copy_number</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">input</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">clones</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
          <s:iterationstrategy>
            <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
              <i:iterator name="input" />
              <i:iterator name="copy_number" />
            </i:dot>
          </s:iterationstrategy>
        </s:processor>
        <s:processor name="QueryDiscoveredFrequency">
          <s:workflow>
            <s:scufl version="0.2" log="0">
              <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:abc3350b-e618-4fdd-8317-cbf5c298804d" author="" title="QueryFrequencyInCorpus" />
              <s:processor name="Flatten_list">
                <s:local>
                  org.embl.ebi.escience.scuflworkers.java.FlattenList
                  <s:extensions>
                    <s:flattenlist s:depth="2" />
                  </s:extensions>
                </s:local>
              </s:processor>
              <s:processor name="PoiAndDpQuery">
                <s:beanshell>
                  <s:scriptvalue>poi_and_dp_query = "(" + poi_query + ") AND (" + dp_query + ")";</s:scriptvalue>
                  <s:beanshellinputlist>
                    <s:beanshellinput s:syntactictype="'text/plain'">poi_query</s:beanshellinput>
                    <s:beanshellinput s:syntactictype="'text/plain'">dp_query</s:beanshellinput>
                  </s:beanshellinputlist>
                  <s:beanshelloutputlist>
                    <s:beanshelloutput s:syntactictype="'text/plain'">poi_and_dp_query</s:beanshelloutput>
                  </s:beanshelloutputlist>
                  <s:dependencies s:classloader="iteration" />
                </s:beanshell>
              </s:processor>
              <s:processor name="XPath_From_Text">
                <s:local>net.sourceforge.taverna.scuflworkers.xml.XPathTextWorker</s:local>
              </s:processor>
              <s:processor name="DocumentsIndex" boring="true">
                <s:stringconstant>MedLine</s:stringconstant>
              </s:processor>
              <s:processor name="ExtractCountXpath" boring="true">
                <s:stringconstant>./aid:result/@total</s:stringconstant>
              </s:processor>
              <s:processor name="AIDA_search">
                <s:defaults>
                  <s:default name="maxHits">1</s:default>
                  <s:default name="defaultField">content</s:default>
                </s:defaults>
                <s:arbitrarywsdl>
                  <s:wsdl>http://aida.science.uva.nl:8888/axis/services/SearcherWS?wsdl</s:wsdl>
                  <s:operation>search</s:operation>
                </s:arbitrarywsdl>
              </s:processor>
              <s:link source="AIDA_search:searchReturn" sink="XPath_From_Text:xml-text" />
              <s:link source="DocumentsIndex:value" sink="AIDA_search:index" />
              <s:link source="ExtractCountXpath:value" sink="XPath_From_Text:xpath" />
              <s:link source="XPath_From_Text:nodelist" sink="Flatten_list:inputlist" />
              <s:link source="discovered_protein" sink="PoiAndDpQuery:dp_query" />
              <s:link source="query" sink="PoiAndDpQuery:poi_query" />
              <s:link source="PoiAndDpQuery:poi_and_dp_query" sink="AIDA_search:queryString" />
              <s:link source="Flatten_list:outputlist" sink="poidp_count_in_corpus" />
              <s:link source="PoiAndDpQuery:poi_and_dp_query" sink="poi_and_dp_query" />
              <s:source name="query" />
              <s:source name="discovered_protein" />
              <s:sink name="poidp_count_in_corpus" />
              <s:sink name="poi_and_dp_query" />
            </s:scufl>
          </s:workflow>
          <s:iterationstrategy>
            <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
              <i:iterator name="discovered_protein" />
              <i:iterator name="query" />
            </i:dot>
          </s:iterationstrategy>
        </s:processor>
        <s:processor name="QueryFrequency">
          <s:workflow>
            <s:scufl version="0.2" log="0">
              <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:abc3350b-e618-4fdd-8317-cbf5c298804d" author="" title="QueryFrequencyInCorpus" />
              <s:processor name="Flatten_list">
                <s:local>
                  org.embl.ebi.escience.scuflworkers.java.FlattenList
                  <s:extensions>
                    <s:flattenlist s:depth="2" />
                  </s:extensions>
                </s:local>
              </s:processor>
              <s:processor name="XPath_From_Text">
                <s:local>net.sourceforge.taverna.scuflworkers.xml.XPathTextWorker</s:local>
              </s:processor>
              <s:processor name="RelativeFrequencyPoiInCorpus">
                <s:defaults>
                  <s:default name="corpus_total">17000000</s:default>
                </s:defaults>
                <s:beanshell>
                  <s:scriptvalue>/* variables
	poi_count_in_corpus
	corpus_total
return
	relative_frequency
*/
import java.lang.Math;

Double rf = new Double(-Math.log((double)(Integer.parseInt( poi_count_in_corpus ) ) / ((double) (Integer.parseInt( corpus_total )))));

relative_frequency = rf.toString();</s:scriptvalue>
                  <s:beanshellinputlist>
                    <s:beanshellinput s:syntactictype="'text/plain'">corpus_total</s:beanshellinput>
                    <s:beanshellinput s:syntactictype="'text/plain'">poi_count_in_corpus</s:beanshellinput>
                  </s:beanshellinputlist>
                  <s:beanshelloutputlist>
                    <s:beanshelloutput s:syntactictype="'text/plain'">relative_frequency</s:beanshelloutput>
                  </s:beanshelloutputlist>
                  <s:dependencies s:classloader="iteration" />
                </s:beanshell>
              </s:processor>
              <s:processor name="ExtractCountXpath" boring="true">
                <s:stringconstant>./aid:result/@total</s:stringconstant>
              </s:processor>
              <s:processor name="DocumentsIndex" boring="true">
                <s:stringconstant>MedLine</s:stringconstant>
              </s:processor>
              <s:processor name="AIDA_search">
                <s:defaults>
                  <s:default name="maxHits">1</s:default>
                  <s:default name="defaultField">content</s:default>
                </s:defaults>
                <s:arbitrarywsdl>
                  <s:wsdl>http://aida.science.uva.nl:8888/axis/services/SearcherWS?wsdl</s:wsdl>
                  <s:operation>search</s:operation>
                </s:arbitrarywsdl>
              </s:processor>
              <s:link source="AIDA_search:searchReturn" sink="XPath_From_Text:xml-text" />
              <s:link source="ExtractCountXpath:value" sink="XPath_From_Text:xpath" />
              <s:link source="Flatten_list:outputlist" sink="RelativeFrequencyPoiInCorpus:poi_count_in_corpus" />
              <s:link source="XPath_From_Text:nodelist" sink="Flatten_list:inputlist" />
              <s:link source="corpus_total_doc_count" sink="RelativeFrequencyPoiInCorpus:corpus_total" />
              <s:link source="DocumentsIndex:value" sink="AIDA_search:index" />
              <s:link source="query" sink="AIDA_search:queryString" />
              <s:link source="Flatten_list:outputlist" sink="poi_count_in_corpus" />
              <s:link source="RelativeFrequencyPoiInCorpus:relative_frequency" sink="min_log_relative_frequency_poi_in_corpus" />
              <s:link source="query" sink="poi_query" />
              <s:source name="query" />
              <s:source name="corpus_total_doc_count" />
              <s:sink name="poi_count_in_corpus" />
              <s:sink name="min_log_relative_frequency_poi_in_corpus" />
              <s:sink name="poi_query" />
            </s:scufl>
          </s:workflow>
        </s:processor>
        <s:processor name="DiscoveredFrequency">
          <s:workflow>
            <s:scufl version="0.2" log="0">
              <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:abc3350b-e618-4fdd-8317-cbf5c298804d" author="" title="QueryFrequencyInCorpus" />
              <s:processor name="Flatten_list">
                <s:local>
                  org.embl.ebi.escience.scuflworkers.java.FlattenList
                  <s:extensions>
                    <s:flattenlist s:depth="2" />
                  </s:extensions>
                </s:local>
              </s:processor>
              <s:processor name="RelativeFrequencyPoiInCorpus">
                <s:defaults>
                  <s:default name="corpus_total">17000000</s:default>
                </s:defaults>
                <s:beanshell>
                  <s:scriptvalue>/* variables
	poi_count_in_corpus
	corpus_total
return
	relative_frequency
*/
import java.lang.Math;

Double rf = new Double(-Math.log((double)(Integer.parseInt( poi_count_in_corpus ) ) / ((double) (Integer.parseInt( corpus_total )))));

relative_frequency = rf.toString();</s:scriptvalue>
                  <s:beanshellinputlist>
                    <s:beanshellinput s:syntactictype="'text/plain'">corpus_total</s:beanshellinput>
                    <s:beanshellinput s:syntactictype="'text/plain'">poi_count_in_corpus</s:beanshellinput>
                  </s:beanshellinputlist>
                  <s:beanshelloutputlist>
                    <s:beanshelloutput s:syntactictype="'text/plain'">relative_frequency</s:beanshelloutput>
                  </s:beanshelloutputlist>
                  <s:dependencies s:classloader="iteration" />
                </s:beanshell>
              </s:processor>
              <s:processor name="XPath_From_Text">
                <s:local>net.sourceforge.taverna.scuflworkers.xml.XPathTextWorker</s:local>
              </s:processor>
              <s:processor name="ExtractCountXpath" boring="true">
                <s:stringconstant>./aid:result/@total</s:stringconstant>
              </s:processor>
              <s:processor name="DocumentsIndex" boring="true">
                <s:stringconstant>MedLine</s:stringconstant>
              </s:processor>
              <s:processor name="AIDA_search">
                <s:defaults>
                  <s:default name="maxHits">1</s:default>
                  <s:default name="defaultField">content</s:default>
                </s:defaults>
                <s:arbitrarywsdl>
                  <s:wsdl>http://aida.science.uva.nl:8888/axis/services/SearcherWS?wsdl</s:wsdl>
                  <s:operation>search</s:operation>
                </s:arbitrarywsdl>
              </s:processor>
              <s:link source="AIDA_search:searchReturn" sink="XPath_From_Text:xml-text" />
              <s:link source="ExtractCountXpath:value" sink="XPath_From_Text:xpath" />
              <s:link source="Flatten_list:outputlist" sink="RelativeFrequencyPoiInCorpus:poi_count_in_corpus" />
              <s:link source="XPath_From_Text:nodelist" sink="Flatten_list:inputlist" />
              <s:link source="corpus_total_doc_count" sink="RelativeFrequencyPoiInCorpus:corpus_total" />
              <s:link source="DocumentsIndex:value" sink="AIDA_search:index" />
              <s:link source="query" sink="AIDA_search:queryString" />
              <s:link source="Flatten_list:outputlist" sink="poi_count_in_corpus" />
              <s:link source="RelativeFrequencyPoiInCorpus:relative_frequency" sink="min_log_relative_frequency_poi_in_corpus" />
              <s:link source="query" sink="poi_query" />
              <s:source name="query" />
              <s:source name="corpus_total_doc_count" />
              <s:sink name="poi_count_in_corpus" />
              <s:sink name="min_log_relative_frequency_poi_in_corpus" />
              <s:sink name="poi_query" />
            </s:scufl>
          </s:workflow>
        </s:processor>
        <s:link source="DiscoveredFrequency:poi_count_in_corpus" sink="Flatten_discovered_frequency_list:inputlist" />
        <s:link source="DiscoveredFrequency:poi_query" sink="Flatten_discovery_list:inputlist" />
        <s:link source="Flatten_discovered_frequency_list:outputlist" sink="MinLogLikelihood:discovered_frequency" />
        <s:link source="Flatten_discovery_list:outputlist" sink="QueryDiscoveredFrequency:discovered_protein" />
        <s:link source="Flatten_query_discovered_list:outputlist" sink="MinLogLikelihood:query_discovered_frequency" />
        <s:link source="PubMedTotal:value" sink="DiscoveredFrequency:corpus_total_doc_count" />
        <s:link source="PubMedTotal:value" sink="MinLogLikelihood:total_frequency" />
        <s:link source="PubMedTotal:value" sink="QueryFrequency:corpus_total_doc_count" />
        <s:link source="QueryDiscoveredFrequency:poidp_count_in_corpus" sink="Flatten_query_discovered_list:inputlist" />
        <s:link source="QueryFrequency:poi_count_in_corpus" sink="Flatten_query_frequency_list:inputlist" />
        <s:link source="discovered_protein" sink="CountListElements:list" />
        <s:link source="CloneFrequencies:clones" sink="MinLogLikelihood:query_frequency" />
        <s:link source="CountListElements:count" sink="CloneFrequencies:copy_number" />
        <s:link source="CountListElements:count" sink="CloneQueries:copy_number" />
        <s:link source="Flatten_query_discovered_list:outputlist" sink="Flatten_querydiscoveredfrequency:inputlist" />
        <s:link source="Flatten_query_frequency_list:outputlist" sink="CloneFrequencies:input" />
        <s:link source="Flatten_query_list:outputlist" sink="CloneQueries:input" />
        <s:link source="MinLogLikelihood:minloglikelihood" sink="Flatten_mll:inputlist" />
        <s:link source="QueryFrequency:poi_query" sink="Flatten_query_list:inputlist" />
        <s:link source="discovered_protein" sink="DiscoveredFrequency:query" />
        <s:link source="query" sink="QueryDiscoveredFrequency:query" />
        <s:link source="query" sink="QueryFrequency:query" />
        <s:link source="Flatten_discovered_frequency_list:outputlist" sink="discovered_frequency" />
        <s:link source="Flatten_mll:outputlist" sink="min_log_likelihood" />
        <s:link source="Flatten_query_frequency_list:outputlist" sink="query_frequency" />
        <s:link source="Flatten_querydiscoveredfrequency:outputlist" sink="query_discovered_frequency" />
        <s:source name="query">
          <s:metadata>
            <s:description>E.g. EZH2</s:description>
          </s:metadata>
        </s:source>
        <s:source name="discovered_protein">
          <s:metadata>
            <s:description>E.g. HDAC1</s:description>
          </s:metadata>
        </s:source>
        <s:sink name="query_frequency" />
        <s:sink name="discovered_frequency" />
        <s:sink name="min_log_likelihood">
          <s:metadata>
            <s:mimeTypes>
              <s:mimeType>text/plain</s:mimeType>
            </s:mimeTypes>
          </s:metadata>
        </s:sink>
        <s:sink name="query_discovered_frequency" />
        <s:coordination name="Ready_BLOCKON_MinLogLikelihood">
          <s:condition>
            <s:state>Completed</s:state>
            <s:target>MinLogLikelihood</s:target>
          </s:condition>
          <s:action>
            <s:target>Ready</s:target>
            <s:statechange>
              <s:from>Scheduled</s:from>
              <s:to>Running</s:to>
            </s:statechange>
          </s:action>
        </s:coordination>
      </s:scufl>
    </s:workflow>
  </s:processor>
  <s:processor name="01_ProcessQuery">
    <s:description>Workflow to optimize a Lucene document retrieval query to
1. increase the priority of recent years (in decreasing order from 2009 down to 2002)
2. limit a subsequent search to a specific organism using  a mesh organism tag</s:description>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:3d2eebb7-0b04-4979-9aa9-3d39b1464216" author="Marco Roos (workflow)" title="Lucene_bioquery_optimizer_with_synonyms">Workflow to optimize a Lucene document retrieval query to
1. increase the priority of recent years (in decreasing order from 2009 down to 2002)
2. replace protein names with protein synonym strings.
3. provide protein names and uniprot ids for bonifide human protein terms in the input query 

(see subworkflow for details)</s:workflowdescription>
        <s:processor name="Lucene_year_priorities" boring="true">
          <s:stringconstant>year:(2009^10 2008^9 2007^8 2007^7 2006^6 2005^5 2004^4 2003^3 2002^2 2002^1)</s:stringconstant>
        </s:processor>
        <s:processor name="Prioritise_lucene_query">
          <s:beanshell>
            <s:scriptvalue>StringBuffer temp=new StringBuffer();
temp.append("+(");
temp.append(query_string);
temp.append(") ");

/* comment if temporarily out of order: */
temp.append(" +");
temp.append(priority_string);

String lucene_query = temp.toString();</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="'text/plain'">query_string</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">priority_string</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">lucene_query</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
        </s:processor>
        <s:processor name="ProteinQueryToSynonyms">
          <s:description>This workflow creates a query string from the query term using Martijn Schuemie's synonym service. The service is limited to proteins, enzymes and genes. An input query that is a boolean string will be split and processed. Until I find a smarter regular expression only terms withing double quotes will be replaced by synonym strings.</s:description>
          <s:workflow>
            <s:scufl version="0.2" log="0">
              <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:ecb927cc-a200-4290-9342-302d5fc836ca" author="Marco Roos (workflow) and Martijn Schuemie (services)" title="ExpandQueryAndFilterProteinTerms">This workflow will try to expand an input query with human/rat/mouse protein synonyms using Martijn Schuemie's UniProt-based synonym service. The service is limited to proteins, enzymes and genes. Terms that are bonifide human/rat/mouse protein names are also produced.

Warning note:
Synonym expansion may add ambiguous terms to a query.

This workflow is a fork from ProteinSynonymsToQuery.xml.

Known issues:
* see the query string input metadata
* the Lucene-based tokenizer removes stop-words from multiword tokens, which likely renders the token unrecognizable for the synonym service. (E.g. 'Enhancer of Zeste', becomes "enhancer zeste".)
* replacement is iterative, so nested replacements (creating very long strings) may occur.</s:workflowdescription>
              <s:processor name="FlattenUniprotIDs">
                <s:local>
                  org.embl.ebi.escience.scuflworkers.java.FlattenList
                  <s:extensions>
                    <s:flattenlist s:depth="2" />
                  </s:extensions>
                </s:local>
              </s:processor>
              <s:processor name="FlattenNewQueries">
                <s:local>
                  org.embl.ebi.escience.scuflworkers.java.FlattenList
                  <s:extensions>
                    <s:flattenlist s:depth="2" />
                  </s:extensions>
                </s:local>
              </s:processor>
              <s:processor name="Flatten_SynonymList">
                <s:local>
                  org.embl.ebi.escience.scuflworkers.java.FlattenList
                  <s:extensions>
                    <s:flattenlist s:depth="2" />
                  </s:extensions>
                </s:local>
              </s:processor>
              <s:processor name="FlattenProteins">
                <s:local>
                  org.embl.ebi.escience.scuflworkers.java.FlattenList
                  <s:extensions>
                    <s:flattenlist s:depth="2" />
                  </s:extensions>
                </s:local>
              </s:processor>
              <s:processor name="Concat_synonyms">
                <s:beanshell>
                  <s:scriptvalue>import java.util.*;
String synstring=query_term;
String syn;
Iterator iterator = synonymlist.iterator();
while ( iterator.hasNext() ) 
	{
	synstring = synstring + " OR ";
	syn = ((String) iterator.next());
	synstring = synstring + "\"" + syn + "\"";
}
new_query = synstring;</s:scriptvalue>
                  <s:beanshellinputlist>
                    <s:beanshellinput s:syntactictype="l('text/plain')">synonymlist</s:beanshellinput>
                    <s:beanshellinput s:syntactictype="'text/plain'">query_term</s:beanshellinput>
                  </s:beanshellinputlist>
                  <s:beanshelloutputlist>
                    <s:beanshelloutput s:syntactictype="l('text/plain')">new_query</s:beanshelloutput>
                  </s:beanshelloutputlist>
                  <s:dependencies s:classloader="iteration" />
                </s:beanshell>
                <s:mergemode input="synonymlist" mode="merge" />
                <s:iterationstrategy>
                  <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
                    <i:iterator name="query_term" />
                    <i:iterator name="synonymlist" />
                  </i:dot>
                </s:iterationstrategy>
              </s:processor>
              <s:processor name="ListFindAndReplace">
                <s:beanshell>
                  <s:scriptvalue>// replace words in the input query by synonym strings plus the original
// input: the input query
// findstringlist: list of words to be replaced
// replacestringlist: list of synonym string to replace items in the findstringlist
// find and replaces string lists form pairs (should be of equal length)

import java.util.regex.*;

String tmp=(String) input;
String findstring;
Iterator find_iterator = findstringlist.iterator();
Iterator replace_iterator = replacestringlist.iterator();

while (find_iterator.hasNext() &amp;&amp; replace_iterator.hasNext())
{
	findstring = ((String) find_iterator.next().toString());
	replacestring = ((String) replace_iterator.next().toString());
	
	Pattern p = Pattern.compile("[\"]*"+findstring+"[\"]*"); 
//	Pattern p = Pattern.compile(findstring);
	Matcher m = p.matcher(tmp);

	tmp = (String) m.replaceAll("("+replacestring+")");
//	testlist.add((String) (tmp+", "+findstring+", "+replacestring));
}

output = tmp;</s:scriptvalue>
                  <s:beanshellinputlist>
                    <s:beanshellinput s:syntactictype="'text/plain'">input</s:beanshellinput>
                    <s:beanshellinput s:syntactictype="l('text/plain')">findstringlist</s:beanshellinput>
                    <s:beanshellinput s:syntactictype="l('text/plain')">replacestringlist</s:beanshellinput>
                  </s:beanshellinputlist>
                  <s:beanshelloutputlist>
                    <s:beanshelloutput s:syntactictype="'text/plain'">output</s:beanshelloutput>
                  </s:beanshelloutputlist>
                  <s:dependencies s:classloader="iteration" />
                </s:beanshell>
                <s:mergemode input="input" mode="merge" />
                <s:iterationstrategy>
                  <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
                    <i:iterator name="input" />
                    <i:dot>
                      <i:iterator name="replacestringlist" />
                      <i:iterator name="findstringlist" />
                    </i:dot>
                  </i:dot>
                </s:iterationstrategy>
              </s:processor>
              <s:processor name="getSynsets">
                <s:arbitrarywsdl>
                  <s:wsdl>http://bubbles.biosemantics.org:8180/axis/services/SynsetServer/SynsetServer.jws?wsdl</s:wsdl>
                  <s:operation>getSynsets</s:operation>
                </s:arbitrarywsdl>
              </s:processor>
              <s:processor name="SplitQuery">
                <s:description>Splits and input query string into its parts. Works for queries that contain search terms, search phrases between double quotes, connected by AND or OR. Behaviour undetermined when other characters such as +, -, or brackets are used. Should work now for well formed patterns with bracketed substrings separated by AND/OR/AND NOT/OR NOT, e.g. (Topic1) AND NOT (Topic2), but not extensively tested.</s:description>
                <s:workflow>
                  <s:scufl version="0.2" log="0">
                    <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:f1d2b701-3cc3-49a9-8cab-dfc3f1e6f5a6" author="Marco Roos (workflow), Edgar Meij (service)" title="Lucene query tokenizer plus">Extracts query terms or phrases from a (Lucene) boolean query.

Known issues:
The Lucene tokenizer is used. This has some side-effects. The conversion of single word terms to lower case is reversed in this workflow, but the drop of stop words in multi-term tokens is not (e.g. 'Enhancer of Zeste' will become 'enhancer zeste').</s:workflowdescription>
                    <s:processor name="Filter_AlphaNumeric">
                      <s:defaults>
                        <s:default name="group">1</s:default>
                      </s:defaults>
                      <s:local>org.embl.ebi.escience.scuflworkers.java.RegularExpressionStringList</s:local>
                    </s:processor>
                    <s:processor name="Remove_duplicate_strings">
                      <s:local>org.embl.ebi.escience.scuflworkers.java.StringStripDuplicates</s:local>
                    </s:processor>
                    <s:processor name="Filter_regexp" boring="true">
                      <s:stringconstant>\W*([\w\s]+)\W*</s:stringconstant>
                    </s:processor>
                    <s:processor name="ReplaceLuceneTokenByOriginalTerm">
                      <s:beanshell>
                        <s:scriptvalue>/*
If Lucene tokenizer is not changed to keep the case intact, this beanshell will replace its results with the original from the query.
In:
	tokenlist (from lucene tokenizer)
	query_string
Out:
	output_list
*/

import java.util.regex.*;

List tmplist = new ArrayList();
Pattern p;
Matcher m;

for (String lucene_term: tokenlist) {
	p = Pattern.compile("(\\\"*"+lucene_term+"\\\"*)", Pattern.CASE_INSENSITIVE);
	m = p.matcher(query_string);
	
	if(m.find()) {	
		do {
			tmplist.add((String) m.group(1));
		} while (m.find());
	} else {
		tmplist.add((String) lucene_term);
	}
}

output_list = tmplist;</s:scriptvalue>
                        <s:beanshellinputlist>
                          <s:beanshellinput s:syntactictype="'text/plain'">query_string</s:beanshellinput>
                          <s:beanshellinput s:syntactictype="l('text/plain')">tokenlist</s:beanshellinput>
                        </s:beanshellinputlist>
                        <s:beanshelloutputlist>
                          <s:beanshelloutput s:syntactictype="l('text/plain')">output_list</s:beanshelloutput>
                        </s:beanshelloutputlist>
                        <s:dependencies s:classloader="iteration" />
                      </s:beanshell>
                      <s:iterationstrategy>
                        <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
                          <i:iterator name="query_string" />
                          <i:iterator name="tokenlist" />
                        </i:dot>
                      </s:iterationstrategy>
                    </s:processor>
                    <s:processor name="queryToArray">
                      <s:description>Use this method to tokenize a Lucene Query into terms.</s:description>
                      <s:arbitrarywsdl>
                        <s:wsdl>http://aida.science.uva.nl:9999/axis/services/tokenize?wsdl</s:wsdl>
                        <s:operation>queryToArray</s:operation>
                      </s:arbitrarywsdl>
                    </s:processor>
                    <s:link source="Filter_regexp:value" sink="Filter_AlphaNumeric:regex" />
                    <s:link source="queryString" sink="ReplaceLuceneTokenByOriginalTerm:query_string" />
                    <s:link source="queryString" sink="queryToArray:in" />
                    <s:link source="Filter_AlphaNumeric:filteredlist" sink="Remove_duplicate_strings:stringlist" />
                    <s:link source="Remove_duplicate_strings:strippedlist" sink="ReplaceLuceneTokenByOriginalTerm:tokenlist" />
                    <s:link source="ReplaceLuceneTokenByOriginalTerm:output_list" sink="queryList" />
                    <s:link source="queryToArray:queryToArrayReturn" sink="Filter_AlphaNumeric:stringlist" />
                    <s:source name="queryString">
                      <s:metadata>
                        <s:description>Queries that contain search terms, search phrases between double quotes, possibly connected by AND or OR. Behaviour undetermined when other characters such as +, -, or brackets are used.

E.g.
EZH2 +(HDAC1 AND SMC1) OR "Enhancer of Zeste Drosophila Homologue 2" AND ('P53' or 'ftsQ')</s:description>
                      </s:metadata>
                    </s:source>
                    <s:sink name="queryList" />
                  </s:scufl>
                </s:workflow>
              </s:processor>
              <s:processor name="FilterProteins">
                <s:description>This workflow filters protein_molecule-labeled terms from an input string(list). The result is a tagged list of proteins (disregarding false positives in the input).

Internal information:
This workflow is a copy of 'filter_protein_molecule_MR3' used for the NBIC poster (now in Archive).</s:description>
                <s:workflow>
                  <s:scufl version="0.2" log="0">
                    <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:df6063f9-b469-4d56-aecc-a62db4bcb3ad" author="Marco Roos (AID)" title="FilterHumanProteinsByUniprot">This workflow filters protein_molecule-labeled terms from an input string(list). The result is a tagged list of proteins (disregarding false positives in the input).

Internal information:
This workflow is a copy of 'filter_protein_molecule_MR3' used for the NBIC poster (now in Archive).</s:workflowdescription>
                    <s:processor name="Filter2">
                      <s:defaults>
                        <s:default name="regex">.+</s:default>
                      </s:defaults>
                      <s:local>org.embl.ebi.escience.scuflworkers.java.FilterStringList</s:local>
                    </s:processor>
                    <s:processor name="UniProtOrNot">
                      <s:beanshell>
                        <s:scriptvalue>if (uniprotIDlist.isEmpty()) {
	uniprotID_or_False = "False";
} else {
	uniprotID_or_False = (String) uniprotIDlist.iterator().next().toString();
}</s:scriptvalue>
                        <s:beanshellinputlist>
                          <s:beanshellinput s:syntactictype="l('text/plain')">uniprotIDlist</s:beanshellinput>
                        </s:beanshellinputlist>
                        <s:beanshelloutputlist>
                          <s:beanshelloutput s:syntactictype="l('text/plain')">uniprotID_or_False</s:beanshelloutput>
                        </s:beanshelloutputlist>
                        <s:dependencies s:classloader="iteration" />
                      </s:beanshell>
                    </s:processor>
                    <s:processor name="Filter1">
                      <s:defaults>
                        <s:default name="regex">.+</s:default>
                      </s:defaults>
                      <s:local>org.embl.ebi.escience.scuflworkers.java.FilterStringList</s:local>
                    </s:processor>
                    <s:processor name="FilterTrueProteinByUniProtID">
                      <s:beanshell>
                        <s:scriptvalue>if (uniprot!="False") {
	true_protein=protein;
	true_uniprot=uniprot;
}</s:scriptvalue>
                        <s:beanshellinputlist>
                          <s:beanshellinput s:syntactictype="'text/plain'">protein</s:beanshellinput>
                          <s:beanshellinput s:syntactictype="'text/plain'">uniprot</s:beanshellinput>
                        </s:beanshellinputlist>
                        <s:beanshelloutputlist>
                          <s:beanshelloutput s:syntactictype="'text/plain'">true_protein</s:beanshelloutput>
                          <s:beanshelloutput s:syntactictype="'text/plain'">true_uniprot</s:beanshelloutput>
                        </s:beanshelloutputlist>
                        <s:dependencies s:classloader="iteration" />
                      </s:beanshell>
                      <s:iterationstrategy>
                        <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
                          <i:iterator name="uniprot" />
                          <i:iterator name="protein" />
                        </i:dot>
                      </s:iterationstrategy>
                    </s:processor>
                    <s:processor name="getUniprotID">
                      <s:arbitrarywsdl retrydelay="1">
                        <s:wsdl>http://bubbles.biosemantics.org:8180/axis/services/SynsetServer/SynsetServer.jws?wsdl</s:wsdl>
                        <s:operation>getUniprotID</s:operation>
                      </s:arbitrarywsdl>
                    </s:processor>
                    <s:link source="FilterTrueProteinByUniProtID:true_protein" sink="Filter2:stringlist" />
                    <s:link source="FilterTrueProteinByUniProtID:true_uniprot" sink="Filter1:stringlist" />
                    <s:link source="UniProtOrNot:uniprotID_or_False" sink="FilterTrueProteinByUniProtID:uniprot" />
                    <s:link source="getUniprotID:getUniprotIDReturn" sink="UniProtOrNot:uniprotIDlist" />
                    <s:link source="input_string" sink="FilterTrueProteinByUniProtID:protein" />
                    <s:link source="input_string" sink="getUniprotID:term" />
                    <s:link source="Filter1:filteredlist" sink="uniprotID" />
                    <s:link source="Filter2:filteredlist" sink="protein_molecule" />
                    <s:source name="input_string" />
                    <s:sink name="protein_molecule" />
                    <s:sink name="uniprotID" />
                  </s:scufl>
                </s:workflow>
              </s:processor>
              <s:link source="Concat_synonyms:new_query" sink="ListFindAndReplace:replacestringlist" />
              <s:link source="FilterProteins:protein_molecule" sink="FlattenProteins:inputlist" />
              <s:link source="FilterProteins:uniprotID" sink="FlattenUniprotIDs:inputlist" />
              <s:link source="FlattenNewQueries:outputlist" sink="new_query" />
              <s:link source="FlattenProteins:outputlist" sink="protein_name" />
              <s:link source="FlattenUniprotIDs:outputlist" sink="uniprotID" />
              <s:link source="Flatten_SynonymList:outputlist" sink="Concat_synonyms:synonymlist" />
              <s:link source="ListFindAndReplace:output" sink="FlattenNewQueries:inputlist" />
              <s:link source="SplitQuery:queryList" sink="Concat_synonyms:query_term" />
              <s:link source="SplitQuery:queryList" sink="FilterProteins:input_string" />
              <s:link source="SplitQuery:queryList" sink="ListFindAndReplace:findstringlist" />
              <s:link source="query_string" sink="ListFindAndReplace:input" />
              <s:link source="query_string" sink="SplitQuery:queryString" />
              <s:link source="SplitQuery:queryList" sink="getSynsets:term" />
              <s:link source="getSynsets:getSynsetsReturn" sink="Flatten_SynonymList:inputlist" />
              <s:source name="query_string">
                <s:metadata>
                  <s:description>(Boolean) query. Protein/gene/enzyme names registered as human, rat, or mouse protein at UniProt will be replaced by a string of synonyms including the original name. Other types of names are left as they are. 

Example inputs:
"EZH2"
"Enhancer of Zeste" AND "HDAC1" AND "chromatin"
EZH2 +(HDAC1 AND SMC1) OR "Enhancer of Zeste Drosophila Homologue 2" AND ('P53' or 'ftsQ')

Known issues:
* It is assumed that each item in the query is a separate biological term, including synonyms that the BioSemantics synonym/uniprot service knows about will lead to unnecessary redundancy in the new query.</s:description>
                </s:metadata>
              </s:source>
              <s:sink name="new_query" />
              <s:sink name="protein_name" />
              <s:sink name="uniprotID" />
            </s:scufl>
          </s:workflow>
        </s:processor>
        <s:link source="Lucene_year_priorities:value" sink="Prioritise_lucene_query:priority_string" />
        <s:link source="query_string" sink="ProteinQueryToSynonyms:query_string" />
        <s:link source="Prioritise_lucene_query:lucene_query" sink="extended_lucene_query" />
        <s:link source="ProteinQueryToSynonyms:new_query" sink="Prioritise_lucene_query:query_string" />
        <s:link source="ProteinQueryToSynonyms:protein_name" sink="protein_name" />
        <s:link source="ProteinQueryToSynonyms:uniprotID" sink="UniProtID" />
        <s:source name="query_string">
          <s:metadata>
            <s:description>Lucene query string</s:description>
          </s:metadata>
        </s:source>
        <s:sink name="extended_lucene_query">
          <s:metadata>
            <s:description>Lucene query based on the input query with the addition of:
1. A Lucene string to give recent years higher priority (in decreasing order from 2009 down to 2002)
2. A mesh organism term to limit subsequent searches</s:description>
          </s:metadata>
        </s:sink>
        <s:sink name="protein_name" />
        <s:sink name="UniProtID" />
      </s:scufl>
    </s:workflow>
  </s:processor>
  <s:processor name="03_ExtractProteins_HomoSapiens">
    <s:description>Workflow to extract proteins from text, followed by filtering protein names known as human protein names.</s:description>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:c0a963bc-2343-4d31-aa8c-304bfe3a6289" author="Marco Roos (workflow), Martijn Schuemie (service)" title="ExtractProteinsFromText_HomoSapiens">Workflow to extract proteins from text, followed by filtering protein names known as human protein names.</s:workflowdescription>
        <s:processor name="FlattenUniProtID">
          <s:local>
            org.embl.ebi.escience.scuflworkers.java.FlattenList
            <s:extensions>
              <s:flattenlist s:depth="2" />
            </s:extensions>
          </s:local>
        </s:processor>
        <s:processor name="FlattenProteinName">
          <s:local>
            org.embl.ebi.escience.scuflworkers.java.FlattenList
            <s:extensions>
              <s:flattenlist s:depth="2" />
            </s:extensions>
          </s:local>
        </s:processor>
        <s:processor name="FilterHumanProteins">
          <s:description>This workflow filters protein_molecule-labeled terms from an input string(list). The result is a tagged list of proteins (disregarding false positives in the input).

Internal information:
This workflow is a copy of 'filter_protein_molecule_MR3' used for the NBIC poster (now in Archive).</s:description>
          <s:workflow retrydelay="10" retrybackoff="10.0">
            <s:scufl version="0.2" log="0">
              <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:df6063f9-b469-4d56-aecc-a62db4bcb3ad" author="Marco Roos (AID)" title="FilterHumanProteinsByUniprot">This workflow filters protein_molecule-labeled terms from an input string(list). The result is a tagged list of proteins (disregarding false positives in the input).

Internal information:
This workflow is a copy of 'filter_protein_molecule_MR3' used for the NBIC poster (now in Archive).</s:workflowdescription>
              <s:processor name="UniProtOrNot">
                <s:beanshell>
                  <s:scriptvalue>if (uniprotIDlist.isEmpty()) {
	uniprotID_or_False = "False";
} else {
	uniprotID_or_False = (String) uniprotIDlist.iterator().next().toString();
}</s:scriptvalue>
                  <s:beanshellinputlist>
                    <s:beanshellinput s:syntactictype="l('text/plain')">uniprotIDlist</s:beanshellinput>
                  </s:beanshellinputlist>
                  <s:beanshelloutputlist>
                    <s:beanshelloutput s:syntactictype="l('text/plain')">uniprotID_or_False</s:beanshelloutput>
                  </s:beanshelloutputlist>
                  <s:dependencies s:classloader="iteration" />
                </s:beanshell>
              </s:processor>
              <s:processor name="Filter1">
                <s:defaults>
                  <s:default name="regex">.+</s:default>
                </s:defaults>
                <s:local>org.embl.ebi.escience.scuflworkers.java.FilterStringList</s:local>
              </s:processor>
              <s:processor name="Filter2">
                <s:defaults>
                  <s:default name="regex">.+</s:default>
                </s:defaults>
                <s:local>org.embl.ebi.escience.scuflworkers.java.FilterStringList</s:local>
              </s:processor>
              <s:processor name="FilterTrueProteinByUniProtID">
                <s:beanshell>
                  <s:scriptvalue>if (uniprot!="False") {
	true_protein=protein;
	true_uniprot=uniprot;
}</s:scriptvalue>
                  <s:beanshellinputlist>
                    <s:beanshellinput s:syntactictype="'text/plain'">protein</s:beanshellinput>
                    <s:beanshellinput s:syntactictype="'text/plain'">uniprot</s:beanshellinput>
                  </s:beanshellinputlist>
                  <s:beanshelloutputlist>
                    <s:beanshelloutput s:syntactictype="'text/plain'">true_protein</s:beanshelloutput>
                    <s:beanshelloutput s:syntactictype="'text/plain'">true_uniprot</s:beanshelloutput>
                  </s:beanshelloutputlist>
                  <s:dependencies s:classloader="iteration" />
                </s:beanshell>
                <s:iterationstrategy>
                  <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
                    <i:iterator name="uniprot" />
                    <i:iterator name="protein" />
                  </i:dot>
                </s:iterationstrategy>
              </s:processor>
              <s:processor name="getUniprotID">
                <s:arbitrarywsdl retrydelay="1">
                  <s:wsdl>http://bubbles.biosemantics.org:8180/axis/services/SynsetServer/SynsetServer.jws?wsdl</s:wsdl>
                  <s:operation>getUniprotID</s:operation>
                </s:arbitrarywsdl>
              </s:processor>
              <s:link source="FilterTrueProteinByUniProtID:true_protein" sink="Filter2:stringlist" />
              <s:link source="FilterTrueProteinByUniProtID:true_uniprot" sink="Filter1:stringlist" />
              <s:link source="UniProtOrNot:uniprotID_or_False" sink="FilterTrueProteinByUniProtID:uniprot" />
              <s:link source="getUniprotID:getUniprotIDReturn" sink="UniProtOrNot:uniprotIDlist" />
              <s:link source="input_string" sink="FilterTrueProteinByUniProtID:protein" />
              <s:link source="input_string" sink="getUniprotID:term" />
              <s:link source="Filter1:filteredlist" sink="uniprotID" />
              <s:link source="Filter2:filteredlist" sink="protein_molecule" />
              <s:source name="input_string" />
              <s:sink name="protein_molecule" />
              <s:sink name="uniprotID" />
            </s:scufl>
          </s:workflow>
        </s:processor>
        <s:processor name="ExtractProteinsFromText">
          <s:description>Workflow to extract proteins from text

Two methods are combined:
Named entity recognition using LingPipe (NERecognize)
Named entity recognition using Conditional Random Fields (applyCRF)
Both are based on machine learning methods.

Default inputs:
Model: 1 = BioCreative I
OutputMode: 1 = IOB format; 2 = SGML format; 3 = a list of entities; 4 = ABNER format
Tokenization: 1 = activate tokenization (makes no difference in practice)
testFile is expected to be a piece of text (string)</s:description>
          <s:workflow>
            <s:scufl version="0.2" log="0">
              <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:ec3e8ad0-b45b-4dbb-b5a9-da5e273d82c1" author="Marco Roos (workflow) and Sophia Katrenko (service)" title="ProteinExtractionFromText">Workflow to extract proteins from text

Two methods are combined:
Named entity recognition using LingPipe (NERecognize)
Named entity recognition using Conditional Random Fields (applyCRF)
Both are based on machine learning methods.

Default inputs:
Model: 1 = BioCreative I
OutputMode: 1 = IOB format; 2 = SGML format; 3 = a list of entities; 4 = ABNER format
Tokenization: 1 = activate tokenization (makes no difference in practice)
testFile is expected to be a piece of text (string)</s:workflowdescription>
              <s:processor name="FilterProteinsByRegexp1">
                <s:defaults>
                  <s:default name="group">1</s:default>
                </s:defaults>
                <s:local>org.embl.ebi.escience.scuflworkers.java.RegularExpressionStringList</s:local>
              </s:processor>
              <s:processor name="FilterProteinsByRegexp2">
                <s:defaults>
                  <s:default name="group">1</s:default>
                </s:defaults>
                <s:local>org.embl.ebi.escience.scuflworkers.java.RegularExpressionStringList</s:local>
              </s:processor>
              <s:processor name="FilterProteins">
                <s:defaults>
                  <s:default name="group">1</s:default>
                </s:defaults>
                <s:local>org.embl.ebi.escience.scuflworkers.java.RegularExpressionStringList</s:local>
              </s:processor>
              <s:processor name="Remove_duplicate_strings">
                <s:local>org.embl.ebi.escience.scuflworkers.java.StringStripDuplicates</s:local>
              </s:processor>
              <s:processor name="SplitProteinsList">
                <s:local>org.embl.ebi.escience.scuflworkers.java.SplitByRegex</s:local>
              </s:processor>
              <s:processor name="String_list_union3">
                <s:local>org.embl.ebi.escience.scuflworkers.java.StringSetUnion</s:local>
              </s:processor>
              <s:processor name="String_list_union2">
                <s:local>org.embl.ebi.escience.scuflworkers.java.StringSetUnion</s:local>
              </s:processor>
              <s:processor name="String_list_union1">
                <s:local>org.embl.ebi.escience.scuflworkers.java.StringSetUnion</s:local>
              </s:processor>
              <s:processor name="SplitStringByRegexp">
                <s:local>org.embl.ebi.escience.scuflworkers.java.SplitByRegex</s:local>
              </s:processor>
              <s:processor name="split_regexp" boring="true">
                <s:stringconstant>\n</s:stringconstant>
              </s:processor>
              <s:processor name="FilterProteinsFromIOBformat2" boring="true">
                <s:stringconstant>(.+)[,.]	B-PROTEIN</s:stringconstant>
              </s:processor>
              <s:processor name="FilterProteinsFromListFormat" boring="true">
                <s:stringconstant>PROTEIN	\[(.+)\]</s:stringconstant>
              </s:processor>
              <s:processor name="FilterProteinsFromIOBformat1" boring="true">
                <s:stringconstant>(.+[^,.])	B-PROTEIN</s:stringconstant>
              </s:processor>
              <s:processor name="applyCRF2">
                <s:defaults>
                  <s:default name="modelFile">1</s:default>
                  <s:default name="outputMode">3</s:default>
                  <s:default name="tokenization">1</s:default>
                </s:defaults>
                <s:arbitrarywsdl>
                  <s:wsdl>http://aida.science.uva.nl:8888/axis/services/CRFapply?wsdl</s:wsdl>
                  <s:operation>apply</s:operation>
                </s:arbitrarywsdl>
              </s:processor>
              <s:processor name="applyCRF1">
                <s:defaults>
                  <s:default name="modelFile">1</s:default>
                  <s:default name="outputMode">1</s:default>
                  <s:default name="tokenization">1</s:default>
                </s:defaults>
                <s:arbitrarywsdl>
                  <s:wsdl>http://aida.science.uva.nl:8888/axis/services/CRFapply?wsdl</s:wsdl>
                  <s:operation>apply</s:operation>
                </s:arbitrarywsdl>
              </s:processor>
              <s:processor name="NER1_ExtractProteins">
                <s:description>This workflow applies the discovery workflow built around the AIDA 'Named Entity Recognize' web service by Sophia Katrenko. It uses the pre-learned genomics model, named 'MedLine', to find genomics concepts in a set of documents in lucene output format.</s:description>
                <s:workflow>
                  <s:scufl version="0.2" log="0">
                    <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:b4c1a118-6a38-40b5-99e9-febbd3c85f2b" author="Marco Roos (AID)" title="Discover_proteins_from_plain_text">This workflow applies the discovery workflow built around the AIDA 'Named Entity Recognize' web service by Sophia Katrenko. It uses the pre-learned genomics model, named 'MedLine', to find genomics concepts in a set of documents in lucene output format.</s:workflowdescription>
                    <s:processor name="prelearned_genomics_model" boring="true">
                      <s:stringconstant>MedLine</s:stringconstant>
                    </s:processor>
                    <s:processor name="Discover_entities">
                      <s:description>This workflow contains the 'Named Entity Recognize' web service from the AIDA toolbox, created by Sophia Katrenko. It can be used to discover entities of a certain type (determined by 'learned_model') in documents provided in a lucene output format.</s:description>
                      <s:workflow>
                        <s:scufl version="0.2" log="0">
                          <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:e7ae8f2a-428f-4afd-93eb-52ccb89273e1" author="Marco Roos (AID)" title="Discover_entities">This workflow contains the 'Named Entity Recognize' web service from the AIDA toolbox, created by Sophia Katrenko. It can be used to discover entities of a certain type (determined by 'learned_model') in documents provided in a lucene output format.

Known issues:
The output of NErecognize contains concepts with / characters, breaking the xml. For post-processing its results it is better to use string manipulation than xml manipulations.
The output is per document, which means entities will  be redundant if they occur in more than one document.</s:workflowdescription>
                          <s:processor name="Default_input_type" boring="true">
                            <s:stringconstant>text</s:stringconstant>
                          </s:processor>
                          <s:processor name="Default_output_type" boring="true">
                            <s:stringconstant>NElist</s:stringconstant>
                          </s:processor>
                          <s:processor name="NErecognize">
                            <s:arbitrarywsdl>
                              <s:wsdl>http://ws.adaptivedisclosure.org/axis/services/NERecognizerService?wsdl</s:wsdl>
                              <s:operation>NErecognize</s:operation>
                            </s:arbitrarywsdl>
                          </s:processor>
                          <s:link source="input_text" sink="NErecognize:input_data" />
                          <s:link source="learned_model" sink="NErecognize:r_type" />
                          <s:link source="Default_input_type:value" sink="NErecognize:input_type" />
                          <s:link source="Default_output_type:value" sink="NErecognize:output_type" />
                          <s:link source="NErecognize:NErecognizeReturn" sink="discovered_entities" />
                          <s:source name="input_text">
                            <s:metadata>
                              <s:description>Example:
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;aid:result xmlns:aid="http://aid.vle.org" query="+content:ezh2 +(year:2007^10.0 year:2006^9.0 year:2005^8.0 year:2004^7.0 year:2004^6.0 year:2003^5.0 year:2002^4.0 year:2001^3.0 year:2000^2.0 year:1999)" total="78" time="2"&gt;
  &lt;doc rank="1" score="0.55880820751190185546875"&gt;
    &lt;field name="PMID"&gt;
      &lt;value&gt;15208672&lt;/value&gt;
    &lt;/field&gt;
    &lt;field name="year"&gt;
      &lt;value&gt;2004&lt;/value&gt;
    &lt;/field&gt;
    &lt;field name="PT"&gt;
      &lt;value&gt;Journal Article&lt;/value&gt;
    &lt;/field&gt;
    &lt;field name="title"&gt;
      &lt;value&gt;Activated p53 suppresses the histone methyltransferase EZH2 gene.&lt;/value&gt;
    &lt;/field&gt;
    &lt;field name="content"&gt;
      &lt;value&gt;... Furthermore, the repression of EZH2 promoter by p53 is dependent on p53 transcriptional target p21(Waf1) inactivating RB/E2F pathways. In addition, the knockdown of EZH2 expression retards cell proliferation and induces G2/M arrest. We suggest that the p53-dependent suppression of EZH2 expression is a novel pathway that contributes to p53-mediated G2/M arrest. EZH2 associated complex possesses HMTase activity and is involved in epigenetic regulation. Activated p53 suppresses EZH2 expression, suggesting a further role for p53 in epigenetic regulation and in the maintenance of genetic stability. Suppression of EZH2 expression in tumors by p53 may lead to novel approaches to control cancer progression.&lt;/value&gt;
    &lt;/field&gt;
    &lt;field name="LuceneDocID"&gt;
      &lt;value&gt;14861224&lt;/value&gt;
    &lt;/field&gt;
  &lt;/doc&gt;
&lt;/aid:result&gt;</s:description>
                            </s:metadata>
                          </s:source>
                          <s:source name="learned_model">
                            <s:metadata>
                              <s:description>Model to discover a set of specific concepts; e.g. the prelearned model named 'MedLine' will make the service discover genomics concepts.</s:description>
                            </s:metadata>
                          </s:source>
                          <s:sink name="discovered_entities">
                            <s:metadata>
                              <s:mimeTypes>
                                <s:mimeType>text/rdf</s:mimeType>
                                <s:mimeType>text/xml</s:mimeType>
                              </s:mimeTypes>
                              <s:description>Entities discoverd in documents provided in lucene output format.</s:description>
                            </s:metadata>
                          </s:sink>
                        </s:scufl>
                      </s:workflow>
                    </s:processor>
                    <s:processor name="Extract_proteins">
                      <s:description>This workflow filters protein_molecule-labeled terms from an input string(list). The result is a tagged list of proteins (disregarding false positives in the input).

Internal information:
This workflow is a copy of 'filter_protein_molecule_MR3' used for the NBIC poster (now in Archive).</s:description>
                      <s:workflow>
                        <s:scufl version="0.2" log="0">
                          <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:df6063f9-b469-4d56-aecc-a62db4bcb3ad" author="Marco Roos (AID)" title="Extract_proteins_fromXML">This workflow filters protein_molecule-labeled terms from an input string(list). The result is a tagged list of proteins (disregarding false positives in the input).

Internal information:
This workflow is a copy of 'filter_protein_molecule_MR3' used for the NBIC poster (now in Archive).</s:workflowdescription>
                          <s:processor name="Strip_xml">
                            <s:beanshell>
                              <s:scriptvalue>import java.util.regex.*;
Pattern pattern = Pattern.compile("&lt;/?[\\w\\d-]+&gt;");
Matcher matcher = pattern.matcher(tagged_term);
String term= matcher.replaceAll("");</s:scriptvalue>
                              <s:beanshellinputlist>
                                <s:beanshellinput s:syntactictype="'text/xml'">tagged_term</s:beanshellinput>
                              </s:beanshellinputlist>
                              <s:beanshelloutputlist>
                                <s:beanshelloutput s:syntactictype="'text/plain'">term</s:beanshelloutput>
                              </s:beanshelloutputlist>
                              <s:dependencies s:classloader="iteration" />
                            </s:beanshell>
                          </s:processor>
                          <s:processor name="Filter_protein_molecules">
                            <s:local>org.embl.ebi.escience.scuflworkers.java.FilterStringList</s:local>
                          </s:processor>
                          <s:processor name="SplitOn_protein_molecule">
                            <s:local>org.embl.ebi.escience.scuflworkers.java.SplitByRegex</s:local>
                          </s:processor>
                          <s:processor name="filter_protein_molecule_regexp" boring="true">
                            <s:stringconstant>&lt;protein_molecule&gt;\w*&lt;/protein_molecule&gt;</s:stringconstant>
                          </s:processor>
                          <s:processor name="splitOn_protein_molecule_regexp" boring="true">
                            <s:stringconstant>(?=&lt;protein_molecule&gt;)|(?&lt;=&lt;/protein_molecule&gt;)</s:stringconstant>
                          </s:processor>
                          <s:processor name="Remove_duplicate_strings">
                            <s:local>org.embl.ebi.escience.scuflworkers.java.StringStripDuplicates</s:local>
                          </s:processor>
                          <s:link source="input_string" sink="SplitOn_protein_molecule:string" />
                          <s:link source="Filter_protein_molecules:filteredlist" sink="Remove_duplicate_strings:stringlist" />
                          <s:link source="Remove_duplicate_strings:strippedlist" sink="Strip_xml:tagged_term" />
                          <s:link source="SplitOn_protein_molecule:split" sink="Filter_protein_molecules:stringlist" />
                          <s:link source="filter_protein_molecule_regexp:value" sink="Filter_protein_molecules:regex" />
                          <s:link source="splitOn_protein_molecule_regexp:value" sink="SplitOn_protein_molecule:regex" />
                          <s:link source="Strip_xml:term" sink="protein_molecule" />
                          <s:source name="input_string" />
                          <s:sink name="protein_molecule" />
                        </s:scufl>
                      </s:workflow>
                    </s:processor>
                    <s:link source="Discover_entities:discovered_entities" sink="Extract_proteins:input_string" />
                    <s:link source="prelearned_genomics_model:value" sink="Discover_entities:learned_model" />
                    <s:link source="text_document" sink="Discover_entities:input_text" />
                    <s:link source="Extract_proteins:protein_molecule" sink="discovered_proteins" />
                    <s:source name="text_document">
                      <s:metadata>
                        <s:description>Example:
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;aid:result xmlns:aid="http://aid.vle.org" query="+content:ezh2 +(year:2007^10.0 year:2006^9.0 year:2005^8.0 year:2004^7.0 year:2004^6.0 year:2003^5.0 year:2002^4.0 year:2001^3.0 year:2000^2.0 year:1999)" total="78" time="2"&gt;
  &lt;doc rank="1" score="0.55880820751190185546875"&gt;
    &lt;field name="PMID"&gt;
      &lt;value&gt;15208672&lt;/value&gt;
    &lt;/field&gt;
    &lt;field name="year"&gt;
      &lt;value&gt;2004&lt;/value&gt;
    &lt;/field&gt;
    &lt;field name="PT"&gt;
      &lt;value&gt;Journal Article&lt;/value&gt;
    &lt;/field&gt;
    &lt;field name="title"&gt;
      &lt;value&gt;Activated p53 suppresses the histone methyltransferase EZH2 gene.&lt;/value&gt;
    &lt;/field&gt;
    &lt;field name="content"&gt;
      &lt;value&gt;... Furthermore, the repression of EZH2 promoter by p53 is dependent on p53 transcriptional target p21(Waf1) inactivating RB/E2F pathways. In addition, the knockdown of EZH2 expression retards cell proliferation and induces G2/M arrest. We suggest that the p53-dependent suppression of EZH2 expression is a novel pathway that contributes to p53-mediated G2/M arrest. EZH2 associated complex possesses HMTase activity and is involved in epigenetic regulation. Activated p53 suppresses EZH2 expression, suggesting a further role for p53 in epigenetic regulation and in the maintenance of genetic stability. Suppression of EZH2 expression in tumors by p53 may lead to novel approaches to control cancer progression.&lt;/value&gt;
    &lt;/field&gt;
    &lt;field name="LuceneDocID"&gt;
      &lt;value&gt;14861224&lt;/value&gt;
    &lt;/field&gt;
  &lt;/doc&gt;
&lt;/aid:result&gt;</s:description>
                      </s:metadata>
                    </s:source>
                    <s:sink name="discovered_proteins">
                      <s:metadata>
                        <s:mimeTypes>
                          <s:mimeType>text/rdf</s:mimeType>
                          <s:mimeType>text/xml</s:mimeType>
                        </s:mimeTypes>
                      </s:metadata>
                    </s:sink>
                  </s:scufl>
                </s:workflow>
              </s:processor>
              <s:link source="input_text" sink="applyCRF1:testFile" />
              <s:link source="FilterProteins:filteredlist" sink="String_list_union2:list2" />
              <s:link source="FilterProteinsByRegexp1:filteredlist" sink="String_list_union1:list1" />
              <s:link source="FilterProteinsByRegexp2:filteredlist" sink="String_list_union1:list2" />
              <s:link source="FilterProteinsFromIOBformat1:value" sink="FilterProteinsByRegexp1:regex" />
              <s:link source="FilterProteinsFromIOBformat2:value" sink="FilterProteinsByRegexp2:regex" />
              <s:link source="FilterProteinsFromListFormat:value" sink="FilterProteins:regex" />
              <s:link source="SplitProteinsList:split" sink="FilterProteins:stringlist" />
              <s:link source="SplitStringByRegexp:split" sink="FilterProteinsByRegexp1:stringlist" />
              <s:link source="SplitStringByRegexp:split" sink="FilterProteinsByRegexp2:stringlist" />
              <s:link source="String_list_union1:union" sink="String_list_union2:list1" />
              <s:link source="applyCRF1:applyReturn" sink="SplitStringByRegexp:string" />
              <s:link source="input_text" sink="applyCRF2:testFile" />
              <s:link source="applyCRF2:applyReturn" sink="SplitProteinsList:string" />
              <s:link source="input_text" sink="NER1_ExtractProteins:text_document" />
              <s:link source="NER1_ExtractProteins:discovered_proteins" sink="String_list_union3:list2" />
              <s:link source="String_list_union2:union" sink="String_list_union3:list1" />
              <s:link source="String_list_union3:union" sink="Remove_duplicate_strings:stringlist" />
              <s:link source="split_regexp:value" sink="SplitProteinsList:regex" />
              <s:link source="split_regexp:value" sink="SplitStringByRegexp:regex" />
              <s:link source="Remove_duplicate_strings:strippedlist" sink="extracted_protein" />
              <s:source name="input_text">
                <s:metadata>
                  <s:description>Example:
We have identified a transcriptional repressor, Nrg1, in a genetic screen designed to reveal negative factors involved in the expression of STA1, which encodes a glucoamylase. The NRG1 gene encodes a 25-kDa C2H2 zinc finger protein which specifically binds to two regions in the upstream activation sequence of the STA1 gene, as judged by gel retardation and DNase I footprinting analyses. Disruption of the NRG1 gene causes a fivefold increase in the level of the STA1 transcript in the presence of glucose.</s:description>
                </s:metadata>
              </s:source>
              <s:sink name="extracted_protein" />
              <s:coordination name="apply1_BLOCKON_apply">
                <s:condition>
                  <s:state>Completed</s:state>
                  <s:target>applyCRF1</s:target>
                </s:condition>
                <s:action>
                  <s:target>applyCRF2</s:target>
                  <s:statechange>
                    <s:from>Scheduled</s:from>
                    <s:to>Running</s:to>
                  </s:statechange>
                </s:action>
              </s:coordination>
            </s:scufl>
          </s:workflow>
        </s:processor>
        <s:link source="input_text" sink="ExtractProteinsFromText:input_text" />
        <s:link source="ExtractProteinsFromText:extracted_protein" sink="FilterHumanProteins:input_string" />
        <s:link source="FilterHumanProteins:protein_molecule" sink="FlattenProteinName:inputlist" />
        <s:link source="FilterHumanProteins:uniprotID" sink="FlattenUniProtID:inputlist" />
        <s:link source="FlattenProteinName:outputlist" sink="protein_name" />
        <s:link source="FlattenUniProtID:outputlist" sink="uniprotID" />
        <s:source name="input_text">
          <s:metadata>
            <s:description>Plain text to extract proteins from.
e.g.
We have identified a transcriptional repressor, Nrg1, in a genetic screen designed to reveal negative factors involved in the expression of STA1, which encodes a glucoamylase. The NRG1 gene encodes a 25-kDa C2H2 zinc finger protein which specifically binds to two regions in the upstream activation sequence of the STA1 gene, as judged by gel retardation and DNase I footprinting analyses. Disruption of the NRG1 gene causes a fivefold increase in the level of the STA1 transcript in the presence of glucose.</s:description>
          </s:metadata>
        </s:source>
        <s:sink name="uniprotID">
          <s:metadata>
            <s:mimeTypes>
              <s:mimeType>text/plain</s:mimeType>
            </s:mimeTypes>
          </s:metadata>
        </s:sink>
        <s:sink name="protein_name">
          <s:metadata>
            <s:mimeTypes>
              <s:mimeType>text/plain</s:mimeType>
            </s:mimeTypes>
          </s:metadata>
        </s:sink>
      </s:scufl>
    </s:workflow>
  </s:processor>
  <s:link source="aida_magic_word" sink="s00_InitializeSemanticStorage:aida_magic_word" />
  <s:link source="max_document_nr" sink="02_RetrieveDocumentsFromMedline:maxHits" />
  <s:link source="query" sink="01_ProcessQuery:query_string" />
  <s:link source="01_ProcessQuery:extended_lucene_query" sink="02_RetrieveDocumentsFromMedline:queryString" />
  <s:link source="01_ProcessQuery:extended_lucene_query" sink="05_ScoreExtractedProteins:query" />
  <s:link source="01_ProcessQuery:extended_lucene_query" sink="s03_AddExpandedQueryToSemanticModel:query" />
  <s:link source="01_ProcessQuery:extended_lucene_query" sink="s03_AddExpandedQueryToSemanticModel_Obsolete:expanded_query" />
  <s:link source="02_RetrieveDocumentsFromMedline:abstract" sink="03_ExtractProteins_HomoSapiens:input_text" />
  <s:link source="02_RetrieveDocumentsFromMedline:abstract" sink="04_ExtractProteinRelations_HomoSapiens:input_text" />
  <s:link source="02_RetrieveDocumentsFromMedline:pubmed_URL" sink="s04_AddDocToSemanticModel:pubmed_URL" />
  <s:link source="02_RetrieveDocumentsFromMedline:pubmed_id" sink="s04_AddDocToSemanticModel:pubmed_id" />
  <s:link source="03_ExtractProteins_HomoSapiens:protein_name" sink="05_ScoreExtractedProteins:discovered_protein" />
  <s:link source="03_ExtractProteins_HomoSapiens:protein_name" sink="s05_AddProteinToSemanticModel:protein_name" />
  <s:link source="03_ExtractProteins_HomoSapiens:uniprotID" sink="06_UniProtXrefURLs:UniProtID" />
  <s:link source="03_ExtractProteins_HomoSapiens:uniprotID" sink="s05_AddProteinToSemanticModel:uniprot_id" />
  <s:link source="04_ExtractProteinRelations_HomoSapiens:relation_term" sink="s06_AddProteinRelationToSemanticModel:interaction_term" />
  <s:link source="04_ExtractProteinRelations_HomoSapiens:uniprot_id1" sink="s06_AddProteinRelationToSemanticModel:uniprot_id1" />
  <s:link source="04_ExtractProteinRelations_HomoSapiens:uniprot_id2" sink="s06_AddProteinRelationToSemanticModel:uniprot_id2" />
  <s:link source="05_ScoreExtractedProteins:min_log_likelihood" sink="s07_AddScoreToSemanticModel:score" />
  <s:link source="05_ScoreExtractedProteins:min_log_likelihood" sink="s07_AddScoreToSemanticModel:score" />
  <s:link source="06_UniProtXrefURLs:EntrezUniProtURL" sink="s05_AddProteinToSemanticModel:entrez_pubmed_URL" />
  <s:link source="06_UniProtXrefURLs:ExpasyUniProtURL" sink="s05_AddProteinToSemanticModel:expasy_URL" />
  <s:link source="06_UniProtXrefURLs:iHopSearchURL" sink="s05_AddProteinToSemanticModel:iHop_search_URL" />
  <s:link source="06_UniProtXrefURLs:iHopSentencesURL" sink="s05_AddProteinToSemanticModel:iHop_sentence_URL" />
  <s:link source="Timestamp:now_ISO8601" sink="s03_AddExpandedQueryToSemanticModel:datetime" />
  <s:link source="Timestamp:now_ISO8601" sink="s04_AddDocToSemanticModel:datetime" />
  <s:link source="Timestamp:now_ISO8601" sink="s05_AddProteinToSemanticModel:datetime" />
  <s:link source="false:value" sink="s00_InitializeSemanticStorage:do_not_add_to_repository" />
  <s:link source="false:value" sink="s00_InitializeSemanticStorage:do_not_clear_repository" />
  <s:link source="false:value" sink="s00_InitializeSemanticStorage:do_not_clear_tmp_rdf_file" />
  <s:link source="query" sink="s01_AddBiologicalModelToSemanticModel:BioModelComment" />
  <s:link source="query" sink="s01_AddBiologicalModelToSemanticModel:ModelIdentifyingName" />
  <s:link source="query" sink="s02_AddOriginalQueryToSemanticModel:query" />
  <s:link source="Timestamp:now_ISO8601" sink="s02_AddOriginalQueryToSemanticModel:datetime" />
  <s:link source="s00_InitializeSemanticStorage:BioAIDinstances_ontology_url" sink="s03_AddExpandedQueryToSemanticModel:InstanceOntologyURL" />
  <s:link source="s00_InitializeSemanticStorage:BioAIDinstances_ontology_url" sink="s05_AddProteinToSemanticModel:instance_ontology_url" />
  <s:link source="s00_InitializeSemanticStorage:RDFoutput_doc_url" sink="s01_AddBiologicalModelToSemanticModel:RDF_doc_filename" />
  <s:link source="s00_InitializeSemanticStorage:RDFoutput_doc_url" sink="s03_AddExpandedQueryToSemanticModel:RDF_doc_filename" />
  <s:link source="s00_InitializeSemanticStorage:RDFoutput_doc_url" sink="s05_AddProteinToSemanticModel:tmp_rdf_output_fileref" />
  <s:link source="s01_AddBiologicalModelToSemanticModel:biomodel_instance_uri" sink="s02_AddOriginalQueryToSemanticModel:model_instance_uri" />
  <s:link source="s01_AddBiologicalModelToSemanticModel:biomodel_instance_uri" sink="s03_AddExpandedQueryToSemanticModel:model_instance_uri" />
  <s:link source="s01_AddBiologicalModelToSemanticModel:biomodel_instance_uri" sink="s05_AddProteinToSemanticModel:model_instance_uri" />
  <s:link source="s02_AddOriginalQueryToSemanticModel:query_instance" sink="s03_AddExpandedQueryToSemanticModel:original_query_instance_uri" />
  <s:link source="s04_AddDocToSemanticModel:doc_instance_uri" sink="s05_AddProteinToSemanticModel:doc_instance_uri" />
  <s:link source="s05_AddProteinToSemanticModel:protein_instance" sink="s07_AddScoreToSemanticModel:protein_instance" />
  <s:link source="02_RetrieveDocumentsFromMedline:pubmed_URL" sink="PubMed_URL" />
  <s:link source="04_ExtractProteinRelations_HomoSapiens:protein1" sink="s06_AddProteinRelationToSemanticModel:protein_name1" />
  <s:link source="04_ExtractProteinRelations_HomoSapiens:protein2" sink="s06_AddProteinRelationToSemanticModel:protein_name2" />
  <s:link source="03_ExtractProteins_HomoSapiens:protein_name" sink="Protein_name" />
  <s:link source="04_ExtractProteinRelations_HomoSapiens:relation" sink="Relation" />
  <s:link source="05_ScoreExtractedProteins:min_log_likelihood" sink="protein_discovery_score" />
  <s:link source="06_UniProtXrefURLs:EntrezUniProtURL" sink="ProteinURL" />
  <s:link source="s02_AddOriginalQueryToSemanticModel:query_instance" sink="s03_AddExpandedQueryToSemanticModel_Obsolete:original_query_instance_uri" />
  <s:link source="s00_InitializeSemanticStorage:BioAID_Repository_url" sink="BioAID_RDFrepository_URL" />
  <s:link source="s00_InitializeSemanticStorage:BioAIDinstances_ontology_url" sink="s01_AddBiologicalModelToSemanticModel:InstanceOntologyURL" />
  <s:link source="s00_InitializeSemanticStorage:BioAIDinstances_ontology_url" sink="s02_AddOriginalQueryToSemanticModel:InstanceOntologyURL" />
  <s:link source="s00_InitializeSemanticStorage:BioAIDinstances_ontology_url" sink="s03_AddExpandedQueryToSemanticModel_Obsolete:InstanceOntologyURL" />
  <s:link source="s00_InitializeSemanticStorage:BioAIDinstances_ontology_url" sink="s04_AddDocToSemanticModel:instance_ontology_url" />
  <s:link source="s00_InitializeSemanticStorage:RDFoutput_doc_url" sink="s02_AddOriginalQueryToSemanticModel:RDF_doc_filename" />
  <s:link source="s00_InitializeSemanticStorage:RDFoutput_doc_url" sink="s03_AddExpandedQueryToSemanticModel_Obsolete:RDF_doc_filename" />
  <s:link source="s00_InitializeSemanticStorage:RDFoutput_doc_url" sink="s04_AddDocToSemanticModel:rdf_output_doc_url" />
  <s:link source="s00_InitializeSemanticStorage:TextMining_ontology_url" sink="s03_AddExpandedQueryToSemanticModel_Obsolete:TextMiningOntologyURL" />
  <s:link source="s03_AddExpandedQueryToSemanticModel_Obsolete:QueryRDFdoc_url" sink="RDFtriples_doc_url" />
  <s:source name="query">
    <s:metadata>
      <s:description>Biological query, e.g. a protein of interest. See Lucene documentation for advanced queries (http://lucene.apache.org/)

Synonyms for protein names will be searched and added for terms within double quotes.</s:description>
    </s:metadata>
  </s:source>
  <s:source name="max_document_nr">
    <s:metadata>
      <s:description>limits the maximum number of hits search will produce. In Taverna 1 '100' works well while a 1000 and above is likely to halt Taverna 1 due to memory problems. This also depends on the memory setting for the java virtual machine by the client (usually your local Taverna).</s:description>
    </s:metadata>
  </s:source>
  <s:source name="aida_magic_word">
    <s:metadata>
      <s:description>A magic word is required to make use of the AIDA semantic repository for BioAID workflows. Please ask Scott Marshall (marshall@science.uva.nl) or Marco Roos (M.Roos1@uva.nl) for the magic word. NB: this semantic repository is for temporary data only. You should expect the repository to be cleared often and without warning.</s:description>
    </s:metadata>
  </s:source>
  <s:sink name="ProteinURL" />
  <s:sink name="PubMed_URL" />
  <s:sink name="protein_discovery_score" />
  <s:sink name="Protein_name" />
  <s:sink name="Relation" />
  <s:sink name="RDFtriples_doc_url" />
  <s:sink name="BioAID_RDFrepository_URL" />
</s:scufl>

